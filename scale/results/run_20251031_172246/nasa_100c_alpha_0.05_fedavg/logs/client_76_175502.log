[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58a241cf-c025-4dbd-ac40-0eb7a79adb5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b0e41f-cc55-4087-9bdd-f6aa53c5c2d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 279e8d93-c61e-477d-ba77-2ca1b36d1883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef986fd7-0270-4121-8075-91044e1bdcbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2f3381b-5741-4a23-aabd-480bb36a0a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a992592d-cc7b-4964-b621-d69857fd184c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa0c64f5-9f97-4f3c-bc0f-e8c05f79a5bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a23fb9af-4b83-4aad-bf61-3af4604e712b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1352fa80-7604-48bf-adba-7f80c33d8cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 058404d6-f54f-4ec1-88d0-f25224094302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7003b29-8634-4083-b4c6-54ef0dadad00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d70c6d-2dc0-4a0f-a292-6f085f1031de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87b9eb34-e4da-432c-b4cb-dcac616216c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3c06fb-ecdf-42e8-8b58-261ba101cd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2438b0-0f4c-409d-8985-297fcee30665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7f5eca3-7527-40fa-95f3-775c1563d2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 281b41ef-52f9-4f99-8687-3dbc1fd49d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982afcca-017e-48e7-a3ae-6faca0632214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ad0581-1465-4860-a936-f4ce38a602b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c30f0e77-5736-4d18-9469-a7e4190e1cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc60f1a7-911c-44d0-bb77-700661287ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49ecf7b6-ef24-45a0-8d59-ff5e58f143b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51158081-b41b-4c5a-a50f-fbb01f81af35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5722dbbe-5b75-44fa-baa9-b8647f7a80e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 124b3f60-6416-4120-924f-57550b293c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbfd068c-9d7c-4a24-90bd-2fa619e7ae58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6754ea3-41f2-4335-9bf0-c044c775c87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd19f405-38c6-422e-852f-47a3783b0a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2d6ffbb-13e1-4ae5-9058-2e60b4f32e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784851aa-a5b5-4f00-b693-849061777029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d590f13d-2158-405b-8b8c-2bae495d8713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862bcc71-1b01-4765-a0f2-adf4f9c6d50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceade2a8-4562-40fd-bf79-75cca80e8649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa7f47f-8c52-4881-8afa-3d89d57b5794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b127cb3-75ca-44d1-8a62-5a269787bc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28799dbc-ba2c-4ace-9669-3ca97a461ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e45b62-2cdb-4edd-ad7b-5fb527ac5f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83eecaf3-198b-45bd-b2d3-a5dc13ec55d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fdfd78d-e86b-496c-b1ea-43315eef9294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c5478aa-b522-41ec-b84c-93c4ed072135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de87ac1-def6-4e18-88cf-dfe181906359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message facd9c28-c367-4db5-b548-cdcd09b66620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb6daba-d70c-47b0-9f9a-03b520d39dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2087fd-658f-4d3e-81ba-984407a4b88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dbd567e-d044-4581-9c12-cc1f52e72acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe4ab883-a621-4043-9c24-5e500f259ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da9bfe39-3706-48d2-8dff-843109ab47dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48fa2c6-b390-4deb-9c03-4603be23b05a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c5c5e37-a3a7-49b4-9490-be1a11cd3d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a47faf-5043-4f49-9086-f6b09105d888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ba73d1-b7c0-481d-9f28-408d9d562211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc05da75-cbd5-4517-90bb-9871ad9b26e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b1df23b-2162-41d9-b091-c4a8c7644519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3735f753-e799-419b-8950-a9f3199d0654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec512780-77d2-43da-9741-2ef1f9b67b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c0bfe1-038f-4d56-943a-c27a75c01926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 684d8aba-9a02-4cd7-b66d-3bab846a0c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90b17b1-790d-4ac5-991d-92f895d3d48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a39a72-8eef-4404-8106-a292596443d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d58d667-3eb0-4b40-9cc2-2d2e74249f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6133f76e-936c-43dc-892b-5417ce7b6f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb680a2-b75b-4e95-9016-dcebc3c44a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e15eae-1bdb-4d7c-abcb-2067af352d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edcaad53-52e9-4d23-8721-4350ec2097ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a5644a-6ba2-4723-a2fa-862b7ac3f634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a613a68-7cb7-4719-a0e3-1e8142f608a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6789fafe-45af-44cf-a001-58c12a7dd0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79a08639-32df-4213-8ab0-41535cd5c167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f6065d6-d6c4-4161-918a-6d97c85cb97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33d7be31-ea35-45c8-95ac-e14841883ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf25df92-d2e8-4f5a-a97e-2104f0306b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60fe352-1d09-4692-be14-5a15c6803037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c317119-8f4b-48f9-ab5e-6109cb7ba0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef0dec2-df07-4918-9607-dfcf9609256b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f969f5-ccf9-41e6-9eda-d9d1ac07eff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b2f1f0e-151d-4a85-be2a-c50023342d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2e07ae7-b0b6-4e3b-8ce5-c31b229045b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a826e1c4-4bbf-4a4f-a160-d85fb674d3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e40e279-efc4-4a33-9bb0-0db0a88a427d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7666054-b34b-41e0-aee0-681624bb038c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43af86a-f347-4d1a-b2e2-9288f7756c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee74b9b-6a78-478b-b98e-9a2fbcfc5bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e116152-1819-47fc-b622-b6f98f41874e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b11c7851-8386-47c3-a2c6-baeae2991acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e4d4cc-59fa-4ee2-a269-22fe9ed33080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8969909-20fa-4e48-b1f8-67988189e28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20385c66-4e99-4f0e-9c72-ba728d451606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc556813-69a2-420b-bdce-51bb69c1708b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de24735e-59ab-40e1-8f53-67022d21c439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee34e8b-5017-40a9-a39a-d50dfcf4647b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33319d3-b1c9-4b3d-89c1-9ad87ec65b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0023ed39-7c76-4564-ab4f-91c145ebb4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b7fa138-3de9-4adb-a66a-8995330107dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b479a58-9db8-4a1d-bfdb-0ff3b7275e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a9af1c9-4d9e-4d72-a4c3-4cd32343c284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11460f3e-e8ee-4e1f-ad06-24a215de176b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b01b6d7d-2a4a-49a2-8715-e051c0929ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14646084-11ec-44c4-940f-5b3eeda0a541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774ead87-bb24-4ef1-ac5c-4d81414bc583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc35aee-c1a3-412b-a923-2245195be154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77c5cd23-750a-4e34-96ba-099c9ed3fa7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f8af90-7565-4578-879e-b2bc67e05af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d56888c-9652-4e51-88ac-31d76b8c45f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c45ee5-82a2-43c5-a242-b08d9ef30f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e763dd2-f470-4c38-8618-66d86f59f7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f57e25fc-7135-4ea6-8301-8dd0a2306c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c31ee5d-a942-4a72-9964-af125eafd15c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d9b37e7-a170-45fb-bfa1-d2b5801664b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9fc418c-81d5-43e0-a478-5c3b89e2a127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d354302-3e01-4148-a50a-14e6be71071a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b879c214-7905-411c-9f49-54130daa3467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ad8dc2-626a-4c39-8319-c73f0323b7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa6cba0-3568-4345-8a2a-60ca9f743fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6df32f3c-2f98-46c1-9c48-6871c245526c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c5b5fe-6f8f-46e8-9d16-61cc168674dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62bdb710-a545-4df5-a778-4f8425268427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd23ae8c-a5fe-4485-bcf6-f4936a4ee6e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5e98f88-4c7a-4b46-af40-4e5fdcc8bcac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66660578-4759-4421-bc5b-4b5f41a5e262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 792ee9d5-e5d4-4186-996e-90c8d599489f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa3d071-bf22-41d0-93b0-325191d08f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ed21f1-5fb8-4991-8236-d096acf2a071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bf58f2-e437-4870-a68b-cfa0a20e09db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dada96ce-bff5-42ec-b79f-e15cd7bef6de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4614585-8405-42b1-b2e0-a867517aa469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b101965d-0345-4d16-9563-31155915b862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7ceaba-2ebb-497e-add9-30c952a6ec53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 240037e7-766d-4d6d-b98b-04360f25c2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ebcd47c-2705-431c-8f14-34cb3bef77e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91cae6b5-50b9-4ef6-bdb1-b038a20efe9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07173fd-2fb0-4ef9-b25c-9b72a75103b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2672a6a-b497-4585-83bd-b516aa0fc5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480d7cd3-2173-4ed1-94f6-fe105a9c1938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6ef3978-6a9e-4b97-96e5-cd113f7b216d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c09f5e-914b-4065-b4df-57b804bd1122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f93b6a68-f8df-4665-81c8-a86502f7123c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 115c1459-44fb-4354-a72f-c93ebeffdb50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bba9434-eb98-4efe-89f7-03a9ae60d9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5957c60e-7db4-4753-8ddf-719e983880f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 073012fb-b323-4b4b-b392-19f55161721a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e67ade-52fc-4c54-88a0-6d34a7a89182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f8970ab-4e51-4802-8c31-fcd97456a932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb31370d-2845-419d-b32c-77b0446a6f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e371a5-311a-434d-bb92-48a1182771c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c4b2de4-a399-4098-bdab-93666897be15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb57e908-f22e-48d4-8562-ff513759ae37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 529b8cfd-626f-4c91-8c28-4801476b3642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c91f497-e6cd-4460-bded-e90363b79d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d277c4f-d530-4c30-b2f2-9d196e5ee750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff06b17a-01e2-4ad2-89b5-2927f2d1decf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e67fad39-e68d-45c9-afa0-76e06b1d8598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4f36ea9-df15-4dd0-97e0-8203e542e1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd358ab-4e74-448b-977d-2e6004968337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d5ecea4-09f1-4a06-83a8-867699533c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4695bfb2-4613-4219-bfb7-eb07b0c24e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc3757c9-8b83-473e-9678-ceac98b067fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04641d12-de7e-4e14-addc-b2644bd44bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959c48fb-b9f8-44e3-aeec-a1495a011550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a67280a-8f20-4201-9946-812bc3ca1a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8820eb34-db65-4425-a855-0aa5753ff175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c0439e5-66e2-4795-9d7e-19e8f5983469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ebc9b24-07cb-4d87-a0d7-03b4e35ad416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e1691a8-fcba-4271-93a9-d2f580bcceec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee45dddf-762c-42d7-ada7-1df1ed5ef868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4eae9c7-cbcd-4ef8-af7a-d0a5f636989f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f276ec1-5dc7-42fa-ae31-e79675c91cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9d6c63b-4be1-4f19-afd5-87536e89c4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24be6c9c-3b2e-4228-897e-4a8088e514f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e85431c-920f-4fcd-9a93-82d1a7c1c116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8164bdcd-d9fa-4a2b-99ca-96f6856c2648
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_76
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_76/test_labels.txt

📊 Raw data loaded:
   Train: X=(608, 24), y=(608,)
   Test:  X=(152, 24), y=(152,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 599 samples, 5 features
   Test:  143 samples, 5 features
✅ Client client_76 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0838 (↓), lr=0.001000
   • Epoch   2/100: train=0.0740, val=0.0834, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0716, val=0.0819 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0692, val=0.0803 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0674, val=0.0784 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0592, val=0.0713 (↓), lr=0.001000
   • Epoch  21/100: train=0.0526, val=0.0708, patience=4/15, lr=0.001000
   📉 Epoch 23: LR reduced 0.001000 → 0.000500
   📉 Epoch 31: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0465, val=0.0754, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 6 Summary - Client client_76
   Epochs: 32/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0525, RMSE=0.2292, R²=0.3549
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.2356
============================================================


============================================================
🔄 Round 7 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0767 (↓), lr=0.000250
   • Epoch   2/100: train=0.0747, val=0.0770, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0742, val=0.0758 (↓), lr=0.000250
   • Epoch   4/100: train=0.0736, val=0.0754, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0730, val=0.0751 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0706, val=0.0734, patience=2/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0685, val=0.0721, patience=4/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0676, val=0.0716, patience=8/15, lr=0.000016
   📉 Epoch 39: LR reduced 0.000016 → 0.000008
   • Epoch  41/100: train=0.0672, val=0.0713, patience=6/15, lr=0.000008
   📉 Epoch 47: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 7 Summary - Client client_76
   Epochs: 50/100 (early stopped)
   LR: 0.000250 → 0.000004 (6 reductions)
   Train: Loss=0.0673, RMSE=0.2595, R²=0.1937
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.1366
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2428, R²: 0.0600

============================================================
🔄 Round 9 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0722 (↓), lr=0.000004
   • Epoch   2/100: train=0.0770, val=0.0721, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0769, val=0.0721, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0769, val=0.0721, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0769, val=0.0720, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0768, val=0.0719, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 9 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0886
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0920
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2418, R²: 0.0661

📊 Round 9 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2421, R²: 0.0636

📊 Round 9 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: 0.0629

============================================================
🔄 Round 13 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 13 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0943
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0803
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: 0.0630

============================================================
🔄 Round 14 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 14 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0909
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.1058
============================================================


============================================================
🔄 Round 15 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 15 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0955
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.1022
============================================================


============================================================
🔄 Round 16 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 16 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.1018
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0809
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

============================================================
🔄 Round 17 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 17 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.1025
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0770
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2420, R²: 0.0637

============================================================
🔄 Round 20 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 20 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.1037
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0736
============================================================


============================================================
🔄 Round 21 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 21 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0926
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.1266
============================================================


============================================================
🔄 Round 23 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 23 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0950
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.1195
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 27 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 27 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.1071
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0789
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: 0.0645

📊 Round 27 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: 0.0646

📊 Round 27 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

📊 Round 27 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

📊 Round 27 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 35 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 35 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1002
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0968
============================================================


============================================================
🔄 Round 37 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 37 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2727, R²=0.0984
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.1082
============================================================


============================================================
🔄 Round 38 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 38 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0992
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.1050
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 39 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 39 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1039
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0832
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

📊 Round 39 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

📊 Round 39 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 47 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 47 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.1059
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0763
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

============================================================
🔄 Round 49 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 49 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.1004
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0971
============================================================


============================================================
🔄 Round 50 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 50 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0942
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.1231
============================================================


============================================================
🔄 Round 52 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 52 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.1045
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0904
============================================================


============================================================
🔄 Round 56 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 56 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0928
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.1333
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

============================================================
🔄 Round 59 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 59 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0999
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0902
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2418, R²: 0.0646

============================================================
🔄 Round 61 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 61 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.0993
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.1046
============================================================


============================================================
🔄 Round 62 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 62 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.1011
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0825
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

============================================================
🔄 Round 65 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 65 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.1008
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.1020
============================================================


============================================================
🔄 Round 67 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 67 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.1079
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0754
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

📊 Round 67 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

📊 Round 67 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 71 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 71 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.1079
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0809
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

============================================================
🔄 Round 72 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 72 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1084
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0538
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 74 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 74 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.1102
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0710
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

📊 Round 74 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 77 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 77 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1081
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0708
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 78 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 78 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1075
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0737
============================================================


============================================================
🔄 Round 83 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 83 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0992
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.1012
============================================================


============================================================
🔄 Round 84 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 84 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.1009
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.1080
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 88 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 88 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1009
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.1049
============================================================


============================================================
🔄 Round 89 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 89 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0964
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0907
============================================================


============================================================
🔄 Round 90 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 90 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.1016
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0996
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

📊 Round 90 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0645

============================================================
🔄 Round 92 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0714, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0713, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0713, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 92 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1034
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0980
============================================================


============================================================
🔄 Round 93 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 93 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.1059
   Val:   Loss=0.0664, RMSE=0.2576, R²=0.0871
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

📊 Round 93 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

============================================================
🔄 Round 95 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 95 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.1009
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.1059
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

📊 Round 95 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

📊 Round 95 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

📊 Round 95 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

============================================================
🔄 Round 102 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 102 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0916
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.1402
============================================================


============================================================
🔄 Round 105 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 105 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.1051
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0698
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

📊 Round 105 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0646

============================================================
🔄 Round 111 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 111 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0983
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.1149
============================================================


============================================================
🔄 Round 112 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 112 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2712, R²=0.0951
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.1307
============================================================


============================================================
🔄 Round 115 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 115 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.1064
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0889
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0647

📊 Round 115 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0647

📊 Round 115 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0647

📊 Round 115 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0647

============================================================
🔄 Round 122 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 122 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.1054
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0887
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0648

============================================================
🔄 Round 126 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 126 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0984
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.1106
============================================================


============================================================
🔄 Round 127 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 127 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.1020
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.1077
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0648

============================================================
🔄 Round 128 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 128 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2694, R²=0.0992
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.1171
============================================================


============================================================
🔄 Round 131 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 131 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.1015
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.1095
============================================================


============================================================
🔄 Round 132 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 132 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.1114
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0704
============================================================


============================================================
🔄 Round 134 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 134 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0951
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.1210
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0650

============================================================
🔄 Round 135 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 135 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.1073
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0835
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0651

============================================================
🔄 Round 137 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 137 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1105
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0689
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0650

📊 Round 137 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0650

============================================================
🔄 Round 140 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 140 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.1049
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0962
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0650

📊 Round 140 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0650

============================================================
🔄 Round 143 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 143 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1023
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.1071
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0650

============================================================
🔄 Round 145 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 145 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0959
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.1309
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0650

📊 Round 145 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0650

============================================================
🔄 Round 150 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 150 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.1027
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.1046
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0651

============================================================
🔄 Round 152 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 152 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0889
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.1607
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0651

📊 Round 152 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0651

============================================================
🔄 Round 156 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 156 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1042
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0897
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0651

📊 Round 156 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2419, R²: 0.0651

📊 Round 156 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0651

============================================================
🔄 Round 161 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 161 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.1057
   Val:   Loss=0.0716, RMSE=0.2677, R²=0.0752
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0651

📊 Round 161 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0651

============================================================
🔄 Round 167 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 167 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0986
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.1257
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0652

📊 Round 167 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0652

============================================================
🔄 Round 173 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 173 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0964
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.1326
============================================================


============================================================
🔄 Round 175 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 175 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.1070
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0920
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0651

============================================================
🔄 Round 176 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 176 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.1011
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.1135
============================================================


============================================================
🔄 Round 178 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 178 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.1036
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.1047
============================================================


============================================================
🔄 Round 179 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 179 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1149
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0629
============================================================


============================================================
🔄 Round 182 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 182 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0993
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.1103
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0652

📊 Round 182 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0653

📊 Round 182 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0653

============================================================
🔄 Round 189 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 189 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.1035
   Val:   Loss=0.0654, RMSE=0.2558, R²=0.1044
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0653

📊 Round 189 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0654

============================================================
🔄 Round 192 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 192 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.1061
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0910
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0654

📊 Round 192 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0654

============================================================
🔄 Round 194 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 194 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2712, R²=0.1015
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.1022
============================================================


============================================================
🔄 Round 195 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 195 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.1086
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0818
============================================================


============================================================
🔄 Round 198 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 198 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.1010
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0909
============================================================


============================================================
🔄 Round 199 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 199 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2701, R²=0.1102
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0778
============================================================


============================================================
🔄 Round 200 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 200 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0995
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.1213
============================================================


============================================================
🔄 Round 201 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 201 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.1012
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1139
============================================================


============================================================
🔄 Round 203 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 203 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.1045
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0996
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0654

============================================================
🔄 Round 204 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 204 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.1130
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0672
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0655

============================================================
🔄 Round 205 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 205 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1150
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0600
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0655

============================================================
🔄 Round 207 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 207 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0959
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.1205
============================================================


============================================================
🔄 Round 209 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 209 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0977
   Val:   Loss=0.0679, RMSE=0.2605, R²=0.1322
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0654

============================================================
🔄 Round 210 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 210 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0903
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.1584
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0655

============================================================
🔄 Round 211 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 211 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0981
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.1277
============================================================


============================================================
🔄 Round 213 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 213 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1023
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.1114
============================================================


============================================================
🔄 Round 214 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 214 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.1041
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0627
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0655

============================================================
🔄 Round 216 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 216 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0983
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.1278
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0656

============================================================
🔄 Round 217 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 217 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.1137
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0603
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0656

============================================================
🔄 Round 221 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0644 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0644, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0644, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0643, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0643, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0642, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0644)

============================================================
📊 Round 221 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.1047
   Val:   Loss=0.0644, RMSE=0.2538, R²=0.1013
============================================================


============================================================
🔄 Round 222 - Client client_76
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 222 Summary - Client client_76
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.1078
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0896
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2419, R²: 0.0655

❌ Client client_76 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
