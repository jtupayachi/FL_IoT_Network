[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a6e500c-3e43-402a-9cb3-6253ec00de8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ac1b04-ca31-4fe4-959f-7403e9655ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743a9754-6866-4f72-8c71-af532416bef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6187cb0-2784-4b6f-80d2-2abf19eb0a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e426ca34-b30a-4811-b28e-c864e8e806dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e3ded3-76e7-478c-88c1-5a7953c0c122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f188888a-b2c6-4b61-80b1-02981eb4600f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c21027f-135d-416f-88a3-d80ed29b8fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6396d510-730b-40a4-a033-d9e94cdb4960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ffd219b-6bf2-40c2-9757-f0ab1c18160c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe328de3-d049-400b-991b-96a892c06834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f052383-3fe4-4ad6-b472-df976695e54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d3967ac-c2b8-45c9-8dbb-6066abd0fb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ae45a11-3ec9-4fab-9cdb-dc98843965a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f157c9a0-81dd-4ebd-be39-4e3572cb35eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c0524be-bc16-4144-8515-a5568f68cb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c934ac42-b4c1-4e81-8c30-f09f9e00a9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4724a0ad-0c83-4a9b-8217-68a29edb242c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef9602a-21e2-4ceb-b748-9c39068e37db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1c182c-cf4b-4944-a342-738cb0c2d219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f880edcf-4cdd-4f3a-8e71-a520cb1405e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7063fe47-b790-4596-a242-2373439f4ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8109f374-57b0-411f-b04d-54aaec3a9c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35ec288-934a-4c63-b805-284ad2d6a128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c368c4-b649-4cb6-b508-920b04edc54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8591bd41-050b-499f-a8c5-be9a23424654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79303536-3df5-4919-8bf4-cca314074041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 410fc585-d0c3-43cb-b1a3-d46506e78e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d39c83ca-3a64-434d-a59d-00949c540e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9465349e-bf2f-4422-bc97-200d302b94aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a449aea-8918-42a4-b753-8a18a220b7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d2a845-933d-4313-a33c-6267bb98554e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d4fc23-ad87-4b01-b923-c8ccc70e7017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42888362-7abf-4d77-b7d7-e59531e72c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83092c4d-5c09-44b3-8af8-9e87036767fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4bf566-f5a4-4712-a7c5-022010814aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1259837-4d62-4eb4-bef4-6d47f7482501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a260766-32a8-44fc-a5d5-71d44037b5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c27f0e5-3a20-4938-9f82-bbe627bfd32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a85c05f-4b8c-483a-b28d-8d31110806f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1adfed32-0c93-45ed-9e0b-4fe50bb8cebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432ccb93-6da5-43dd-92af-4c0df8c54d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821fe7bf-f17d-4e0f-9c45-147f841e5f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd2fad7-c990-4c5f-90a9-c116acda8a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a6c511e-5a7d-45f7-8b72-14aaa2089eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f02c3aa-3568-4f4f-9c2a-a277d8cebe82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6629d8d7-6568-40f7-92dc-5c34ef679d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a3d7353-91f3-4ae6-9743-54b82d4bb7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51148795-5ab6-4f42-9707-fe1853dbc714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e8315d7-b8d8-4b9d-aa0d-ead31d701579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08421cfb-8391-468a-abd4-005ff72c8c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e74b300-6bfb-433a-81c1-d9cffc0c111a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c36db0d4-dcaa-4a78-8d25-c088592453a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0bd82b5-47cf-4058-8c45-53509a7099a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed70de00-e234-48f6-82b8-64c0031a2ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e9c2f2-2b52-4fc6-b645-de5e33243f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8b7dc1-ac33-43d0-8f5f-0f50c5d99e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f782e13b-79a6-4cbc-8ce0-c1380d12ef0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc3ce55-a89d-4142-9d85-cba4b06314a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7622df-287e-454e-b268-d9be12728a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 496d9051-5f4c-4a10-8db1-8a5f18fe40ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb912436-2dd7-4f18-8957-726303e130c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d54e42f3-8595-4be7-b83c-73fcff22b229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 468ffc74-e2c0-4631-9230-6fde54917af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93e583ee-d27c-4bd4-9321-0239e8120b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a749f15-8edc-4332-81a9-26443f66cd62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4edc8b-9b6f-4704-937d-55e70f75a493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd8a4be4-2419-4296-a748-d216de3e7384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb3c5ed-f73e-4d4d-bd83-b86fff54755d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ebf0f65-4701-4d52-8c4c-705d1caa9986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9eaebe-eeb8-4422-8e8e-b5bf99cc293e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f54fd39-d198-498f-a04f-ab5548ef40ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff438c7-12d7-465b-b0ed-6ea31784ff48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed958583-8052-4380-9a1a-0d53de8db757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd7ded6-f527-4149-9a9f-5214ee281921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6b6de8-ff90-474d-b703-9ae43be09257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7472b73e-912e-423b-b74b-66054501baba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8541c3b-90bc-49a2-90e4-54c86189914a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67bee8d3-34d9-4195-9912-299d7c3d21c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a219066f-6fca-49a6-9664-f55419705d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a639736-b27f-4678-9b4e-d2c25dfc46cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db75965-df85-480e-a9b6-0b56316b9aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5993a86-42bb-4979-87b2-009ba9c78bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e4337ff-d29c-433d-afde-d919c4c7e6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d665607-253c-415a-8f12-81931a58c787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be014777-2f28-480b-9624-70321bec4e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aab64ee9-9e47-4eaf-b5bc-bf73dda926d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cde1b48-d507-4afd-975e-647976308a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98ef41ca-3045-4afd-a638-1fee3d74381c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d0c762-c871-4f6a-be32-d7894c394bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e7053f-bb8e-450e-9636-e865c8980abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddf9e22-2937-4e9a-b231-8f77b59230fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ceac84-2e17-4909-9aa7-64b4cbf0fdfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd0d83f-108e-4513-a868-574b62b6d391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0d24f34-e2c2-4770-8494-da45ecba4e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 645873c5-7087-4aa8-8cfb-ff7886c8ffba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7bcafbe-9db1-46fd-99ba-aaace364e4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30c20d2-f023-45cb-814d-f33912f31e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676f4031-ac7c-4419-b690-4cb22ec6f82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f08f69b-9886-42c1-b22d-5184fcc66bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b097935-1303-441a-a64c-b71a6f0f9209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6305c9-21cf-4504-8e3f-16fc0a91d1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9504510-7549-4515-bd9a-1f38d98a4e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 147c6534-5630-4a70-83ea-e0c309e9f7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 017307a0-110e-45b6-a342-7ba5c2709183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59999235-c95d-4281-a6ed-83c6eed27339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd0c856-0dd9-4d14-8028-8f325a01592e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4091bad9-97fc-42fe-b63d-8307738d8687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a653def-4d5c-4639-82fa-e49cd6c99c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b419f0ed-5155-4e56-a479-9848551de936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6f32c7-c323-483c-9dc6-2823a3b93202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a5e212-94a2-49c7-be24-5502c64a65ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d659b1d5-5444-45cf-94c7-264df71a1793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fee5449-2738-4b40-bc91-2723d93ced17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca16d49c-7478-47cb-941f-cefe44b41978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 260e114a-010e-4bdb-9dd9-19d1c375faa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6922f2-9a37-42a7-89d4-720ed46a07c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ed24d8-b25f-4004-b74a-54374da2e226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35797b4-f4b3-409b-80a4-2a5186ad96af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feceb62c-da7b-486c-965c-e1a4701f0645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3cb0c5-9555-4824-9acf-1773bdc11bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c6a6ef-8119-4f07-9852-b00d9ddb6d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a4241bb-146f-4430-b7ac-6df41f0f57ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0da942-6b89-4c27-8b4a-da6a411e8f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7980f4f-9939-4c76-98e9-a4aae715b111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4f33e5d-ba04-4d30-8f0d-97605ab659cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d8a2c27-4ffa-4b5b-b14e-f9d7d1f4a1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0951e1e3-32be-451e-87bd-77dca697b709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ce0bd01-4d09-4cf6-872e-ecea1a26bcf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19d00b8b-5174-4ee8-a059-dbb3f0125b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249f6ced-d640-477c-a724-e88151f74677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 472771fe-81b5-451f-b118-57510b9d0dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c2895aa-7233-47bd-8aa4-20a790d411eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bad2a95-ca4f-4195-a09d-3d2f224f8d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ff9a903-c79a-43aa-82b6-32e12dc2af17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b416fe55-02be-4ab7-83c9-76f488d9ba5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 401ddb35-5dbd-4410-bec4-7620fa0a3a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f3cb7e-3f22-413f-9469-7e253fd2b5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ab4a330-8a34-45bb-a8c8-1118cb08607f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44389f56-d760-4f5a-99a9-793ee0f96ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a705f53-93f4-4848-9f31-2a12e9a3ef4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca8cd38-d204-4873-bd1e-00e81a61c425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa904f8-4117-4dad-9955-5c22f24473e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cab1811-59d2-487b-aef2-83bfb6d6a6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ac11a7-2cc6-4e78-9241-d56077d95ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78c74456-7e27-4a22-9195-96350b2a43b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e21032-d415-4f1a-b6b1-f3e3a83e4a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b3aef4-43e9-4f83-a6f0-ed7303b3fff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2088dffa-424d-4323-af30-59575566b94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05845db8-73b1-417b-9e4b-adbf7e2614c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530a6f0d-8ee8-4e4c-9c85-859c00f01188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9502cabf-91d7-44a3-b7e3-70a6ee6aaae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f33c7dc-fb7c-4f85-9dbd-d913f15fc0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b47fc114-a793-4cce-a482-ccfb30e48e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa4e6ed-d6f0-4bf9-9f0d-aec3f6c5b4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e54f6c54-794e-42e4-84f4-d3bafb854a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57acb9f4-fea1-4b7f-be38-88b761d232d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706294bc-bc28-4be5-a099-79b9cf3b6dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2eb1faa-479c-445e-a5fa-c1cac44d893b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_77
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_77/test_labels.txt

📊 Raw data loaded:
   Train: X=(1518, 24), y=(1518,)
   Test:  X=(380, 24), y=(380,)

⚠️  Limiting training data: 1518 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  371 samples, 5 features
✅ Client client_77 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2520, R²: 0.0280

📊 Round 0 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2521, R²: 0.0290

============================================================
🔄 Round 13 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0726 (↓), lr=0.001000
   • Epoch   2/100: train=0.0776, val=0.0722, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0764, val=0.0714 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0757, val=0.0708 (↓), lr=0.001000
   • Epoch   5/100: train=0.0754, val=0.0707, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0699, val=0.0679, patience=1/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0576, val=0.0715, patience=11/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 13 Summary - Client client_77
   Epochs: 25/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0686, RMSE=0.2620, R²=0.1692
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.1340
============================================================


============================================================
🔄 Round 15 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0727 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   ✓ Epoch   2/100: train=0.0777, val=0.0721 (↓), lr=0.000250
   • Epoch   3/100: train=0.0768, val=0.0719, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0763, val=0.0717, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0760, val=0.0714 (↓), lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0742, val=0.0705, patience=3/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0728, val=0.0701, patience=8/15, lr=0.000063
   📉 Epoch 26: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 15 Summary - Client client_77
   Epochs: 28/100 (early stopped)
   LR: 0.000500 → 0.000031 (4 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.1098
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0871
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2514, R²: 0.0325

📊 Round 15 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2512, R²: 0.0343

📊 Round 15 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2512, R²: 0.0345

============================================================
🔄 Round 19 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0719 (↓), lr=0.000031
   • Epoch   2/100: train=0.0789, val=0.0719, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0787, val=0.0717, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0784, val=0.0716, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0782, val=0.0715, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0777, val=0.0712, patience=5/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0774, val=0.0712, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 19 Summary - Client client_77
   Epochs: 21/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0590
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0770
============================================================


============================================================
🔄 Round 21 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0629 (↓), lr=0.000008
   • Epoch   2/100: train=0.0812, val=0.0628, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0812, val=0.0628, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0811, val=0.0627, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0811, val=0.0627, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0807, val=0.0623, patience=1/15, lr=0.000008
   • Epoch  21/100: train=0.0802, val=0.0618, patience=1/15, lr=0.000008
   • Epoch  31/100: train=0.0799, val=0.0615, patience=11/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0618)

============================================================
📊 Round 21 Summary - Client client_77
   Epochs: 35/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0580
   Val:   Loss=0.0618, RMSE=0.2486, R²=0.0993
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0365

============================================================
🔄 Round 22 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0762 (↓), lr=0.000008
   • Epoch   2/100: train=0.0779, val=0.0762, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0778, val=0.0761, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0777, val=0.0761, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0776, val=0.0760, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0773, val=0.0759, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 22 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0552
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0357
============================================================


============================================================
🔄 Round 23 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0744 (↓), lr=0.000002
   • Epoch   2/100: train=0.0782, val=0.0744, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0782, val=0.0744, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0782, val=0.0744, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0782, val=0.0744, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0781, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 23 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0507
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0569
============================================================


============================================================
🔄 Round 24 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 24 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0620
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0174
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 24 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 28 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 28 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0528
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0386
============================================================


============================================================
🔄 Round 30 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 30 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0558
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0370
============================================================


============================================================
🔄 Round 32 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 32 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0462
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0782
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 33 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 33 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0591
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0208
============================================================


============================================================
🔄 Round 34 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 34 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0506
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0508
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 35 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 35 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0621
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0153
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 38 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 38 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0427
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0869
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 40 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 40 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0562
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0392
============================================================


============================================================
🔄 Round 41 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 41 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0555
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0430
============================================================


============================================================
🔄 Round 43 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 43 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0478
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0743
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 43 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 47 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 47 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0482
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0717
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 50 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 50 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0505
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0601
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 54 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 54 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0507
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0620
============================================================


============================================================
🔄 Round 55 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 55 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0565
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0352
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

📊 Round 55 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 57 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 57 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0543
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0129
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2509, R²: 0.0360

============================================================
🔄 Round 59 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 59 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0540
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0370
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2509, R²: 0.0360

============================================================
🔄 Round 60 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 60 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0589
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0243
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0360

============================================================
🔄 Round 62 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 62 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0510
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0363
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0360

============================================================
🔄 Round 66 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 66 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0514
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0605
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0361

📊 Round 66 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0361

📊 Round 66 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0361

📊 Round 66 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 74 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 74 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0525
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0579
============================================================


============================================================
🔄 Round 76 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 76 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0571
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0407
============================================================


============================================================
🔄 Round 77 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 77 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0447
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0816
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 81 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 81 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0457
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0645
============================================================


============================================================
🔄 Round 84 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 84 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0588
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0319
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 86 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 86 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0483
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0711
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 91 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 91 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0364
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0764
============================================================


============================================================
🔄 Round 94 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 94 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0488
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0761
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 94 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 94 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 101 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 101 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0552
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0415
============================================================


============================================================
🔄 Round 107 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 107 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0447
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0886
============================================================


============================================================
🔄 Round 109 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 109 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0514
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0629
============================================================


============================================================
🔄 Round 110 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 110 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0567
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0391
============================================================


============================================================
🔄 Round 111 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 111 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0614
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0180
============================================================


============================================================
🔄 Round 112 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 112 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0547
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0478
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 113 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 113 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0641
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0024
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

📊 Round 113 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

📊 Round 113 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 120 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 120 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0499
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0666
============================================================


============================================================
🔄 Round 122 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 122 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0539
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.0554
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

📊 Round 122 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 126 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 126 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0482
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0777
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 128 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 128 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0591
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0362
============================================================


============================================================
🔄 Round 129 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 129 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0560
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0470
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 129 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 129 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 135 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 135 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0628
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0220
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 141 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 141 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0484
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0817
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 141 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 145 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 145 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0505
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0572
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 146 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 146 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0546
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0491
============================================================


============================================================
🔄 Round 147 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 147 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0566
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0451
============================================================


============================================================
🔄 Round 149 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 149 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0448
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0906
============================================================


============================================================
🔄 Round 150 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 150 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0559
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0498
============================================================


============================================================
🔄 Round 151 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 151 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0624
   Val:   Loss=0.0897, RMSE=0.2996, R²=0.0265
============================================================


============================================================
🔄 Round 152 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 152 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0655
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0158
============================================================


============================================================
🔄 Round 153 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 153 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0605
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0244
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 155 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 155 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0478
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0704
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 157 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 157 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0544
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0533
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

📊 Round 157 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 159 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 159 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0540
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0536
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 161 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 161 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0488
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0716
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 164 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 164 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0575
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0411
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 164 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

📊 Round 164 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 168 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 168 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0508
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0717
============================================================


============================================================
🔄 Round 169 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 169 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0551
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0541
============================================================


============================================================
🔄 Round 171 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 171 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0593
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0326
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

📊 Round 171 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 174 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 174 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0557
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0494
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 177 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 177 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0529
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0573
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

📊 Round 177 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 180 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 180 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0601
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0288
============================================================


============================================================
🔄 Round 181 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 181 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0506
   Val:   Loss=0.0661, RMSE=0.2570, R²=0.0764
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 181 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 184 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 184 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0539
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0422
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 184 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 190 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 190 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0624
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0268
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 194 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 194 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0603
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0332
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 195 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 195 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0519
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0661
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0361

📊 Round 195 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 195 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 199 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 199 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0602
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0206
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 203 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 203 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0530
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0326
============================================================


============================================================
🔄 Round 205 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 205 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0605
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0376
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2508, R²: 0.0361

============================================================
🔄 Round 207 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 207 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0502
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0745
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 207 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 207 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

📊 Round 207 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0362

============================================================
🔄 Round 213 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 213 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0471
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0900
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2508, R²: 0.0363

============================================================
🔄 Round 214 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 214 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0571
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0282
============================================================


============================================================
🔄 Round 215 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 215 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0636
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0183
============================================================


============================================================
🔄 Round 216 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 216 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0536
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0579
============================================================


============================================================
🔄 Round 219 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 219 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0525
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0673
============================================================


============================================================
🔄 Round 221 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 221 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0580
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0333
============================================================


============================================================
🔄 Round 224 - Client client_77
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 224 Summary - Client client_77
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0606
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0356
============================================================


❌ Client client_77 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
