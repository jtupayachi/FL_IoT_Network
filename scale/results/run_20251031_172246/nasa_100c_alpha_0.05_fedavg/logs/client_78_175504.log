[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3795e5c0-1cb6-4dfd-bf61-8d7e3c87a929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0be780d2-33f3-42c4-a0f3-75ed5e873228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 148526a7-4395-4abc-ac21-4251576d722c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ea25dd-95eb-4610-b6f6-7f649ef2a86a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b5b249b-6227-460a-98ee-fc30e1e2d693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a056fe7-4af5-407d-ac5f-dfb5669bb4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc6d0560-d59b-4cc8-af42-bb51b9956673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d7f07b0-0ee8-4155-bc67-d91b293e0c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b06b145-6eed-4ec2-989f-582f17eab72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c47732e-019d-47eb-9587-07f450556c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f50a892-ed8f-4d60-8079-243fbabdccdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 228a7568-7954-4877-8f71-6f17f24f339f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9fd269-2878-4d1c-8dd4-8b2ef0a657a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cae1632-2d46-46f9-8dcf-78740491b9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10be5a5b-01d0-48b5-8db7-6344b977c859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66e84e89-a8c3-446a-8362-6df44c8d5057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922ccbc9-e195-4930-90dc-53768f188395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec87342-5ea9-4337-b853-af4ef4d312c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170bb20c-faa9-4386-8d84-494af10d65b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60be2bda-c496-4880-ba0d-ed0e2ac98161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba66c0a-d8c1-4b1a-82a5-2f8a62cdadad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b2eae41-317d-452d-b606-bbb8b27fd9f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f69490-e896-4389-b30e-fdc3e24cb606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d42f2c1-4163-472a-ae0c-4a059dc19c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e184b2-a1cb-46f7-b6c9-f41219234d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9a1bab-76ec-4dbd-95c9-1dd97468f5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d28c5daa-40aa-4255-8415-90774dedb2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba52b33b-2782-44f4-a47f-19a2aeef4b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713b3952-920b-479e-8e49-84f0b9c85373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8af0ad8-db89-4e34-93fb-d0a28c14edcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b4f70d-a587-4c13-ba30-6c8ed706d41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5353a81c-8968-423f-b49d-ab277a4fef1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86045b50-6636-40b2-9a0b-1731871ab60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4146f35-acce-499d-b1c0-0777f76e72b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25af75eb-0315-4768-a57f-96f2c951ef12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b9883a3-c22d-4367-af94-5c40295e323a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1aae85-3c0b-4e63-97a1-9267e14f6e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49dbc773-1ebd-4ae9-b668-75c6a964c7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffeffcc6-da2b-421d-b663-a6b9fe5395fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c523f12-99e2-4bf8-b1f3-98eb59586e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 731b0ed7-1f34-4889-aa8f-3354d5ff3439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 253a7068-d6f9-4219-9e1b-e00c07f47a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de1f9d17-e5df-4a2c-af86-5d3a3e89c816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6589f7-02f1-4c6c-a79c-b4c4c9f2c4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab9a9c79-8527-4c40-b0ba-9d338a74126a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997cc275-75b7-49c9-a762-f9b0ce6a8f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3841a75-442d-4e48-a968-feb560978682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dbe8f3a-6364-4d8c-b290-ab1b39b93198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0f875d-ea4b-4613-b49c-2288a28d237f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d515a98-76cd-46b9-9a1a-d85309677556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bd7161-624f-414d-90b6-5a6a0d9b2d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e602d00a-eabb-4f94-9320-a3a3bef629df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd5ff3e-079b-4527-bf4a-8122ae0eb5fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf1c8791-1873-44d0-a43e-5188933e24f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d559ea0b-2d0d-4852-bcd5-2f7a9a031b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a84640-b28f-49ae-96eb-cfe219ae957c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b2a1e0d-caeb-466d-832f-de7ac353beba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0f1f77-8338-4bf9-aeb9-660cd4428c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4812a24-0fdb-468c-b6af-b245444b860f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ddf2c8-fdc8-4903-9757-680e6dc7886c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a0e420d-13e2-4942-97a1-0631f45a9b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d8a6d84-3b0b-4cf5-8f76-39593ad5b6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c1729a-6a90-4b59-9596-1a25595a3837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301ea9d3-628a-46b0-a1cc-ff8ae67cbca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b05fe94-5339-44d9-aef1-8894e733622c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbe936fd-118c-4c66-b3bd-85cde4bf4ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9970ec-12b2-4ccc-af43-7d59ba80ada0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e03ef3b2-18f7-465c-a1cf-85b076f497d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a1cf13c-4954-47a8-b77b-1dcdfc2a04f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c8e3e5-2a50-470c-a5c6-ef77aebfc913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9d750e-56cf-42fa-9b27-bda8f21aa54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7553773-232a-408b-877f-b6ecee85036e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a47ef5-4674-49c4-804a-47275fc6b633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f4f2397-c874-4ee0-9585-1e05f4aebdb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b61815dc-0105-4288-b701-52f8c3f22721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a142742-125f-44c2-9caa-a05e09300651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c758c72-5d8c-4f9e-91c0-ddf43768aedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message debf6eeb-0864-4a55-8569-a645a6794003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0c09791-ecf2-426e-ac23-8f591ce0ba54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1834522d-712f-4034-bf5a-e179826167b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 541d086b-e3f2-429f-9f54-7a682d53968e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7bf277d-5cf4-4200-8018-8a44e9a74d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883295e6-29db-4ad0-b7d5-a1d0144eb765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac28c0f3-ea03-46f5-abf7-8020e15ca51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b1a80b-8516-4dea-a532-5638cdea894b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95839df2-d542-42a7-bd7c-b9292b1a155a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e526ac-73fe-4af0-b829-5007d58151e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874033ab-3c0f-48f3-b0fc-76062e041f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1365f4e-5b3a-4b2b-b9ae-35f6abcd6465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a8c7a0-c50c-4fc4-bbbb-412360785512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45295fa7-494c-4fcb-9ef7-a6393c44734a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 675f601f-a305-48a9-bbcb-a9220c2391a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d5f3531-6cc2-4016-ab90-74b877a1a963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87647883-a259-433c-9da1-05f2c04d3b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3803c77e-dca1-4313-8ee3-fb6fdc48dd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff4948db-b798-49f2-8ae3-6b05c38d7d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e8eeee-6433-45e7-935f-8b1c4ea74deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ed2796-14f6-4c94-8d56-ba244b17073b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4987f7f-3f1a-4e26-8ee5-c5d5ee5c9cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08241aa0-278e-48a4-a487-d31bcd526175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c56a706a-3d14-41df-a6e8-30d8424fc526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c72ca14-0d69-4f2a-a685-c6dca2b4302e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 569874b2-9ad3-4bbd-8430-5589ca0f472b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1ccb936-7b51-4b75-9c35-f0a2d3a1cf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85add2b9-6538-40a8-8cd9-3307d6132382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1edf3272-9c63-4c1f-a1be-c2c862215b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b155e1-4f4d-4d6a-935c-6fd645cce55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32bf9dcc-0e86-4690-a80b-3f6625787144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62ee46b2-0ee5-42de-8330-3043cf4e4eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b90ea4-e1fc-4427-b5c3-649d274bd8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 538cfbb1-ee2b-49fd-851c-5c5d6d408dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f3784d6-3d98-4496-b2c0-2710d017911f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bf81730-dd79-4c67-8e3c-35695bdeadc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6c2c402-29ce-4c4f-b4e1-bf04792d8840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6bf9a97-57ab-4d08-9cbb-be3770d30837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c186b01-8e1a-433a-8eae-7d7fe8547302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b607bf2-1979-4729-8c94-bf12f104b3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 048a8362-c2e3-4cb6-bbba-f2efee79e7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9dff8d4-1272-4f1f-947a-f1455edb6f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4523a20-c179-4d5a-82a1-cc2382a830b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8da05f0-4bd1-4766-845e-db9bd6af7cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30f17dd-66c7-40ad-9997-73d2e3d95a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9878f262-04b5-4029-9444-ab4119c79f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b016d7-d13e-465a-9ca5-783225ee0881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1802c7-04a6-46ee-8c1b-48d8aa7158fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 082b1c0b-de90-4532-8f13-d0a7d26a6f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d76e0791-983e-4a01-a080-971af881c5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12fb7953-5f10-4bbe-a2d9-148111a1ffeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb21b1b-22a5-4dfe-a247-69ef8ea9cd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ac3fd3-761a-4c49-9953-3f7ed832c30b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 259e67b1-26db-4349-a86a-db22c1208292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b830e066-d772-46fc-ae11-d5e15b67f791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a23f09b-5d2b-4a53-ba38-1bd18b486cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bfc2e16-5933-4c59-9386-8a0559dc28dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2fba071-8e5b-46e5-a179-701f5fa8ecb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba88b759-07b6-4bbe-8543-f7104e83ee0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2947335a-97fe-4e6d-b9ce-94954bd37d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aec56a2-ee4e-48ba-bf09-69fe1538c94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a96c8511-b254-4bd0-a4e5-2e4026538784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c56659-4e19-4815-a48e-8f21e33d8427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e4c4aca-76c1-481a-abb8-1ee2f888a4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5152e93f-b354-42b9-bb6d-a3ba0c39abd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 304c7682-5bde-4bb8-a286-c6fe23433c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bf75891-c582-4465-ac37-addc79a04b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1097c0-e539-45a4-872d-2beb0672a06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b053c744-cc8e-4e15-ad42-8cd4a3a7d592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce2a6a33-eec2-45fa-a1a0-b1f81c9724dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0731f1-498d-484a-89a9-468d79a0ba84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf567449-d7bd-4773-b6fc-aee4a925cac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2683ea34-223b-4145-80dd-30299bc28545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5c169d-176d-4051-bbd1-46d0e50f2270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5758abb-279e-40d3-b2cd-c3e30c4e5726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90c3973e-0610-43a0-9bea-f78a3d5b4e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 532e2b83-19e6-40d4-bd49-bef89b8d68be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f15f335-d572-44e5-a287-624d83db0243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 815cf35f-1950-42fa-85c5-a0193e9736c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a8173e8-a4fc-44e2-b880-1cd8b355c1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ee16b0-cf4d-496f-89ae-e195a4bd8c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f2e6b9-7f65-4e1e-8273-18737617cd18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e4b610b-1a5c-410d-b9af-01850de0238b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3748a748-87ed-47d7-a917-2ef08eedfd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 383d5f15-f0e0-42b2-86d6-f1322a8cfccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a078929-ffa2-4a72-bff6-fd81a48cff11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c71228-b30f-43da-ba28-9419620a9d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 167b6072-74a3-4a63-9a23-4de0f74a0ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6aea9ec-f00d-4b0d-a4ef-5753ee4937e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a39e9aa4-ff5b-402d-a9d8-feda9ce30ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57486171-857a-4526-9076-7d4ba996f707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb527a05-3e62-4f1c-9e77-f6a7a3ab11a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01195991-3ea4-4807-83bb-0f60edf03cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208e4428-6bba-4bdc-99d5-1028467ef729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008dda15-42db-4f1e-9fb2-ecea2a2b9b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570e2210-63da-4bdb-a287-df9bcc711fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b1555d8-f5e5-495e-ba8f-5933cc20dc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d15162-c0c2-4969-b5ff-74d892da2bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3cd795-964f-45ed-b323-67cdf753985e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb9b06b-7a4f-403c-99b0-9dcdbfc05b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f79db8f-f2e8-4c9e-a3ef-27d00f9b261b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c28b8c-2699-4996-9b56-33359be21160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0df7218a-44ff-4dae-adde-b8e5a8b086b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2c1377-817f-4857-a06c-51f9a4b33e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3566481-6c8f-4a45-96ca-7714a07f4874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068867ea-2fa3-4ccb-9a0d-0877826ff996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8180bf19-2b36-4c7a-a8fc-c5148ff56f30
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_78
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_78/test_labels.txt

📊 Raw data loaded:
   Train: X=(512, 24), y=(512,)
   Test:  X=(129, 24), y=(129,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 503 samples, 5 features
   Test:  120 samples, 5 features
✅ Client client_78 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2448, R²: 0.0541

============================================================
🔄 Round 9 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0809 (↓), lr=0.001000
   • Epoch   2/100: train=0.0785, val=0.0813, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0767, val=0.0816, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0758, val=0.0822, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0751, val=0.0835, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0707, val=0.0888, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 9 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0534
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0294
============================================================


============================================================
🔄 Round 10 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0877 (↓), lr=0.000250
   • Epoch   2/100: train=0.0763, val=0.0895, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0760, val=0.0893, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0757, val=0.0892, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0754, val=0.0896, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0745, val=0.0903, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 10 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0474
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0414
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2434, R²: 0.0562

📊 Round 10 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2433, R²: 0.0564

============================================================
🔄 Round 14 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0805 (↓), lr=0.000063
   • Epoch   2/100: train=0.0781, val=0.0806, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0780, val=0.0807, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0779, val=0.0807, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0778, val=0.0808, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0774, val=0.0809, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 14 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0393
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0782
============================================================


============================================================
🔄 Round 15 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0846 (↓), lr=0.000016
   • Epoch   2/100: train=0.0772, val=0.0847, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0772, val=0.0847, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0771, val=0.0847, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0771, val=0.0847, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0769, val=0.0848, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 15 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0350
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0961
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2415, R²: 0.0637

============================================================
🔄 Round 16 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0783 (↓), lr=0.000004
   • Epoch   2/100: train=0.0800, val=0.0784, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0799, val=0.0784, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0799, val=0.0784, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0799, val=0.0784, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0798, val=0.0785, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 16 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0564
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0147
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2412, R²: 0.0652

============================================================
🔄 Round 17 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 17 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0555
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0159
============================================================


============================================================
🔄 Round 18 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 18 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0477
   Val:   Loss=0.0685, RMSE=0.2617, R²=-0.0354
============================================================


============================================================
🔄 Round 19 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 19 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0358
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0927
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2414, R²: 0.0641

============================================================
🔄 Round 20 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 20 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0420
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0768
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0666

============================================================
🔄 Round 23 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 23 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0513
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0340
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0671

============================================================
🔄 Round 24 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 24 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0674
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0223
============================================================


============================================================
🔄 Round 26 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 26 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0311
   Val:   Loss=0.0666, RMSE=0.2580, R²=0.1213
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 28 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 28 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0437
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0640
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 29 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 29 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0341
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0417
============================================================


============================================================
🔄 Round 30 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 30 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0596
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0044
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

============================================================
🔄 Round 40 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 40 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0600
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0074
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

📊 Round 40 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 48 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 48 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0520
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0309
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 48 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

============================================================
🔄 Round 50 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 50 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0511
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0363
============================================================


============================================================
🔄 Round 51 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 51 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0524
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0132
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 56 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 56 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0499
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0284
============================================================


============================================================
🔄 Round 58 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 58 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0699
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0352
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2409, R²: 0.0667

============================================================
🔄 Round 60 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 60 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0576
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0393
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2409, R²: 0.0667

============================================================
🔄 Round 61 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 61 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0645
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0203
============================================================


============================================================
🔄 Round 63 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 63 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0365
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0813
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0667

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 63 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 77 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 77 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0446
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0394
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 78 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 78 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0525
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0040
============================================================


============================================================
🔄 Round 79 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 79 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0515
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0154
============================================================


============================================================
🔄 Round 81 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 81 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0476
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0506
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

📊 Round 81 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

============================================================
🔄 Round 83 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 83 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0476
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0493
============================================================


============================================================
🔄 Round 84 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 84 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0425
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0681
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 84 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

============================================================
🔄 Round 86 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 86 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0529
   Val:   Loss=0.0950, RMSE=0.3083, R²=0.0317
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 86 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

============================================================
🔄 Round 90 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 90 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0523
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0098
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 92 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 92 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0520
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0242
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

============================================================
🔄 Round 94 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 94 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0497
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0410
============================================================


============================================================
🔄 Round 95 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 95 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0528
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0157
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 100 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 100 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0525
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0297
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

📊 Round 100 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

📊 Round 100 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

📊 Round 100 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 104 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 104 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0394
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0825
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 106 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 106 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0533
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0281
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2407, R²: 0.0671

============================================================
🔄 Round 108 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 108 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0532
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0229
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2407, R²: 0.0671

============================================================
🔄 Round 109 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 109 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0478
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0435
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2407, R²: 0.0671

============================================================
🔄 Round 111 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 111 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0503
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0020
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 116 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 116 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0519
   Val:   Loss=0.0662, RMSE=0.2574, R²=0.0157
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2407, R²: 0.0671

============================================================
🔄 Round 117 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 117 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0513
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0325
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2407, R²: 0.0671

============================================================
🔄 Round 120 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 120 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0492
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0145
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2407, R²: 0.0672

============================================================
🔄 Round 121 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 121 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0374
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0804
============================================================


============================================================
🔄 Round 123 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 123 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0529
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0285
============================================================


============================================================
🔄 Round 124 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 124 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0498
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0423
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2407, R²: 0.0671

============================================================
🔄 Round 126 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 126 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0383
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0868
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

📊 Round 126 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0670

============================================================
🔄 Round 129 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 129 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0674
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0384
============================================================


============================================================
🔄 Round 131 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 131 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0366
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0838
============================================================


============================================================
🔄 Round 133 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 133 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0454
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0563
============================================================


============================================================
🔄 Round 135 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 135 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0553
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0057
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0667

============================================================
🔄 Round 137 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 137 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0636
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0124
============================================================


============================================================
🔄 Round 140 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 140 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0565
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0175
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 142 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 142 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0391
   Val:   Loss=0.0674, RMSE=0.2596, R²=0.0773
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 143 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 143 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0407
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0752
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 146 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 146 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0394
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0805
============================================================


============================================================
🔄 Round 147 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 147 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0366
   Val:   Loss=0.0672, RMSE=0.2592, R²=0.0925
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2408, R²: 0.0669

📊 Round 147 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 154 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 154 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0617
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0169
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 155 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0624 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0624, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0624, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0624, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0624, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0624, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0624)

============================================================
📊 Round 155 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0392
   Val:   Loss=0.0624, RMSE=0.2498, R²=0.0908
============================================================


============================================================
🔄 Round 157 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 157 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0444
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0510
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

📊 Round 157 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0667

============================================================
🔄 Round 160 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 160 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0532
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0186
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0667

📊 Round 160 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0668

============================================================
🔄 Round 164 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 164 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0512
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0231
============================================================


============================================================
🔄 Round 166 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 166 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0358
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0950
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2409, R²: 0.0666

📊 Round 166 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2409, R²: 0.0666

📊 Round 166 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2409, R²: 0.0666

📊 Round 166 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2409, R²: 0.0666

📊 Round 166 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0667

============================================================
🔄 Round 173 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 173 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0475
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.0464
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2408, R²: 0.0667

============================================================
🔄 Round 174 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 174 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0561
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0055
============================================================


============================================================
🔄 Round 177 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 177 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0402
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0681
============================================================


============================================================
🔄 Round 178 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 178 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0490
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0411
============================================================


============================================================
🔄 Round 181 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 181 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0508
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0300
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2409, R²: 0.0665

============================================================
🔄 Round 182 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 182 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0566
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0031
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2409, R²: 0.0665

============================================================
🔄 Round 184 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 184 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0504
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0388
============================================================


============================================================
🔄 Round 186 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 186 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0429
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0598
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0663

============================================================
🔄 Round 187 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 187 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0441
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0314
============================================================


============================================================
🔄 Round 188 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 188 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0488
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0305
============================================================


============================================================
🔄 Round 189 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 189 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0412
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0605
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0663

============================================================
🔄 Round 192 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 192 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0416
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0707
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0663

============================================================
🔄 Round 194 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 194 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0537
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0261
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0663

============================================================
🔄 Round 199 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 199 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0636
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0198
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0662

============================================================
🔄 Round 202 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 202 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0398
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0757
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0663

📊 Round 202 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2410, R²: 0.0662

📊 Round 202 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2410, R²: 0.0661

📊 Round 202 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2410, R²: 0.0661

============================================================
🔄 Round 206 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 206 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0389
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0820
============================================================


============================================================
🔄 Round 207 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 207 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0536
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0241
============================================================


============================================================
🔄 Round 208 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 208 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0523
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0309
============================================================


============================================================
🔄 Round 209 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 209 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0542
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.0137
============================================================


============================================================
🔄 Round 210 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 210 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0611
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0210
============================================================


============================================================
🔄 Round 211 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 211 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0427
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0666
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0663

============================================================
🔄 Round 213 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 213 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0538
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0219
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0663

============================================================
🔄 Round 214 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 214 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0568
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0057
============================================================


============================================================
🔄 Round 215 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 215 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0431
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0656
============================================================


============================================================
🔄 Round 216 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 216 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0576
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0054
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2410, R²: 0.0661

📊 Round 216 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2410, R²: 0.0661

============================================================
🔄 Round 219 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 219 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0596
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0030
============================================================


============================================================
🔄 Round 220 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 220 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0491
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0428
============================================================


============================================================
🔄 Round 221 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 221 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0432
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0571
============================================================


============================================================
🔄 Round 223 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 223 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0471
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0490
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2409, R²: 0.0662

============================================================
🔄 Round 224 - Client client_78
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 224 Summary - Client client_78
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0435
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0663
============================================================


❌ Client client_78 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
