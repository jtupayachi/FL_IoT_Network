[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eca220d-59f8-4562-a707-0a1254b149c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1275eaa-ade6-4860-9817-cdb66da5080d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46652e09-dea2-4c06-a97d-4d48ad6f6cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c746a34-39c4-4567-bfbf-d9735d522067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c109dddc-bde3-4587-bab8-6a359242440e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef9088aa-f194-47d8-8cba-7530bf376146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c06f13d-9a80-4767-9052-b21178eba931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9786ad47-12ec-42d9-96c4-58805b27232f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de779765-8b0c-4678-a628-6f55716ba570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd0ec2c8-b378-487b-a040-13443db145cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f06a174-be0b-450a-9e2f-3965d9abc14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d5a6eb-22b0-40de-8974-dfcc7c51e9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234e086a-d51d-43f3-9948-79de5ba6a398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7bbe42e-df03-4df0-8347-0fe1ca54798f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413d1701-096b-4a49-a96e-2920a8809945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b4e5ec-5be6-48f6-bf21-415dc97b8b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35b6f929-40d9-4595-a43d-eb00cad50640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b671c537-8686-4780-9376-e7cd0f0f8eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c02d85c5-aa19-46ae-9400-a4e24a30645b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baea855c-ef76-4ddc-a696-0bba3f8779f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e86e6a9f-dcb9-49a5-8b5e-d321342cd7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ceff75-98b7-4924-8d0c-5ae1d305531c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e165c7-df23-4db3-bdd9-5578321b60cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 903f4b11-ab52-4ad4-a423-6e436cdc1b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74875c2-628f-45b0-9f32-a44a7239128e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8becbc-2bdc-4d01-8cec-84064aad4dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a377b72e-33d8-4f12-b59b-0b647073d9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bc2b4e3-6d92-403e-ac8f-435802e86b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 185f2e2e-cc0b-42d5-94a4-50db545ecf22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e5a063-c437-4f90-ba3c-92b8ed71b47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77967832-ca52-44d8-b794-c3c4cfd100a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41de4128-0f45-43c5-b05f-9ec9072fd9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d5ca2be-1b6c-4e2a-a875-d9c84670b2a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc85ac2-e25e-4893-a0c5-88cafbde56b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4483e852-5a79-43df-9299-74d12ab2a743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 786c13e8-d503-4832-a0c8-0c4b6820c6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264fe984-8ba1-417e-8457-89d1b8c85712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2254ee33-edc5-4c1d-88d8-cbb5198f8aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19370553-2024-4a0d-99ac-42ea40af17e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f26bac-ebfd-4a3f-a525-832ac35460a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cafa7f6c-cc2a-4722-92a0-49847a3d5de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206f4c65-0dd7-4e0f-9003-f44f21d68026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57cdd5b7-7c83-4472-b059-994f852f9867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b9d44d-3eff-4a50-88f5-9bdef7abd1ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 929eb469-60a5-4e01-8607-c7cd866f5739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e168b6f1-8ec1-45be-919f-30b9b8f9db54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93cfee46-c24f-4274-8cdd-2b66a4387061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a52be76-ac9e-4898-8b02-ff43942a6c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecbd9ebe-0cf5-47f1-b5f6-e8417c645d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa119ff5-a6e4-4d0f-b7f4-663fae59df01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea072b94-b11a-4911-9680-f60f6bdd19d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1290ddb8-065e-4aae-8039-5bd2d09b06ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527c9559-296a-4c16-af71-1b1b6adddeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 282b9e00-4827-45e3-9632-1c905ea17510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5198bd18-08de-40c2-8037-2f919b59e93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35795019-d1c6-43e9-9bb7-7127456eece0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df280169-dd01-4471-8ed2-8e7c7e57b564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87509ef2-2453-4246-aa2e-debd3fdd37fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43af3b54-7671-4083-b880-1d1eebe9e585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa118edd-0c31-4cd1-8faa-aae08d9babe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 303dfbae-a04f-4c59-9902-ed25bc35cd00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62ac8b7e-48d9-4a8f-b43c-19276ca2ea9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ca1652d-6972-401c-8a14-d66c9ce4a37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30309847-b51a-4738-8b95-ba2b9973a106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd1c235-8cb9-4ead-8b9c-7ac63f134a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e390e565-e015-4397-bfdc-a44cbf62ed2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e09f482f-a3ec-4b06-a574-033faa2c7b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd3f154-8dc2-4393-9076-4e738d773c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e74cfb10-9707-48b3-986f-c10eeecfe3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9a998d-53df-4ca9-8761-b2037723a21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e38b63b2-e84e-4224-8ab8-553d89caf79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fba7b6b-e299-412a-b304-d60262fe9956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80889c8c-c8d0-4faf-92a3-733796c552dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17179d35-ae43-4497-9c94-cc4396a71f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52fe16e0-0e11-448a-8407-0fbd631dadda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9207a2a-c112-4e6a-b93b-ad2d2d6811f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e0c6461-8a62-4854-ac42-ff24f824231b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60a1c8ca-8531-4c16-9487-eb443d23f3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83d9f07c-628b-4d49-ad1b-9b1b383df2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee7ddd52-8edd-4191-aaa4-f36ab10dbfd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4838861a-cefc-4880-aa4d-022e453820ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f1abe1e-8f9f-4cec-86af-0fd7406c66ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 569b7beb-0ed9-47c0-9c52-fb97c83dc76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37a20b1c-fed5-4074-8d33-5499402f0609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3400fbff-9ccb-446f-8046-b49d7f60411a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44616304-221f-4f28-9654-5a3079a72acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51740ee-81d8-4e99-9146-949507e3c33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4bef2bb-2f9e-4d8c-a716-46041eb9b300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed74169c-74a5-4067-b154-45721bb1d60a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a9db48d-25c5-4d8b-b59f-301f48738fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6875a61b-f229-4abb-bbef-9435fb7a8c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee686ba-37df-4db6-abb6-f5c63dd63655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e6d325-699d-4730-8e1b-99d2fe652689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fee9bf4-e2a3-4a9f-b3a7-c5b68e95c04c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921b0fb2-46aa-4e8d-bc10-13655967e738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cca2377-c05d-408d-afaf-5c1eaf29d890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d42e63a1-d478-40f0-aa07-1418c7ec354f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d4827c9-7173-44c8-890c-ef611c9d2344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffcf48a3-2149-4575-84e0-844b389127b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49a16463-2112-40fa-89e6-84edd6d61141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a1cb68-810e-40ce-94bf-08e39baa6a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84194989-a9ed-4068-9b8a-f24a2f61b995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dff67430-b69d-4a90-affb-7307d0733010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 355da1e7-8e87-4705-8a18-1dd0fc532b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fecf2a6-2c6b-41b2-94ab-f4b61c39c1a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da519a8d-6497-43f1-8276-9090985fb74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3742a2f1-798d-4b64-9f2c-e5b4cafb9eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 425cdd64-938c-477b-b274-b9c84120c76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35bda95c-8981-409f-97b7-0ab04ac6824c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b822ac84-fd0d-44d7-bf4d-938a5d75139a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a2cbff-a050-4034-aee2-be0eaa849f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eac929c-1079-4c59-a324-3e25e802effe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b2ff60-431f-4d54-b1df-991ed555dee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb028b3d-38a2-4b42-8996-86cdc9d0b2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e6213c-7c84-41ac-b1fc-de5443a17cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea6efe51-498a-458f-97a6-4bc67198536c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e321df4-7dbb-4c7f-9db9-46747aabbb19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b5edd59-6343-41bf-9840-39e42b96ce38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64596f35-a1df-483d-94f9-ba8daea3dc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf203a5d-8f13-4592-a769-fef74cca2e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a6359fb-a6fd-4187-8a1d-e77300efe06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1823ce42-2840-49a6-ad4d-e5db08be5a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d51ea6-b904-4a9f-94bd-bd93a87ba936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444f2881-4c28-4fb2-9dd1-29041da859c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed8cece-f278-4648-aec5-61ffb984ae9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aad3898-cf4d-4b90-b839-f30549ef85e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa8bea8-2d93-4f28-84dd-e9f82d7b8c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d3b6aa-ac9a-4312-ad7f-7936cb120237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d254c8-5927-445f-bd8d-efaf003adbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d3b45c-70f3-451b-bce6-0fa080ec4a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59f2846b-0014-4cde-b0db-fae87bb48473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69eeee53-5d4c-4c4d-ae91-77b94722565c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a45f4111-459f-4b5d-ade6-47975570b3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 682c3097-3602-4cdd-a82b-3cd6b03c7315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6653231e-f2c5-4f2b-8a7e-f24525be0970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac5c5a10-4406-4a15-a5eb-cb63875d30a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90882e2-afd8-451e-b44d-380dc282dc1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a5c98c-2953-4d22-802b-547ae9b3f92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d55de4-25fc-4a37-b49d-2510c99de89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 887914e1-bb01-401b-82e2-c27a5b92f5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53583b3e-7103-4474-a34f-36fc08c6a6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd8e8ea-7959-4f83-be32-9d4ce0e9fdca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027bdea6-8b51-46fb-90ef-83a0f5ba8781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1df62b6-2a6e-4496-9ca4-3d1cebc69cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94abf697-75bd-4392-887c-ee701cb1ee88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da58a1c7-3347-4cfa-8efc-9b065dc0e646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae7e843-a284-4f1a-9d19-c822fa386119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32345efc-5412-4c19-972f-48bb7ad4f988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6124b6-0a22-4e21-a634-4c772dd6432b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd5b866-7e45-44d1-a351-fb09e5498cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39a6f59e-95fc-4145-bcaa-f5de75c2d991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fac5a909-95f8-4229-8a56-80e9e8ad6372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbadf51e-e671-4246-b4e7-4ce6df10dfef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c6dbc93-9b5c-4e46-a231-d3f9b2333caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6454f51b-a97b-4128-9bde-9b1d33014f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a1097b-6e63-4cae-a5e6-e2f90b39a3d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad76165-1a2d-440c-82eb-b673b84956d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be853d4-2458-4fe0-a295-c741daa14c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df65ce38-6275-491f-97b6-e1896eb1ae2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b6c656-7e76-4951-ac80-0f51e1c318d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d799996-4147-4721-b0d7-e4a9ff8d43dc
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_79
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_79/test_labels.txt

📊 Raw data loaded:
   Train: X=(1288, 24), y=(1288,)
   Test:  X=(322, 24), y=(322,)

⚠️  Limiting training data: 1288 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  313 samples, 5 features
✅ Client client_79 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0035

📊 Round 0 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

============================================================
🔄 Round 8 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0731 (↓), lr=0.001000
   • Epoch   2/100: train=0.0837, val=0.0740, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0835, val=0.0736, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0830, val=0.0738, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0740, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0755, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 8 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0199
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0052
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2480, R²: -0.0021

📊 Round 8 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2485, R²: -0.0047

============================================================
🔄 Round 13 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0865 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0823, val=0.0852 (↓), lr=0.000250
   • Epoch   3/100: train=0.0819, val=0.0851, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0817, val=0.0848, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0847, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0806, val=0.0840, patience=2/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0800, val=0.0836, patience=12/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0798, val=0.0835, patience=9/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 13 Summary - Client client_79
   Epochs: 37/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0262
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0347
============================================================


============================================================
🔄 Round 14 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0818 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   • Epoch   2/100: train=0.0828, val=0.0819, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0827, val=0.0819, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0827, val=0.0820, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0826, val=0.0820, patience=4/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0824, val=0.0821, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 14 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0054
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0095
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0048

📊 Round 14 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2484, R²: -0.0046

============================================================
🔄 Round 16 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0820 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0831, val=0.0819, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0831, val=0.0819, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0831, val=0.0819, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0830, val=0.0819, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0830, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 16 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0037
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0205
============================================================


============================================================
🔄 Round 18 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 18 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0035
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0012
============================================================


============================================================
🔄 Round 21 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 21 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0026
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0128
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0035

============================================================
🔄 Round 22 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 22 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0040
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0165
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2482, R²: -0.0035

============================================================
🔄 Round 28 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 28 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0075
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0242
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0032

📊 Round 28 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0032

============================================================
🔄 Round 33 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 33 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0008
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0097
============================================================


============================================================
🔄 Round 34 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 34 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0042
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0237
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0032

📊 Round 34 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0032

============================================================
🔄 Round 42 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 42 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0026
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0443
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0032

📊 Round 42 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0032

============================================================
🔄 Round 45 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 45 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0075
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0164
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0031

============================================================
🔄 Round 46 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 46 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0015
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0140
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0032

📊 Round 46 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0031

📊 Round 46 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0031

============================================================
🔄 Round 50 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 50 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0059
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0133
============================================================


============================================================
🔄 Round 51 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 51 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0004
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0128
============================================================


============================================================
🔄 Round 53 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 53 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0057
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0002
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

============================================================
🔄 Round 57 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 57 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0053
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0152
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2480, R²: -0.0030

============================================================
🔄 Round 61 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 61 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0068
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0193
============================================================


============================================================
🔄 Round 62 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 62 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0012
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0028
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2480, R²: -0.0030

📊 Round 62 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2480, R²: -0.0030

📊 Round 62 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

============================================================
🔄 Round 67 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 67 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0019
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0145
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

============================================================
🔄 Round 68 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 68 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0005
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0048
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

📊 Round 68 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

📊 Round 68 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

📊 Round 68 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

📊 Round 68 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0029

============================================================
🔄 Round 75 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 75 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0064
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0187
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

📊 Round 75 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0029

============================================================
🔄 Round 78 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 78 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0046
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0124
============================================================


============================================================
🔄 Round 80 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 80 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0024
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0167
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2481, R²: -0.0030

============================================================
🔄 Round 83 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 83 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0008
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0089
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0029

============================================================
🔄 Round 84 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 84 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0088
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0275
============================================================


============================================================
🔄 Round 87 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 87 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0059
   Val:   Loss=0.0985, RMSE=0.3138, R²=-0.0327
============================================================


============================================================
🔄 Round 90 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 90 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0025
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0041
============================================================


============================================================
🔄 Round 91 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 91 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0009
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0033
============================================================


============================================================
🔄 Round 92 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 92 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0007
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0032
============================================================


============================================================
🔄 Round 93 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 93 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0021
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0051
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0028

============================================================
🔄 Round 94 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 94 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0098
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0261
============================================================


============================================================
🔄 Round 95 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 95 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0016
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0201
============================================================


============================================================
🔄 Round 98 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 98 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0072
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0076
============================================================


============================================================
🔄 Round 99 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 99 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0049
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0141
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0029

============================================================
🔄 Round 102 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 102 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0102
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0077
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0029

📊 Round 102 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0029

📊 Round 102 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0029

============================================================
🔄 Round 105 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 105 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0063
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0499
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0029

============================================================
🔄 Round 106 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 106 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0035
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0577
============================================================


============================================================
🔄 Round 107 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 107 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0014
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0255
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0029

============================================================
🔄 Round 109 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 109 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0043
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0273
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0028

============================================================
🔄 Round 111 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 111 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0064
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0540
============================================================


============================================================
🔄 Round 112 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 112 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0066
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0343
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0028

📊 Round 112 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0028

📊 Round 112 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0028

📊 Round 112 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0028

📊 Round 112 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0028

============================================================
🔄 Round 121 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 121 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0024
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0049
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0028

============================================================
🔄 Round 126 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 126 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0104
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0263
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0027

📊 Round 126 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0026

📊 Round 126 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0026

============================================================
🔄 Round 133 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 133 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0066
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0197
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0026

============================================================
🔄 Round 135 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 135 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0066
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0045
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 135 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 135 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 135 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

============================================================
🔄 Round 139 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 139 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0059
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0070
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 139 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 139 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

============================================================
🔄 Round 142 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 142 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0050
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0148
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 142 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 142 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 142 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

============================================================
🔄 Round 146 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 146 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0054
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0180
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

============================================================
🔄 Round 148 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 148 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0027
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0002
============================================================


============================================================
🔄 Round 149 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 149 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0044
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0022
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 149 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0024

📊 Round 149 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0023

============================================================
🔄 Round 157 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 157 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0015
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0004
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0023

============================================================
🔄 Round 160 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 160 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0033
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0233
============================================================


============================================================
🔄 Round 161 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 161 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0016
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0007
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0023

============================================================
🔄 Round 164 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 164 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0000
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0116
============================================================


============================================================
🔄 Round 167 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 167 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0068
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0022
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0022

============================================================
🔄 Round 171 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 171 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0020
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0006
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0021

📊 Round 171 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0021

📊 Round 171 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0021

============================================================
🔄 Round 178 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 178 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0013
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0114
============================================================


============================================================
🔄 Round 179 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 179 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0031
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0301
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0020

============================================================
🔄 Round 182 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 182 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0002
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0044
============================================================


============================================================
🔄 Round 185 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 185 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0020
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0139
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0019

============================================================
🔄 Round 187 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 187 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0022
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0021
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0018

============================================================
🔄 Round 191 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 191 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0010
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0115
============================================================


============================================================
🔄 Round 195 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 195 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0011
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0297
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: -0.0017

📊 Round 195 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: -0.0017

============================================================
🔄 Round 198 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 198 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0033
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0221
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0017

📊 Round 198 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: -0.0017

📊 Round 198 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: -0.0016

============================================================
🔄 Round 208 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 208 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0064
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0354
============================================================


============================================================
🔄 Round 209 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 209 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0003
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0085
============================================================


============================================================
🔄 Round 210 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 210 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0048
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0279
============================================================


============================================================
🔄 Round 211 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 211 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0114
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0296
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: -0.0016

============================================================
🔄 Round 212 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 212 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0036
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0230
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: -0.0016

📊 Round 212 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2478, R²: -0.0016

============================================================
🔄 Round 215 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 215 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0013
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0111
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2478, R²: -0.0015

============================================================
🔄 Round 219 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 219 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0005
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0181
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2478, R²: -0.0015

📊 Round 219 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2478, R²: -0.0015

📊 Round 219 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2478, R²: -0.0015

============================================================
🔄 Round 222 - Client client_79
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 222 Summary - Client client_79
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0058
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0048
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2478, R²: -0.0015

❌ Client client_79 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
