[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a36cba-a540-434a-9a88-926684dba470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ca82cd-55a8-49e6-b340-b35729d1a7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40c45511-45b2-48d3-b5c4-79208f047986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a17f8ac-112c-4405-b3f3-eebf901e7c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69fd3be0-16cf-4225-bd25-27c25afe7f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2d75c71-4ba5-484e-a0d3-c6266e0245a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b58321-447a-44d3-a94a-bd35f236eb71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b236952-aede-4f67-8b0c-a449449c5754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b6b9c8c-e61c-4a29-bce4-2d347d38827d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d0c3e83-36d6-43f6-bb0a-80003adfc218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979c8222-776b-42e3-9c78-749c7944a90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1acafa31-b938-4dd3-b2d3-11b6c583ccd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88429e1b-8678-4634-b1f5-4af47c185afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e702a7-6d46-44ce-ac9f-e73851eec2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e5ad4d-5a87-44dc-a27b-123efde76bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40fe318b-9715-4939-9706-181811147a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a55ba942-c94e-470e-a31f-20b43704b2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff504323-54b1-4efe-9a44-e40c9f460ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e694c010-42de-43fa-bdce-3dbd4cc6255a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c37eb22c-33d8-4026-9718-970ef21eaeac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f55729-7abb-4687-a0a5-077b5d429693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33e53a46-1426-41a2-bd38-b4f7deafc0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f017c2-63eb-4b95-bf12-ccd5c99d0b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a73cec-354c-419a-b40a-151e406cabb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b13a76c-cf18-42b9-b0f2-10752b4839ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aaec2d6-f411-4fa2-9956-e6bd910b6ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f023a35-80c7-4196-b9c0-3b171abd0590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50da1a26-1d0c-4e0a-9cd0-5806fb2bd8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f1df54-c09d-4b24-b847-365a9af1b7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6956b812-abb3-4c09-a4ca-0dd99c2ef6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e3dda6-2fe8-43ae-8e23-04d5e374d90a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb72ddc-6228-46cb-aedd-a1424076a592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be954d3-1916-4ad3-ace0-53ebb3e064e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4cb1938-33fc-464c-a891-05f6651dafdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ddfa33b-89be-42ad-b3b9-cf7ca8d8be4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a25d136-4d4c-4fc9-b7f1-f5795394e12d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 821b9c54-3630-4fe5-a8fa-470fc9893258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee546fd-0b4e-4e85-8c89-e9cd194cb41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d32a65dc-831b-4485-b77a-a7aa761021d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b58237-2be0-4d08-becb-03a66a2c1ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e68479ca-9ee2-4fb2-b4e2-aad205ab69ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5563a718-f937-4ed4-8739-aeecd1cd1ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8802aa4d-71e0-480f-8cc4-3ad579cb81af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95466d2e-0c5a-406f-a9fc-2e4e47512bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3035d4-ed5c-4e90-b116-c68aaa455748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67fa5a21-e42d-4a58-8920-24adcbafec51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd5123a8-366b-43d5-a59d-10dc3dd12e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b48f3ff-9ddf-45a2-bb9a-777d3d20996a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f1e55c-3da4-463d-9e4a-a4024a22e46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c988e991-5681-49c9-8fc1-d7b109dc4a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c53e8798-d483-4f7b-85f9-a982ae0e0576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4580919f-18da-4ecf-a9dd-7810af1b0fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca4a3bc-e0f6-4df6-9451-eabc7b5f18d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b841a07-257e-4c47-9c01-5b5b1abeee01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19bebdea-ea15-4339-a4a9-6cfb12ed2afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97d2282c-5ddd-44c0-8009-f3a1b5d65d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e30536-722c-4778-910f-cad21d934686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7617a1d9-5463-4731-a32e-d9faaf3af48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4468d60-8a84-46a4-9204-dbdc1f060bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7dad47-9169-4bfc-b514-d441ec273018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e8c651a-8d94-4799-af55-358a9be71e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea30561-2f70-4c28-a960-9aa0bf9dc807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a07256a-0981-417f-b2ed-439a3aac4f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce610690-a800-48fd-84b6-de2fd9944653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce13f1fb-6894-41ff-8ff5-d1822a241fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d11a99-fa98-4eb9-a047-929a9be2d200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee28e3b-c21c-47dc-ad7d-94b530567932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff37799a-0599-4abe-b658-b4e656148e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa0db48-8bec-4462-9c30-70903fc4fe46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7517b26-060e-4006-908c-6d43f1423998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2215c96-1f3a-4640-9c87-c488593ffbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a53c2c6-d8ff-4446-a01d-3d61aade5954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f40a510b-c0cc-4782-8196-219b20dd8bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4295b4bc-2dbf-49e6-a53f-92977615faef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c71a29ce-4af1-4f95-b01a-64aeb156e6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c768fe-dc29-4f6c-a279-e5d0fc0e3a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0f719f-c255-4fd4-a55f-a9e39a8eee1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66f0f740-0a14-47d8-ae07-9219b4d59021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6833574d-9c39-46be-93ce-1456cb10504e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa87326-e5db-4ca2-bd5e-0a88fe3497d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a173e90-cf7d-4b52-9b40-27cb31698bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f31b33b-a525-4337-b0ab-71c248c70e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 242abf80-7226-44f3-9dbf-4661cd57be94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a3e1f6-bf87-48a0-bfec-c2b9bf2beef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b945fad-a2d7-4f7e-a1f9-aead6902b225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403d5853-45cc-4364-85ca-2a9be2dc92e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10435ea-7ef2-4aca-9cff-133d0a63fb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a99813-d2cf-4bb5-9eac-12d43f84f8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35cfedb3-4d3e-4a6c-a556-1015e4c27bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d511614-71b6-42c1-a388-49ddd6b9db39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce0e32a-0a7d-4f5e-92ef-897ddff63594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bae8895-fcec-42d0-9b5c-a5b73548d879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34f9000c-b6dc-4940-a479-7f9a1e214e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7f8eeae-4976-45d6-8888-6e0f8273c759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba395aa9-e298-4023-82cb-c32075d09dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f22a4b-f0ba-4b11-bd1b-8c1cc83df505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69f228c-4a75-4616-b07c-2f68786c7b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a79031-e026-475c-b71f-2a304e8d3444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2647933f-f898-410c-b2b2-9ecde1e9e2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 652f4470-a5ec-4691-80ce-80d9acdc85f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdedf2e4-3691-498b-aa3e-2ca9ce9e67ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e728f815-204e-4ee7-b846-a8ad72dd7e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70171b07-7838-47ad-ac18-8a23235bcdbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d52347-87d7-4200-989b-73f037f7bd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87512bd3-eaf7-4a4a-855a-efa8de20f9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6451d130-c688-4fd2-9233-b1573c92046c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e878d459-2d43-46cf-9dd2-f6caee2cf14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94914f26-2cd1-446c-a4e1-677f3d0edfdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35767994-28ca-4025-897d-5cc8e455b0f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a786365-4fb0-4d73-9a14-0f66c9c71a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a28a7c9-7dbe-4294-80cc-c95de433d02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52e59cfb-112d-4590-b4db-080fc7ad19a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 657f675c-36fb-4a41-bfed-dc7b48ce0509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e56c86d-f493-4f1a-9a66-828d8bffe01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6d4c7d-453f-4d1f-b1e3-0a9d7fe53506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b8b465a-b399-4328-9acd-f23378435cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04e4bc7a-05b9-4deb-b25b-7e402e98df3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cb90220-c77b-4938-8b4e-c6734757eaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e5ed562-bf9c-45b8-87c7-93983d2c2e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9826b8e-8beb-4a43-9d75-147ba09fd9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57ac6be-1510-45d3-8a1b-a70682b04a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de6547f-0043-4cd7-88c7-4598d4afd460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bee1a42-8832-413c-a44e-ba6d3bfef42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7b54dbc-e784-4e7b-a606-1965e50cfcad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f2c8eb-cc0e-4326-ab1e-4bb8cc745c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4776c8-cf87-40e0-9e6c-0a59f2f7daf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d54c2c-1566-4c08-a7d9-92f39eed1061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 659776f0-0e68-4f80-9d60-2ee4318c2668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a483da83-9cfa-4297-b84a-6d97adb1e9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac4cd3f0-33ba-446e-9304-68259435c1c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040c97e2-1a77-4001-a38f-d1268980e4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abb7fd3c-6950-4851-99b8-172560ba37a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ed2587-5643-496b-acf3-d81d2a60c670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 668ec0a1-18ff-462b-8f02-23eb79403263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ebd7624-17c0-40a8-9550-da39ccb1ceb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b37db24-7c3d-44ac-baf6-99b4876a40b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4766d88-e336-4251-99c2-6875fc046e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61105db1-f8f8-4626-bc28-1eb031184ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c42d60-1f97-4cbf-bd3a-46ef7a061d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43cfc8ee-0c6b-4ba2-8c8b-bd50985209be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53fb50c0-79e3-4aa2-9983-5668193d69a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73d0121-0f50-45a5-8188-03a4f14343da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72365ae8-ca27-4341-9fe8-016810285d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33ad71de-3c7f-468d-9f26-5f2c856f6027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d93bf229-5962-4a41-a459-439764e7ced2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b30e6cee-b915-4439-b072-ba9f62906030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 153a1cd0-6fe0-43cf-b894-473ee648b0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9500821-0564-40a1-893b-78ad80f2390c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c4e313-6875-4fb4-9840-e725b8ac2083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 248f53e2-5eff-4998-b579-0044441b465f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7b4c4ec-9757-4c50-aea2-06b94896173d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8870f09d-f1ee-4f7c-be62-25d6332d2344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59f6b981-2ea0-4237-8db6-ed738a035cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7700ba7f-5ab8-4c56-b2cd-53a3b9b262db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18d34cf-35a5-4a49-aabe-bc71513ffdd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef9aa27-db65-461c-ad69-bb08f4a75683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e92510-0526-4146-99a1-6304c9732732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f96ff69-af3b-4d89-a80b-ff8f77da89da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66d07a9-e347-4c2c-98d4-f3632e7d9013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc9ef78-9450-403a-b9da-fd5bf886ff6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f174463-d4fe-4afc-976d-22c7c2f66e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f44b1de-6430-4075-8b80-ba513ea00172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9248087-0a1a-40a4-87ba-81ad921f95ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2023b903-ab23-4ea9-8d15-d05f2f5899f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a05bda-42ef-46ad-a3fe-dca022326c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51e0624a-e925-4167-b631-5c499b7e9de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d23d45a-9526-4099-b40f-11723ee5ce43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2f7577-0c43-48a1-9ca4-6a2f7021ce88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b96069-b97d-4f83-87fc-2afd1d6b3778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa72d2ca-5332-4755-84d4-c5fec76e4ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c1ef65-504f-46e2-b198-825edbe55c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a65330-841b-42e1-8d94-9bb01c4a8647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e852f746-0375-4e04-91e2-a4689780a9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecbfeb6e-4f3e-47f8-901a-d2e967fe9dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93d1feb7-042b-42d5-a2eb-670a919d2600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0350d79-55c5-4467-81e2-c1a1979f1abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b8df8a6-29db-4014-9ac1-15c02303fc17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02eed8ef-32db-4df4-8a79-4cf9c8a26641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f54056-394e-475e-8a84-6d25d6ccd4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da48d121-f989-4a63-8966-b8225a94b5eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f83e76f0-3917-443e-8050-33f6e51c6486
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_7
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_7/test_labels.txt

📊 Raw data loaded:
   Train: X=(1690, 24), y=(1690,)
   Test:  X=(423, 24), y=(423,)

⚠️  Limiting training data: 1690 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  414 samples, 5 features
✅ Client client_7 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2479, val=0.1011 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0924, val=0.0890 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0827, val=0.0869 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0817, val=0.0853 (↓), lr=0.001000
   • Epoch   5/100: train=0.0809, val=0.0849, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0797, val=0.0842, patience=5/15, lr=0.001000
   • Epoch  21/100: train=0.0780, val=0.0833, patience=2/15, lr=0.001000
   • Epoch  31/100: train=0.0743, val=0.0812, patience=1/15, lr=0.001000
   • Epoch  41/100: train=0.0655, val=0.0830, patience=7/15, lr=0.001000
   📉 Epoch 42: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 1 Summary - Client client_7
   Epochs: 49/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0711, RMSE=0.2667, R²=0.1377
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0721
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2520, R²: -0.0012

📊 Round 1 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2510, R²: 0.0116

📊 Round 1 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2469, R²: 0.0466

📊 Round 1 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0621

============================================================
🔄 Round 7 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0705 (↓), lr=0.000500
   • Epoch   2/100: train=0.0791, val=0.0701, patience=1/15, lr=0.000500
   ✓ Epoch   3/100: train=0.0785, val=0.0694 (↓), lr=0.000500
   • Epoch   4/100: train=0.0781, val=0.0690, patience=1/15, lr=0.000500
   ✓ Epoch   5/100: train=0.0779, val=0.0685 (↓), lr=0.000500
   • Epoch  11/100: train=0.0766, val=0.0669, patience=2/15, lr=0.000500
   • Epoch  21/100: train=0.0745, val=0.0657, patience=4/15, lr=0.000500
   📉 Epoch 27: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0712, val=0.0665, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 7 Summary - Client client_7
   Epochs: 32/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.1159
   Val:   Loss=0.0659, RMSE=0.2566, R²=0.1574
============================================================


============================================================
🔄 Round 8 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0714 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0789, val=0.0709 (↓), lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   • Epoch   3/100: train=0.0785, val=0.0706, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0779, val=0.0705, patience=2/15, lr=0.000125
   • Epoch   5/100: train=0.0778, val=0.0705, patience=3/15, lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0770, val=0.0703, patience=3/15, lr=0.000063
   📉 Epoch 19: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0763, val=0.0702, patience=13/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 8 Summary - Client client_7
   Epochs: 23/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0930
   Val:   Loss=0.0704, RMSE=0.2652, R²=0.0941
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2420, R²: 0.0728

📊 Round 8 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2419, R²: 0.0741

============================================================
🔄 Round 12 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0745 (↓), lr=0.000031
   • Epoch   2/100: train=0.0786, val=0.0743, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0782, val=0.0741, patience=2/15, lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   ✓ Epoch   4/100: train=0.0779, val=0.0740 (↓), lr=0.000016
   • Epoch   5/100: train=0.0777, val=0.0739, patience=1/15, lr=0.000016
   • Epoch  11/100: train=0.0772, val=0.0736, patience=7/15, lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 12 Summary - Client client_7
   Epochs: 19/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0746
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0831
============================================================


============================================================
🔄 Round 13 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0768, val=0.0828 (↓), lr=0.000004
   • Epoch   2/100: train=0.0767, val=0.0828, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0766, val=0.0828, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0766, val=0.0828, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0765, val=0.0828, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0762, val=0.0828, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 13 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0712
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0341
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2414, R²: 0.0769

============================================================
🔄 Round 14 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0765, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 14 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0695
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0532
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2400, R²: 0.0832

============================================================
🔄 Round 17 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 17 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0708
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0716
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2401, R²: 0.0830

📊 Round 17 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2400, R²: 0.0834

============================================================
🔄 Round 19 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 19 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0710
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0650
============================================================


============================================================
🔄 Round 23 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 23 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0702
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0769
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0873

📊 Round 23 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

📊 Round 23 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

📊 Round 23 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

============================================================
🔄 Round 27 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 27 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0716
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0754
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0871

============================================================
🔄 Round 28 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 28 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0646
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.1012
============================================================


============================================================
🔄 Round 29 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 29 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0807
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0352
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

📊 Round 29 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

============================================================
🔄 Round 34 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 34 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0677
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0654
============================================================


============================================================
🔄 Round 35 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 35 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0748
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0499
============================================================


============================================================
🔄 Round 36 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 36 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0781
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0517
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

📊 Round 36 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

============================================================
🔄 Round 41 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 41 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0750
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0502
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0873

============================================================
🔄 Round 42 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 42 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0832
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0276
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0873

📊 Round 42 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0873

============================================================
🔄 Round 47 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 47 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0615
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.1133
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

============================================================
🔄 Round 49 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 49 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0730
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0675
============================================================


============================================================
🔄 Round 52 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 52 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0758
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0591
============================================================


============================================================
🔄 Round 54 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 54 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0701
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0789
============================================================


============================================================
🔄 Round 55 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 55 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0787
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0412
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

============================================================
🔄 Round 57 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 57 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0780
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0484
============================================================


============================================================
🔄 Round 59 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 59 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0801
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0424
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

============================================================
🔄 Round 60 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 60 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0706
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0775
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

============================================================
🔄 Round 61 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 61 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0692
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0798
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0872

📊 Round 61 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0873

============================================================
🔄 Round 63 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 63 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0604
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.1205
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0873

📊 Round 63 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2392, R²: 0.0873

============================================================
🔄 Round 67 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 67 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0643
   Val:   Loss=0.0672, RMSE=0.2593, R²=0.1070
============================================================


============================================================
🔄 Round 68 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 68 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0543
   Val:   Loss=0.0712, RMSE=0.2667, R²=0.1227
============================================================


============================================================
🔄 Round 70 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 70 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0608
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.1226
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2392, R²: 0.0875

============================================================
🔄 Round 72 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 72 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0760
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0590
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2392, R²: 0.0875

============================================================
🔄 Round 73 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 73 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0746
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0657
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2392, R²: 0.0875

============================================================
🔄 Round 75 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 75 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0809
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0333
============================================================


============================================================
🔄 Round 77 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 77 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0899
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0119
============================================================


============================================================
🔄 Round 78 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 78 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0840
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0285
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2392, R²: 0.0876

============================================================
🔄 Round 79 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 79 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0755
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0580
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2392, R²: 0.0876

📊 Round 79 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0877

============================================================
🔄 Round 82 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 82 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0681
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0851
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2392, R²: 0.0876

============================================================
🔄 Round 84 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 84 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0801
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0440
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2392, R²: 0.0876

============================================================
🔄 Round 85 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 85 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0693
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0800
============================================================


============================================================
🔄 Round 86 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 86 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0661
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0993
============================================================


============================================================
🔄 Round 89 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 89 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0775
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0393
============================================================


============================================================
🔄 Round 90 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 90 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0616
   Val:   Loss=0.0679, RMSE=0.2607, R²=0.1245
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0877

============================================================
🔄 Round 91 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 91 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0757
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0432
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0877

📊 Round 91 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0877

============================================================
🔄 Round 93 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 93 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0833
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0271
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0877

============================================================
🔄 Round 95 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 95 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0679
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0521
============================================================


============================================================
🔄 Round 96 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 96 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0723
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0731
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2391, R²: 0.0878

============================================================
🔄 Round 102 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 102 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0731
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0759
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0878

============================================================
🔄 Round 103 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 103 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0732
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0740
============================================================


============================================================
🔄 Round 104 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 104 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0863
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0135
============================================================


============================================================
🔄 Round 107 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 107 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0747
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0604
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0879

============================================================
🔄 Round 108 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 108 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0767
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0612
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0880

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0879

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0879

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0879

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0879

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0881

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2391, R²: 0.0881

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2391, R²: 0.0881

============================================================
🔄 Round 120 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 120 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0716
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0719
============================================================


============================================================
🔄 Round 121 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 121 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0779
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0433
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2391, R²: 0.0881

============================================================
🔄 Round 124 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0617 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0617, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0617, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0617, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0617, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0616, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0617)

============================================================
📊 Round 124 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0601
   Val:   Loss=0.0617, RMSE=0.2484, R²=0.1408
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2391, R²: 0.0881

============================================================
🔄 Round 125 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 125 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0731
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0621
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0881

📊 Round 125 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2391, R²: 0.0881

============================================================
🔄 Round 129 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 129 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.0848
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0386
============================================================


============================================================
🔄 Round 130 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 130 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0615
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.1262
============================================================


============================================================
🔄 Round 131 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 131 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0634
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.1156
============================================================


============================================================
🔄 Round 133 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 133 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0785
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0569
============================================================


============================================================
🔄 Round 134 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 134 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0802
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0479
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0879

📊 Round 134 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0880

📊 Round 134 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0880

============================================================
🔄 Round 142 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 142 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0867
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0277
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0881

📊 Round 142 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2391, R²: 0.0881

============================================================
🔄 Round 145 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 145 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0763
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0659
============================================================


============================================================
🔄 Round 146 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 146 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0778
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0623
============================================================


============================================================
🔄 Round 148 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 148 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0750
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0486
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2391, R²: 0.0882

============================================================
🔄 Round 149 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 149 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0831
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0407
============================================================


============================================================
🔄 Round 150 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 150 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0736
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0777
============================================================


============================================================
🔄 Round 151 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 151 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0805
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0428
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0881

📊 Round 151 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

📊 Round 151 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

============================================================
🔄 Round 157 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 157 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0799
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0484
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

📊 Round 157 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

📊 Round 157 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

============================================================
🔄 Round 165 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 165 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0732
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0811
============================================================


============================================================
🔄 Round 167 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 167 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0725
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0843
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0881

============================================================
🔄 Round 169 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 169 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0716
   Val:   Loss=0.0675, RMSE=0.2597, R²=0.0887
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

============================================================
🔄 Round 170 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 170 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0860
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0282
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

📊 Round 170 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

📊 Round 170 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

📊 Round 170 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0883

📊 Round 170 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0883

📊 Round 170 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0883

============================================================
🔄 Round 180 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 180 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2712, R²=0.0740
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0746
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

============================================================
🔄 Round 185 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 185 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0799
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0492
============================================================


============================================================
🔄 Round 186 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 186 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0742
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0763
============================================================


============================================================
🔄 Round 187 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 187 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0717
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0654
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2390, R²: 0.0881

============================================================
🔄 Round 189 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 189 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0697
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0871
============================================================


============================================================
🔄 Round 191 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 191 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0669
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0839
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0881

============================================================
🔄 Round 197 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 197 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0717
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0884
============================================================


============================================================
🔄 Round 198 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 198 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0802
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0530
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

============================================================
🔄 Round 200 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 200 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0666
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.1051
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

📊 Round 200 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

============================================================
🔄 Round 204 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 204 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0801
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0546
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2390, R²: 0.0881

============================================================
🔄 Round 206 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 206 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0723
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0789
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

============================================================
🔄 Round 209 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 209 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0642
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.1185
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0882

📊 Round 209 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0883

============================================================
🔄 Round 212 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 212 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0867
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0288
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0883

============================================================
🔄 Round 213 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 213 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0672
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.1075
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0883

📊 Round 213 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0883

📊 Round 213 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0883

📊 Round 213 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0884

📊 Round 213 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2390, R²: 0.0884

============================================================
🔄 Round 224 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 224 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0775
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0585
============================================================


============================================================
🔄 Round 225 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 225 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0766
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0702
============================================================


❌ Client client_7 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
