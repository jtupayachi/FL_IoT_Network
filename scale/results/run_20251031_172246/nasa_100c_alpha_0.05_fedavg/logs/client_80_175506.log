[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74629c8a-3f78-4721-a305-c4373478ad31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b2e6f69-6ad7-439e-8cc4-e20b373642be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 082b8565-1a18-4e9f-b496-a1a7fa9c350a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d98f918-0c4a-47d2-a0a7-9d9c2fa7f775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ab42ed5-f44d-4434-8da6-2dfe33c93fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e58851d-69f2-4184-9d49-bdc99d893337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b457fb-fc3e-4a92-ad2d-94446e56dc37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba2da959-825e-4061-a87a-051a1f40d40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67af5d3b-171f-46df-8218-98345ff20942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d4fe6a1-c0da-4aec-931a-096467d5dbfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94dcd37-ef5a-449c-9568-8d031fa6db03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 890753b5-0d83-423f-98b8-58103f1ab44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 307033de-88eb-4e15-b711-99666de1c5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c268d9-3df9-44da-9059-7b6d3ed341da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe65f08-3e86-4d5c-a9d2-5d319b33ec3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49461dd-3721-4b98-9982-4563559fbb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2adc8e9-e9fa-4405-8c28-afdef047115f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13339bbb-d785-4f3c-9d94-dd1dd2c81d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084d2d5d-e04e-4799-97ac-ceb5106b6654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e02aef3-1006-423d-8b0d-92fb0b8818fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5cc4d9-fba3-4734-b00a-45a146f5d5af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d66d73-fc2f-4f15-8071-9aead2624aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e9d505-02ea-43b8-8565-e2860150f683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02cd5d1-59ce-43fc-96b8-14c18af1451f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78de409c-05d2-443c-9d11-4e517d4c0bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71761e5a-6a37-430b-8e60-f4fd33bc548a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c19007-ddff-4e9e-bdb7-d04597149b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf2cc15d-4ae1-4278-ba79-75bf21e9f0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29065a4f-8009-480a-96c6-97820e069e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2130cb00-f216-4138-9cd7-840a2a50ef1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 996f2783-1bf7-48e3-82d2-7c9cbf6fe1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53217ed6-1b21-40b9-b605-d124ab0b8e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05626852-4b97-43ea-be4b-f06c591760ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820af115-f861-4496-a876-4a932345f978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590d0e41-0ab9-47a4-af27-ff6dbfba10d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d7dbaf-bc0f-444c-9601-ed790c131a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3763caa9-f40f-4871-b9e1-6e939a4c37fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5c2c2c-4b78-4626-97f1-9ede9710fc39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c30c312a-b9f5-44b9-9f64-694efccd0b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b192974-bbee-4f10-a463-82f47665f7bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17945948-b533-4aef-a9bf-86c4ac94441e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a7893a-f041-4aa1-80a2-df47a77d4375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982f4700-ad69-4bc9-894b-b09a42067268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9df513-b351-4593-b0c3-d37d250ecf04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e44449e-fa71-4cf0-8896-ddb2ebf4bb18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146a00c9-1b5c-4096-8d97-bf27802de1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a221578-ef1e-48e7-aeb8-d6d8fdd46285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0825ad68-a453-4e89-a852-c8edf990b786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4267915-ba4f-4e88-becc-ad2a5b91b048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e0c7ca-1409-4b90-b035-0124b2e29cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 630dc68d-138e-45a2-a4a9-696b1d3fd08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a02a480-6e11-458c-85f2-dbaa57585ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb1560d-8f5d-416f-bab6-b74e1694e692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d212b02a-8a42-4bde-8b0b-f4f81290a39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2489ed46-ff3c-4dae-9519-1a82a123aa9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943af32f-38a8-4c8c-9c08-ab4c19cc903c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0419e66-e043-42c3-aa56-dd14136d9c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b824220-1ab2-44bb-bebf-c4d53d24625c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f5b95f-0206-4881-9981-954b5ab2d571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db44b9a2-4c61-4b48-9e4f-d7a9996a0f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3a74dff-925d-4001-b5a3-467c22083220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206b62bf-33e6-45bd-8d9b-6a57aa59c2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 824cf6a1-f74d-4929-9df0-5da31c86212f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f6156f-a7ea-4c37-bc7a-12bab9785ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54e5e69-a57c-4fe0-89d4-3577da5acaf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8379eb6-c78d-49cc-b7b0-23dc1636f8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7fe07b-67ae-4ff8-af17-c3adf122b544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea2b3ba3-e3e8-4a6f-95f6-e5ca789dcd7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4358d5d5-c237-44ca-a3e5-ea40c8fbd7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcb67cb2-5888-4b7e-a3cf-bf1719949133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cede483-329e-4a07-bc00-0d5bf628d79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5439970-c092-48eb-b560-37c2ce417984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72bae02d-e28d-4641-8bd0-43d1412c980b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00e27f6e-1370-4a81-b5f0-5ffeb9ec2264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cfaf19b-49f2-4c9a-ab41-4153b5436d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5c71c54-c35c-4fe7-8d3b-292e90475fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65471a02-1cb5-4681-a7b7-962cb91efcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4d1de4-8d41-4daf-878d-cc73383a3c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60304f21-671d-458c-8123-87385946bbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06952cd6-1012-4d43-952d-c07a2f2841ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 487b216e-53fe-4cc7-a650-5e1aad22ec3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd5609cb-abd9-4210-beed-e13c5dd584d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 649b7873-fde3-4413-99e3-de26bf95f00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ed7c45c-b19d-4368-a964-7232111b7c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e26ed44-a979-4179-98f2-d960844626f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6ddf59-88cc-4a84-854a-a87301c3aecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fba1738-48aa-4927-84ba-36fdef74fa1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54f83dc-2478-4d74-b3a0-23b91f5025c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efa3fae8-c137-44c4-8a59-3ba423b6a245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d39307d1-45d5-4d41-b6c2-d7c050dc7c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8f162f2-1f30-476e-ae24-889c83515e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87a158a-424c-4865-965e-bfa82ce7d35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 176d60ad-54e6-4333-9287-3565abc61e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2c0c5a-b6f4-4343-a223-3cb67a8d4c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72637b74-98fb-4527-adfa-d09a0f3aa753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc165ae8-9951-4c78-b762-ec8b80491e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccad445-df5e-47e7-b7e3-22e362aa7ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f2bf1a-3614-42e6-bba9-bc099e71996c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 041277c6-1531-410d-abf5-ef13569a2768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b3a89f6-86ce-4c5c-a421-146188bb1cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37af1d33-6f23-4a76-acc0-f0910acf213f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a92f48-f0e3-4799-8765-920c3a487b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631493fd-4567-44be-b7c9-6f4d79616e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e91a67c-018a-4aa8-96ae-a00afaa2a955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c585b9ca-7932-46eb-a340-2b8c267dd8b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8d9f05-6fb1-4c1d-803d-f80f4656d8c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7407b158-e92f-41c2-9a5e-8f3ffcefd2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd4c5c2-6c75-4a2c-858a-f4a92bbd0107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caa21916-78b1-4f97-8e91-ca23f539beef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a2583eb-4c5f-4136-893f-6056d781131b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fce13de-bb33-44fd-8c1d-88fde14c905f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3430c3e0-4c28-481f-8da3-486354cd5baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9707e4ca-cb20-447e-88e1-7c7a10b82847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a19d183-f489-4255-acae-667da3987f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4a8db32-c4c7-4efe-840e-e45de4e6d907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72537ac5-3e96-4ab2-86fa-32691c63e9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b7174a-4cce-4a1a-8991-aa0c29e63dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc8e5024-9b42-46b9-9b91-0ba23ab46cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c892cb41-2226-4368-840b-d29e9ab01c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a082f8b-811a-4794-9979-cc226e8c5a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91140cb4-59a6-4416-a568-dd483cff064b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd02437-f80e-4099-8c44-a1b772cde302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7a42a0-65e0-48bb-9cd1-e5b7e3771b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd03211-f069-4e99-9437-5b17dd7ee8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 319f20ef-8039-4465-b4be-46538339647b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13bc713-4199-4baa-96b9-526812288aee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c87ea7-a207-41c5-bb4a-67d6d31e638d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944f54ad-b2bc-4e16-8861-bf3e55d8694f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2099e91-9a8a-4153-99b0-08b870b52841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c9f4ed7-3389-4df4-9c86-f44f17fb45e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6af2242f-4b9e-40bb-bc5e-d3274260fabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a27eb193-a732-4c6f-9b72-370dbf2569ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5185d563-7785-4513-aeee-78f8ba78917a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e253d3e1-c261-45ba-aa2a-f3b09710067e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 716ae197-9e70-4242-a0b7-54cb55d6e61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552b3a1b-b070-4745-87cb-07744160d36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0256bc-4d05-468d-b210-e4e992cf567d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b3f733-ff9f-4973-8dd2-1541820c51b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde80b46-fc58-4087-af03-57292c2a394f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab34220b-fcbe-4977-a5ba-88e1e6849d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d12c2c0-c055-4876-a4a3-22dfd37ebade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c547d324-ca23-45d2-ab77-b061fdba14bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda3497d-cd19-4500-924c-da2c14a0aaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f5d110d-a783-4f90-a7e9-80f13958d7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 863d0f20-da0b-45e2-8c30-0c15c3bde0de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4051e16f-f895-49a6-ac2b-74f6f7b4ddba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9951ea35-dabf-4acd-be4b-7c9948e4bf2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa3abd8-1434-49fd-8a72-e657816f5b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c6964d-f7f7-46a9-afd0-d6cdd62728f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4754a7c5-dc9c-4495-a213-0c5c32ee9ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94afd0ef-8669-4d9c-bad3-17842ea41a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8e544c-63c2-4beb-a026-da2bacd491c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01592d0a-97d7-4202-a388-f186c2e64f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfcd36e7-309d-4c0f-afff-6a7107f9c58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f30333b-cace-4539-a172-4708c3989c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9408f6f8-d10d-4d1c-88f0-e09cae47053d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f5a1139-ef8f-4789-b253-75bf1e347f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4262f1e1-6a55-4188-b118-1edb8525389e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e55dc98-b5a1-4aa9-936e-accd09da8e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 705ea342-3251-4987-b755-ad1764e48454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e651c0c1-7d44-4668-bd7b-0f41e7245a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd7d6b64-d585-4ce7-a3fb-f93804f8270a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b1aef7-8562-4c35-8067-edfae79d7b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7a4a03e-6d64-4b0c-92ae-3095e5116a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b9f3bf0-161b-4df1-b568-df2ba3ed4d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35bdf97-11e1-4069-ad64-055f82bc9f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b6689f9-ebbc-4e58-9e65-9bfa6df5252d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 993c30c6-37e0-4fa7-bc11-9c6ab70f4282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bc17927-1dc2-4cd5-a5c8-cc2dd0374184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a1ea5df-7c84-4f14-b8f0-307874407558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 849a291b-84d5-4412-a77f-2bb95bde1293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52312881-1885-4eab-976e-c213e9f9e466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b017c9dd-0401-498f-93bf-82d15e1546d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25418489-70de-480b-be76-02091d3ddc11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 093ca934-e922-431b-a283-a2845f924cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6929a0-71d1-4b4a-b04b-db2b039cd432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01c1f82b-72c9-4e8f-9a3d-77ad21354f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b32b8779-21d9-4165-9f61-76a889d04981
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_80
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_80/test_labels.txt

📊 Raw data loaded:
   Train: X=(1172, 24), y=(1172,)
   Test:  X=(294, 24), y=(294,)

⚠️  Limiting training data: 1172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  285 samples, 5 features
✅ Client client_80 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0726, RMSE: 0.2695, MAE: 0.2326, R²: 0.0768

📊 Round 0 Test Metrics:
   Loss: 0.0727, RMSE: 0.2696, MAE: 0.2325, R²: 0.0766

============================================================
🔄 Round 14 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0846 (↓), lr=0.001000
   • Epoch   2/100: train=0.0689, val=0.0841, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0675, val=0.0824 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0661, val=0.0817 (↓), lr=0.001000
   • Epoch   5/100: train=0.0652, val=0.0826, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   ✓ Epoch  11/100: train=0.0629, val=0.0772 (↓), lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0557, val=0.0768, patience=2/15, lr=0.000250
   📉 Epoch 26: LR reduced 0.000250 → 0.000125
   • Epoch  31/100: train=0.0529, val=0.0767, patience=12/15, lr=0.000125
   📉 Epoch 34: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 14 Summary - Client client_80
   Epochs: 34/100 (early stopped)
   LR: 0.001000 → 0.000063 (4 reductions)
   Train: Loss=0.0559, RMSE=0.2364, R²=0.3223
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.1280
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0721, RMSE: 0.2685, MAE: 0.2310, R²: 0.0838

📊 Round 14 Test Metrics:
   Loss: 0.0721, RMSE: 0.2684, MAE: 0.2307, R²: 0.0844

============================================================
🔄 Round 16 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0839 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0707, val=0.0833 (↓), lr=0.000063
   • Epoch   3/100: train=0.0703, val=0.0829, patience=1/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0700, val=0.0828 (↓), lr=0.000063
   • Epoch   5/100: train=0.0697, val=0.0826, patience=1/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0688, val=0.0819, patience=4/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0683, val=0.0816, patience=5/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0681, val=0.0814, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 16 Summary - Client client_80
   Epochs: 31/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0685, RMSE=0.2617, R²=0.1420
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.1743
============================================================


============================================================
🔄 Round 17 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0706 (↓), lr=0.000008
   • Epoch   2/100: train=0.0744, val=0.0705, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0743, val=0.0704, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0742, val=0.0703, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0742, val=0.0702, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0736, val=0.0698, patience=3/15, lr=0.000008
   • Epoch  21/100: train=0.0731, val=0.0695, patience=13/15, lr=0.000008
   • Epoch  31/100: train=0.0728, val=0.0693, patience=9/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 17 Summary - Client client_80
   Epochs: 37/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1364
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.1272
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0719, RMSE: 0.2681, MAE: 0.2302, R²: 0.0868

============================================================
🔄 Round 20 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0700 (↓), lr=0.000008
   • Epoch   2/100: train=0.0745, val=0.0699, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0744, val=0.0699, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0743, val=0.0698, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0742, val=0.0697, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0738, val=0.0695 (↓), lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0735, val=0.0693, patience=10/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 20 Summary - Client client_80
   Epochs: 26/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.1335
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.1063
============================================================


============================================================
🔄 Round 21 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 21 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.1180
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.1329
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2295, R²: 0.0899

📊 Round 21 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0898

📊 Round 21 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0898

============================================================
🔄 Round 27 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0705, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0705, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0704, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0704, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0704, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0703, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 27 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0708, RMSE=0.2660, R²=0.1284
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.1022
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2295, R²: 0.0897

📊 Round 27 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2295, R²: 0.0897

============================================================
🔄 Round 31 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 31 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2680, R²=0.1227
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.1014
============================================================


============================================================
🔄 Round 32 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 32 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.1062
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.1856
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2295, R²: 0.0898

============================================================
🔄 Round 34 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0705, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0704, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0704, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0704, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0704, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0703, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 34 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0702, RMSE=0.2650, R²=0.1243
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.1190
============================================================


============================================================
🔄 Round 36 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 36 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.1221
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.1240
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2295, R²: 0.0898

============================================================
🔄 Round 38 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0667, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0667, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 38 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.1155
   Val:   Loss=0.0668, RMSE=0.2584, R²=0.1512
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0898

📊 Round 38 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

============================================================
🔄 Round 40 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 40 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1159
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.1469
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

============================================================
🔄 Round 42 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 42 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.1259
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0899
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

============================================================
🔄 Round 44 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 44 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.1284
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0937
============================================================


============================================================
🔄 Round 45 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 45 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1190
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1382
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

📊 Round 45 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0900

📊 Round 45 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

📊 Round 45 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

📊 Round 45 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

============================================================
🔄 Round 51 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 51 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1227
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.1203
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0900

============================================================
🔄 Round 52 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 52 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1251
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.1144
============================================================


============================================================
🔄 Round 53 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 53 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.1333
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0761
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2295, R²: 0.0899

📊 Round 53 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

============================================================
🔄 Round 55 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 55 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1192
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.1394
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

============================================================
🔄 Round 56 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0634 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0634, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0634, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0634, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0634, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0633, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0634)

============================================================
📊 Round 56 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.1173
   Val:   Loss=0.0634, RMSE=0.2518, R²=0.1429
============================================================


============================================================
🔄 Round 58 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 58 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.1183
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.1434
============================================================


============================================================
🔄 Round 59 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 59 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1405
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0485
============================================================


============================================================
🔄 Round 60 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 60 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.1166
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.1512
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

📊 Round 60 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0899

📊 Round 60 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0900

📊 Round 60 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0900

============================================================
🔄 Round 67 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 67 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1316
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0867
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0902

============================================================
🔄 Round 69 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 69 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1271
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.1063
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0902

📊 Round 69 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0902

============================================================
🔄 Round 73 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0656 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0656, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0655, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0655, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0656)

============================================================
📊 Round 73 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.1138
   Val:   Loss=0.0656, RMSE=0.2561, R²=0.1650
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0902

📊 Round 73 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2294, R²: 0.0903

============================================================
🔄 Round 75 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 75 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1268
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.1043
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2293, R²: 0.0903

📊 Round 75 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2293, R²: 0.0904

============================================================
🔄 Round 78 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0652, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 78 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.1200
   Val:   Loss=0.0653, RMSE=0.2555, R²=0.1343
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0904

📊 Round 78 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0904

📊 Round 78 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0905

📊 Round 78 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2293, R²: 0.0903

============================================================
🔄 Round 84 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 84 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.1205
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.1385
============================================================


============================================================
🔄 Round 85 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 85 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.1219
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.1333
============================================================


============================================================
🔄 Round 86 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 86 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.1232
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.1275
============================================================


============================================================
🔄 Round 87 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 87 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.1165
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.1412
============================================================


============================================================
🔄 Round 88 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 88 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.1168
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.1529
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0904

============================================================
🔄 Round 89 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 89 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.1248
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.1207
============================================================


============================================================
🔄 Round 90 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 90 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.1324
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0876
============================================================


============================================================
🔄 Round 92 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 92 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2727, R²=0.1240
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.1177
============================================================


============================================================
🔄 Round 93 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 93 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1342
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0826
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0905

📊 Round 93 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0905

📊 Round 93 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0905

============================================================
🔄 Round 98 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 98 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.1173
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.1308
============================================================


============================================================
🔄 Round 99 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 99 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.1233
   Val:   Loss=0.0680, RMSE=0.2607, R²=0.1285
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0907

============================================================
🔄 Round 102 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 102 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.1221
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.1306
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2293, R²: 0.0907

📊 Round 102 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2292, R²: 0.0907

============================================================
🔄 Round 104 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0711, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0711, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 104 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2663, R²=0.1393
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0684
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2292, R²: 0.0908

============================================================
🔄 Round 106 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 106 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1253
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.1194
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0908

📊 Round 106 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0908

📊 Round 106 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0908

============================================================
🔄 Round 112 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0702, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0702, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0702, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0702, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0702, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0701, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 112 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0703, RMSE=0.2651, R²=0.1330
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0885
============================================================


============================================================
🔄 Round 113 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 113 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2663, R²=0.1347
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0614
============================================================


============================================================
🔄 Round 117 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 117 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2686, R²=0.1256
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.1201
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0910

📊 Round 117 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0911

============================================================
🔄 Round 121 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 121 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2690, R²=0.1148
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.1587
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0911

============================================================
🔄 Round 123 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 123 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2701, R²=0.1257
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.1187
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0910

📊 Round 123 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0909

============================================================
🔄 Round 131 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0709, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0709, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0708, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0708, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0708, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0707, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 131 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0710, RMSE=0.2664, R²=0.1309
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.1017
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0910

📊 Round 131 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0910

📊 Round 131 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0909

============================================================
🔄 Round 137 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0644 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0644, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0644, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0643, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0643, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0642, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0644)

============================================================
📊 Round 137 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.1128
   Val:   Loss=0.0644, RMSE=0.2537, R²=0.1738
============================================================


============================================================
🔄 Round 139 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 139 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1209
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.1353
============================================================


============================================================
🔄 Round 140 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 140 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.1195
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.1454
============================================================


============================================================
🔄 Round 142 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 142 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2708, R²=0.1224
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.1360
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2292, R²: 0.0910

📊 Round 142 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0911

============================================================
🔄 Round 149 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0645 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0645, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0645, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0645, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0645, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0644, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0645)

============================================================
📊 Round 149 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.1182
   Val:   Loss=0.0645, RMSE=0.2540, R²=0.1442
============================================================


============================================================
🔄 Round 150 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 150 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1354
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0841
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0911

============================================================
🔄 Round 153 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 153 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.1196
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.1488
============================================================


============================================================
🔄 Round 154 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 154 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2708, R²=0.1219
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.1374
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0912

============================================================
🔄 Round 155 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 155 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.1305
   Val:   Loss=0.0743, RMSE=0.2727, R²=0.0971
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0912

============================================================
🔄 Round 158 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 158 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.1241
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.1249
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0912

============================================================
🔄 Round 159 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0704, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0703, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0703, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0703, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0703, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0702, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 159 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0702, RMSE=0.2650, R²=0.1370
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0715
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

============================================================
🔄 Round 164 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 164 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1182
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.1475
============================================================


============================================================
🔄 Round 165 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 165 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.1257
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.1195
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

============================================================
🔄 Round 167 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 167 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.1345
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0793
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

📊 Round 167 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

============================================================
🔄 Round 169 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 169 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.1263
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.1198
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

📊 Round 169 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0913

📊 Round 169 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0913

============================================================
🔄 Round 174 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 174 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1197
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.1434
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0914

============================================================
🔄 Round 178 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 178 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.1233
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.1355
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0914

📊 Round 178 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0913

📊 Round 178 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0913

============================================================
🔄 Round 182 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0641 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0641, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0640, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0640, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0640, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0639, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0641)

============================================================
📊 Round 182 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.1207
   Val:   Loss=0.0641, RMSE=0.2531, R²=0.1445
============================================================


============================================================
🔄 Round 183 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 183 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.1416
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0562
============================================================


============================================================
🔄 Round 186 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0634 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0634, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0634, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0634, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0634, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0633, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0634)

============================================================
📊 Round 186 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.1258
   Val:   Loss=0.0634, RMSE=0.2518, R²=0.1240
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

============================================================
🔄 Round 187 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 187 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0707, RMSE=0.2660, R²=0.1425
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0575
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

============================================================
🔄 Round 194 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 194 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2678, R²=0.1362
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0648
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

============================================================
🔄 Round 195 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 195 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.1293
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0921
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

============================================================
🔄 Round 197 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 197 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1384
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0623
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0913

============================================================
🔄 Round 199 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 199 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1236
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.1349
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0914

============================================================
🔄 Round 200 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 200 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1301
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.1086
============================================================


============================================================
🔄 Round 201 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 201 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.1314
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.1022
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0914

📊 Round 201 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0914

============================================================
🔄 Round 203 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 203 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.1164
   Val:   Loss=0.0682, RMSE=0.2611, R²=0.1627
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2292, R²: 0.0912

============================================================
🔄 Round 206 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 206 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1230
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.1240
============================================================


============================================================
🔄 Round 208 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 208 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.1219
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.1427
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0914

============================================================
🔄 Round 209 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 209 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.1204
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.1472
============================================================


============================================================
🔄 Round 211 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 211 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.1228
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.1391
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0915

📊 Round 211 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0915

============================================================
🔄 Round 214 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 214 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1276
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.1165
============================================================


============================================================
🔄 Round 215 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 215 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1279
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.1169
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0915

📊 Round 215 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0914

============================================================
🔄 Round 217 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 217 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.1138
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.1609
============================================================


============================================================
🔄 Round 218 - Client client_80
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 218 Summary - Client client_80
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.1283
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.1136
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0915

📊 Round 218 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0916

📊 Round 218 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0916

📊 Round 218 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2291, R²: 0.0916

❌ Client client_80 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
