[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5499f90f-36af-4e59-b1fc-07958152ddbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e7bc73f-8803-4025-900a-81d94f51d8d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0759069b-b21f-48e7-b0ef-2aee1ad74875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d1c312d-0079-42ea-a284-27f75b22498a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b2aa4da-f916-4b22-b539-3144757a2cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae04d2d-cfaf-49d4-8892-c268ac93e3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 752d2f26-2f68-4575-ad99-96feca3d6ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab116e2c-2004-4bdc-aed8-40dcec9170c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0fb596c-fc57-4424-a027-d3565b702570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46458e2f-e425-4d96-a6a4-a3d64ee5e815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d414b461-413a-41c6-814d-60830451a99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b1d9be-8cb4-4b55-a594-abe93ffac38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ad54ee-c106-4a9e-b42a-2cc6c69f3d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cb97dfa-b776-44a2-8c1a-040ebaf3867f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a56b34-8201-45bc-b4a9-96b9c1ce4ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699eccdd-c5ee-42af-bb69-426796f36bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7731792d-40c8-4e55-b6c9-006d71299db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c24264-d79c-4816-bb91-d68230a42088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff4f1926-bb48-46b0-8aa3-3fc72ae6e599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad63d6d-1b91-4c92-bca4-3f14c3c2bb45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8acbfe-d9f3-40bb-ad8e-faabd7045e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d577f3-95df-4de6-9e1b-ccc898dabf77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 708d4a3c-0c77-4ceb-8aa1-955a97c2fc37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce0c409d-4b86-46d2-9d5f-fb1f151b185d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 653184b6-f01e-4c1a-81c3-87cd2ee2abfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 226a6056-dfbf-48a1-8b75-2ca1aa7808f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 174556ec-470a-4e4e-b2c8-a1cc4601157b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebde3841-c891-4f23-adfd-439da1887d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92bbb0c0-9dec-4ae1-8bd6-d4cdd696697f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f802f2-7c86-421b-b555-d57d62de4571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8e88e0-688b-477b-9c33-861eef5a13e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b8a2aa8-4b3e-4cb5-a1d8-fe0830f98eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24427392-ad15-42ce-9250-1cace7dd90eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38fa4d55-aab2-4547-a05e-fbdbfbe7b497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ca0cd0-05ce-4a9d-904b-bedca8b7e8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea8282a-e230-4e5e-bd1c-6c0f712296cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ce5bf2-bdd6-458a-a0f1-3cf4f7b6bc00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfe21ae4-0e01-4c2c-b25e-c87114b001ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6004128b-fb6b-450a-8b0e-bedced55a9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d44f2dc-5db4-4e65-9d69-01e77736194c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5862ab-b6f6-4047-ac50-4dfb6a309716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 650a720e-a8fe-4c94-a37e-b37ce305190b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a6d41e5-f97b-448b-9cdd-04245d3b5193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d6d14d-8b98-4cc2-8254-432582d210dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1aedad0-df02-4e5e-8fd6-761bf6a66f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d9895e-b1bc-44bc-a392-cc2c1bdd396b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ddb7e21-e251-4588-a89f-5b59f48b166c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2017e185-9d7e-4949-aa59-caa26f213592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 186d8268-420b-4e46-8aa0-20e57446bdc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f809e7d9-2b46-4cac-9b0e-a373febd979f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8d15262-8945-4dca-8334-f95282babdeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cdba15-273d-4b6e-a5bb-521fec40fbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1df15979-7276-4fe3-8fb3-eec36f3c3ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a36e8cc-6196-41e4-9d73-497e10d8a9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e55b731-cc51-4e03-b64f-8bfe77bf2ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5079d829-9830-4bd2-9c6d-b95f19d3051e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4997a6e-20d7-42e4-bfcb-ae0a291c2233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ecd1dde-4600-4a79-9148-9b0dca114fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3488a227-8b04-433c-b5f4-14c08f82d268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ec4704-0f04-4fcf-98d2-ec59c5bb4122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b52eef1-3d37-4d71-aa6a-2714176117fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b5b0232-add8-42bb-89b6-534cedcf0f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4752624b-4064-4481-bb78-ecc5848fc248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dfd4c7b-62d6-4abf-8e41-9d184a3ef220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a35cfd5-1eb2-421f-a3a5-7e9c8648f4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e58e8f7-877c-4bb0-82db-2d92ba6515b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6623996c-915c-4eb9-9631-298d56cee671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf053ae-1ce5-4435-b14d-ec6742b48029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b21cf288-ea73-4882-8ed9-30d54de24770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ad7909-d31d-4610-bbab-08260f029992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6360efd3-26b0-4b57-b1a2-0b99b45eb19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d983957d-efd1-4280-b9ec-78e8f7a347dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff5b6252-6e46-4c9f-8305-f58c7cc7edd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc574b68-f767-4931-84fe-fb6d728896fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc7a96f-ae79-47ab-86e4-63ff260e4934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49092acd-39dc-4b5b-b52b-87b6ea74c749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b3570b0-b93a-49d7-8a63-563a87571b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef2878b-de78-4e56-a07e-2c0fbc6967b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c03a48-9f6f-4d5d-91cd-38db7a2cfad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 953324ae-d70e-4c99-bf3d-90a90a9a50af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d416c7a7-fd75-46ec-9360-cbac0d9018a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527ba0c2-d34e-41f8-8f85-88deb59da5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ee20fa-b478-46ab-a482-fe31b8cabdec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c12e22-d767-4f28-872b-e1309d064d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4036ee25-bafb-49f6-ace3-709ece3f3f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4202c618-4f79-4f22-bde1-d311f186a0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8711dab-4ab2-4c37-a6b5-73e2728c5b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75cef6a0-0df6-4d11-b7cf-ca9d46fb33a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a63315fc-256e-402a-8d4a-23711dca744d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19f18d2-4abd-4591-a41c-59ad72b92293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e91abd84-07ce-4a18-98cf-97d65710d32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79585585-bc5e-451b-99ad-841222a8092a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edce6786-5f10-4f1e-956a-41c19dc743d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df219307-6c94-48e1-987f-baa5ac72d7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0646c1f2-a961-4423-aaac-de3ceeee7f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f856ce9-5fa2-41e2-9827-b4427c5cfc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb41af51-3985-427d-a152-3235fd499648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5604b31f-6b24-4ca2-84c2-0f5e12737f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f457bf3-9a93-47a7-be31-53a538335c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41116f31-a221-4e42-b2fd-303365633186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d89143-cbba-4c3f-9581-12c8ddc1f042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6514c827-681f-433e-aafb-97e2f8c4a347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de66a01e-ee66-49ee-b3d3-0396273cff9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0dd572-7671-42ad-a388-4efc1b871ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48235841-a9ab-4a58-a76d-5f8b3e266e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55b20f25-148f-4b60-8527-022f0f100c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4338e37-d37d-4181-b820-71c5ce6f7830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f694b58d-9651-408e-8dc8-2659aa495ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b0cc4d-d234-4cac-9ea6-8d6267da14c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04db2931-559e-4863-a572-e14dec9b42ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc614ecf-aab2-4264-b2e8-d12facd5de69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59f9ede-1601-4b39-8135-29fa8093f146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6810f7e7-3a8a-4408-b3a3-0527a7c80191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d530259a-b9bc-4efc-ab79-c3ea267e6d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d2fb66-ccf0-4275-a26f-192638358b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b72c0bd-a1bc-46af-bc1e-5174933164c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bc9b432-6a33-455e-a8b0-12eb4d79f3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0dbd67f-bede-47c9-9523-32c8285e0b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1981b05a-6ccc-4a82-a0a2-188d2fe23c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f8cbb6-b7dc-4b07-ba6c-be06d5e96ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9136010-ff61-4d87-8fd8-c86b81235dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6fc36d4-e0b2-4fce-b9fd-8198c2e5ee61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4ff356e-8daa-453d-bbd9-1c8ef6925da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6e754da-b12a-44b3-a1cd-e21eb5fbd95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2002828c-5e33-40cd-844c-25f413563fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c2af8a-0cb8-49ad-9fd9-22bcb4006224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c525db1c-c668-42fb-9bea-8f8a72599c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d15cd48a-3115-41bd-a1d0-78b845f6819f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa5dd1d0-7890-4aa1-abf1-fa596361145f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44ee7d8-d243-4f74-8e15-e3e0bbe8fe90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee865e08-aa3a-44e9-96fc-61b1cad5d4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb60323c-9987-49f0-89c8-1c6a6db0c91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d379b7ae-33a4-4d20-8ddb-440d8f42b2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3aef595-11fa-45c5-bd13-4eb93336b83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb1f319-2121-44df-a34f-70b55820fcc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 966a4c80-f9b2-461c-b540-25b2d2773123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9abf8f70-90b0-437a-a362-cfb5569bfe5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75ef8fae-8faf-4f35-9dac-e4f5d9d4a44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e7f8b1-84d0-4964-accc-bf5ebbd7c18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7321b0b-b209-42de-93ad-e90e809736d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8cd133-a46f-4168-9b39-0c00ab88ad66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4617a5d6-a54e-47fb-be54-2d947367fe66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1b557b0-fc89-496b-8507-56b812e0764d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad3f6c17-9448-4e5e-acd5-e089b90e5860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44bbf25f-5bac-458d-b4f9-45d9ddbc77af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e3fd92-bf7c-4814-979b-2df2279fae21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 792bf814-68d6-47c7-bd31-86ad123730d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce28399-8fad-470b-9689-d5d592dcc760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc9897c9-0b43-4de0-a5ab-9de889e0b2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 595ee779-13d8-4f3a-8a15-b513a82388de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a46b9014-76dd-49e0-96db-0c9cea5b4507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ba865a-b838-473e-b659-d9671601a053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5aea73-5099-4045-9965-3dd56b5106ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98234578-8136-4fad-9437-ca095860bb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb7e65e-431c-4eda-ad53-01224f75a7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b2e390-1c39-4dab-82b3-c53b9df1c61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98fb42ce-c007-4319-862f-d4a330b4e2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d6f007e-9fd4-4219-ad5c-0d4225836157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c0255d-9bbc-49e6-98ee-dcaf4a56a184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc71f03-16c9-42d1-9fd8-5c75a5515d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a377a5fe-5a86-40b2-8ce4-aa80370cd67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2feb5ab-159c-4c5b-91aa-68635a1b125c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad907aac-6e32-4aea-9cb1-bd49880043d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd364621-bc9d-46c2-bd87-b326d86b759a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf0d1cc1-d21f-46e3-b41a-0dec5ef0251a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff766d5-858b-4996-838d-474aa787c75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5cb9b7a-9a41-416f-a44c-be6a69f9db95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e281a0c-ebc0-4543-8e1f-519c01c5a775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d26a6e7c-a842-43af-9299-c44b272e308e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1923c76e-9a5f-4702-9b8c-5761c41edd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592c0158-35b8-4166-bafe-1108a4c6fd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4320e2c1-4b35-480d-a507-7d5e5effc93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07424eaa-eb1d-413c-8806-12546729b4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2f4a82-c8ef-4472-9790-46eb3a06c694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b272258f-3513-45c2-88cc-e1964fc05f3f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_81
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_81/test_labels.txt

📊 Raw data loaded:
   Train: X=(1208, 24), y=(1208,)
   Test:  X=(303, 24), y=(303,)

⚠️  Limiting training data: 1208 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  294 samples, 5 features
✅ Client client_81 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0910 (↓), lr=0.001000
   • Epoch   2/100: train=0.0768, val=0.0918, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0762, val=0.0922, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0754, val=0.0924, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0747, val=0.0918, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0696, val=0.0913, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 8 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0308
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0325
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2511, R²: 0.0032

============================================================
🔄 Round 10 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0769 (↓), lr=0.000250
   • Epoch   2/100: train=0.0813, val=0.0771, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0805, val=0.0772, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0801, val=0.0771, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0798, val=0.0772, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0785, val=0.0773, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 10 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0163
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0121
============================================================


============================================================
🔄 Round 12 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0768 (↓), lr=0.000063
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0818, val=0.0768, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0816, val=0.0767, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0807, val=0.0764, patience=10/15, lr=0.000063
   • Epoch  21/100: train=0.0799, val=0.0760, patience=9/15, lr=0.000063
   • Epoch  31/100: train=0.0792, val=0.0754, patience=6/15, lr=0.000063
   • Epoch  41/100: train=0.0787, val=0.0749, patience=7/15, lr=0.000063
   • Epoch  51/100: train=0.0781, val=0.0743, patience=7/15, lr=0.000063
   • Epoch  61/100: train=0.0774, val=0.0738, patience=7/15, lr=0.000063
   • Epoch  71/100: train=0.0765, val=0.0732, patience=7/15, lr=0.000063
   • Epoch  81/100: train=0.0757, val=0.0727, patience=7/15, lr=0.000063
   • Epoch  91/100: train=0.0747, val=0.0721, patience=7/15, lr=0.000063

============================================================
📊 Round 12 Summary - Client client_81
   Epochs: 100/100
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1130
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0820
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2505, R²: 0.0062

📊 Round 12 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2506, R²: 0.0063

============================================================
🔄 Round 17 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0858 (↓), lr=0.000063
   • Epoch   2/100: train=0.0794, val=0.0857, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0790, val=0.0856, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0787, val=0.0854, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0784, val=0.0853, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0776, val=0.0847 (↓), lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0770, val=0.0848, patience=10/15, lr=0.000016
   📉 Epoch 22: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 17 Summary - Client client_81
   Epochs: 26/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0352
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0295
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2505, R²: 0.0067

============================================================
🔄 Round 19 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0772 (↓), lr=0.000008
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0819, val=0.0770, patience=2/15, lr=0.000008
   📉 Epoch 4: LR reduced 0.000008 → 0.000004
   • Epoch   4/100: train=0.0819, val=0.0769, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0818, val=0.0769, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0817, val=0.0766, patience=1/15, lr=0.000004
   📉 Epoch 12: LR reduced 0.000004 → 0.000002
   📉 Epoch 20: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0816, val=0.0765, patience=11/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 19 Summary - Client client_81
   Epochs: 25/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0154
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0234
============================================================


============================================================
🔄 Round 20 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 20 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0040
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0091
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

📊 Round 20 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0058

============================================================
🔄 Round 22 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 22 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0080
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0078
============================================================


============================================================
🔄 Round 23 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 23 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0041
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0151
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2505, R²: 0.0054

============================================================
🔄 Round 25 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 25 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0105
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0126
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0056

📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

📊 Round 25 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

============================================================
🔄 Round 34 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 34 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0062
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0003
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

============================================================
🔄 Round 35 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 35 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0016
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0258
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

📊 Round 35 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

============================================================
🔄 Round 40 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 40 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0107
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0142
============================================================


============================================================
🔄 Round 42 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 42 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0078
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0022
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

============================================================
🔄 Round 43 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 43 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0052
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0142
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

📊 Round 43 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

📊 Round 43 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

📊 Round 43 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

============================================================
🔄 Round 47 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 47 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0170
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0355
============================================================


============================================================
🔄 Round 48 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 48 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0087
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0068
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0058

📊 Round 48 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0057

============================================================
🔄 Round 53 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 53 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0090
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0124
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0058

============================================================
🔄 Round 56 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 56 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0022
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0196
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

============================================================
🔄 Round 60 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 60 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0097
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0116
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0059

============================================================
🔄 Round 61 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 61 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0036
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0188
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0059

📊 Round 61 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0059

📊 Round 61 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0059

============================================================
🔄 Round 64 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 64 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0029
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0200
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0059

📊 Round 64 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0059

============================================================
🔄 Round 69 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 69 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0113
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0201
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0058

📊 Round 69 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0058

============================================================
🔄 Round 72 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 72 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0015
   Val:   Loss=0.0666, RMSE=0.2580, R²=0.0269
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0059

📊 Round 72 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0059

============================================================
🔄 Round 76 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 76 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0061
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0074
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0058

📊 Round 76 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0059

📊 Round 76 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0058

============================================================
🔄 Round 81 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 81 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0056
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0065
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0059

============================================================
🔄 Round 83 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 83 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0204
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0583
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0059

============================================================
🔄 Round 85 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 85 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0089
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0026
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0059

============================================================
🔄 Round 86 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 86 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0031
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0205
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2505, R²: 0.0059

📊 Round 86 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

============================================================
🔄 Round 88 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 88 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0060
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0057
============================================================


============================================================
🔄 Round 89 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 89 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0037
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0168
============================================================


============================================================
🔄 Round 90 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 90 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0053
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0038
============================================================


============================================================
🔄 Round 91 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 91 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0073
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0050
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

📊 Round 91 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

📊 Round 91 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

============================================================
🔄 Round 95 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 95 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0095
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0046
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

📊 Round 95 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

📊 Round 95 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

============================================================
🔄 Round 100 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 100 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0098
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0098
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

============================================================
🔄 Round 101 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 101 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0030
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0336
============================================================


============================================================
🔄 Round 103 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 103 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0040
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0159
============================================================


============================================================
🔄 Round 105 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 105 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0011
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0119
============================================================


============================================================
🔄 Round 106 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 106 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0021
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0254
============================================================


============================================================
🔄 Round 107 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 107 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0062
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0103
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

============================================================
🔄 Round 108 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 108 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0106
   Val:   Loss=0.0707, RMSE=0.2658, R²=-0.0242
============================================================


============================================================
🔄 Round 109 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 109 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0050
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0140
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

📊 Round 109 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0061

============================================================
🔄 Round 111 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 111 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0015
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0301
============================================================


============================================================
🔄 Round 114 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 114 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0218
   Val:   Loss=0.0937, RMSE=0.3060, R²=-0.0465
============================================================


============================================================
🔄 Round 116 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 116 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0027
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0206
============================================================


============================================================
🔄 Round 117 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 117 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0040
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0077
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0061

============================================================
🔄 Round 120 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 120 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0180
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0373
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0060

============================================================
🔄 Round 123 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 123 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0025
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0253
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2504, R²: 0.0061

============================================================
🔄 Round 125 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 125 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0048
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0130
============================================================


============================================================
🔄 Round 127 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 127 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0018
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0215
============================================================


============================================================
🔄 Round 128 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 128 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0044
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0161
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2504, R²: 0.0062

📊 Round 128 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2504, R²: 0.0063

============================================================
🔄 Round 131 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 131 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0086
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0005
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2504, R²: 0.0064

📊 Round 131 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0064

============================================================
🔄 Round 134 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 134 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0011
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0315
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0065

============================================================
🔄 Round 136 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 136 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0170
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0280
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0065

📊 Round 136 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0065

============================================================
🔄 Round 143 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 143 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0033
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0239
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0065

============================================================
🔄 Round 148 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 148 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0034
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0225
============================================================


============================================================
🔄 Round 150 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 150 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0042
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0208
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0066

📊 Round 150 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0066

============================================================
🔄 Round 152 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 152 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0044
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0167
============================================================


============================================================
🔄 Round 153 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 153 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0025
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0209
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0066

📊 Round 153 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2504, R²: 0.0066

============================================================
🔄 Round 158 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 158 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0085
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0034
============================================================


============================================================
🔄 Round 159 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 159 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0089
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0020
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2503, R²: 0.0067

============================================================
🔄 Round 161 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 161 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0012
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0194
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2503, R²: 0.0067

📊 Round 161 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2503, R²: 0.0067

📊 Round 161 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2503, R²: 0.0067

📊 Round 161 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2503, R²: 0.0068

============================================================
🔄 Round 167 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 167 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0120
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0162
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

============================================================
🔄 Round 168 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 168 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0048
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0070
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

============================================================
🔄 Round 170 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 170 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0130
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0190
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

============================================================
🔄 Round 171 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 171 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0151
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0261
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

============================================================
🔄 Round 172 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 172 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0066
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0077
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0069

📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2503, R²: 0.0070

============================================================
🔄 Round 184 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 184 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0087
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0076
============================================================


============================================================
🔄 Round 186 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 186 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0142
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0298
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2502, R²: 0.0073

============================================================
🔄 Round 187 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 187 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0056
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0052
============================================================


============================================================
🔄 Round 190 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 190 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0115
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0164
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2502, R²: 0.0074

📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2502, R²: 0.0075

📊 Round 190 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2502, R²: 0.0075

============================================================
🔄 Round 197 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 197 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0100
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0005
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0076

============================================================
🔄 Round 203 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 203 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0067
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0117
============================================================


============================================================
🔄 Round 206 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 206 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0071
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0043
============================================================


============================================================
🔄 Round 207 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 207 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0046
   Val:   Loss=0.0724, RMSE=0.2692, R²=0.0548
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0077

📊 Round 207 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0077

📊 Round 207 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0077

============================================================
🔄 Round 210 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 210 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0105
   Val:   Loss=0.0661, RMSE=0.2571, R²=-0.0170
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0077

📊 Round 210 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0078

============================================================
🔄 Round 215 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 215 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0053
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0147
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0078

============================================================
🔄 Round 217 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 217 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0157
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0475
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0079

📊 Round 217 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0079

📊 Round 217 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2502, R²: 0.0079

============================================================
🔄 Round 225 - Client client_81
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 225 Summary - Client client_81
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0160
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0248
============================================================


❌ Client client_81 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
