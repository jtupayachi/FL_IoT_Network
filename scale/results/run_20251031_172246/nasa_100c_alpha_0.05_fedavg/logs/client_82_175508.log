[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0251d3b8-1518-4ab0-a98b-392f5b13d2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad8c508-f50a-4f04-aec3-993fdc08249b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75c3d1af-b6a6-46a9-ac50-917b1ac8ca11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ca8d7c-2376-4312-9bb4-7b37729b15af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c26941a-32d5-4095-960e-2f4df3eb56ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d9016a-ba70-4250-92af-6df498e30cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54cc32ca-ab00-4c7c-81e5-29b4e7adb3b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac1dac09-db3d-4c44-b31b-caf6e61052ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d24c4ad-189e-4029-b595-af7f294132d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f50f4a8f-5828-4947-8578-4ee7edd495b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8da470-62ff-4c44-a7c5-973705962086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65dec524-adf6-4aeb-baab-20180b82e2f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c7d410-f327-4924-9fcd-aebff1abe3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f8e6c23-e635-4223-9df3-053a02da0a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a97d9a0-4dec-4ac1-83da-199f616c24b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21bc0ba3-d9ad-4007-a9f1-e72988a9581d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b88ab76f-4026-4268-91a3-6f6e1a6752e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f8c89b3-1124-4886-a78b-6d9b97887463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d14dabf-846d-43f8-8469-df941e2e10a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af015e06-e756-4b24-94a5-f55220fa56c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5441d3a9-a94f-462a-820e-8edcc7797dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc2b44f-7b4f-4457-9166-f97defaad274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c56c97-1f22-4acf-889a-77c1b2e1a73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95be2c3-8d14-43ca-a92d-c7d1b8bd8734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0e55ee-013d-407b-988b-f17d85055ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4da47bc-93a0-4b5f-8e7b-8d7c22ebc9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa98c60-8ad5-4da1-a8cd-36c943b3c3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d067293-a0c6-4c70-8b2e-9391dede9be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ac276d-63fa-4461-83a5-2945c98e39c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff06394-dab3-4d70-8bd8-b7bec00795e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac09901-67fa-4dab-9b44-268ac88d6ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e2aa03c-db2b-4a68-9b61-6361500b0710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53691fc7-c03a-46f3-be16-b8db83e4bde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e12ed3-f465-4313-8d1e-0c0e6c389966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0863dac6-8675-4572-a086-534d83565fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c266d77-b47c-45cc-b07c-e0b21f570df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e440f68f-96e7-4852-964a-8b3da5f28bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 327e4df6-9dc3-4bc5-9d24-dc6a09238ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 632c8fa2-8e79-49ca-b9c5-134e97b94032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caa046e0-b5e2-4624-bb0e-6eddef811628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e87913-33a0-4e79-820b-390ea81f024b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e7c9c1-2dca-4463-a80a-cb9a91a4bde3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 363bfedf-eabf-41a7-8c73-aac1b13d0908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53166f00-20eb-46e5-ace1-e2e1cf14260b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f9372a-6f85-45e4-b657-afbeec1407d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e1564e8-16e0-468b-960a-419bec729654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59a98915-4512-4d33-84d0-f7d5fcd01a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d7d0fa7-0c56-4cd3-b199-08edc0423911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eef900b-9b40-47b2-b795-d522ebb98f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a73e143-e2be-468b-be21-059c147d0d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a179d72b-06b0-46b2-8e7d-a485cdf01db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4866a2f7-4e4f-43f0-80b3-7d0aeb013a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c061d638-46e2-496a-98df-bdc3f99f9770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f7c0b40-fe16-48ae-9083-53c078d65da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b956818-0d07-481f-b47a-60bb2e96af50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 794b004b-9d01-426f-a82f-935ec5c20980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7819b3cd-c1dd-4379-93b0-49b2725ec090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fafc079-251e-4ade-97ce-dd0430881a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8c3bb4-d2f2-48e1-b84c-9602bb5a017b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a276052a-5b09-433b-840e-d37f9dbb207d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d583e27b-a968-4ce6-a80e-ea3f602e697c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ad1f41-658d-4b60-9b41-d77ea8b55adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d148c321-5a23-4482-bacb-03d13017b7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aaaa756-0288-448e-8f1b-f6f710cc57f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a635025-843e-4975-bbd8-6043fb6cf27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a42d016-74c2-43e5-9d60-99b0437cd53b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f60e6dea-0e56-457d-9dc0-fd75f5fa90e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b738934b-5859-4d18-badb-95c2706d9cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d542b06b-558a-4a03-aa5d-ef12251297fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc2b786-0aa0-43bd-ae70-c95398c02608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb088e2-a043-46a3-846e-49bc635cf25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98730657-aad8-42e2-8604-73d8c7a84750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c725e796-6fd6-45a5-8284-394498c7b8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9fc79b9-3b3b-469e-a589-496e2a999eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f7b25e-11c7-4f2c-a72b-5d8a1f3b9362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 861a28c2-be7f-47f8-bbde-ee0375c6f787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad090eec-66da-42b1-bc82-787a69ada76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb3a720-c712-48f7-b46d-205c94997539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb09fbc-c5de-4856-a218-9aaaee586096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a07439-f6da-4081-af3a-f8ddcb56f416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d5e0fd-a390-41d1-89ce-2cbe52b4e7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c92d9da-d649-4820-a55e-69698abc3754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d259ce45-f273-461b-94b9-c349da4689f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a3262e5-7119-4566-afae-3a95cc0b50e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8b26533-068b-476d-9f46-4009f94d2102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d6eb705-3bdd-43d0-bb1d-1d64e2abfc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6411053-58f0-4ef1-ab82-73e1bc83d1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c9168e-e36e-4bce-8533-dae01b6175a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b51a1e3-69ca-4138-a6d6-6e01b9a712a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ca49d30-9c9a-4c01-878d-db97052a28f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac66d2cb-4f0f-4ca9-8e6c-8387bfc961da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b5aaee7-0efc-4a7f-b337-0ac375ba3dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec3741f3-6475-4073-892f-d93bec4ce037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa72aac6-3629-45c4-93d0-035b06044458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f7bc76e-1ced-4f4f-aa57-964f8be93ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc9c1c5-a47e-43d1-b9ed-7ec9cac787e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a49bcc-1969-4458-a760-a4a6faf0f555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ec080f-398d-4968-9b71-b04d20d70b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21523ef7-348f-4185-aed1-60279f9ed255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58d57cb-6089-4dfd-a12a-a1600c526d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b47130-5a41-49a1-af5e-3eac2e4aeb5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763fb606-640d-4371-b2a3-cbee772a5a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ecbbac-f32e-4f85-ada5-552a07697aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d0f63f-f71e-42d5-80a2-a8283c9d91ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e1d4d44-50e4-4264-9380-802752e4f81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df843f36-717a-476a-9216-5b1fc4b46cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fbb7d2d-6fef-47d1-aac9-9e2835ca72a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eb0834b-c737-4811-b2f0-60de6ed285d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc3284d8-a57b-4181-83c8-5e9be441c44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d88065-5e1d-4cb4-9947-f95174198d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d11db9d-30f4-4a53-af24-5c163ab79a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ae0bb8-6ee5-49fa-b895-02987c2bc177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c28184-d2c3-4aa8-9261-25b975aa3f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d58fd7-f872-4aec-b5b5-84e64b690874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a96943e-dd48-4c77-8bcc-4b231b0fc68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02583bed-78c0-463c-9ec2-76e33ffaa6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac9562ee-9aee-4719-8c50-4707bd66b88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d039ba5d-c1b5-4c2b-995f-3fe5b2d36c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a3506d9-04d6-461f-88a1-926f85d87015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68dbf183-d9a4-40c8-a8ce-b8756a28da57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b28fd22-c28b-4838-83d0-dfa72908351c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 310f0927-34ca-49c5-837d-d6f0f490db0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a30a4d2-b4c0-4cf9-892d-46b0ea3649a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d96dc2-2a33-4e80-bcca-1e4e121bfc18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c021fce1-f627-40cf-b493-d453fc5a7ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a4abb3-7ca2-4c41-8b4a-41856ab3c9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd597d28-4c8a-47e3-a273-50fc75c77a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92e51464-ae2f-4dbe-ae96-2f2617601d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b42809f8-a851-4e09-b886-b07419347554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db2a3ad-49c8-4cd5-8eca-42a0e07e4710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 889b2cc6-462b-46c5-9099-68240851434a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19e0a1e3-50c2-4851-aaf2-04e4ad45b678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63122a70-dcaa-489b-8a91-e73110e0600e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f55f93-b92c-47c3-b236-700d434dada6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 723df3bc-4534-4877-803f-e73390065145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message addb2c76-57cd-43e3-906c-11a6f109a688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b331b660-6280-48c4-b15a-53c344bdd321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbf18fca-80af-465e-ba53-c5c1dd892826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddb491cd-56fd-4709-9a6e-552943285271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c00cb24d-eb30-4b76-9b92-c12e42fb55ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d858b8dc-b04e-4579-bb2c-3e3a87640470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5c7cd2-bd9c-4463-8765-29e8cd634a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe3e3a9-cc9a-4725-a8e7-bb53fcd64e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af25e19-d94d-4310-a71b-842bcedaf2bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d4c426a-819b-496e-ac28-8292a1867460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 870ebf35-4b94-4239-9806-0fb828e3ca35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 644e7032-32f9-4412-a47b-ff42fc88fa83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b7f041-478c-4771-842d-953dac8ef4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b883da-3027-4866-8294-816dbeafd188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3faafb-5fd4-42f4-956a-bb53d47ee0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c130c4bf-c833-4823-87c9-2fa834b7b1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc165f76-fe34-42f9-b434-f71c5d50e6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafc28ab-d92b-4c69-b54e-92e4e9cd706f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0770e0-2375-4657-baf1-8faafb6f4eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96524dd3-5972-420f-9a9b-3da6e5cbde62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd3083b8-7f28-4fe3-b1f1-721cad794ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e86f43-39b6-4f03-bc65-d2aa5eb09870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 086c0fe5-49f7-4a9a-8a49-a04bb6b7d8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba3d7c6-1974-4e91-927d-122e19f12be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c85fa493-8c6a-4d7e-92b6-7ee7bd26cc50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a99d26-d73d-455f-8fd6-fe2ff59fac6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7acac51d-051e-4238-a53e-f09cd6e61cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13983ecd-2b83-4a7d-b93a-fd977af3a6e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f473563-f459-4f22-98e3-f68bfca3a5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ad3e51-6b82-46a9-90a2-3889b06a69ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0641f86f-2c2e-415f-b4cd-314b68ca9815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d3d32fd-d6ab-4c4e-bfd3-c17177dd169a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fe85529-1fd5-4f02-892e-03fb44f528bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d5cc1d-e999-4c33-9cfc-a8b3ba9dbd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6da91e7-e87b-4548-8f84-84ee4e40b35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb5f9392-e1c8-4446-a377-2a5051af5b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ab1395-fedf-4330-ba7a-b81fbc816159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7870a77-99e1-4bb7-ad0f-25fdaf33a28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c2ad477-bfe0-429d-b193-cd8625dc841a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe9ac38d-8b90-42c5-a875-18edc3431100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78638e49-e97a-4934-90cb-0bfd6194ca9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7fec277-28c3-4344-88b0-fe06c3cc0347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c955c5e-18a1-4b49-b96b-3494992a51d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40f93a3-50c5-4dbc-8cce-e3951cf21fcf
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_82
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_82/test_labels.txt

📊 Raw data loaded:
   Train: X=(1604, 24), y=(1604,)
   Test:  X=(401, 24), y=(401,)

⚠️  Limiting training data: 1604 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  392 samples, 5 features
✅ Client client_82 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2524, R²: 0.0120

📊 Round 0 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2531, R²: 0.0064

📊 Round 0 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2524, R²: 0.0099

============================================================
🔄 Round 12 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0822 (↓), lr=0.001000
   • Epoch   2/100: train=0.0827, val=0.0831, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0823, val=0.0839, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0822, val=0.0847, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0775, val=0.0848, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 12 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0213
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0169
============================================================


============================================================
🔄 Round 13 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0777 (↓), lr=0.000250
   • Epoch   2/100: train=0.0840, val=0.0778, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0836, val=0.0781, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0833, val=0.0781, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0829, val=0.0782, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 13 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0212
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0088
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2525, R²: 0.0088

============================================================
🔄 Round 15 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0810 (↓), lr=0.000063
   • Epoch   2/100: train=0.0830, val=0.0811, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0828, val=0.0812, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0827, val=0.0811, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0826, val=0.0811, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0822, val=0.0810, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 15 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0176
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0187
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2520, R²: 0.0116

============================================================
🔄 Round 17 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0813 (↓), lr=0.000016
   • Epoch   2/100: train=0.0834, val=0.0813, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0834, val=0.0813, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0834, val=0.0813, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0833, val=0.0813, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0832, val=0.0813, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 17 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0168
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0186
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0120

============================================================
🔄 Round 18 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0739 (↓), lr=0.000004
   • Epoch   2/100: train=0.0851, val=0.0739, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0851, val=0.0738, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0851, val=0.0738, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0851, val=0.0738, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0850, val=0.0738, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 18 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0193
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0075
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2519, R²: 0.0117

============================================================
🔄 Round 22 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0895 (↓), lr=0.000004
   • Epoch   2/100: train=0.0811, val=0.0895, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0811, val=0.0895, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0811, val=0.0895, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0811, val=0.0895, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0810, val=0.0895, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 22 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0171
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0165
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0131

============================================================
🔄 Round 23 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 23 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0178
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0117
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

============================================================
🔄 Round 25 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 25 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0182
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0005
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

============================================================
🔄 Round 27 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 27 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0195
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0058
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0131

============================================================
🔄 Round 29 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 29 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0187
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0105
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

============================================================
🔄 Round 33 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 33 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0245
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0177
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

📊 Round 33 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0133

📊 Round 33 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

📊 Round 33 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

📊 Round 33 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0133

📊 Round 33 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0133

============================================================
🔄 Round 45 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 45 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0172
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0044
============================================================


============================================================
🔄 Round 47 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 47 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0145
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0184
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

📊 Round 47 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

============================================================
🔄 Round 50 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 50 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0152
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0206
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0133

============================================================
🔄 Round 52 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 52 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0175
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0108
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0132

============================================================
🔄 Round 56 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 56 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0127
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0289
============================================================


============================================================
🔄 Round 58 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 58 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0255
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0190
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2515, R²: 0.0131

============================================================
🔄 Round 59 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 59 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0120
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0372
============================================================


============================================================
🔄 Round 62 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 62 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0117
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0380
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0133

📊 Round 62 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0134

============================================================
🔄 Round 67 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 67 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0201
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0004
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0134

============================================================
🔄 Round 69 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 69 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0173
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0147
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0135

============================================================
🔄 Round 70 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 70 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0201
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0005
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0135

============================================================
🔄 Round 72 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 72 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0084
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0370
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0135

📊 Round 72 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0135

📊 Round 72 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 76 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 76 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0153
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0199
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

📊 Round 76 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

📊 Round 76 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 79 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 79 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0199
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0000
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

📊 Round 79 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

============================================================
🔄 Round 81 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 81 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0156
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0065
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

============================================================
🔄 Round 82 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 82 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0098
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0337
============================================================


============================================================
🔄 Round 83 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 83 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0169
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0139
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 86 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 86 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0125
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0303
============================================================


============================================================
🔄 Round 87 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 87 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0183
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0090
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 88 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 88 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0102
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0317
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

============================================================
🔄 Round 90 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 90 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0211
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0038
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0138

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0138

============================================================
🔄 Round 97 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 97 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0211
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0027
============================================================


============================================================
🔄 Round 98 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 98 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0117
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0344
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0138

📊 Round 98 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

============================================================
🔄 Round 102 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 102 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0142
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0221
============================================================


============================================================
🔄 Round 103 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 103 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0112
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0362
============================================================


============================================================
🔄 Round 104 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 104 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0159
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0174
============================================================


============================================================
🔄 Round 105 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 105 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0140
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0252
============================================================


============================================================
🔄 Round 106 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 106 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0101
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0424
============================================================


============================================================
🔄 Round 108 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 108 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0093
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0472
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

============================================================
🔄 Round 110 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 110 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0155
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0162
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

============================================================
🔄 Round 111 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 111 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0130
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0304
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

📊 Round 111 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

============================================================
🔄 Round 114 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 114 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0192
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0061
============================================================


============================================================
🔄 Round 115 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 115 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0133
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0274
============================================================


============================================================
🔄 Round 116 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 116 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0135
   Val:   Loss=0.0866, RMSE=0.2944, R²=0.0243
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

============================================================
🔄 Round 120 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 120 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0160
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0158
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0142

============================================================
🔄 Round 121 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 121 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0152
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0211
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0142

📊 Round 121 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0142

📊 Round 121 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0142

============================================================
🔄 Round 124 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 124 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0182
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0032
============================================================


============================================================
🔄 Round 125 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 125 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0143
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0186
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0142

============================================================
🔄 Round 126 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 126 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0139
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0221
============================================================


============================================================
🔄 Round 127 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 127 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0114
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0108
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0141

📊 Round 127 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

============================================================
🔄 Round 131 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 131 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0127
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0241
============================================================


============================================================
🔄 Round 132 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 132 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0150
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0056
============================================================


============================================================
🔄 Round 135 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 135 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0295
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0340
============================================================


============================================================
🔄 Round 136 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 136 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0063
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0485
============================================================


============================================================
🔄 Round 137 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 137 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0105
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0412
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0138

📊 Round 137 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

============================================================
🔄 Round 141 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 141 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0098
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0408
============================================================


============================================================
🔄 Round 142 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 142 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0244
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0198
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

📊 Round 142 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

📊 Round 142 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

============================================================
🔄 Round 148 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 148 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0183
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0025
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

============================================================
🔄 Round 150 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 150 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0231
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0211
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0140

📊 Round 150 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

📊 Round 150 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

============================================================
🔄 Round 161 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 161 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0158
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0171
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

📊 Round 161 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

📊 Round 161 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

============================================================
🔄 Round 166 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 166 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0151
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0202
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

📊 Round 166 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0138

============================================================
🔄 Round 168 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 168 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0155
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0159
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0138

============================================================
🔄 Round 169 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 169 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0240
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0245
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

============================================================
🔄 Round 170 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 170 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0126
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0284
============================================================


============================================================
🔄 Round 173 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 173 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0180
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0091
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

📊 Round 173 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

📊 Round 173 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

📊 Round 173 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0139

📊 Round 173 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2514, R²: 0.0140

============================================================
🔄 Round 179 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 179 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0150
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0200
============================================================


============================================================
🔄 Round 182 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 182 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0069
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0334
============================================================


============================================================
🔄 Round 184 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 184 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0154
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0096
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0138

============================================================
🔄 Round 186 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 186 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0136
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0243
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

📊 Round 186 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

============================================================
🔄 Round 188 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 188 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0148
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0108
============================================================


============================================================
🔄 Round 190 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 190 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0183
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0081
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 197 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 197 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0179
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0060
============================================================


============================================================
🔄 Round 198 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 198 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0169
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0128
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

============================================================
🔄 Round 199 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 199 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0137
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0259
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

📊 Round 199 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 202 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 202 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0057
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0527
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

============================================================
🔄 Round 204 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 204 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0119
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0305
============================================================


============================================================
🔄 Round 205 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 205 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0140
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0089
============================================================


============================================================
🔄 Round 208 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 208 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0123
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0250
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2515, R²: 0.0136

📊 Round 208 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 211 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 211 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0127
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0279
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0137

============================================================
🔄 Round 214 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 214 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0267
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0239
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 216 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 216 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0182
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0068
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2515, R²: 0.0136

============================================================
🔄 Round 219 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 219 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0111
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0263
============================================================


============================================================
🔄 Round 222 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 222 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0179
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0028
============================================================


============================================================
🔄 Round 223 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 223 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0152
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0173
============================================================


============================================================
🔄 Round 224 - Client client_82
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 224 Summary - Client client_82
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0148
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0163
============================================================


❌ Client client_82 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
