[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4534ea75-3318-40a2-9779-3da85c673360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5020b776-ee9f-4b0d-97c7-8159a86b575c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee23f81-534c-4972-9355-b3ebbc4aa6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6df7ed-ce6d-447d-9c55-7f765d5cf6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f76552-9dcb-43d5-84ab-0cd0977551be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 304c30a0-3df9-49cb-880c-8a7f23a19e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb8a0e2-83ca-46e9-8509-f4e480021523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f34be50-10bd-4813-b59c-3d45445111ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66b972a2-1d1b-4839-8fcb-50578da253d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94d6ced-0162-4293-9dcc-ecebb83c8f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f46efc4-ef5f-4746-8d93-a1631a522b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef88132-5450-4f58-89ef-6124ae86d8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55152fe6-8410-4283-b35c-82ac2b4aefd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92604f73-c712-47fa-b454-d9b509859a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f17ce3-3574-4c1b-bda0-d2e556895d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276ec338-c588-4dd3-86c7-16c359979d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d6e7e3-a685-4544-84fe-f8ceb19737c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75041a78-8eca-4b7e-8aa4-c4e4bb400524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aeb663d-d71c-4f5b-8ff5-3e602c3c78bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acd76a21-5b02-4bef-bc1a-d5d7e5741329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd2f70e-782c-4784-b86f-e1b916f5bec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9949440-00df-486d-aca8-bbaa89cf838c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6072fa2-5504-42f1-b4b9-e85ea12adf08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f5a0f1-ae3b-4b7f-b7f2-7594b5570057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a5e550d-fb99-4506-9146-e977ca447855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8291f44d-01c0-44ce-b17b-cb565772888a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5918aa64-7575-48d4-8085-bfc4e2ce8aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a15610b6-8dae-441f-881d-83b587d54266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7eb6bd-5dcd-41a0-8f2c-f55e1dd8a225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90241e98-3f61-4bb8-adb1-e1b5ce151e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1e5fb2-c288-4e87-9303-24964ab410f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfda6640-37bc-4431-a26d-c2a114f15364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901f0af9-5c61-4b87-b8a5-f66394e82666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5209d8b-8037-483d-8d13-8c741921785b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4bf0b23-e671-4cb9-a982-7b096c5175cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16eec309-199e-407c-8641-a1efbbf60146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc381b73-629c-43e9-855c-e2798e5db124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 963f7ebf-39f9-4a29-bb82-d837a3007de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5677f09-80db-406a-9d08-f44008b3f27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc15cc21-9731-4023-a2a2-0dd4f8570b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63d21a7-569b-4399-84b1-f073e3c792c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee05d485-3631-47c9-9867-ba92f563c03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e815b14-d4a2-4dd8-86f9-af1ec2287bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e01a1f2f-9257-44fd-8d2a-abf0ce1d3f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c96cc2-146a-48a9-bc1f-ba6ea4f45554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a370ccdf-045d-440a-ab2e-c38ce30b7e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de1a686b-76e3-4b21-9c19-21772cb28e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3b08d4a-cb7b-4410-b2e0-8d658c100e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01edb462-79e3-4696-9f52-620527e9f21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b0df1e6-d153-449e-a7c0-396f2a3828ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030af241-cccc-4e82-b61b-12f892c0aaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f43f7bd-d4e5-4dbf-9ccf-f2ffdb2d33ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7492da4-4bdd-46f2-bdb7-bf7d05d09285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eba197c-2f3d-4467-9b06-8d93ed5643e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686fe405-6ad0-4eab-a1eb-80300c76dfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30ead793-0af9-48fb-993b-ca67a41139da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aafaa60-591f-4a65-b3c5-8183cfc74396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aae35e5-4899-4943-99ef-e2c9a2a4fa51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c93bbce-dd3c-4855-8f2c-0b4e602a9e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5408a59-ac62-4cc2-a3fe-5c21f651ce68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b9fcfea-f3ad-4883-82d5-ef2d0baece8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 024731f7-d4f1-49ec-8cec-abf2140885fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bffa93c3-77b5-4a09-b630-8602afaa0ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb9cbc22-36e1-41ae-b09a-28cbf85971ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53527537-dee5-4132-af0d-79fd7fe524cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e13f568-8a51-419b-b250-c55a900861c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2c5178b-c606-47a3-8845-1c6b49532ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d436b80-2237-4a27-a2d7-dab00adffc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45111aed-e0a6-4dbe-9f3a-ca546132a211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe12cd1-3ab4-438e-b412-f989eefda0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b693ecc-ef50-44d0-92f3-c93cea9f1ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf2fdcd1-d8f6-4078-8943-401abf9f0740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adfac1de-85d0-492f-9bf0-27426cee767b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6cda1e2-4d61-45a7-8bdc-cd2df0e0859e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fedb4d2-8708-4462-9a24-cf1a04d4dcfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74dbcb8b-a7c8-476a-b8c2-577d4dfe5836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2616fff3-acea-4691-9ff0-a8028316bf9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 999b9d5f-9947-413a-b463-8fc9bed47987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a38c29f-bb24-48cd-84f5-c6a80150eb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e0e62fa-028c-4dcd-957c-d942b5bebb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8420dba7-ba4b-49e2-acd3-e53d6806714d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a430c42d-aa75-4836-af30-66c7bc1944ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d79da1-c4c1-460e-874e-e32bd8c2c387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34d2a712-26dc-42fe-a05f-599f69e3b499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03cefee9-0c15-45cc-b6f7-ee12f1f028d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1249958-2842-4e45-b461-1cb46b51eee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc38e49-d59a-49c3-82e0-324aa3ea941b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2490766-f4f0-4a8e-9449-4728777dc4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb58663-5cb6-45b4-a9ae-ab3095a06f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87b1639-817b-4a31-81e4-bc25b1f7470d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9245e634-3652-4c91-b4fa-015859371fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71d3d4c-0deb-4902-9c6e-416f2a44852b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ffb0b8-b343-4055-b5fb-4b8e224e4c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae4b3196-9641-4149-bde3-3b3602ae0a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae819db9-c054-4cd5-a538-e3e746b9122a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86b31e70-1b8f-4974-8433-7faac0c52d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8edfc1f1-61ce-4346-b267-238f19e4bfba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eebc9b67-5d56-47cc-bcea-387daa78a727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9a8940-304c-4cf9-b844-6d49f7705a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f66f3f-60d5-4e10-89ba-fb80da10dd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61115dfb-a408-4994-9439-550f178072e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9616c1-b476-415e-97fb-56c32a0ace12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08cb6489-0a10-4f32-ae6d-4d35a2842588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fae84c6-4a19-45be-a738-7ef04db83df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba62eb2-e18b-4a06-b670-bf7addbabf5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ac007c-6afb-4e9f-9b73-bcf85972a909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6f874b-67e4-4661-b881-fb35a97afd5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43841896-4610-46f8-b75e-8bbdaee05be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5773630a-ee60-4451-a44c-2a5f6d6fcf11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80afacad-dd07-416a-8bc1-da7601de5f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd3ccca-d13b-4f34-bec8-4fb8cd29bf6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1adb1da4-875a-48e9-8f07-a1a770d495fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16516b3b-77ba-443a-9fab-a3b51458661e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a745f949-3d3d-4081-b3fb-c09f80bf1379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8debf18a-b78a-412e-9bda-c3385922ce02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f78de5-6e99-4ec4-8601-edaee7d100b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924c6b37-dcc6-40ce-9e7f-0e84633ac0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ca73c4-3c2c-4f06-9deb-7799b93e3ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04730632-4ea5-4cb9-8822-6ad7674bdc50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42abcc47-58c1-4ae5-8dcd-18597961d2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c151f10f-8df7-4f61-805c-d8d360318ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd17fc5f-1a12-40e1-839d-9b863f05638f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed17ded3-7599-40b0-968b-79b558f0d890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d79e08-1358-426c-9454-1cd97a3471f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9885c4cd-2d77-47cb-8dc0-a853c90488c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c2c151-55db-405d-98d4-5d5e37288f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0fa729-efa1-45bd-bd26-3064da9fa928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2d4a40-803c-4c83-89f0-1510c2485bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0f5ef5-6223-4864-acf5-b0adbec92bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3018a3-6d49-4726-a996-c79c9892c732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd1927f-a0cb-4d2e-bb57-c75f4c6b6e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a33413-e6bc-4448-a962-98428d9be7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f48b684b-a043-447d-8b6f-763ad3487835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac97362b-1ce2-42ef-b8f9-503a6ceb0837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75db6108-dda4-4486-b19b-b60483c2b69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34af3378-2eb7-4a68-be27-d5da0b71c37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c780ac-9d61-441f-8ea3-812eb975ffd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609a8a94-da38-4d1a-a01b-0619960b4c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1198314-245d-433d-94dc-8192fe2cf666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73575ab1-124b-422a-abe8-98ff44c3eacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c6ca04-9c1c-4a1e-b390-f4844b024418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfaa1420-eb3a-48ab-ba9f-1602e60a4e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33fa8bd-286d-4449-be60-3232a4825ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b64b0c-eb12-47a2-8f75-5f2761c37d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea1b576c-b94e-4218-85e7-00fb504b3ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cbf30b3-a857-47e6-b3e4-30c87ffcd1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f1c0d44-449e-420a-a25d-02dfb0f314af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4515595b-ce21-48d2-9606-41c96e32af76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c6c93b5-3d48-45f2-90f5-435efb8795ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9926bb0b-fc89-4b6a-8a02-4873120c1757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4e4b57-d28f-4745-860a-07160d71fe72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c372933b-55b6-4e1b-92a3-862d2db3cfd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eedade1-a0fd-4e55-8187-80f511e75ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc5f9c8f-41b4-4b96-94e7-90c17979d79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91f6ac8f-81ce-486e-931d-fdd0d2ab179b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a4bc1e0-6d5d-4721-bc52-8a2996dae02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0b810b-ef85-4c1a-8b82-dd51522dc1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec7c1eb-a8e9-4dd3-b975-d5d191f81751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 391c2669-6c6a-4cbd-ad46-62ee249fd5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f6aa1e-4730-4718-acc4-54e9e2fe7f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fbc2aa3-6b0d-4b83-a0d7-ee47f71b62e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae07ff6-3dde-42f1-8e7a-267e86057952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bf1b5e3-839c-4011-a34e-89778a88d014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1661a063-7d50-4879-b296-b74adff6c708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4efc85d-4f71-46bd-888d-9a12ee06a384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aade1acd-eaf3-482d-ad58-a1f825a19088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3070800f-c2f1-4a93-9cbe-bcfd1225af6d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_83
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_83/test_labels.txt

📊 Raw data loaded:
   Train: X=(559, 24), y=(559,)
   Test:  X=(140, 24), y=(140,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 550 samples, 5 features
   Test:  131 samples, 5 features
✅ Client client_83 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0878, RMSE: 0.2964, MAE: 0.2560, R²: -0.0055

============================================================
🔄 Round 10 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0669 (↓), lr=0.001000
   • Epoch   2/100: train=0.0834, val=0.0678, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0802, val=0.0702, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0786, val=0.0697, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0782, val=0.0698, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0746, val=0.0677, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 10 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0078
   Val:   Loss=0.0669, RMSE=0.2587, R²=0.0257
============================================================


============================================================
🔄 Round 14 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0756 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0836, val=0.0737 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0826, val=0.0726 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0820, val=0.0720 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0815, val=0.0715 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   ✓ Epoch  11/100: train=0.0799, val=0.0701 (↓), lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0788, val=0.0692, patience=6/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0784, val=0.0689, patience=6/15, lr=0.000016
   📉 Epoch 39: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 14 Summary - Client client_83
   Epochs: 40/100 (early stopped)
   LR: 0.000250 → 0.000008 (5 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0704
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0452
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2547, R²: -0.0133

============================================================
🔄 Round 17 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0805 (↓), lr=0.000008
   • Epoch   2/100: train=0.0858, val=0.0803, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0857, val=0.0802, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0856, val=0.0800, patience=3/15, lr=0.000008
   ✓ Epoch   5/100: train=0.0854, val=0.0799 (↓), lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0850, val=0.0795, patience=6/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0847, val=0.0792, patience=8/15, lr=0.000002
   📉 Epoch 23: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 17 Summary - Client client_83
   Epochs: 28/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0244
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0004
============================================================


============================================================
🔄 Round 18 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 18 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0205
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.1000
============================================================


============================================================
🔄 Round 20 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 20 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0276
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0485
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2550, R²: -0.0177

📊 Round 20 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0181

============================================================
🔄 Round 22 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 22 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0392
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0239
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0180

============================================================
🔄 Round 23 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 23 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0221
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.1017
============================================================


============================================================
🔄 Round 25 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 25 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0337
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0526
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0179

============================================================
🔄 Round 29 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 29 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0684
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0478
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0180

============================================================
🔄 Round 32 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 32 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0289
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0695
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0181

📊 Round 32 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0182

📊 Round 32 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0182

📊 Round 32 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0182

============================================================
🔄 Round 38 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 38 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0404
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0235
============================================================


============================================================
🔄 Round 39 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 39 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0288
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0672
============================================================


============================================================
🔄 Round 40 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 40 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0393
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0423
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0890, RMSE: 0.2982, MAE: 0.2551, R²: -0.0183

📊 Round 40 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0184

📊 Round 40 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0185

📊 Round 40 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0185

============================================================
🔄 Round 47 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 47 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0552
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0453
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0184

============================================================
🔄 Round 49 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 49 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0438
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0557
============================================================


============================================================
🔄 Round 50 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 50 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0229
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0941
============================================================


============================================================
🔄 Round 51 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 51 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0317
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0652
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0186

============================================================
🔄 Round 53 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 53 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0555
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0209
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0185

============================================================
🔄 Round 55 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 55 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0367
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0373
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0185

============================================================
🔄 Round 57 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 57 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0231
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0921
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0184

============================================================
🔄 Round 61 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 61 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0413
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0195
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0186

============================================================
🔄 Round 63 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 63 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0481
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0113
============================================================


============================================================
🔄 Round 65 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 65 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0333
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0537
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0188

📊 Round 65 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2552, R²: -0.0189

============================================================
🔄 Round 69 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 69 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0356
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0525
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2553, R²: -0.0192

📊 Round 69 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2553, R²: -0.0193

============================================================
🔄 Round 77 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 77 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0311
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0596
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2553, R²: -0.0194

📊 Round 77 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2553, R²: -0.0194

============================================================
🔄 Round 80 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 80 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0322
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0718
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2553, R²: -0.0195

============================================================
🔄 Round 81 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 81 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0332
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0602
============================================================


============================================================
🔄 Round 82 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 82 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0351
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0474
============================================================


============================================================
🔄 Round 83 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 83 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0505
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0206
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2553, R²: -0.0194

============================================================
🔄 Round 85 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 85 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0328
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0723
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2553, R²: -0.0195

============================================================
🔄 Round 88 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 88 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0436
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0104
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2553, R²: -0.0195

============================================================
🔄 Round 89 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 89 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0279
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0839
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0891, RMSE: 0.2984, MAE: 0.2553, R²: -0.0195

============================================================
🔄 Round 91 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 91 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0387
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0316
============================================================


============================================================
🔄 Round 92 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 92 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0328
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0865
============================================================


============================================================
🔄 Round 93 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 93 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0725
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0819
============================================================


============================================================
🔄 Round 94 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 94 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0210
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.1114
============================================================


============================================================
🔄 Round 96 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 96 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0392
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0362
============================================================


============================================================
🔄 Round 97 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 97 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0424
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0194
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0198

📊 Round 97 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0199

============================================================
🔄 Round 99 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 99 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0359
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0459
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0199

============================================================
🔄 Round 102 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 102 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0029
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.2082
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0200

============================================================
🔄 Round 103 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 103 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0451
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0117
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0200

============================================================
🔄 Round 104 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 104 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0368
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0513
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0201

============================================================
🔄 Round 106 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 106 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0257
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0923
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0202

📊 Round 106 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0202

============================================================
🔄 Round 113 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 113 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0369
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.0521
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0891, RMSE: 0.2985, MAE: 0.2554, R²: -0.0203

============================================================
🔄 Round 114 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 114 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0268
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0811
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0891, RMSE: 0.2986, MAE: 0.2554, R²: -0.0204

============================================================
🔄 Round 117 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 117 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0224
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.1237
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0891, RMSE: 0.2986, MAE: 0.2554, R²: -0.0206

📊 Round 117 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0207

📊 Round 117 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0208

============================================================
🔄 Round 123 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 123 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0399
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0302
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0207

📊 Round 123 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0207

📊 Round 123 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0207

============================================================
🔄 Round 127 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 127 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0424
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0451
============================================================


============================================================
🔄 Round 128 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 128 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0439
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0187
============================================================


============================================================
🔄 Round 129 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 129 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0261
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.1040
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0206

============================================================
🔄 Round 131 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 131 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0348
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0614
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0891, RMSE: 0.2986, MAE: 0.2555, R²: -0.0206

============================================================
🔄 Round 132 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 132 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0378
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0471
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0206

📊 Round 132 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0206

============================================================
🔄 Round 134 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 134 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0439
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0190
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0891, RMSE: 0.2986, MAE: 0.2555, R²: -0.0206

============================================================
🔄 Round 136 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 136 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0416
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0319
============================================================


============================================================
🔄 Round 137 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 137 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0328
   Val:   Loss=0.0787, RMSE=0.2804, R²=-0.0614
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0891, RMSE: 0.2986, MAE: 0.2555, R²: -0.0205

============================================================
🔄 Round 138 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 138 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0377
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0441
============================================================


============================================================
🔄 Round 140 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 140 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0261
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0945
============================================================


============================================================
🔄 Round 141 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 141 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0496
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0073
============================================================


============================================================
🔄 Round 142 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 142 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0499
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0126
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0207

📊 Round 142 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0207

============================================================
🔄 Round 145 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 145 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0388
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0418
============================================================


============================================================
🔄 Round 146 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 146 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0390
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0349
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0208

📊 Round 146 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0208

============================================================
🔄 Round 152 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 152 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0352
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0647
============================================================


============================================================
🔄 Round 155 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 155 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0300
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0813
============================================================


============================================================
🔄 Round 157 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 157 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0371
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0827
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0210

============================================================
🔄 Round 160 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 160 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0175
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.1238
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0210

📊 Round 160 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0210

============================================================
🔄 Round 167 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 167 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0290
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0744
============================================================


============================================================
🔄 Round 168 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 168 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0439
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0143
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2555, R²: -0.0209

============================================================
🔄 Round 169 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 169 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0235
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.1059
============================================================


============================================================
🔄 Round 171 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 171 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0553
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0245
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0212

============================================================
🔄 Round 180 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 180 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0252
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0886
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0211

============================================================
🔄 Round 181 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 181 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0507
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0035
============================================================


============================================================
🔄 Round 182 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 182 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0273
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0847
============================================================


============================================================
🔄 Round 184 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 184 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0401
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0439
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0211

📊 Round 184 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0211

📊 Round 184 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0211

============================================================
🔄 Round 190 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 190 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0464
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0049
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0211

============================================================
🔄 Round 192 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 192 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0286
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0855
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0211

============================================================
🔄 Round 193 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 193 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0268
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.1078
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0211

============================================================
🔄 Round 194 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 194 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0446
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0399
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0212

📊 Round 194 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0213

============================================================
🔄 Round 201 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 201 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0216
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.1003
============================================================


============================================================
🔄 Round 203 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 203 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0401
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0643
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0211

📊 Round 203 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0213

============================================================
🔄 Round 207 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 207 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0384
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0477
============================================================


============================================================
🔄 Round 208 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 208 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0457
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0454
============================================================


============================================================
🔄 Round 210 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 210 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0158
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.1397
============================================================


============================================================
🔄 Round 211 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 211 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0287
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0862
============================================================


============================================================
🔄 Round 213 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 213 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0419
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0268
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0217

📊 Round 213 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0216

============================================================
🔄 Round 216 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 216 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0369
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0475
============================================================


============================================================
🔄 Round 218 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 218 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0470
   Val:   Loss=0.0700, RMSE=0.2647, R²=-0.0215
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2556, R²: -0.0217

============================================================
🔄 Round 219 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 219 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0357
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0590
============================================================


============================================================
🔄 Round 221 - Client client_83
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 221 Summary - Client client_83
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0358
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0518
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2557, R²: -0.0218

📊 Round 221 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2557, R²: -0.0218

❌ Client client_83 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
