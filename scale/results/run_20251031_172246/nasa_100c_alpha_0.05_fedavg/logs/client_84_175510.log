[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b204cd2-6f80-4229-8925-4dc493d9f168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c242ce1-cc0c-4e69-a0df-50d08395b2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e475f8f-28f9-4657-8d3b-5d67e33db703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c3f1fa1-6d8c-40b4-a56a-9c49c88cfb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 097b9aa9-2c6e-48ad-afb5-31883c962a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a288bd-bfb7-4bdc-860a-3c5494292ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5ea19e9-78ed-4f64-a127-1f08665ac579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83ad3e3-c2c4-4e4e-b39d-50abf6f3a55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d24c21-1eb4-4a09-9f80-9f1825ace020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b81289c-c9a1-42cc-96e0-9430bef4a5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3887b45-2bf8-4f82-b295-fc1c6a5d81af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61bcf7b6-a611-48aa-86e1-7c44e86ed232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8b46b3-2594-49ae-b191-23a3a3587071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1030fba8-5937-4dde-b7ba-b20bb9ea8cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8970e056-8fb4-4955-a779-27fa56896323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da3ed8b-3e29-4dd1-80ed-8ced8bb88fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 711c6adb-1f54-411f-852f-99288de4ff68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69690141-b66c-4088-9a24-a15cfe83891a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e196e51b-5858-41a7-9273-18ca48d92295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d690314-b6c0-4293-b200-1537b3d685eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df8797f7-8775-48f2-a6bf-ecfee8561f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4070da97-87be-4f88-92b4-f6b814a484db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e3ce3c7-c071-47f6-8289-eec8025bbc20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67698d2-54cb-47e4-8be3-276c9ef7c3e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 197f3770-f5d8-48f6-aa2e-e5ae835cb698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600badfc-b8f7-4422-bbfe-0dfad1a5451a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f327379-d08e-41e7-8562-d80602317807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3774f05c-b6ae-4d27-819a-94d75ab8fe54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b08140-4b6c-4fd2-9f57-2ce24f635c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d165f1c0-39ed-49d4-8f23-a8afd98a42bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a79fa91-1bdc-4cab-8417-a9426665c652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d5b2db-0876-4183-9fe4-91d83ffd565a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e28098c8-8450-4dd9-91f7-591bad3ddcf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed96cc69-765e-405d-b508-b21e10b67db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 543761ed-6295-43c6-9137-f25e5c8bf2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b3c4f31-7bd8-4b38-ba36-2e22669a2eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5e706f-24e2-4f93-82b3-e18cf9d0e6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24c0e5c-974e-4f64-9384-63d1d52c776e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f9e6616-2667-44de-9113-48de6739d742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36bb0cc-1c16-4bd0-9574-0029f83905ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 729c9a77-c02f-4784-9524-c7e6a861c439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86a0c2e4-4f05-4550-a2ae-143e830f6547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f84206-9be4-4d96-bb69-10f86bf2833a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f177edce-633b-46d6-a59b-748b221ad93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71e4c2a3-7bd4-45c6-b5f1-3224b90facd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a6e95a-6338-40e1-8fc2-6c515cccf03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ff73cc3-e70e-40bc-ad7c-3e905ee437a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e90b731-27c6-45a6-8dbd-18b6073cb689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b586d889-2fb4-4373-8866-e5577d5b50d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd61ae1-ce22-415a-947d-41a287da022f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3935aa06-021c-46b7-9040-1338127438c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ff627a-2ecc-4141-88af-8c1f6d4fa45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b23248b-2279-4c8e-8a92-39fd5e899018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de06dcb7-873a-4276-b720-fe0089c74f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a01249e-114c-432e-b7f0-5045fa42f100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f32f18-6f6d-4b3b-b3a2-2fd26f28b5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97a6dcc7-bb32-4676-89cf-8bd6d2f74a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 015124e5-69e6-4de7-b835-86e8a9d9e19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943437f1-1779-497c-9da6-0fa115272bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6544192-8223-4de5-a389-c475056a7dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a78dfe6-16dc-410b-8ee5-8f24d15ac890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbd468d5-8a40-4c17-afe4-9cb449373706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51bc5a3-84b8-4c70-8f63-b476b759ff20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a25a7a87-6cb0-4b12-95da-93f0a6440051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a9bc6b8-d6ad-4066-bada-21894bc2c912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069e778c-d599-4765-98f1-e2d9a9079fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5efc551-8dfc-415a-b925-9728ef7c5b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48414859-2a23-4848-b852-e93acc87a750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbe7bb90-da6d-4d17-b9b1-581aa5492531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba3abf4-fb31-4141-9407-9a1369dc9211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e173ab-dd31-4848-b4ef-c985786333e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fead920-935c-4f73-8a22-ca573ecc39c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c026d5e-be40-45d9-8daf-50196a7c5ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd35ee3-9783-4e23-a38a-ed54fde68614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d59f3e0-84df-48e1-93bf-617b75b84c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 707a8807-cff5-4068-b9de-d31260ca28a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38160566-3757-449f-a4ce-8d57a9377819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05aea3c0-66e1-457b-9ff2-cddf6c62dd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46f8c42e-eda6-4f5b-ae45-6bcecb499f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29217b90-b04f-4ce6-90cb-787da9bdd441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac541f6f-a268-4925-b832-b051818aa2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fccdca-02f5-4b46-b8e2-b47a696e6d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e3cfc8-28d5-41c9-85e2-bbd2bee5196f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe43b5a-fa9f-45a7-9b1f-c8bd54a8e02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6601d2e6-c012-4948-83e1-92adb73ca7eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d9f20ca-a95d-45b4-bcc7-a3eeef01bcbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 439c3101-8723-4dba-8f4c-34b789059cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7626fba8-bfcb-48bf-bde8-08ce65f8e4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42651fdb-0507-45af-8ddc-f9418a4ca56e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9445a5a4-516f-4735-ad3d-46003d211f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 330a6ad4-f0dc-431d-8b08-4a22abdf844f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45668dff-22e9-4b40-8123-a877568b4393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7dab530-e341-409b-8eea-1ac5e3f48554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf00b63-813b-4cb2-b027-f26f35d35ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e081245-5690-484c-afee-6acdc012a7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f988ebd2-f6fc-4a2d-8b13-a09afc42737b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b14428d-d638-4cc5-925f-0f0e0f93cea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38755cd-2395-48d2-9af1-ae68e3277ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf5ae4a5-8f08-4d04-84bc-8b23d178b746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fda68cc-9ff0-4246-ab0a-b1a988405e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2693ec37-7537-4453-a10f-f9e2a91b36ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8b035b-7ebd-4325-b985-5055e092990b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c618f2ce-8c3c-441e-86a7-3a623eb3d33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ef5dd85-a40a-4943-aa49-03d3aa9d716c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0c33e7-2779-4fbf-bc8d-d847574beac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9deab913-e8d5-4c5c-838e-5a1c38e5c5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88550936-c09a-4cdd-b0bd-08185a9bf983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68d8b946-161d-4b69-995f-c9fa34d9e13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cdfd098-2a95-4692-a613-644bed3efc2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e60085e-7e77-4e41-a2cb-c70dee2b4772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c2a23a-6000-4fc8-849d-98f5d5955b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb7b24d-03de-4080-9419-d2589fc80df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4bc47af-5261-4445-a8e9-a6c58e469289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12273048-2649-417d-b07b-b2211e89205d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85cfbd28-d26d-4db6-9dbf-d6ede0146d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d367244b-e214-4fba-b1cb-3f1d57fb92af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80ff327b-c5a0-4c3b-a82a-1546c3f5474f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ed53fb-3719-41a5-ac8a-1ba5a1a54d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10dff8a2-3a0a-40db-a081-e913d13e68ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abda2ee2-2014-4b74-bc86-02c0802fb944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef3f7a4-f923-49b2-b7e6-c633a0dd3cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa02c2cb-5f02-46d9-8692-5663f3010e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8721e16-b5ce-4738-8ec4-f1a3c1334672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7bcd8c-b410-4949-b9f5-92cdf4a372e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba069df-7ea6-42a2-a077-ca7745da4281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d108d62-8813-4596-b070-ba646bbf1134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63570a06-fb63-44f1-8505-e5a2b0afed06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361353ab-1568-41cf-9abf-2ede801fce87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816fad42-953b-425b-bfba-fbc0ebd38376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc7decf-3719-4fab-90b2-ff14fc19c911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 351f71b3-b08a-4c5e-b9b0-bac122d99a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18382166-4695-477b-8713-83aaf525f6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82195581-e086-443a-82df-b8b8416f3992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 148eb099-8b91-477b-ac4b-3f850763bfe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ffe616-829b-48e3-b8ee-70ee6ab28a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e77bfd1-8c06-43cf-85a3-968d2dc1ca77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6b33fd-a2fe-45fd-b67e-4bdf1ff6bfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1967ab7d-93fb-482a-9886-01250d4bbf76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef995c8-97b9-4298-819e-f3b89c86f7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2396fda1-031f-476f-baba-7c080f16bac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f9ed13-fbb4-4dd9-b999-37045778de71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3484786-c495-4fbb-8225-54642d4b7147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f05b47b-288d-4549-943d-d1aec89a38ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fea1ec7-e116-49e2-8ee3-9ded389bb75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab0b858a-2bff-4592-83bc-b88f7275881a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03538429-5ad4-4d49-aaf1-e20749c318a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0420f77f-092e-48f3-8b43-d1c2b90a6463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e75347-2979-4a0a-812f-596ea6fce441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e61d568d-9000-45ad-b4f2-018e4eb149cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac31d41e-d683-489b-8a75-7e02943d5510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1891afba-5798-4a88-a98c-5b418a304129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b570e90a-1251-471c-bb3d-bad02081d935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f38dbc8-3453-4dbb-b8c5-77f6f3ba58e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de74149-9b85-4f99-a313-c84da2da6f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae30ed3-2827-423d-b473-dd9dfdcf00c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc862fe-f8dd-4982-809c-3140486de26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 186efe3b-0875-475c-aac0-5afb3ca60a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1091d03e-5699-4052-adac-5af282806960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13387dc4-786e-49f8-8e98-f2e6d7671a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ccb6ae-a8ab-4776-b479-73deef89a411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b9aa84-0bfd-485b-9027-7d6477f78bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cad24dd-52dc-4d78-8759-ca521ba30a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2ae7cdf-f507-42ad-b974-b3d8154e3745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5472935f-bee3-490d-97ef-05a76b653f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822eac1d-19ae-47bd-a9a9-22c7ea0d5494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a752c8ec-2c78-4c10-be74-49ac65cb2da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e81fd06-64fe-406f-9dc0-f366e8da8273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf207dc-ff7c-43ca-9f7d-6f32a601de61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48579c4-5fd5-4481-8892-9851c62d0c30
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_84
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_84/test_labels.txt

📊 Raw data loaded:
   Train: X=(2020, 24), y=(2020,)
   Test:  X=(506, 24), y=(506,)

⚠️  Limiting training data: 2020 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  497 samples, 5 features
✅ Client client_84 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2313, R²: 0.0556

============================================================
🔄 Round 8 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0740 (↓), lr=0.001000
   • Epoch   2/100: train=0.0773, val=0.0748, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0767, val=0.0756, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0756, val=0.0729 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0740, val=0.0713 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0691, val=0.0679 (↓), lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0607, val=0.0717, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 8 Summary - Client client_84
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0677, RMSE=0.2601, R²=0.1805
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.1350
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2320, R²: 0.0517

============================================================
🔄 Round 9 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0779, val=0.0779 (↓), lr=0.000250
   • Epoch   2/100: train=0.0766, val=0.0784, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0761, val=0.0780, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0756, val=0.0779, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0752, val=0.0776, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0725, val=0.0767, patience=4/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0709, val=0.0759, patience=4/15, lr=0.000063
   📉 Epoch 25: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0703, val=0.0755, patience=14/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 9 Summary - Client client_84
   Epochs: 32/100 (early stopped)
   LR: 0.000500 → 0.000031 (4 reductions)
   Train: Loss=0.0712, RMSE=0.2668, R²=0.1182
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.1110
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2316, R²: 0.0556

============================================================
🔄 Round 10 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0792, val=0.0688 (↓), lr=0.000016
   • Epoch   2/100: train=0.0791, val=0.0688, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0790, val=0.0687, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0790, val=0.0687, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0789, val=0.0686, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0786, val=0.0685, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 10 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0555
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0643
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2320, R²: 0.0545

============================================================
🔄 Round 14 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0768, val=0.0777 (↓), lr=0.000004
   • Epoch   2/100: train=0.0768, val=0.0776, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0767, val=0.0776, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0767, val=0.0776, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0767, val=0.0776, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0766, val=0.0774, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 14 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0625
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0414
============================================================


============================================================
🔄 Round 15 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0738, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 15 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0587
   Val:   Loss=0.0878, RMSE=0.2962, R²=0.0687
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2315, R²: 0.0594

============================================================
🔄 Round 16 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 16 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0642
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0570
============================================================


============================================================
🔄 Round 17 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 17 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0529
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0976
============================================================


============================================================
🔄 Round 18 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 18 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0703
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0431
============================================================


============================================================
🔄 Round 19 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 19 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0545
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.1056
============================================================


============================================================
🔄 Round 21 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 21 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0711
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0516
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0737, RMSE: 0.2715, MAE: 0.2310, R²: 0.0641

============================================================
🔄 Round 24 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 24 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0665
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0707
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0737, RMSE: 0.2715, MAE: 0.2310, R²: 0.0643

============================================================
🔄 Round 26 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 26 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0645
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0805
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2310, R²: 0.0644

📊 Round 26 Test Metrics:
   Loss: 0.0737, RMSE: 0.2715, MAE: 0.2310, R²: 0.0643

============================================================
🔄 Round 28 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 28 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0549
   Val:   Loss=0.0660, RMSE=0.2570, R²=0.1186
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0737, RMSE: 0.2715, MAE: 0.2310, R²: 0.0643

============================================================
🔄 Round 29 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 29 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0731
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0445
============================================================


============================================================
🔄 Round 31 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 31 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0615
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0788
============================================================


============================================================
🔄 Round 32 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 32 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0776
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0189
============================================================


============================================================
🔄 Round 33 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 33 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0752
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0348
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2310, R²: 0.0645

📊 Round 33 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2310, R²: 0.0645

📊 Round 33 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2310, R²: 0.0645

============================================================
🔄 Round 36 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 36 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0763
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0319
============================================================


============================================================
🔄 Round 37 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 37 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0648
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0642
============================================================


============================================================
🔄 Round 38 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 38 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0708
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0562
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2310, R²: 0.0645

📊 Round 38 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2310, R²: 0.0646

============================================================
🔄 Round 40 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 40 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0756
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0293
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2310, R²: 0.0646

============================================================
🔄 Round 41 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 41 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0705
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0531
============================================================


============================================================
🔄 Round 47 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 47 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0623
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0624
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2310, R²: 0.0647

📊 Round 47 Test Metrics:
   Loss: 0.0736, RMSE: 0.2714, MAE: 0.2310, R²: 0.0648

📊 Round 47 Test Metrics:
   Loss: 0.0736, RMSE: 0.2714, MAE: 0.2310, R²: 0.0649

📊 Round 47 Test Metrics:
   Loss: 0.0736, RMSE: 0.2714, MAE: 0.2309, R²: 0.0648

============================================================
🔄 Round 54 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 54 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0643
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0799
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0736, RMSE: 0.2714, MAE: 0.2309, R²: 0.0649

📊 Round 54 Test Metrics:
   Loss: 0.0736, RMSE: 0.2714, MAE: 0.2309, R²: 0.0649

============================================================
🔄 Round 60 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 60 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0553
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.1185
============================================================


============================================================
🔄 Round 62 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 62 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0745
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0399
============================================================


============================================================
🔄 Round 66 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 66 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0684
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0672
============================================================


============================================================
🔄 Round 67 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 67 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0734
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0478
============================================================


============================================================
🔄 Round 69 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 69 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0654
   Val:   Loss=0.0662, RMSE=0.2574, R²=0.0817
============================================================


============================================================
🔄 Round 70 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 70 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0720
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0534
============================================================


============================================================
🔄 Round 73 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 73 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0757
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0366
============================================================


============================================================
🔄 Round 75 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 75 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0729
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0509
============================================================


============================================================
🔄 Round 76 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 76 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0622
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0905
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0736, RMSE: 0.2713, MAE: 0.2309, R²: 0.0655

📊 Round 76 Test Metrics:
   Loss: 0.0736, RMSE: 0.2713, MAE: 0.2309, R²: 0.0656

📊 Round 76 Test Metrics:
   Loss: 0.0736, RMSE: 0.2713, MAE: 0.2309, R²: 0.0656

📊 Round 76 Test Metrics:
   Loss: 0.0736, RMSE: 0.2713, MAE: 0.2309, R²: 0.0656

============================================================
🔄 Round 81 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 81 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0646
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0840
============================================================


============================================================
🔄 Round 82 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 82 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0654
   Val:   Loss=0.0687, RMSE=0.2620, R²=0.0807
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0736, RMSE: 0.2713, MAE: 0.2309, R²: 0.0656

📊 Round 82 Test Metrics:
   Loss: 0.0736, RMSE: 0.2713, MAE: 0.2309, R²: 0.0656

============================================================
🔄 Round 84 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 84 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0554
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0942
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0736, RMSE: 0.2713, MAE: 0.2309, R²: 0.0657

📊 Round 84 Test Metrics:
   Loss: 0.0736, RMSE: 0.2713, MAE: 0.2309, R²: 0.0657

============================================================
🔄 Round 89 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 89 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0676
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0150
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0736, RMSE: 0.2712, MAE: 0.2309, R²: 0.0658

📊 Round 89 Test Metrics:
   Loss: 0.0736, RMSE: 0.2712, MAE: 0.2309, R²: 0.0658

============================================================
🔄 Round 94 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 94 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0689
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0671
============================================================


============================================================
🔄 Round 95 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 95 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0643
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0749
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0736, RMSE: 0.2712, MAE: 0.2309, R²: 0.0659

============================================================
🔄 Round 97 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 97 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0629
   Val:   Loss=0.0674, RMSE=0.2597, R²=0.0909
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0736, RMSE: 0.2712, MAE: 0.2309, R²: 0.0659

============================================================
🔄 Round 98 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 98 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0636
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0903
============================================================


============================================================
🔄 Round 99 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 99 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0642
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0850
============================================================


============================================================
🔄 Round 100 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 100 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0609
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0996
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0735, RMSE: 0.2712, MAE: 0.2308, R²: 0.0661

📊 Round 100 Test Metrics:
   Loss: 0.0735, RMSE: 0.2712, MAE: 0.2308, R²: 0.0661

============================================================
🔄 Round 108 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 108 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0641
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0840
============================================================


============================================================
🔄 Round 110 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 110 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0723
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0386
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0735, RMSE: 0.2712, MAE: 0.2308, R²: 0.0662

============================================================
🔄 Round 113 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 113 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0644
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0852
============================================================


============================================================
🔄 Round 115 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 115 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0782
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0295
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0664

============================================================
🔄 Round 117 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 117 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0619
   Val:   Loss=0.0675, RMSE=0.2598, R²=0.0989
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0665

📊 Round 117 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0665

============================================================
🔄 Round 120 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 120 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0773
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0386
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0666

📊 Round 120 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0666

📊 Round 120 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0666

📊 Round 120 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0666

============================================================
🔄 Round 125 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 125 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0717
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0487
============================================================


============================================================
🔄 Round 128 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 128 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0704
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0617
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0667

============================================================
🔄 Round 132 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 132 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0671
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.0794
============================================================


============================================================
🔄 Round 135 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 135 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0622
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0636
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0667

============================================================
🔄 Round 137 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 137 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0688
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0723
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0667

📊 Round 137 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0668

📊 Round 137 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2308, R²: 0.0669

============================================================
🔄 Round 143 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 143 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0748
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0192
============================================================


============================================================
🔄 Round 144 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 144 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0699
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0124
============================================================


============================================================
🔄 Round 147 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 147 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0673
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0795
============================================================


============================================================
🔄 Round 148 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 148 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.0716
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0530
============================================================


============================================================
🔄 Round 149 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 149 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0778
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0355
============================================================


============================================================
🔄 Round 150 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 150 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0663
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0827
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2307, R²: 0.0670

📊 Round 150 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2307, R²: 0.0671

============================================================
🔄 Round 153 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 153 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0647
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0785
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2307, R²: 0.0671

============================================================
🔄 Round 154 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 154 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0661
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0850
============================================================


============================================================
🔄 Round 157 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 157 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0710
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0643
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0735, RMSE: 0.2710, MAE: 0.2307, R²: 0.0672

============================================================
🔄 Round 159 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 159 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0691
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0707
============================================================


============================================================
🔄 Round 160 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 160 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0633
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0673
============================================================


============================================================
🔄 Round 161 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 161 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0598
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.1038
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0735, RMSE: 0.2710, MAE: 0.2307, R²: 0.0672

============================================================
🔄 Round 163 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 163 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0710
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0629
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0735, RMSE: 0.2710, MAE: 0.2307, R²: 0.0673

📊 Round 163 Test Metrics:
   Loss: 0.0735, RMSE: 0.2710, MAE: 0.2307, R²: 0.0672

============================================================
🔄 Round 167 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 167 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0612
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.1032
============================================================


============================================================
🔄 Round 169 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 169 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.0723
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0602
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2307, R²: 0.0674

============================================================
🔄 Round 173 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 173 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0718
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0496
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2307, R²: 0.0674

============================================================
🔄 Round 174 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 174 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0681
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0737
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2307, R²: 0.0675

============================================================
🔄 Round 176 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 176 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0675
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0766
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2307, R²: 0.0675

============================================================
🔄 Round 180 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 180 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2741, R²=0.0819
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0220
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2307, R²: 0.0675

============================================================
🔄 Round 182 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 182 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2719, R²=0.0749
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0439
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2307, R²: 0.0676

============================================================
🔄 Round 183 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 183 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0704
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0677
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2307, R²: 0.0676

📊 Round 183 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2307, R²: 0.0676

📊 Round 183 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2306, R²: 0.0676

============================================================
🔄 Round 188 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 188 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0632
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.1012
============================================================


============================================================
🔄 Round 189 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0644 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0644, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0644, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0644, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0644, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0644, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0644)

============================================================
📊 Round 189 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0563
   Val:   Loss=0.0644, RMSE=0.2538, R²=0.1153
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2306, R²: 0.0676

============================================================
🔄 Round 190 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 190 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0774
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0364
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0734, RMSE: 0.2710, MAE: 0.2306, R²: 0.0677

============================================================
🔄 Round 194 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 194 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0631
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0715
============================================================


============================================================
🔄 Round 196 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 196 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0709
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0589
============================================================


============================================================
🔄 Round 200 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 200 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0757
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0476
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0678

============================================================
🔄 Round 202 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 202 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2674, R²=0.0786
   Val:   Loss=0.0943, RMSE=0.3070, R²=0.0268
============================================================


============================================================
🔄 Round 203 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 203 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0753
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0420
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0678

============================================================
🔄 Round 205 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 205 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0782
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0356
============================================================


============================================================
🔄 Round 206 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 206 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0776
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0329
============================================================


============================================================
🔄 Round 207 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 207 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0699
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0707
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0679

📊 Round 207 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0680

📊 Round 207 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0680

📊 Round 207 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0680

📊 Round 207 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0681

============================================================
🔄 Round 213 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 213 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0733
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0523
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0681

📊 Round 213 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0681

============================================================
🔄 Round 218 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 218 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0647
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0828
============================================================


============================================================
🔄 Round 220 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 220 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0696
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0739
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0682

============================================================
🔄 Round 222 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 222 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0651
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.0950
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2306, R²: 0.0683

============================================================
🔄 Round 224 - Client client_84
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 224 Summary - Client client_84
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0655
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0889
============================================================


❌ Client client_84 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
