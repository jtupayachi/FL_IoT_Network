[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49636fe3-a0b6-47ae-90c6-70e12a3dacbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b85789-80fc-4b65-8fa5-cb7c2b932902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da96e3f8-f13f-4c90-b036-96c5499466b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2d58a4e-dcad-44da-b242-44184f7cf0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d53c4ed-d029-4b81-b62c-449a13c0bd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559bb453-2f8f-4373-8308-10f1bb335ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e1ead34-12de-46b1-abf2-c584a63d0891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45610fca-949d-47b4-8469-3dcb49d42c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 805641c8-7c73-4118-886b-539c5712764b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b0d16a-9dff-44a4-99fe-76c9456603ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b53df67-6575-4660-be73-c458d22c8a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34bffb9e-62a3-46ab-b506-8e83ade7ccbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64cab8e1-2bfd-4ec8-9735-065f3e03e949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7ba8d1-60a3-42f5-bf76-359ec1d2ad72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11dee777-4660-46fc-905b-150d23a14ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d0e666-fe20-440f-91ec-8fca153383a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a670496-98a2-4f9b-9d6f-1223f2f04c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe0fa12-299b-4e71-880d-6aa05683d96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8095354e-411a-4518-a754-39ff5884017e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6efd6354-2e41-4719-91a1-74a5dfbf3e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bfa9c40-9c0d-4f66-be04-5a3e664f17c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a237c187-230e-41c0-b42e-259748bb771d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0fdc948-ace7-40c6-bbe4-5e85f4e09a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62acd7e8-26a0-43de-b8a4-e215a4c7bfa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31fc0e02-fc23-426f-9b4c-e8ae628f6fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5afe9b0b-1cb1-4d4a-8097-711112fae4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 884d4252-96cc-4426-97ee-c190c951181f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5ae8967-e387-4d3f-a30b-a3b0e39ce1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48839e30-bab9-4d78-b004-a4530ed720b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c80257-e405-4dc3-b67f-765577f284a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613f9e0a-aafa-45c8-ac50-c352423e3138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18cfda00-8165-4530-8382-ffc872de0e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33997d64-2ca2-4a14-bc48-8257ea79080e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d9abbff-4f60-4f01-8091-61d26f2d4ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16cd8a7c-500a-48b3-9c1a-bbd3b10f84b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a1997b9-dd62-45dc-8688-72ef46fedacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8aaa34c-4a08-4079-bf01-a64fad0621a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090c7dbf-6ad3-4c7a-b955-7433cf86314a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b46c423-2aee-4cee-8e0f-ab09969e76a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7411f88e-4c7f-44eb-aa5c-75884efaf873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f8710e-7d0f-483e-8e6b-27f4301d98b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 722be793-a5c5-45a7-ad3c-8b6431d58d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bcc52b-2996-468d-9473-8570ec6aaac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee2e74fb-6d95-4591-96a5-1e31c1a772f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96d6cdc5-fa19-48ad-9f31-4e21a8cad01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25190ae5-47aa-4f3e-93c7-0fdc6ae64d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39bbb2d7-55ea-4d38-8313-b83945d6ce15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127ec2f1-3fec-4254-a021-b2c8eae31ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ecc8f78-fbbf-439c-840f-0710b9702e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db22046a-07cb-42d9-8209-c8fb2b5fdfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ee06923-e1d5-4f5f-ac96-a7f19ae9ac25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b7ce61-8790-4f6d-bd91-a5669db14753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae167c7c-0dfe-419f-80a6-46b9f49698c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210eed79-5f8a-4944-a5c9-772cf4f08600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ca828d-c32b-4fa8-87c3-e7411e3d7821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a71505-2a7b-4ae4-8ce0-468dbe6bdedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be75663b-0c69-407e-9cf3-08d110a40e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1fdc586-dc3d-482f-a92c-8006aabf82dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e6ad78-13f8-4a47-a74e-afd851d0eb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d8dc3a6-8842-4be5-bfc0-c8b9c5e1cf3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69115076-ccb7-4d0c-9387-9640d43351bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6e0d1a-0745-4999-8a40-b154aef657d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331d5468-ad7c-4298-9b0f-3c1074587957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233cdd77-59db-4a1f-a4e6-e800bbbbac05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b57fddf7-6ae9-495e-b218-0a3163e1b719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17f7808-387f-4991-8196-43ceee778966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e83b9e01-6d89-4afd-8cba-247ea70c585b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b5f51b-cd04-4609-b3be-4226f8aa9228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b44e6a3f-064c-4121-ada8-28f7c98846fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e825d736-da3d-4b8b-b5b3-c5a5b8dcb08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2539511f-4774-4b16-8f14-731415b52a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d830d3fe-afca-4e89-bd19-7f571cb8c31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6941e48b-15ff-40d2-8b10-22dca24fa389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0256be41-4115-4b97-be65-fc85a1276edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e613cfa-7f0e-4833-8c21-d631dada2600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa0e8788-a66c-47b7-be26-f2b434dd767f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a32eebe-7819-4d0a-870a-d4cc995afcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f3442a8-3b22-4d46-babe-a0ae994a34af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841fcbd0-c15b-4fd6-9ebd-37916f0ccac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeeb652d-a137-492c-a012-df531c9747f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72cae092-6f58-4252-9037-c34f3c16fd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17f11f8e-bc4c-4eb7-8e9d-ccc7aaf1306a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bc01ce3-412f-4102-b40e-0f107a571e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 795e2fcf-df8f-4157-be74-e576ca451656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac332bb1-4bdd-436a-9c42-7881f9a4ebe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92a11f9c-d137-47fd-bc92-e9db5a2eea84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed60b496-6a82-4029-80a6-94dd884f16c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b29c8832-d181-4aaf-9107-35b685cd8dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f34b48a7-145c-4db3-aa68-f397d464bbe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12947629-5608-4d6b-ab00-415a06cd780c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efd2921-eb2d-474d-b7da-03720f39f769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31466deb-3526-417f-92dd-c58ea399bcbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0852228-4e4b-4678-983e-f2b00dfcd86d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce819be5-5899-4c20-be9e-8313e19e4ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e577c97e-f216-4243-94af-d61ff1eedac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33ded616-a7f5-40d3-9d46-e93f27b6672e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fab3fb29-36ee-4a91-8f5f-83ba9c304166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5784e17c-5812-4fb4-89ef-1481434950e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bb1cefa-6f03-47ab-a5ed-a7c87d485a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd542ee8-944c-45f2-8eda-916d8b18d438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3e75efe-36dc-4d2c-a1f6-a7ab6814df4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f76106-b18e-46a1-b4ca-4cd37726b765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1d5f98-8068-4905-9e81-6ea3625dc980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d317fec-0a71-48f2-b402-659c476a7f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e8596a-588a-4062-befc-7a657dc6c311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b5e82e1-05ad-4a1c-8075-c58549ac622e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b317d2-8ae8-47cb-9ca9-c7922effd998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f25589d7-afe2-4da5-8f18-aee1d636d96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8047f56-8932-43e6-a3d5-94c8fc2ff8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed3cf7a-a64f-4c56-a4e9-894254d2a16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5533d47-fd72-41da-acbe-279787d61d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e667dc-7433-42b5-a285-86c661c3cdd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f2a293-a67b-45ad-9226-061a25402b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1434c0f-45ab-47d8-a0a5-2d3f9029497f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c64bb13-0319-4a66-82d2-453042ca9759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 412318ec-aa78-40dc-a6dd-131d1cc7e32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a776ef41-e24e-4327-9335-aaf71007d614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb9a1a5-bfb8-49f2-a242-a95e14af9510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b62bff5-8664-4959-9171-fb202d47ecfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e36479c-e9df-45ac-b3bb-f48f1b2ec43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d1654cd-f5ac-43fb-bff7-ccebf3c36f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1574e8-53c2-4ad7-9cff-de0fd75d78fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0af7cd18-adde-46b9-92f8-1663b99e8a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe37349-5bd5-4d1f-bec2-abdf6e1d4da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d7c586-b186-4d93-946f-bacc1859b6e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 049db8cc-d175-41e2-9e6b-06150dfaaa68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 496a42b5-a465-44a0-91c5-a1626ac880ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3402a176-fc81-446b-a30c-3f287634e509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21246a42-8331-454a-9af7-c4a31bbc0761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e3be56b-07fc-4a67-a4a0-43eef0534eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec87d8f-8d9b-45ff-98b4-fdd631437244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f325b6-e2f8-4243-8214-fa185ebdcb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cad5254c-17bf-48d8-b22f-4627c4c98749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b99ca1f5-2a65-462e-87fb-bf167a475740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a30152-1554-4faa-b1d6-94a7bd86acb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c0e567-33bc-4a6f-a45e-959149da8be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 534c8b43-21f7-4af6-a78d-6945b6f33819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d48b77-64eb-4584-88cd-32a0a1ea4dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75f14a07-3443-4db6-b5ee-dfc18868ab39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b0c0725-494e-47e1-ad7f-96c3b8fdf13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef2be250-35cd-40f6-8fbb-ceaacc148ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e10d8e-f5f4-419c-897d-0da08d06b01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6476671-9696-47a4-acc8-e00846bb055f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73bf5368-0f50-4f67-964a-cd553a20075b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fccdcb7c-7444-4e46-ba66-add3d60e8296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 441b788e-062c-49b7-8d0f-b7ec2d893b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58339da6-ca22-4bd0-a13b-c35af9e1eab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c5f4e59-dd3a-4a08-b7a2-7631d1a361f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af56a06f-cd5a-4a86-830e-c75dc747ab67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3079bbd4-98ac-4ab7-bda3-a03f5d325166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717ed4c2-fbde-40c1-9c67-0d1e31e5c0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b919b10-7df1-4495-97a2-1ff48161e813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb9f7e9-0a32-44b9-98a7-0b91a063bf55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3500159-8142-461d-aae5-15b3386ec21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc934510-4557-48c0-a090-aecf73615114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406733fc-aca4-44a3-9926-56bec4e532f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2147b8a1-c13c-49e8-8b35-a2f33f35d247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec030dd9-a5d2-4e8f-8f50-e82af3ba8b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e87b6c82-7280-46ce-b0ee-5732be9ebd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b56f64e-a503-4eac-bd98-22d73f3c73b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 658e8dda-4ee4-40a5-b197-ca0fc3c0ed2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 546b7c98-2eda-4c01-8f2e-e5e99368a887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1793f302-c6e0-4d27-99a6-f732c43093e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 965bf09d-8d5a-4a2a-9ee1-3736e441ac51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a533cd-ce03-4389-a4d6-1eec4736db4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f8fbad-381e-48e7-851f-9b5419a6c211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53873388-aeae-41da-a95d-91c832790094
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_85
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_85/test_labels.txt

📊 Raw data loaded:
   Train: X=(1160, 24), y=(1160,)
   Test:  X=(291, 24), y=(291,)

⚠️  Limiting training data: 1160 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  282 samples, 5 features
✅ Client client_85 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2427, R²: 0.0387

📊 Round 0 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2420, R²: 0.0411

============================================================
🔄 Round 9 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0867 (↓), lr=0.001000
   • Epoch   2/100: train=0.0739, val=0.0875, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0734, val=0.0878, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0728, val=0.0874, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0719, val=0.0863, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0664, val=0.0873, patience=5/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0597, val=0.0886, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 9 Summary - Client client_85
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0698, RMSE=0.2642, R²=0.1267
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0504
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2415, R²: 0.0402

============================================================
🔄 Round 11 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0710 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0775, val=0.0696 (↓), lr=0.000250
   • Epoch   3/100: train=0.0769, val=0.0694, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0762, val=0.0691, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0758, val=0.0691, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0736, val=0.0686, patience=5/15, lr=0.000250
   📉 Epoch 20: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0706, val=0.0686, patience=7/15, lr=0.000125
   📉 Epoch 28: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 11 Summary - Client client_85
   Epochs: 29/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0718, RMSE=0.2680, R²=0.1428
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0850
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2414, R²: 0.0403

============================================================
🔄 Round 13 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0771 (↓), lr=0.000063
   • Epoch   2/100: train=0.0769, val=0.0770, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0766, val=0.0770, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0763, val=0.0770, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0759, val=0.0768, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0747, val=0.0764, patience=4/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0740, val=0.0763, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 13 Summary - Client client_85
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0863
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0504
============================================================


============================================================
🔄 Round 14 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0780, val=0.0738 (↓), lr=0.000008
   • Epoch   2/100: train=0.0780, val=0.0737, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0779, val=0.0737, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0779, val=0.0737, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0779, val=0.0737, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0777, val=0.0736, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 14 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0568
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0744
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2407, R²: 0.0436

============================================================
🔄 Round 15 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0736, val=0.0893 (↓), lr=0.000002
   • Epoch   2/100: train=0.0736, val=0.0893, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0736, val=0.0893, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0736, val=0.0893, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0736, val=0.0893, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0735, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 15 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0673
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0448
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2408, R²: 0.0433

============================================================
🔄 Round 17 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 17 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0687
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0333
============================================================


============================================================
🔄 Round 18 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 18 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0647
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0474
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2408, R²: 0.0435

============================================================
🔄 Round 20 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 20 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0524
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0930
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2406, R²: 0.0437

📊 Round 20 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2406, R²: 0.0439

📊 Round 20 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

📊 Round 20 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

============================================================
🔄 Round 26 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 26 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0576
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0754
============================================================


============================================================
🔄 Round 27 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 27 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0639
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0536
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0437

============================================================
🔄 Round 28 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 28 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0706
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0293
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

📊 Round 28 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

============================================================
🔄 Round 35 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 35 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0632
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0398
============================================================


============================================================
🔄 Round 37 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 37 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0591
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0728
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0437

============================================================
🔄 Round 39 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 39 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0612
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0680
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

============================================================
🔄 Round 43 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 43 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0597
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0592
============================================================


============================================================
🔄 Round 44 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 44 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0552
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0854
============================================================


============================================================
🔄 Round 46 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 46 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0546
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0886
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

============================================================
🔄 Round 49 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 49 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.0703
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0342
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

============================================================
🔄 Round 52 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 52 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0650
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0531
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

============================================================
🔄 Round 53 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 53 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0628
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0616
============================================================


============================================================
🔄 Round 54 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 54 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0697
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0289
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0437

📊 Round 54 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0437

📊 Round 54 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

📊 Round 54 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0437

============================================================
🔄 Round 60 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 60 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0658
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0421
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0437

============================================================
🔄 Round 63 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 63 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0657
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0508
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

============================================================
🔄 Round 65 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 65 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0628
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0597
============================================================


============================================================
🔄 Round 66 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 66 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0630
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0535
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0438

============================================================
🔄 Round 67 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 67 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0687
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0387
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0439

============================================================
🔄 Round 68 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 68 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0623
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0606
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0439

📊 Round 68 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0439

📊 Round 68 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0439

============================================================
🔄 Round 73 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 73 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0711
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0308
============================================================


============================================================
🔄 Round 76 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 76 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0587
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0801
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0440

============================================================
🔄 Round 82 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 82 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0598
   Val:   Loss=0.0661, RMSE=0.2571, R²=0.0768
============================================================


============================================================
🔄 Round 84 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 84 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0707
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0255
============================================================


============================================================
🔄 Round 85 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 85 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0630
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0567
============================================================


============================================================
🔄 Round 88 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 88 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0600
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0519
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0440

📊 Round 88 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0441

📊 Round 88 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0441

============================================================
🔄 Round 93 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 93 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0578
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0778
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0440

📊 Round 93 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0440

============================================================
🔄 Round 96 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 96 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0611
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0666
============================================================


============================================================
🔄 Round 97 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 97 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0708
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0292
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0441

📊 Round 97 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0441

📊 Round 97 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0442

============================================================
🔄 Round 102 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 102 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0567
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0811
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0442

📊 Round 102 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0442

============================================================
🔄 Round 106 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 106 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0634
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0565
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0442

============================================================
🔄 Round 109 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 109 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0577
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0797
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0442

============================================================
🔄 Round 110 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 110 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0614
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0561
============================================================


============================================================
🔄 Round 111 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 111 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0670
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0409
============================================================


============================================================
🔄 Round 112 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 112 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0641
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0541
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0442

📊 Round 112 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

📊 Round 112 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

📊 Round 112 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

📊 Round 112 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

📊 Round 112 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

📊 Round 112 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

📊 Round 112 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

============================================================
🔄 Round 125 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 125 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0653
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0359
============================================================


============================================================
🔄 Round 127 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 127 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0654
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0523
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

📊 Round 127 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

📊 Round 127 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 136 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 136 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0580
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0828
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0442

============================================================
🔄 Round 138 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 138 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0635
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0616
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0442

📊 Round 138 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

📊 Round 138 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 142 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 142 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0584
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0794
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

📊 Round 142 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 148 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 148 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0663
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0491
============================================================


============================================================
🔄 Round 149 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 149 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0614
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0697
============================================================


============================================================
🔄 Round 150 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 150 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0639
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0589
============================================================


============================================================
🔄 Round 151 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 151 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0648
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0302
============================================================


============================================================
🔄 Round 153 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 153 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0575
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0774
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

📊 Round 153 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

============================================================
🔄 Round 156 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 156 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0665
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0486
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

📊 Round 156 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

============================================================
🔄 Round 158 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 158 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0550
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0832
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0443

📊 Round 158 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

============================================================
🔄 Round 163 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 163 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0630
   Val:   Loss=0.0704, RMSE=0.2652, R²=0.0633
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

📊 Round 163 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 166 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 166 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0662
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0514
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

============================================================
🔄 Round 171 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 171 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0555
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0882
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 176 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 176 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0618
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0680
============================================================


============================================================
🔄 Round 178 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 178 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0624
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0660
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

📊 Round 178 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 181 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 181 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0635
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0570
============================================================


============================================================
🔄 Round 183 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 183 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0659
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0520
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0444

============================================================
🔄 Round 184 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 184 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0644
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0399
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 186 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 186 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0632
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0634
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 188 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 188 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0514
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0967
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

📊 Round 188 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 194 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 194 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0647
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0557
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 195 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 195 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0615
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0628
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

📊 Round 195 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 197 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 197 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0615
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0678
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 198 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 198 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0608
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0659
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2405, R²: 0.0443

============================================================
🔄 Round 199 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 199 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0632
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0526
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2404, R²: 0.0444

============================================================
🔄 Round 201 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 201 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0708
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0243
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2404, R²: 0.0443

📊 Round 201 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2404, R²: 0.0443

============================================================
🔄 Round 205 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 205 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0568
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0859
============================================================


============================================================
🔄 Round 207 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 207 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0575
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0840
============================================================


============================================================
🔄 Round 209 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 209 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0631
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0602
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2404, R²: 0.0444

============================================================
🔄 Round 212 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 212 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0658
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0458
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2404, R²: 0.0445

📊 Round 212 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2404, R²: 0.0444

📊 Round 212 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2404, R²: 0.0445

📊 Round 212 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2404, R²: 0.0445

============================================================
🔄 Round 223 - Client client_85
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 223 Summary - Client client_85
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0613
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0707
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2404, R²: 0.0446

📊 Round 223 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2404, R²: 0.0446

❌ Client client_85 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
