[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b032f274-b257-4c09-87f5-1d7c78a313bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f676d6-7e36-46fc-aaba-7134a82505ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9496aa67-e839-47c9-9697-1b665f58c92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b97140b8-f687-4b1a-bc97-b1370278e8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aef7cf9-4bea-467a-8b35-2dbb7b047919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c46cf6-dc41-4a42-82e5-ecf0bef0b4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ce4999-7995-4b13-be84-0eacfd63dbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c43689-64ae-45fe-97ea-3f7286a941ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91d951f8-9f9f-4588-9e67-da013379cadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc2f0956-81d0-4001-a572-3bd14a3626b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c19fe86-4ea2-46cd-baec-5c162ed2570b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a1705f-5d97-4993-8f8c-eef4ac5843c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6245b6fe-3b2e-475d-98e5-f6225d7aed32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcee77ce-992d-4579-a324-effb3097a27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eef7d2a-43f3-427b-afa0-65a25e8cff46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36dbc85f-c27f-4b52-9a14-f7e91e895985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d413a51-04de-443b-9e56-20cfef395c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195defd5-0e01-4010-b0f8-795e0a7c29ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68099b3-bf77-4647-a266-e4c5e29f0e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21052c1c-692c-4708-bc62-1bf35ca4a8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69ba452-d856-4ff4-a256-43f88a4bacd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6bc3eed-5ea3-41ea-a997-5346e3ccb52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5442e6fb-fd60-4f43-963b-fe3d42e91c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc2eead7-151f-4c7c-a088-99d1234d80bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30a8bd3a-34d7-4f62-9ccb-ff2a4fe7d787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4494030-1a59-40e6-8878-633c7f980e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b34da4-4aaa-45b9-8afc-2413166aa0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e93d93-78c3-4ff5-a6b0-52633f9d8be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d352e405-8e8a-4478-9f87-64b83e36099d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e2d80f-a4e5-406f-8aac-2a7dd474cd56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 430630fa-50da-43aa-9e7f-46624e5ce3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd3fbca-09e7-463e-a62f-1508dbd863b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6559c19-229b-4ec4-92b1-17554bfafb6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f34f35e6-852c-4749-8f80-6e3aa2462e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9be9c2cf-8e78-423b-a32f-2e0939a66420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c341181-6b1a-40e8-972d-81b23d3d350d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5053d7bd-7400-4d24-9b79-31d3d885ebce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07dce5bf-6838-448a-822b-04a51687db9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4353ecb-9215-47bb-ab2c-c9ebdb556985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d27df23d-d83b-45e6-a113-e36907f9e527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f374e503-43f0-495d-aea8-1039d934ea58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d6659f-9a96-4510-b1dc-78400199245f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9323c257-ca35-4c75-9327-96e121bccbb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49557b4f-6059-430d-8739-a2334549c9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df96d02-3a12-492c-973d-afb157d44f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141ba097-8db1-40f8-8f82-912bf7ac2da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c223b0-165f-4875-91d0-19da67442f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25af755d-27f9-416e-99bc-0c2bf06a5ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26917b31-f6bd-4b66-8955-1302e78fef6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74f58049-812d-4bfe-9fee-ad2a9b758e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bca3d78-9735-4b72-95ab-880e08245c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 506598fb-4d8e-4dcb-9631-bd07adb8b3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c98cd3-2390-4ec3-b184-f29932c2a207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2328f23-a5db-4599-a4bd-ba750a1b7b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b4c87a-5a01-4853-a4bf-48c1f46cdd83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c7a7576-6639-4094-ab24-94c56bc412d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831713c1-1e1e-4f3e-bdd5-4e91da482f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94713688-cd67-4698-b01e-0c176d5b7e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b9f99b-d825-4690-95d8-df71b88cdfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b3a160e-9894-4473-b26f-daec572a107f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd53cbc-44ad-444f-9e86-9b0a142a942c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c96093e7-b300-4d15-ad91-a007b0e2d23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 358306ed-dab9-493c-b7e3-b8103bc633f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ae9ad7-07c0-47db-aaa5-88fe7cd662b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message becb7896-5e7d-448b-9486-744ca3137fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e985fcf7-9506-4b0c-b4c2-1d356490c239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf32e532-747f-46f0-bd62-209619943059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b38de933-68fc-4782-962d-d98e8417bda4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6060611f-18c1-4283-902e-f2c953d0f2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d21338d7-ca71-43b0-a0bb-4eef3e017a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8628c4-bca5-4a42-a555-9779b1cb0aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee93653-4b29-4381-8b14-adbc4d2904f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d76266cd-ddaf-4eaa-8ddc-54a5d90d6b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff63edb2-3b43-4c09-a5d9-e86b6b02059e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276e937e-c6b9-48ca-9153-0a180d0c9fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb8055a7-9d44-4baf-ac13-e6cbaa59618c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daac7224-772b-4de3-afdc-75ed21d13be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f473d6-4bfa-4fd5-85ff-349d5bffca43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7aca9f-f75e-47ef-8034-3e0f93c22253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496ee6e4-6b6b-4f96-9075-9b0dc06864f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5719d171-898b-4461-8e71-a344578be6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0161ec9c-9124-4245-ba83-2e088508d177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66f9c4a-a132-4867-a101-2c46e39a3469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1a9cb15-98c9-4257-bec2-8dc984395f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b6ed31f-bf85-418f-89e6-5ff4d15ca339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b598204d-857b-476e-8aca-e58ad029bc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e439db7-bfda-421e-aeff-9d2dfd966884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f01ad5-ca78-4f7b-a781-9b82e125ba03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa665f7b-fb8c-4261-bf84-17a7eab5a0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33738537-7819-4701-b3fb-f51b61b4d4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 967c557e-8fd3-4b0e-9a44-2e5acaeb1a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8a4145f-2a4d-4356-b340-e43d6bde7a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8e598c-e554-47e1-8f24-6391c420f3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5538db32-3123-48e7-9502-6573c1e0accf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b852c742-88f6-4057-9b70-b8f12e8ace87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e789d9cf-9601-4681-9e38-d06d155e872c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182b96eb-42ee-4bc3-a25d-25c557913f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1215f785-6ba7-4bdc-8ce6-b3217ca09403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9672e6a-08a0-4c99-88e9-ab544265740a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dad4964-6f10-4dd4-8c0d-192ab1b8c158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0414d509-7f9d-45e0-bdd4-5d38b57dd30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ed1d06-4c9d-407b-bae6-647c4c7de6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05054fba-4a25-4d2a-a20f-bb1c5fe0de79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd331b9-c7a7-456e-a3ae-1c01eff9fd6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58759340-f19f-4523-82de-ea4cdc3ccb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9693fb19-148d-482e-81ce-5fc7d6798c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fef09f5-3447-4c77-9ef0-c2ed5122401c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca020dd3-8b53-4201-9949-e7fa7ba70bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595482d4-a66b-49db-a5cf-3432ef411c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae0b033-bb3e-4133-b366-4c17fac6cb80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4041d7-3ab2-40a2-9269-f121f61575b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a344bea-ec17-4978-ad62-05e825394a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ebede0-155e-4956-b6b1-9f866d6bb6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04523d9-abc2-4614-8f7b-56829a0ab519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e455c6-9b32-4150-838c-44d79b76f5d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeaa6bbe-ace5-4ae7-b001-a85421555189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16087275-a996-4e10-b4df-f842c9eb520f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90450add-6677-4362-a474-0ad9ae4eb2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e19602-8f3f-4abf-989f-e290c61d23c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afba8b4a-7cde-4de9-b42f-e665e0b4d3ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f920ec7-914e-44d3-8213-2ef1308e1832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f55c8a8b-b770-4b64-a3d5-4be5193d2926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3cc11ef-9116-406e-a089-9aa331a30108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 445b3eda-72d1-45e2-a60b-20fe4d14c6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e45a683c-2f39-4bca-9045-4da826d032a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ad8d5d8-5789-4ff2-8f72-d1587bf2f511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85decf8e-5803-47e3-9956-f24cf3961115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29491c46-ed2c-4c55-86d4-e4779dc99d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02d700db-7b9f-4236-ae8b-2ea4d9b9365e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f220e00-eb74-4431-92e0-50bf6e94b67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032ffee9-cb17-42ed-84cc-7599be3e9984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 947c05aa-7a66-4d01-8365-6e9dc5f2b125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31c34542-24fc-40e0-a281-e4aab78a87f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b081768a-ec97-4b7a-90fe-f3fa84ffc6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64fd09d4-95d4-4689-b248-fba0094ff528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 415d400d-14f4-47da-8277-8b35ac8a5f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c34739-4fa8-4965-9719-1e1b52614c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27083f7d-592a-4148-bd6f-0d5b9d543594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d266ff-9dd0-4101-8036-1a768f208be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b391d692-fc27-47cf-bc16-e6db6ffbb5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4dd28d3-b424-458d-892e-20bd50deb908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66e4598e-4050-4b8e-b70c-4f3a7668d2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa849be-79de-484e-8634-53816851d767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4ccbfa6-18ed-401d-a6f2-29261ce7ba97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae5e663-76ca-4e02-ad3c-8c357dbd3289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c6e6615-4560-4700-88a1-d44e1c4dd2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8b4c93-f9a4-455e-9c61-72da6035cc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a0341a-1b24-4e0e-ba07-1f520838706d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8945042b-b39e-418a-b5a8-30b2133524a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb1a2ae-d27e-46c9-b000-4ecc74d36ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56df1a90-d6da-47a4-913b-4a964247b579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e93579e-433c-4ee8-b526-14d9c5366e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214cd89f-fce0-4b45-9c9b-138296671340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 678ceab4-2711-4b48-8be4-823ef5dcc369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5df21e7-938c-482a-8c2e-9652859930a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e12cad16-47fe-4a5f-b2a2-4e3a61d42b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a98e3cb-5441-4b16-b95f-87ff499baa8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ccd30c-2b3f-442a-a7a2-50d3f423b9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30fcace9-ef1d-46fa-a989-591e392da9e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb88d3af-a471-4195-b497-1fa692475435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 409501ba-9f08-4052-8f53-0a8adefa073e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd09dad9-f635-47e4-ae47-477d46aa5aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5586cd-f5b8-4f1f-81e7-71ed8c66c06e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 844c51e8-167b-4be9-91d3-bcfaa3f55e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2cffc90-6e15-45b3-8e83-ccdee3a04780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50dfe46c-abb2-4d4f-8ba7-dd574ac8e024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f0b694-702c-408e-9949-ab4969463284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a9fbfb-3642-4cb0-a256-3c8b9fea1e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff4d8d9-5138-4226-8399-091098dccd39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10357acb-6c81-4dc1-9b2b-4e08268af4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20cd68d1-891d-42a5-b002-7aa465094c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdc0cd0-79df-4a38-b631-a45e933250e3
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_86
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_86/test_labels.txt

📊 Raw data loaded:
   Train: X=(698, 24), y=(698,)
   Test:  X=(175, 24), y=(175,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 689 samples, 5 features
   Test:  166 samples, 5 features
✅ Client client_86 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0909 (↓), lr=0.001000
   • Epoch   2/100: train=0.0851, val=0.0967, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0853, val=0.0915, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0839, val=0.0891 (↓), lr=0.001000
   • Epoch   5/100: train=0.0830, val=0.0901, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   ✓ Epoch  11/100: train=0.0812, val=0.0870 (↓), lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0786, val=0.0864, patience=2/15, lr=0.000250
   • Epoch  31/100: train=0.0766, val=0.0854, patience=5/15, lr=0.000250
   • Epoch  41/100: train=0.0735, val=0.0844, patience=3/15, lr=0.000250
   • Epoch  51/100: train=0.0690, val=0.0837, patience=7/15, lr=0.000250
   • Epoch  61/100: train=0.0633, val=0.0829, patience=3/15, lr=0.000250
   • Epoch  71/100: train=0.0582, val=0.0806, patience=1/15, lr=0.000250
   ✓ Epoch  81/100: train=0.0533, val=0.0785 (↓), lr=0.000250
   ✓ Epoch  91/100: train=0.0487, val=0.0761 (↓), lr=0.000250

============================================================
📊 Round 7 Summary - Client client_86
   Epochs: 100/100
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0429, RMSE=0.2071, R²=0.4821
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.1138
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2565, R²: -0.0256

============================================================
🔄 Round 8 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0889 (↓), lr=0.000250
   • Epoch   2/100: train=0.0870, val=0.0890, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0861, val=0.0892, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0855, val=0.0891, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0852, val=0.0892, patience=4/15, lr=0.000250
   📉 Epoch 6: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0842, val=0.0890, patience=10/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 8 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0286
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0138
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2559, R²: -0.0189

============================================================
🔄 Round 9 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0775 (↓), lr=0.000063
   • Epoch   2/100: train=0.0872, val=0.0775, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0870, val=0.0776, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0868, val=0.0777, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0866, val=0.0777, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0860, val=0.0779, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 9 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0227
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0350
============================================================


============================================================
🔄 Round 10 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0886 (↓), lr=0.000016
   • Epoch   2/100: train=0.0849, val=0.0883, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0848, val=0.0881, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0847, val=0.0880 (↓), lr=0.000016
   • Epoch   5/100: train=0.0846, val=0.0879, patience=1/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0844, val=0.0876, patience=7/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0843, val=0.0874, patience=5/15, lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002
   📉 Epoch 30: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0842, val=0.0874, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 10 Summary - Client client_86
   Epochs: 31/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0243
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0458
============================================================


============================================================
🔄 Round 11 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 11 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0286
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0681
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2553, R²: -0.0144

============================================================
🔄 Round 13 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 13 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0473
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0038
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2549, R²: -0.0130

============================================================
🔄 Round 14 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 14 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0246
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0800
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2552, R²: -0.0131

============================================================
🔄 Round 17 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0998, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0998, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0998, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 17 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0374
   Val:   Loss=0.0999, RMSE=0.3161, R²=-0.0376
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2551, R²: -0.0126

============================================================
🔄 Round 22 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 22 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0335
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0409
============================================================


============================================================
🔄 Round 24 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 24 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0437
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0026
============================================================


============================================================
🔄 Round 26 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 26 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0267
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0685
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

============================================================
🔄 Round 30 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 30 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0354
   Val:   Loss=0.0980, RMSE=0.3130, R²=-0.0557
============================================================


============================================================
🔄 Round 33 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 33 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0371
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0231
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0146

📊 Round 33 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

📊 Round 33 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

📊 Round 33 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

============================================================
🔄 Round 39 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 39 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0374
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0193
============================================================


============================================================
🔄 Round 41 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 41 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0300
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0662
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0146

============================================================
🔄 Round 45 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 45 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0364
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0266
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

📊 Round 45 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

============================================================
🔄 Round 47 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 47 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0356
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0304
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2557, R²: -0.0147

📊 Round 47 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

📊 Round 47 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

📊 Round 47 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

============================================================
🔄 Round 52 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 52 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0318
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0507
============================================================


============================================================
🔄 Round 53 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.1034 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.1034, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.1034, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.1034, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.1034, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.1034, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1034)

============================================================
📊 Round 53 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0298
   Val:   Loss=0.1034, RMSE=0.3216, R²=-0.0508
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2557, R²: -0.0147

============================================================
🔄 Round 54 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 54 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0436
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0179
============================================================


============================================================
🔄 Round 55 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 55 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0459
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0016
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2557, R²: -0.0147

============================================================
🔄 Round 56 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 56 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0257
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0704
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2557, R²: -0.0147

📊 Round 56 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2557, R²: -0.0147

============================================================
🔄 Round 61 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 61 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0396
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0218
============================================================


============================================================
🔄 Round 62 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 62 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=-0.0340
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0435
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2557, R²: -0.0147

📊 Round 62 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2557, R²: -0.0147

============================================================
🔄 Round 64 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 64 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0400
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0231
============================================================


============================================================
🔄 Round 66 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 66 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0422
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0016
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

📊 Round 66 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

📊 Round 66 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

============================================================
🔄 Round 74 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 74 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0408
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0090
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

============================================================
🔄 Round 76 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 76 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0375
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0322
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

📊 Round 76 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0147

============================================================
🔄 Round 80 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 80 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0240
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0909
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0146

============================================================
🔄 Round 82 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 82 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0352
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0311
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0146

============================================================
🔄 Round 85 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 85 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0477
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0103
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0146

============================================================
🔄 Round 91 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 91 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0365
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0261
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0146

============================================================
🔄 Round 92 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 92 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0431
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0016
============================================================


============================================================
🔄 Round 94 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 94 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0319
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0445
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0146

📊 Round 94 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 97 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 97 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0357
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0296
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

📊 Round 97 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

📊 Round 97 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

📊 Round 97 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

📊 Round 97 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

📊 Round 97 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 104 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 104 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0266
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0648
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 107 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 107 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0383
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0189
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 109 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 109 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0336
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0381
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 110 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 110 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0354
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0366
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 111 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 111 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0417
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0068
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 112 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 112 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0336
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0405
============================================================


============================================================
🔄 Round 115 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 115 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0240
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0782
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0145

📊 Round 115 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 118 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 118 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0308
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0544
============================================================


============================================================
🔄 Round 119 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 119 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0417
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0054
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0145

📊 Round 119 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 121 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.1007 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.1007, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1007)

============================================================
📊 Round 121 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0353
   Val:   Loss=0.1007, RMSE=0.3173, R²=-0.0323
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0145

📊 Round 121 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 126 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 126 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0357
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0297
============================================================


============================================================
🔄 Round 128 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 128 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0378
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0207
============================================================


============================================================
🔄 Round 130 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 130 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0361
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0378
============================================================


============================================================
🔄 Round 131 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 131 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0391
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0229
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 131 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0145

============================================================
🔄 Round 136 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 136 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0413
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0062
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 138 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 138 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0319
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0666
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 138 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 138 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 138 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 147 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 147 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0334
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0427
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 147 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 147 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 151 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 151 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0247
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0896
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 155 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 155 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0335
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0560
============================================================


============================================================
🔄 Round 156 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 156 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0314
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0626
============================================================


============================================================
🔄 Round 157 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 157 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0426
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0039
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 159 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 159 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0357
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0305
============================================================


============================================================
🔄 Round 161 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 161 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0266
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0910
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 162 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 162 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0402
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0104
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 166 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 166 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0476
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0283
============================================================


============================================================
🔄 Round 168 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 168 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0373
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0444
============================================================


============================================================
🔄 Round 170 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 170 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0421
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0078
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 170 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

📊 Round 170 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 170 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 178 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 178 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0376
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0216
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

📊 Round 178 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 180 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 180 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0398
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0350
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 181 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 181 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0341
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0385
============================================================


============================================================
🔄 Round 184 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 184 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0373
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0229
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0144

============================================================
🔄 Round 185 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 185 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0292
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0558
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 187 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 187 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0301
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0599
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

📊 Round 187 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 189 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 189 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0386
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0172
============================================================


============================================================
🔄 Round 192 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 192 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0336
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0444
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 194 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 194 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0339
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0505
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 195 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 195 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0283
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0652
============================================================


============================================================
🔄 Round 196 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.1001 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.1001, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.1001, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.1001, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.1001, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.1000, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1001)

============================================================
📊 Round 196 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0279
   Val:   Loss=0.1001, RMSE=0.3164, R²=-0.0591
============================================================


============================================================
🔄 Round 197 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 197 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0449
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0173
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 208 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 208 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0354
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0339
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

📊 Round 208 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 212 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 212 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0352
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0318
============================================================


============================================================
🔄 Round 216 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 216 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0447
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0029
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 219 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 219 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0401
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0489
============================================================


============================================================
🔄 Round 221 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 221 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0346
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0369
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

📊 Round 221 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 224 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 224 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0243
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0725
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2556, R²: -0.0143

============================================================
🔄 Round 225 - Client client_86
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 225 Summary - Client client_86
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0376
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0245
============================================================


❌ Client client_86 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
