[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7927d8a8-ebe8-4431-9d49-bebae044982a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 232e721f-a043-4979-955b-e2dfc2cbce9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012615b3-401f-4349-856f-0937c8d0e3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86056f89-c092-40be-9239-a92bc6036070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 122cc164-4c1a-44b1-a143-ea0c0407015b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac6424a-513e-4447-8c7c-7213352570a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89be3c20-26bf-4cb5-8eaa-b37f0c7e536e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3379844c-8731-4253-8e1d-d27c0f03eb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c29be8cc-563e-4cb1-bc41-b83a1921bd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdfb22bc-51f9-49a6-89f9-9411d591961c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3a24d8-b5c3-4fcf-ae49-c34b3b47512f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5aa63ed-108b-421c-89a6-4ec02d6a90fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1940c38-d750-4d43-b0e4-81ad214e7bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1914b27b-881d-4850-803d-0ad15c75194f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22966a8-0042-4f87-a426-9240d6fb1935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce0d63f3-d0b9-4674-a275-afcecd1fc493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc6425e-cffe-47cc-9a67-90f90afeeecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78d97149-4640-439d-846d-bfc6386150d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8337b279-5b3a-48e6-a02e-3ec8825986eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032ca4ae-1ed9-4f4a-ad21-9fae285eb1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773f66e3-d8ce-415a-b22f-76f0c9bc5eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36e0984e-a905-4034-8b2f-ffdf21cf0d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 344f0fa8-cf3d-451e-af28-ed36bf405bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dcdaa95-f5dd-4413-96eb-6e41595760a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580ff582-0983-4a5b-b854-032a662bb38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ed39a1-5c62-45d8-bea4-171ca95ea816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6b1c90f-869b-4704-ac46-fc5a11280ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4717d86-dbd6-41c2-809f-7a7ef34831ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c9578ee-9208-42cd-886c-5a24172f0369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50436150-f3e6-46d9-b2d0-09fae2deaba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab3e184-3fd9-422b-a80c-99c9aa23694a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a2379ea-c89f-4d39-a16b-40633868a17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c34a6d-7a65-4b37-96b8-163da0c878b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c75cb77-bdf9-4e25-8bea-9b742c7499f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ef3b5d-fff5-4768-9e96-f4a16ee1ba6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f96b41-119c-49c8-8c1d-463838f88c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0113657-db72-401b-8de6-2aabd9e0086d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f19e33-f0f1-4ad1-82e0-91b75c059cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd8bd7d-8915-4662-bb24-2cef85dc8d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5cb771-c15e-4834-8e45-e8c71c2c6eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6589b55f-bbaf-4212-b1a3-cdc6810344e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df2f9500-d0a7-431e-b95a-fb8c1baf5154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7307e7f7-d32b-4805-876a-2e5610ec72bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b710bbb-33cf-4b9d-9329-f74bd0a5e188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7172475f-1f60-4e57-be27-c375c302c10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc431b34-0a78-4848-8be6-8834f078e80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e4c8353-0409-4c8c-b174-562dfdb9eec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9c24a25-b008-49db-ac2f-023b680068aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 052383c1-b0b9-4f64-882a-06981f5c676b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb82284e-e48f-4a4e-a3ed-64f17242c64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6755c8c7-9c3b-4f64-beba-e49c797c2aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d925f75-82f0-4a39-be40-9b51ecd65fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff67dbc9-5e0f-416f-b429-2cf53f292d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e573651f-1cd4-41ab-8b39-6e1db2d78631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb076e2a-8148-44e9-b434-0d2e6fd08874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d1ed7b-fae3-4539-a9b9-011a89717aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8c460af-d840-4c04-a97b-f31a3858246a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6b1ac80-83df-45c0-af6c-750012dde24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c13cd80d-510f-4980-aa4a-e8ff30962790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 877238b6-43db-43fb-8915-151dfdc7a708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7c4ee06-afd2-43fd-af2a-9a83d27dc8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14606f76-7056-44b8-9ce5-586175464943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafa17bc-c5b4-4251-8ee5-4e64f2474309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f59f2434-cecf-4ba4-aa49-acaa844dd306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58245912-1e2d-4992-8581-f737ee91ea0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9891f971-2892-49b1-aa7e-b3272ba5261a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1629250-de8b-4d2f-b53a-35e93e3f5889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a155120a-c029-4581-8a2e-3b5585bf2d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c52fa8-9f33-4bbb-9ee4-3b1a7d41bd78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0c229b9-002c-46ce-8eb3-0ad7c0d94165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e0d830-d092-4207-829e-ab596dd9c5f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c4f8be2-a923-443e-a5c1-3930fd386eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1560347-6ec1-4022-81d8-4c62b0e5001c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb13540-c4b5-427d-8252-90a0bce18d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c41591e-6a24-4f5e-bded-91700180b1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b8e0f7-0821-4b34-922f-ac8527c0f257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380c0171-2e9e-46c7-8111-d853c0e2429b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97eec3dc-a67e-4482-8cc5-a3dc93c3462a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46df8f8-a9d6-4a06-81a5-e0e0bac2fb5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fbb5fb9-d431-4f98-a671-15933d29f54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e4ed7f-7284-4847-ba53-47eaad12e539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94bf3e6a-a7fc-40de-9680-dbbc163a9eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f6aa91-4480-44ee-8271-888a73b93be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86174a25-3d06-4477-90bd-a52976c9c1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e02f8af-4c60-47a4-9dcb-b8b8aaaf8ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f774066-908c-4986-a718-05e0eab4729a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 219092eb-ce80-4ab3-b5d4-f432b4d4d197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 501419c5-a9c3-44fb-9b03-995d88ed6028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fd997af-4bc6-405f-9409-e896ec2f226f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abda91b2-437c-424f-8c03-177a9b0869e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20621927-22f9-4eb7-aa93-2f0b25c96e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ff6aec1-2938-4cc6-996b-26559cc55965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8997d8-ac07-462b-ae84-dc7662a45b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9756d59-e2dc-4e47-bc5b-c329facdec6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dad0479-e7a7-4c10-89f0-26acb2c0b1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a3c5ab4-0841-4106-b36a-bc7c40e986df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb0ccf6d-1c9c-45a0-bbb6-b97acc2a7e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158ba850-eb4f-4210-9a86-663118408d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a286794d-e46b-4e0a-b613-341088d30627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1faefb34-cfcc-445d-b6cb-6b7247e8eaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac4f255-3066-4c8d-8adf-2fc21cef3a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66ec63d-0ed8-4939-8501-ba611ca07c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200212ee-162b-4c9c-9978-f5ebcb54edd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b7a0fa-1825-4328-b261-c6b58ebd01b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b15662ce-0b9a-4982-8562-f65e395209dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aafa1dc9-2012-4d4b-8cab-1fa6ec532d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e4af44-0f63-48a2-bdbe-942b671dd734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b835cad-5c6b-4313-a9b2-f6809e32c637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a044ed0d-e795-4221-a0f7-e8475f849c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a201ce-355d-41f6-a134-87b8fe205a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99055f1a-7b3e-455b-911a-12ddfb97847d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e6e994-5877-4068-9dce-3cda97d54899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2967a0e-4ba9-4f5b-b058-3e4e40af816d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9b8bf3-a1b4-413f-a4c6-a5e12ee53c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc722d58-4f8c-4382-b01d-925dbf8a09f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa12408-caa0-42c2-abdb-7b0c98016d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81487459-cf14-4533-8f1a-1733d68e4215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80ae4ee6-b71f-4f63-8bfd-76f1e0298813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f4a3ec-3cbc-40e4-adee-7e3adfd8ef11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9e76b6-c0d6-41ee-a73c-24c5253a6b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9607e6-3311-4acc-b238-fa25c2baf452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e459363-efdf-479b-b1a8-38705cc5488b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba03486-c185-4fdc-bfa1-c7afed14dc1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19b6684d-0c30-4d68-9edb-692e97dadded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5247bf00-4e18-475b-8cc6-232d46d73a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62ad2430-ed27-4bb6-ab96-2421936876bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d48b0ac-7608-46fb-ab1b-04524a07df1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45188eae-6b34-44cc-b0c5-3e576c18aa54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d788ac9-b029-461e-af5c-7a6936edc35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c91297-223e-4298-b889-834711b791cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67697c83-44d8-4f93-afae-347c8f5b623b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d636906-ddba-4a86-93ec-2c5219ee422d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd078cda-5e18-4ee5-a8c5-f64814fb26ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05f5ebb-ee38-4cf8-9f74-5f07b3ba791e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182eee25-6bae-446e-a281-0eb25936ea15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e411a310-9559-401e-be11-7ecdd20d9f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2478b841-0ff7-4dc0-ad85-5a6074f4b820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071a15d3-5b80-463f-b44b-62d2edd04225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 002e001a-b23b-4fef-a8bb-b0a635e5a1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a337b6f-e639-4b87-a892-0522f0967365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b635e2c6-5961-4b92-90e8-0a9ea2822ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 978908bf-ebaa-4709-bc92-2b505daafa00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1193889c-c02c-4b5b-84e8-50273614b3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993b55e2-cb37-4809-9054-74a3a7ca97dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f40a73-82e6-4e0b-990a-acc7a4adf3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ce249e-b275-42d7-9af5-5c0393196eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc06f72-4f13-4539-8255-0d0fbb203709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d83df7-e978-4a7d-bb2b-bd1d6d65a27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc8344f-6a20-409a-adf9-4ebb4fa9019c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1edaa76-c0ec-4f47-bebd-ee5158dd7a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8913c450-ebc8-4e7d-b514-364812a39733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53d3c8f8-1047-4f1e-ae11-aa6daf8ff128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04221ff9-25bd-44c6-8619-c48e625f8030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e48144-e83a-415b-97c9-a10ebf937120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ddd547-7015-4158-9edd-56c14d505b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a325efd-ceaf-4232-9c31-a726fa85881c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7c4006d-4561-4ab2-9fa5-33344ef66bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b5bbfd-4ca8-46f8-aed4-23df79a8dba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eab0852-bcf9-4f33-94ac-229e186b63c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0649100-ed31-474c-ad9a-ad4d17f49126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d18a4b85-83bd-4f82-aedc-3bb7b84274ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbea16b6-8d10-4211-964a-a152232702ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92087c6a-0e47-46a6-82de-1bea231828b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cb1c8a0-8fbc-48d6-a0f0-3e38255c5afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f79b1f-e0cc-40b3-a4f3-e85247d79cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e989f8-5ae8-444b-a86d-dc45a1d8725d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 753b59d1-f032-40f2-a10a-a9309809ced3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28e1835b-0abf-4076-8617-917a0e68ce77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a5699a-a34d-4d4f-a36c-0d3d4d8c57c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbef2cc5-5b16-4c8f-b669-3f0872efc847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf19a96-effd-4332-8342-f9a255ee603d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41af1102-25d2-47d5-8171-7ba53c899017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b908f8-a43e-4d25-a68a-abb909e5b7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eec9e12-5f7d-4771-9463-dfa2c6de65e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55159eca-0e4a-4c26-95e9-84ad1260dc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 101ece31-4206-4d38-ad8a-d6d4e3100c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4165b069-5a47-4b3c-8ae0-d367ffaa5263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 097b783e-505d-4532-a53e-80b452cf7914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdea8146-330b-4e6d-bc17-ab4dbf589d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1134ec5b-4079-4718-8718-a9d52cc8a58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8de1f3e2-4f9b-43f3-9189-b9eed9f98b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7243ee26-352d-42cd-9fe7-bfb26af6154c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_87
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_87/test_labels.txt

📊 Raw data loaded:
   Train: X=(1701, 24), y=(1701,)
   Test:  X=(426, 24), y=(426,)

⚠️  Limiting training data: 1701 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  417 samples, 5 features
✅ Client client_87 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2463, R²: 0.0218

============================================================
🔄 Round 8 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0768 (↓), lr=0.001000
   • Epoch   2/100: train=0.0818, val=0.0790, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0812, val=0.0817, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0776, val=0.0851, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 8 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0212
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0191
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2469, R²: 0.0187

============================================================
🔄 Round 10 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000250
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0806, val=0.0806, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0804, val=0.0805, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0794, val=0.0805, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 10 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0084
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0036
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2469, R²: 0.0183

============================================================
🔄 Round 11 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000063
   • Epoch   2/100: train=0.0816, val=0.0772, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0815, val=0.0771, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0814, val=0.0771, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0814, val=0.0771, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0810, val=0.0771, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 11 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0032
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0251
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2472, R²: 0.0155

============================================================
🔄 Round 12 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0836 (↓), lr=0.000016
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0801, val=0.0834, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 12 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0037
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0073
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2472, R²: 0.0157

============================================================
🔄 Round 15 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000004
   • Epoch   2/100: train=0.0808, val=0.0831, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0807, val=0.0831, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0807, val=0.0831, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0807, val=0.0830, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 15 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0138
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0357
============================================================


============================================================
🔄 Round 16 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 16 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0066
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0017
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2470, R²: 0.0169

📊 Round 16 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2471, R²: 0.0165

============================================================
🔄 Round 18 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 18 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0051
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0049
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2471, R²: 0.0161

============================================================
🔄 Round 20 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 20 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0052
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0012
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0175

============================================================
🔄 Round 25 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 25 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0156
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0452
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0175

📊 Round 25 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0175

============================================================
🔄 Round 27 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 27 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0087
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0079
============================================================


============================================================
🔄 Round 28 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 28 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0141
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0240
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0175

📊 Round 28 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0175

📊 Round 28 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0176

============================================================
🔄 Round 38 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 38 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0036
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0129
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0176

============================================================
🔄 Round 41 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 41 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0040
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0055
============================================================


============================================================
🔄 Round 45 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 45 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0104
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0433
============================================================


============================================================
🔄 Round 46 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 46 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0055
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0033
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0177

📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0177

📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0177

📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0177

============================================================
🔄 Round 55 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 55 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0019
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0223
============================================================


============================================================
🔄 Round 56 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 56 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0047
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0013
============================================================


============================================================
🔄 Round 57 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 57 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0060
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0004
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0177

============================================================
🔄 Round 58 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 58 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0085
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0063
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0177

============================================================
🔄 Round 59 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 59 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0019
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0212
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0178

📊 Round 59 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0178

============================================================
🔄 Round 64 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 64 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0077
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0040
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0179

============================================================
🔄 Round 65 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 65 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0071
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0002
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0179

📊 Round 65 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2469, R²: 0.0179

============================================================
🔄 Round 69 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 69 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0061
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0018
============================================================


============================================================
🔄 Round 70 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 70 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0019
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0148
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2469, R²: 0.0180

📊 Round 70 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2469, R²: 0.0180

📊 Round 70 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2469, R²: 0.0180

📊 Round 70 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2469, R²: 0.0181

============================================================
🔄 Round 75 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 75 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0057
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0042
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2469, R²: 0.0181

============================================================
🔄 Round 76 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 76 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0063
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0014
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2468, R²: 0.0181

============================================================
🔄 Round 79 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 79 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0046
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0510
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0182

📊 Round 79 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0182

============================================================
🔄 Round 82 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 82 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0021
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0094
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0182

============================================================
🔄 Round 84 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 84 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0080
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0026
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0182

============================================================
🔄 Round 85 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 85 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0070
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0098
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0182

============================================================
🔄 Round 88 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 88 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0054
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0092
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0182

============================================================
🔄 Round 91 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 91 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0038
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0378
============================================================


============================================================
🔄 Round 92 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 92 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0052
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0107
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0183

============================================================
🔄 Round 94 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 94 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0006
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0248
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0183

============================================================
🔄 Round 99 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 99 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0027
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0219
============================================================


============================================================
🔄 Round 101 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 101 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0118
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0190
============================================================


============================================================
🔄 Round 103 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 103 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0076
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0008
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0185

📊 Round 103 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0185

📊 Round 103 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0186

============================================================
🔄 Round 107 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 107 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0016
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0198
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0186

============================================================
🔄 Round 108 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 108 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0117
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0279
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0186

============================================================
🔄 Round 110 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 110 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0033
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0143
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0186

============================================================
🔄 Round 111 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 111 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0064
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0035
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0186

📊 Round 111 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0187

============================================================
🔄 Round 114 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 114 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0029
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0273
============================================================


============================================================
🔄 Round 116 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 116 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0018
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0158
============================================================


============================================================
🔄 Round 117 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 117 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0166
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0331
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2468, R²: 0.0188

📊 Round 117 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0188

📊 Round 117 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0189

============================================================
🔄 Round 123 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 123 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0050
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0070
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0188

📊 Round 123 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0188

============================================================
🔄 Round 125 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 125 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0016
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0213
============================================================


============================================================
🔄 Round 127 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 127 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0051
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0121
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0188

============================================================
🔄 Round 130 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 130 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0056
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0109
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2467, R²: 0.0188

============================================================
🔄 Round 132 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 132 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0110
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0146
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0188

📊 Round 132 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0188

📊 Round 132 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0188

============================================================
🔄 Round 137 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 137 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0011
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0246
============================================================


============================================================
🔄 Round 138 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 138 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0036
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0041
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0188

============================================================
🔄 Round 144 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 144 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0065
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0006
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0189

============================================================
🔄 Round 147 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 147 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0054
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0105
============================================================


============================================================
🔄 Round 148 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 148 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0129
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0247
============================================================


============================================================
🔄 Round 149 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 149 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0080
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0010
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0190

📊 Round 149 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0190

📊 Round 149 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0190

============================================================
🔄 Round 154 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 154 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0101
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0157
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0190

============================================================
🔄 Round 157 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 157 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0045
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0147
============================================================


============================================================
🔄 Round 160 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 160 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0053
   Val:   Loss=0.0954, RMSE=0.3088, R²=0.0062
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0190

============================================================
🔄 Round 161 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 161 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0159
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0626
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0190

============================================================
🔄 Round 162 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 162 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0059
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0015
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

📊 Round 162 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

============================================================
🔄 Round 164 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 164 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0063
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0075
============================================================


============================================================
🔄 Round 166 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 166 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0052
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0108
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0190

============================================================
🔄 Round 169 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 169 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0042
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0393
============================================================


============================================================
🔄 Round 170 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 170 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0060
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0089
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

📊 Round 170 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

============================================================
🔄 Round 172 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 172 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0073
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0034
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0192

============================================================
🔄 Round 175 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 175 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0022
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0221
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0192

============================================================
🔄 Round 177 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 177 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0059
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0247
============================================================


============================================================
🔄 Round 179 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 179 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0002
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0307
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0192

============================================================
🔄 Round 180 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 180 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0076
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0148
============================================================


============================================================
🔄 Round 181 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 181 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0052
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0075
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

============================================================
🔄 Round 183 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 183 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0142
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0249
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0192

============================================================
🔄 Round 186 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 186 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0096
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0079
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

📊 Round 186 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

============================================================
🔄 Round 188 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 188 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0063
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0024
============================================================


============================================================
🔄 Round 191 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 191 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0013
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0153
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

📊 Round 191 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

============================================================
🔄 Round 194 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 194 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0040
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0158
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

============================================================
🔄 Round 196 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 196 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0150
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0474
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0191

📊 Round 196 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0192

============================================================
🔄 Round 198 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 198 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0016
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0254
============================================================


============================================================
🔄 Round 199 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 199 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0028
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0135
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0192

============================================================
🔄 Round 202 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 202 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0096
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0101
============================================================


============================================================
🔄 Round 204 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 204 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0047
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0043
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2467, R²: 0.0192

============================================================
🔄 Round 207 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 207 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0082
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0018
============================================================


============================================================
🔄 Round 208 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 208 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0078
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0006
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2467, R²: 0.0192

============================================================
🔄 Round 212 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 212 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0057
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0089
============================================================


============================================================
🔄 Round 213 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 213 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0171
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0495
============================================================


============================================================
🔄 Round 214 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 214 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0118
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0155
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2467, R²: 0.0193

============================================================
🔄 Round 216 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 216 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0072
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0158
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2467, R²: 0.0193

============================================================
🔄 Round 218 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 218 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0046
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0006
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2467, R²: 0.0193

📊 Round 218 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2467, R²: 0.0193

============================================================
🔄 Round 220 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 220 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0047
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0131
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2467, R²: 0.0193

============================================================
🔄 Round 221 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 221 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0066
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0109
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2467, R²: 0.0194

============================================================
🔄 Round 224 - Client client_87
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 224 Summary - Client client_87
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0083
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0005
============================================================


❌ Client client_87 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
