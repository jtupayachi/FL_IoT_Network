[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249ccf4b-e08e-467c-aae3-1c15bcd0f95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ad3c57-16f4-43db-a3e1-b8297afebcef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f93c0d5-25ce-4dac-bb11-50b8c4012694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eac7e20-cc92-40fb-ab50-18e434ec4321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aed7584-040c-403f-9bfb-f1d4a8c2a27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69928732-99b8-4e5e-b88c-3ac34ec3f120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797fbdb5-1e49-4e4f-b89d-318bce3c2e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51323313-f3e7-4deb-9979-27f10602df3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3008198c-710f-4daf-affe-50c5e59efeaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f1ca3b-b1c4-4e13-b5f0-64550a8c745a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 279939c5-ace8-4534-87d1-1adf7b24aa67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8c68656-1d09-46cc-96cf-e19230f36acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08c08370-803d-4c0c-a987-37de862ab682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af19a448-1bc8-447d-8a9c-0b6eb3bda721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919d86a8-7bb6-400d-bcc4-e0f0350d91dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9254faa-891f-4243-be1b-94d0ba90a236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ac633c-30d9-4247-bf72-662bb950d11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26fcf3e9-a39a-4749-9812-be6fc6465b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54848f8-6eee-465b-a637-3b66869dc069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f95c10b-ca02-41d1-85f1-c2aa644e77e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c31be8cc-99a3-4fdb-8263-d1fc2fb215eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f32f9d-eeee-4cbf-9b63-df905ae308d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2cf36a-9292-4159-a7f3-8c17ed3b30e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f743e9-e5c7-4077-8fa5-33d386f1f2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23d43cc-615b-43bf-bec7-d91dc0f7443f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77beedb7-0932-417a-814f-328b615b39e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d93d0c5-6f1c-4044-bee5-94cd364ccfbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca890cd-3316-4c11-a35b-7a07b6a69203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67aee668-3a1a-41bf-8a55-38d4e7ae57fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ade597b7-c4bb-4799-a0c0-e56b1c7b4f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68706901-77f0-4fc9-8abe-5aedf0a5299f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2368746-67e1-485d-b422-1c08a74a1790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dafd43e-ad60-4616-9bac-d70a8685d797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5daebc44-a01f-4d6a-b297-e058b996482f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ac5dd0-0ec1-4765-a932-5c298af72988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 605e4173-2a28-4a84-b853-b1be85a2be81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57436293-e234-4ea9-ab25-1a5fe39fdf10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4cea8ff-780b-46cb-a3dc-7e0521875020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72ba02b6-d912-44db-ae6e-8eb5ef0014ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c49479-25a0-47a6-8278-7d2bfa78b3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6b64c9-7638-4a1f-bf44-6a5af01aac78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72117623-f1ed-46a2-94ca-46183cee8cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99482d77-e6c2-4a85-9feb-826787faef6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 786062b1-c957-4342-b3f5-92effbe796c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a36054-586e-40e3-b632-9cbfe8480db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6bfd51d-f912-4609-baa0-73d3a693dff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b66be7-f942-434e-b1ba-8bfb21f34418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b24791a7-4960-4d27-b383-23e1f5e60a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2e2019-8d47-4e78-9eb7-d2f8b7892aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da2d0a1d-3b6d-428c-bed2-c672fede2291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3fdd3ce-88e7-445f-8161-0006eadd70af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a60940-ce75-443a-b6f5-eab03a2a0574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f118f39-c84d-4ee8-b972-936a8c2a9728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5b007d-3e79-4518-a455-d28be7425765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1554201-4780-46f8-8c68-7a0aaa012032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cbe4acb-fb97-4ed7-9339-f3319f330cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982629da-9126-4f56-abe0-b6c60d368943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e09a47a9-20fa-4f3e-ba49-7d39d3aee4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5f9445-83a6-459a-a63a-16e7220315f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b03b1cb-0d12-4753-99a6-366d8c1bb9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc15c86-950b-4547-a1aa-0b85b3f6cf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fba6756-f90d-43a9-8996-bf3cc8ba516f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27102210-c35f-406e-af1b-2d4f0e6f1110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 273d676c-6e1b-4268-b788-b218b6d2306e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54657090-0ec9-4532-ae2e-872c747cc1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4886d25-1de5-4885-a588-587bcb6cd545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bec9e6c1-edb2-4fbd-86fd-a7c20dc33f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f85e281-da01-4c25-a104-225da48febf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dc991ab-9c9a-4b5d-bb60-5797139117ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151912bb-e78e-4445-a019-2fc65f0c3bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c8fa9b-5b50-41c8-aefe-4c4b6657e811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd0d29ed-c471-492c-ad29-844cd5679776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee833c4f-e6c0-490b-82e0-54dad228be4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d95bd9c-0750-408b-8902-352532d28342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557fcfb7-ff6d-4f5d-a536-b78ff5026090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7037d272-e9ce-45bf-81fb-5a756038b0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561adced-9985-4760-bfd3-12a43ea258b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f63d8ea-9b04-411e-abe4-63ef6dcc9f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a12601e-d0af-4997-b33b-4b2a0dd9e881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaebb0e0-7f7b-4360-9a18-b43469bb72b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0073498f-ddb9-4793-8dc2-a9079d6bae53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a596ec3-1ef9-47a5-ad75-049fd8188745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dfc59e5-f7fa-46e4-8e90-0d22c42127cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814d270c-463c-4ce2-9992-324327048e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f377a6ae-60c7-4cf2-a88e-43f6ea184b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b6b1621-f3a2-4177-947f-23722faeb59c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 271d20c2-296e-4e76-91d5-cd24f3e3d58d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01146a46-5150-4321-b271-1d4774f9d5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78df2bce-62ca-4fdc-8082-25ea26d58654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a36b5b-c6b8-4195-8c19-afec42db851c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0effb445-b523-434c-a156-d10059b35aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 810d7328-88b9-4824-a144-b1002db01ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d81f817c-6614-424a-a050-d068c93ca786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74df18b-6362-453e-924d-2f7d549867b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 632677c1-98fa-4f41-9a7e-665cb2f6c53d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12695773-8176-45e9-85ae-4582f6a847f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97b1514-df85-4dbe-8294-f5c25e19797b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d454bb94-c290-4a54-a7f4-92962240fc27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45271ba5-8463-46b4-8446-fbc96e438095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2006aba8-0c58-4f6b-ad85-b5ccdfa07345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a662fa-d842-401c-b7ae-69fecd1ad7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf5efb0-53c4-4b77-8a1d-ad716e623bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a75f22e6-a548-4218-a4ed-a514c1e028d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc569d5b-d69c-44e1-98b6-7ca38e64ac6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137e73b1-b8a1-4c2c-8ffe-d7bd750df6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b9afc9-86f1-4443-97cd-4d421c4e9321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7312fe5-9961-49ed-bf62-946ac6eaead8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3167c5-af64-414b-b395-49592f860773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcfe91e2-41f7-4795-bfde-1ab6d23650e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c3cfaec-5a1e-4f31-bb14-806462214bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e0251b-7951-487a-9782-d4998fe449bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7743540c-46da-45cb-a62c-4feed5bee061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc2fadb-517a-4984-9444-de2726806319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f574c1-c8fc-40f3-b754-2e020531d613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b511a9-1ed2-4ce9-87e5-30618a62ba54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29207098-a299-426e-91d1-854533094433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f0c741-6130-44ab-847f-a1b43887c3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c72934-32b6-4df9-b635-fa386adefbd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921fd690-9146-425c-a08b-76a89df855c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73cecc80-f6a1-4a71-9041-6fbb4262c3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 129515bc-e7e0-4fe4-9fb9-4a15a28eea32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb1448f-ddf4-41c0-970e-44073c41f4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 766d7823-7e52-4c08-9fe6-f8f9441d0623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e99ff1-f400-440f-8008-2459d1f2f953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7483ce45-f628-48a4-876d-923e1986cbfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29be3954-ecf0-46c0-9725-d18c60c54d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd0f671-f0d1-4674-910c-6fdf5325e9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b87e055-1917-4646-b890-2ebfd343f5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10278ce6-9c8b-4337-a921-5fc3f8a864ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb02a2b-6fe5-4858-8dcc-12fc72a4568d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8453d3c9-f4a2-4c56-9afc-867e5133e64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0680d5a2-b600-4bc2-b77e-4546a67dc7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c68b1e5-be54-48d3-9c52-4a71790a5edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c34333d6-daaa-4e86-bd54-ee93f086b6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66286b93-83a9-46a2-b8e4-b049fdc3dcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d197bef3-d131-43c2-9741-ad29cdd88cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c7f4580-7504-4db9-a243-57c87e182c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de9111b8-a635-4504-8bd3-1caa1e39b04f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623014eb-490e-45b3-8f8a-b1bb9c938790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13089694-99b1-4334-82dd-35b1331cb6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 002eef6f-d42e-44a5-ab9a-66209b4225af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79821e7c-a231-47d0-8e5d-870fee20c765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 537cbba0-2b1b-4dd9-9528-64f0aa77fce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a16918d-67e3-4e9e-a974-ceef33085439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b559c9c1-2e65-4290-a963-0e90fa72ae37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26c8a839-8c4c-4909-a7fc-59648ff9456d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc7781cd-57f2-4fee-9933-73c9f798bc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c37d54-ca23-484c-888c-cbd1a6c3f76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bf55ec1-5279-4693-8251-136bdd454c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d8b62e-55be-4278-ac92-35699cf219dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eb00cac-cdd1-4335-b409-e4c373fff7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71154c4-ebbe-4724-9ce9-2f1861b3cfd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389d2f62-c0f6-4f95-a393-019c6123d8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317502dc-af4e-4697-bea4-fa8a03425418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c86032c-279c-4345-baa1-40b82ce49362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d63242-b213-4a49-b27a-3ea44929e52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c638211e-4c61-416f-aa4f-eba671032d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 135d19bb-823c-4cc0-849b-579144aa9c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4dc73e-c1dd-4b71-ba1a-5e2ed0973e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a40a13-1982-4934-af34-f365145d024a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb629b73-3515-424f-802d-4a6235c2f41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a376c03c-cc03-4484-afab-a5c4ebbf5148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63be7664-ed75-4532-994e-2f9b956f519a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f5b58d-ea1c-4db6-b094-5f84daac5bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419c6d3a-b410-4c43-b529-d53b5340ec8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016b75ef-89c3-42fc-937c-658e5d73033f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b334ec-a9fa-4520-b9ef-57e9f9396a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 469f0542-64f8-4f78-b02a-80d65c419427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b26a3d5-0e0e-470b-a89b-9ec73c56221d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5345342f-7026-45ad-813b-31752bf897b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012c64dc-46f8-4d13-bb9f-9759a78c4530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486745dd-337d-4e7b-9ac3-0d3f1f4eb336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 402beae9-fd3f-4dad-b80b-c2c1cedbcd1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57c9c70b-ad54-4a40-a0b0-ab9a9f5a2f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd2bd3d2-d675-42f6-97d6-29dd2d54ac65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba6c755-5ebb-4e1d-8c35-21b2ce0bcf09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97625dae-ee63-4d46-93da-3d5c53bfb814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98125ad1-01c0-439b-b5b8-78a19463f424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e49e26b-3267-4d85-8b27-c025be6d5660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548edec8-97ca-4f0e-a6c8-2b77089e2214
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_88
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_88/test_labels.txt

📊 Raw data loaded:
   Train: X=(1537, 24), y=(1537,)
   Test:  X=(385, 24), y=(385,)

⚠️  Limiting training data: 1537 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  376 samples, 5 features
✅ Client client_88 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0852 (↓), lr=0.001000
   • Epoch   2/100: train=0.0815, val=0.0850, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0811, val=0.0848, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0808, val=0.0851, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0805, val=0.0849, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0773, val=0.0856, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 8 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0040
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0241
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2588, R²: -0.0299

============================================================
🔄 Round 10 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0750 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0844, val=0.0741 (↓), lr=0.000500
   • Epoch   3/100: train=0.0837, val=0.0739, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0832, val=0.0738, patience=2/15, lr=0.000500
   • Epoch   5/100: train=0.0829, val=0.0738, patience=3/15, lr=0.000500
   • Epoch  11/100: train=0.0815, val=0.0737, patience=9/15, lr=0.000500
   📉 Epoch 14: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 10 Summary - Client client_88
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0024
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0048
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2588, R²: -0.0288

============================================================
🔄 Round 11 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0857 (↓), lr=0.000250
   • Epoch   2/100: train=0.0818, val=0.0853, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0810, val=0.0850 (↓), lr=0.000250
   • Epoch   4/100: train=0.0805, val=0.0849, patience=1/15, lr=0.000250
   📉 Epoch 5: LR reduced 0.000250 → 0.000125
   • Epoch   5/100: train=0.0802, val=0.0848, patience=2/15, lr=0.000125
   • Epoch  11/100: train=0.0792, val=0.0846, patience=8/15, lr=0.000125
   📉 Epoch 13: LR reduced 0.000125 → 0.000063
   📉 Epoch 21: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0785, val=0.0845, patience=6/15, lr=0.000031
   📉 Epoch 29: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 11 Summary - Client client_88
   Epochs: 30/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0272
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0048
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2586, R²: -0.0261

📊 Round 11 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2586, R²: -0.0273

============================================================
🔄 Round 15 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0844 (↓), lr=0.000016
   • Epoch   2/100: train=0.0831, val=0.0843, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0830, val=0.0843, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0829, val=0.0843, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0828, val=0.0842, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0824, val=0.0842, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 15 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0244
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0176
============================================================


============================================================
🔄 Round 17 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0777 (↓), lr=0.000004
   • Epoch   2/100: train=0.0852, val=0.0778, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0852, val=0.0778, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0851, val=0.0779, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0851, val=0.0779, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0849, val=0.0780, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 17 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0323
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0080
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2579, R²: -0.0226

📊 Round 17 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2579, R²: -0.0227

============================================================
🔄 Round 23 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 23 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0258
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0169
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0224

📊 Round 23 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0227

📊 Round 23 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2579, R²: -0.0228

============================================================
🔄 Round 28 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 28 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0224
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0447
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2579, R²: -0.0229

============================================================
🔄 Round 30 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 30 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0225
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0303
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0227

============================================================
🔄 Round 32 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 32 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0245
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0249
============================================================


============================================================
🔄 Round 33 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 33 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0183
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0481
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0227

============================================================
🔄 Round 36 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 36 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0243
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0404
============================================================


============================================================
🔄 Round 37 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 37 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0254
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0272
============================================================


============================================================
🔄 Round 38 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 38 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0193
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0575
============================================================


============================================================
🔄 Round 39 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 39 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0253
   Val:   Loss=0.0703, RMSE=0.2652, R²=-0.0409
============================================================


============================================================
🔄 Round 41 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 41 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0312
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0018
============================================================


============================================================
🔄 Round 43 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 43 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0246
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0355
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0226

============================================================
🔄 Round 45 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 45 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0305
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0010
============================================================


============================================================
🔄 Round 47 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 47 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0243
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0233
============================================================


============================================================
🔄 Round 52 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 52 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0203
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0397
============================================================


============================================================
🔄 Round 53 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 53 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0245
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0274
============================================================


============================================================
🔄 Round 54 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 54 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0231
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0277
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2579, R²: -0.0229

============================================================
🔄 Round 56 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 56 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0286
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0139
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2579, R²: -0.0229

============================================================
🔄 Round 57 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 57 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0176
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0523
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2579, R²: -0.0230

============================================================
🔄 Round 59 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 59 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0282
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0075
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2579, R²: -0.0230

============================================================
🔄 Round 60 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 60 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0197
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0419
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2579, R²: -0.0230

📊 Round 60 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2579, R²: -0.0230

============================================================
🔄 Round 62 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 62 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0242
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0227
============================================================


============================================================
🔄 Round 63 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 63 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0303
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0002
============================================================


============================================================
🔄 Round 64 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 64 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0297
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0021
============================================================


============================================================
🔄 Round 66 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 66 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0356
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0156
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0227

📊 Round 66 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0227

============================================================
🔄 Round 71 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 71 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0212
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0356
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0226

📊 Round 71 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0226

============================================================
🔄 Round 73 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 73 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0237
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0257
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0226

============================================================
🔄 Round 75 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 75 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0248
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0455
============================================================


============================================================
🔄 Round 76 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.1011 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.1011, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.1011, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.1011, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.1011, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.1011, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1011)

============================================================
📊 Round 76 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0204
   Val:   Loss=0.1011, RMSE=0.3180, R²=-0.0392
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0225

============================================================
🔄 Round 78 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 78 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0309
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0020
============================================================


============================================================
🔄 Round 79 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 79 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0265
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0124
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0225

============================================================
🔄 Round 80 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 80 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0247
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0208
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

📊 Round 80 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0226

============================================================
🔄 Round 84 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 84 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0197
   Val:   Loss=0.0796, RMSE=0.2820, R²=-0.0429
============================================================


============================================================
🔄 Round 86 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 86 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0262
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0168
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0225

📊 Round 86 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0225

============================================================
🔄 Round 89 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 89 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0312
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0012
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0225

📊 Round 89 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0225

============================================================
🔄 Round 94 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 94 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0310
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0003
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2578, R²: -0.0225

📊 Round 94 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

============================================================
🔄 Round 97 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 97 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0260
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0159
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

============================================================
🔄 Round 98 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 98 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0220
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0310
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0223

============================================================
🔄 Round 100 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 100 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0244
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0239
============================================================


============================================================
🔄 Round 102 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 102 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0238
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0428
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0223

============================================================
🔄 Round 104 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 104 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0255
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0213
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0222

============================================================
🔄 Round 107 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 107 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0282
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0073
============================================================


============================================================
🔄 Round 108 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 108 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0236
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0248
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0222

============================================================
🔄 Round 111 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 111 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0230
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0272
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0223

📊 Round 111 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0223

============================================================
🔄 Round 115 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 115 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0181
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0484
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0897, RMSE: 0.2994, MAE: 0.2577, R²: -0.0220

📊 Round 115 Test Metrics:
   Loss: 0.0897, RMSE: 0.2994, MAE: 0.2577, R²: -0.0220

============================================================
🔄 Round 122 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 122 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0255
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0239
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0221

📊 Round 122 Test Metrics:
   Loss: 0.0897, RMSE: 0.2994, MAE: 0.2577, R²: -0.0221

============================================================
🔄 Round 126 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 126 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0163
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0595
============================================================


============================================================
🔄 Round 128 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 128 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0270
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0203
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0223

📊 Round 128 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

============================================================
🔄 Round 135 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 135 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0267
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0145
============================================================


============================================================
🔄 Round 136 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 136 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0203
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0551
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0226

============================================================
🔄 Round 139 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 139 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0221
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0414
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0225

📊 Round 139 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0225

📊 Round 139 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

============================================================
🔄 Round 146 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 146 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0235
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0272
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

📊 Round 146 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

============================================================
🔄 Round 149 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 149 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0166
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0647
============================================================


============================================================
🔄 Round 150 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 150 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0303
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0008
============================================================


============================================================
🔄 Round 151 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 151 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0163
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0583
============================================================


============================================================
🔄 Round 152 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 152 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0267
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0159
============================================================


============================================================
🔄 Round 154 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 154 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0189
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0413
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

============================================================
🔄 Round 156 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 156 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0199
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0406
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

============================================================
🔄 Round 158 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 158 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0169
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0566
============================================================


============================================================
🔄 Round 161 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 161 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0261
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0312
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0225

============================================================
🔄 Round 164 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 164 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0228
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0342
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0226

============================================================
🔄 Round 166 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 166 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0252
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0331
============================================================


============================================================
🔄 Round 167 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 167 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0204
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0390
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0226

============================================================
🔄 Round 168 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 168 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0251
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0176
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0226

============================================================
🔄 Round 170 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 170 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0291
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0025
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0226

📊 Round 170 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0226

📊 Round 170 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0225

============================================================
🔄 Round 173 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 173 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0275
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0102
============================================================


============================================================
🔄 Round 174 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 174 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0246
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0209
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0224

============================================================
🔄 Round 176 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 176 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0228
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0618
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0225

============================================================
🔄 Round 179 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 179 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0186
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0487
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0227

============================================================
🔄 Round 181 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 181 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0197
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0485
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0227

📊 Round 181 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0227

📊 Round 181 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2577, R²: -0.0226

============================================================
🔄 Round 184 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 184 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0293
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0009
============================================================


============================================================
🔄 Round 185 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 185 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0220
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0422
============================================================


============================================================
🔄 Round 186 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 186 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0254
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0341
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2578, R²: -0.0229

============================================================
🔄 Round 191 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 191 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0244
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0230
============================================================


============================================================
🔄 Round 192 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 192 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0178
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0570
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2578, R²: -0.0230

📊 Round 192 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2578, R²: -0.0230

============================================================
🔄 Round 195 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 195 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0290
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0028
============================================================


============================================================
🔄 Round 196 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 196 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0277
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0104
============================================================


============================================================
🔄 Round 197 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 197 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0267
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0149
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0229

============================================================
🔄 Round 199 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 199 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0175
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0488
============================================================


============================================================
🔄 Round 200 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 200 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0296
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0155
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0229

============================================================
🔄 Round 203 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 203 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0175
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0550
============================================================


============================================================
🔄 Round 204 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 204 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0331
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0095
============================================================


============================================================
🔄 Round 207 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 207 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0279
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0138
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2578, R²: -0.0230

📊 Round 207 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2578, R²: -0.0230

============================================================
🔄 Round 210 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 210 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0267
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0108
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0230

============================================================
🔄 Round 211 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 211 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0181
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0473
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0229

============================================================
🔄 Round 213 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 213 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0193
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0424
============================================================


============================================================
🔄 Round 215 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 215 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0210
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0370
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2578, R²: -0.0231

📊 Round 215 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2578, R²: -0.0231

============================================================
🔄 Round 218 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 218 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0209
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0406
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0230

============================================================
🔄 Round 219 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 219 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0159
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0628
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0230

============================================================
🔄 Round 220 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 220 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0288
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0035
============================================================


============================================================
🔄 Round 221 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 221 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0326
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0145
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0229

📊 Round 221 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0229

📊 Round 221 Test Metrics:
   Loss: 0.0897, RMSE: 0.2996, MAE: 0.2577, R²: -0.0229

============================================================
🔄 Round 225 - Client client_88
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 225 Summary - Client client_88
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0177
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0466
============================================================


❌ Client client_88 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>
