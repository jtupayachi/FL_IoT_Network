[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88fac39c-29ec-4db6-987b-764f0f9c3545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bde514fd-4aa1-4677-be65-eeee28091a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a18681a-c396-4cf0-bc07-789feb5f1e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc17fa26-85aa-4aab-8e75-447fd1b095d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c59c4447-abd2-4b43-8520-7875ae218ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e97c0d7-ab7f-41eb-98b5-c657b0ce47b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b55f77f-98f3-4b61-b34c-8c45f6a4657b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c02c0130-93f5-4749-8673-19aaa3f7fc81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daef479a-0192-4885-9080-f5c128f68f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 548e0456-c214-44bf-a3fb-3d2d8dd6c16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e9a9a1-8d9b-4990-a750-7111a9335c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2ea618-264a-4722-bcf9-924b813d79be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdeecd2f-af44-463f-af02-1ded024283ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfee4626-23f1-4fca-ac92-2d11de2bd630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7252365-cf68-44f0-8b74-9938d24fe800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b93893-6c9d-4ccc-b83c-508dddbaab1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad76ad9-c2d1-4d5d-89d2-8ddfc9f6a350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75486b85-a450-4d49-a51d-bbc9a82e42f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23178a6d-2ea2-45f0-a427-e106549ff393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d47dfb4-8376-4b48-b849-92121563860a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf749fe9-de2c-4b01-a4fa-d60e96c419c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d3eee91-08e0-4bff-8a00-22a8bff39b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d8926c-317d-448d-9416-109514e4ce60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52391e1-feeb-446f-b64e-8c9fe23b797e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a67f6d-75fa-4b01-a3bd-722c32c50f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8485bf66-ccc0-48f9-8b90-911b0631914e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 846a04d4-eac7-4e2e-a926-07d642793b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 560fff56-d4c6-48c0-8119-94328ab9caa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433aa12a-d31e-4aff-825a-2331f5423900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f348ae-729c-4e6e-bf95-4c86dd066250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec73615e-db9b-4cdd-baed-c0ed4cd17f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205e6d58-2a2a-49b7-b023-6a3203fd08a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1b284d-4deb-45fb-97a5-8ca2fad05ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef39811-61b7-4e35-96c9-c39ed9fc7cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0a3d89-ecf9-47be-ad6b-3731e71b17d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c397a306-9972-4a50-82ff-15490b1ffb67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5c538e-3324-4f2c-a0d3-d73bd45164d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 947e0e95-aa7d-449e-b5c4-a1ef5492bddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 699b6717-5ba1-4ad7-852b-73260f3511a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8990ba1-4d12-44e0-a272-92d99fca38af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9139ac0c-8f31-45f9-983a-70966d7f907f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4102338f-7817-4f53-b5c5-5b87ecb94213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0a54f68-6f89-466a-b6d9-fcbe18afeccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cb7e3f4-e51f-41eb-a21d-5f5a00cd9f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c904ab48-be58-44de-83d4-abe1ed0ed980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b23463f2-5d90-4a38-a06d-b952456f89da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c31420c3-2ab6-4c28-96d6-3304da57794f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71022765-f671-4de0-975c-c89bb54fc1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ff194f-f6a4-4e3f-b3dc-1995f038592f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa77ce7c-5257-49c4-ba52-5097e3d47ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0885d739-0018-4d2b-a1d1-ecbd38a7c7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837ba9d0-4e9c-456c-8e6c-3c736a42a68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05319aa6-e703-48e8-ad34-481a202a9da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bffb5b56-951b-4761-9128-604a437b0113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c069c2-8421-4fd5-809c-a8a52d765e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ca9ae5-bb91-4ee4-ab39-884f6bfa0340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123a58a1-60e4-496c-ba8d-56d6a8804a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b367aa58-e0de-4c1a-b0a1-ef355e8189b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7a3dbef-e3a7-4fb2-9ecd-349b74243143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76fa7363-7c4d-4fdc-8972-c33a5bdcc050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b0e08d-7377-4c98-a21e-905c0145e159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f5f41b-da4d-4611-945f-d6079e4c18db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7521374b-e9eb-4bee-ad6d-e09f664e9dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2ae1ab-d883-4eb5-ac88-907eb5f57e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d8be806-0d73-4cea-9e4a-5265f7440570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f520d306-7923-4a55-b728-938de3ca4b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b75439-ccaa-4352-8278-da8e73bb47de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e55bbf-6dcb-4dab-800e-4593d33276e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 654dceb0-9837-49c6-a8ae-080199032733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf8c5ba-02ea-443a-9b8c-8242f485963b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a75d9cf-3792-4a99-af50-80bdcc2a9e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74defa15-dc31-470c-a373-0f99bc770bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a153f05-5a5a-46f3-9b45-d0a69803c957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f81d2760-02a0-4d21-929f-0d6d4700fc91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d16471e3-d74f-4818-854a-3ff2a1a56de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eac962a-a888-4311-9145-38020f546179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43a4b8d-a496-4fd4-8337-70ecf8c1858b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 772ed76e-aa13-44cc-84d1-17a3c4352352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4401d9d4-476f-410c-9885-bb44ff012348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebc1c93e-255f-4ee5-93d8-33b67940fa63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5f4108-4338-46f0-8885-bbd211c9a0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f19a3a-3561-4285-8376-df4210b2fef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e2720e-f302-499f-b280-e8eb7cf1bf34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 347e3a99-3db2-4e1e-b420-8de3babbe2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf9b11d3-52b9-4b10-b5e4-b6fd4c2c3e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c007b0-6b51-4b33-acd2-74c3ce95d0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e85b9a-f667-48f4-bd5c-0a901282a2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fab66fb-51bb-4176-81af-bbb54d13e885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6896f9-3b1c-423d-a32a-085731fdc8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c55586-a99e-43dc-846b-bd809bcc0802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4503a2bc-949a-4759-a623-fc07c802c373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8369f0e9-7efd-4a7f-b353-f3f8bf31c55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e0378a9-48db-48ff-9982-a8f7b174269e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d558c0a1-1b75-402d-9bc5-5649a6c76c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f7aa7f6-9091-4423-a393-c2308b8d1611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f80981-9f3e-4a4d-ae83-6ddc8a9e7e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdd78d0-c2c4-47d1-bcbe-ccc3f5acd587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ebd3135-7006-4e47-9905-4f8b2bd3622d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf155c01-9f43-4b52-8691-69ef0f315b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6536bb7a-1cad-4556-adda-a906e15c5201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d129fdf-9517-42e3-9867-8255d06f5c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e32fd920-ff38-4262-86b1-71a2883c30e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f184390f-a461-4821-bda8-c3701a7e13c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d58698a-3185-4567-bcd9-b7e4b4157f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f7992ed-8805-4bfc-8dbc-b07582e6cf73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb330482-3a98-42e8-8691-7d9568c8f3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efaa579-49df-46a9-8a24-4c00f70a1b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46150f58-2da6-485d-9492-6b0967e30bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4915ee55-e6db-470b-af3f-fce917200e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf538b13-68ab-45a4-a784-15a8a81c74ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c0ca4f-49d2-4130-827e-69b40a1a5d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd875398-405a-4b13-a845-5b11c18d1281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab85dda2-7c1b-4e07-8035-b2d5767caf28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8985c7c5-ee6d-4a5d-9bc5-def96efc348f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1008f1d7-f5e8-44c8-8eb6-bc99e754ca6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f40d0eb-6a3c-4f12-9985-00317abdd197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9ad623-5057-4f0f-af41-8a720998b014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869855bd-e313-491e-8ada-d083809bcc6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f29ebe68-6c7c-4ebd-9086-b20f6575b9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13a5f13c-b82e-49f2-bee2-bc60ad4cc362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd79cefa-9262-43cb-8f8b-cbc5cef1e627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 445f3c48-b859-49d3-916c-82e546dd81db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e2c3e6-307e-4eee-9dc9-8f368004d2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5eedd5a-20ba-456f-9c5d-45cc6431b4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e126a642-403f-4862-a5eb-9e6f2233f137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bde8008-4564-48e3-bb69-fb0aa5eba765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2a253a-a03d-4bce-8771-89e7da270559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14718356-9750-47e7-a366-988d75aa1074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f894fc0-5838-429f-88e6-880e926942ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb8ac3f-a324-4195-a938-2704f433c715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c167fa-cf79-4842-96e0-1ba9dc3b0b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b202e9e3-8015-4ef0-9989-e9d859a3f958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550ae9e4-36d3-4a9f-ad0a-497d619d397a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca5f9ad-8589-419e-b51b-4ce7b4ede91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6452db9d-a80e-4356-a91e-6b5ddc91d571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41899f79-43e3-4908-87ec-ae28d0e8f96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c30da5e-ab37-47be-8fac-76a8ff8f51c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17ab55a1-0201-49d1-9288-8988dbfac244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ee164f-e903-407d-8e16-2de2c7085aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c8b19f-79e1-4683-b094-38a92d9e038a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff046a44-f822-439f-8b9a-4be85161e200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b55356-6b4e-42f5-87b5-d8242f9ac811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b78fdd-2329-43ef-b308-cc12a5a9a2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3cbdbf3-a597-44b0-b818-e0851a55943f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b9718f-2508-4b13-9f47-0fcf790402c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ebc3c2b-c1a4-4fc6-95ed-9a81847090f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d0a85c-1b51-413d-b1b7-82c080ff5f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77dd4e0e-fe1a-4330-8ef2-e8d7de1d39d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1cf671d-4e68-4694-a254-3b8ad5e33496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c148c8-bd7a-4566-ba96-413f22700319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8e3fc1-ac72-446b-9b41-af70973d19f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e34899e-b40b-42ea-929b-788afd5a2125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9184eb43-b8c7-4852-9929-b7596a515c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56cec20a-0b7d-4dfd-a7cf-4da9fd306027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd05907-fc04-4d6d-b62a-a84797e68cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b00f032-a509-424b-826b-04b53b90ea99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae102ec1-33bd-4856-9ebe-ef8982710a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f4683b-0f6a-4392-a91d-91f56a9bc624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cedda8f4-5f14-4fb5-8434-70dc4ec6ccb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf8cc4f-ee8b-4ac0-8f94-6cdc9a7f7f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a2a1d2e-7375-4428-b8be-97ba3d528a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f19ae915-49cd-4b1a-add9-7c7fd9231b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a82b19c-6e53-45eb-987b-047c52a4e3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42626475-c8bb-45aa-8623-414393c8c6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93022839-12c4-41df-abe7-bfa66cb43502
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_89
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_89/test_labels.txt

📊 Raw data loaded:
   Train: X=(1393, 24), y=(1393,)
   Test:  X=(349, 24), y=(349,)

⚠️  Limiting training data: 1393 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  340 samples, 5 features
✅ Client client_89 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2587, R²: -0.0148

📊 Round 0 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2588, R²: -0.0159

============================================================
🔄 Round 11 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0803 (↓), lr=0.001000
   • Epoch   2/100: train=0.0878, val=0.0831, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0857, val=0.0816, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0840, val=0.0811, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0838, val=0.0813, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 11 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0046
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0237
============================================================


============================================================
🔄 Round 13 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000250
   • Epoch   2/100: train=0.0832, val=0.0851, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0824, val=0.0849, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0820, val=0.0851, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0851, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0808, val=0.0852, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 13 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0185
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0544
============================================================


============================================================
🔄 Round 17 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0878 (↓), lr=0.000063
   • Epoch   2/100: train=0.0834, val=0.0876, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0829, val=0.0872 (↓), lr=0.000063
   • Epoch   4/100: train=0.0825, val=0.0870, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0823, val=0.0870, patience=2/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0818, val=0.0870, patience=8/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 17 Summary - Client client_89
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0130
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0492
============================================================


============================================================
🔄 Round 19 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0824 (↓), lr=0.000016
   • Epoch   2/100: train=0.0853, val=0.0823, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0851, val=0.0822, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0851, val=0.0822, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0849, val=0.0820, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 19 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0261
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0585
============================================================


============================================================
🔄 Round 20 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0816 (↓), lr=0.000004
   • Epoch   2/100: train=0.0852, val=0.0816, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0852, val=0.0816, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0852, val=0.0816, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0851, val=0.0816, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0851, val=0.0816, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 20 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0321
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0282
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2588, R²: -0.0233

📊 Round 20 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2587, R²: -0.0228

📊 Round 20 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2587, R²: -0.0229

============================================================
🔄 Round 24 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 24 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0354
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0220
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2587, R²: -0.0227

============================================================
🔄 Round 28 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 28 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0369
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0311
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2587, R²: -0.0226

📊 Round 28 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2587, R²: -0.0226

============================================================
🔄 Round 30 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 30 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0338
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0273
============================================================


============================================================
🔄 Round 31 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 31 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0395
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0119
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2587, R²: -0.0226

📊 Round 31 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2587, R²: -0.0226

📊 Round 31 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2587, R²: -0.0226

============================================================
🔄 Round 35 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 35 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0260
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0582
============================================================


============================================================
🔄 Round 36 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 36 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0353
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0241
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2587, R²: -0.0225

============================================================
🔄 Round 38 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 38 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0386
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0090
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2587, R²: -0.0225

============================================================
🔄 Round 41 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 41 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0385
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0200
============================================================


============================================================
🔄 Round 42 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 42 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0275
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0531
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2587, R²: -0.0225

============================================================
🔄 Round 46 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 46 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0314
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0694
============================================================


============================================================
🔄 Round 48 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 48 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0434
   Val:   Loss=0.0776, RMSE=0.2787, R²=0.0105
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0224

============================================================
🔄 Round 51 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 51 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0353
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0272
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0222

📊 Round 51 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0221

📊 Round 51 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0221

============================================================
🔄 Round 60 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 60 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0367
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0170
============================================================


============================================================
🔄 Round 61 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 61 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0368
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0276
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0221

📊 Round 61 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0221

📊 Round 61 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0221

============================================================
🔄 Round 73 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 73 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0256
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0767
============================================================


============================================================
🔄 Round 75 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 75 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0355
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0233
============================================================


============================================================
🔄 Round 76 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 76 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0396
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0163
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0220

============================================================
🔄 Round 77 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 77 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0337
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0265
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0220

============================================================
🔄 Round 79 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 79 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0368
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0203
============================================================


============================================================
🔄 Round 80 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 80 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0317
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0390
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0220

📊 Round 80 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2587, R²: -0.0220

📊 Round 80 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0219

============================================================
🔄 Round 83 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 83 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0343
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0263
============================================================


============================================================
🔄 Round 85 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 85 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0275
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0779
============================================================


============================================================
🔄 Round 86 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 86 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0451
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0170
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0219

============================================================
🔄 Round 89 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 89 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0366
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0181
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0219

============================================================
🔄 Round 91 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 91 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0368
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0138
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0219

============================================================
🔄 Round 94 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 94 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0287
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0528
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0218

============================================================
🔄 Round 96 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 96 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0331
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0275
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0218

============================================================
🔄 Round 102 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 102 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0287
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0446
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0218

📊 Round 102 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0218

📊 Round 102 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0218

📊 Round 102 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2586, R²: -0.0218

============================================================
🔄 Round 109 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 109 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0300
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0469
============================================================


============================================================
🔄 Round 110 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 110 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0302
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0377
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2586, R²: -0.0217

📊 Round 110 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2586, R²: -0.0217

============================================================
🔄 Round 113 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 113 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0277
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0512
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2586, R²: -0.0217

============================================================
🔄 Round 115 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 115 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0347
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0258
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2586, R²: -0.0217

📊 Round 115 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2586, R²: -0.0217

============================================================
🔄 Round 121 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 121 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0280
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0483
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2586, R²: -0.0217

📊 Round 121 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2586, R²: -0.0217

============================================================
🔄 Round 130 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 130 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0309
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0368
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0214

📊 Round 130 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0214

============================================================
🔄 Round 132 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 132 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0352
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0316
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0214

============================================================
🔄 Round 133 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 133 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0315
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0503
============================================================


============================================================
🔄 Round 134 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 134 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0385
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0021
============================================================


============================================================
🔄 Round 135 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 135 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0375
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0114
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0212

📊 Round 135 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0212

============================================================
🔄 Round 137 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 137 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0384
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0038
============================================================


============================================================
🔄 Round 138 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 138 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0325
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0430
============================================================


============================================================
🔄 Round 139 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 139 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0324
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0285
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0212

============================================================
🔄 Round 143 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 143 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0281
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0455
============================================================


============================================================
🔄 Round 145 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 145 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0304
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0386
============================================================


============================================================
🔄 Round 147 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 147 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0323
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0716
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0212

============================================================
🔄 Round 150 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 150 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0447
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0140
============================================================


============================================================
🔄 Round 151 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 151 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0349
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0178
============================================================


============================================================
🔄 Round 152 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 152 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0398
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0019
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0211

============================================================
🔄 Round 155 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 155 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0257
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0538
============================================================


============================================================
🔄 Round 156 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 156 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0297
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0390
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2586, R²: -0.0211

📊 Round 156 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2586, R²: -0.0210

📊 Round 156 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2586, R²: -0.0210

============================================================
🔄 Round 161 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 161 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0250
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0601
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2586, R²: -0.0210

📊 Round 161 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2586, R²: -0.0210

============================================================
🔄 Round 164 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 164 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0225
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0919
============================================================


============================================================
🔄 Round 167 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 167 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0382
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0142
============================================================


============================================================
🔄 Round 168 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 168 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0349
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0165
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0208

============================================================
🔄 Round 169 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 169 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0243
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0654
============================================================


============================================================
🔄 Round 170 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 170 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0286
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0431
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0208

📊 Round 170 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0208

============================================================
🔄 Round 172 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 172 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0325
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0275
============================================================


============================================================
🔄 Round 173 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 173 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0334
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0384
============================================================


============================================================
🔄 Round 175 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 175 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0326
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0274
============================================================


============================================================
🔄 Round 176 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 176 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0330
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0263
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0208

============================================================
🔄 Round 177 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 177 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0253
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0708
============================================================


============================================================
🔄 Round 178 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 178 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0343
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0213
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0208

📊 Round 178 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0207

📊 Round 178 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0206

📊 Round 178 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0206

============================================================
🔄 Round 183 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 183 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0309
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0326
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0206

📊 Round 183 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0205

📊 Round 183 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0205

============================================================
🔄 Round 190 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 190 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0406
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0010
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0204

📊 Round 190 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0204

📊 Round 190 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2585, R²: -0.0204

============================================================
🔄 Round 193 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 193 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0203
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0805
============================================================


============================================================
🔄 Round 194 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 194 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0344
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0203
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2585, R²: -0.0203

📊 Round 194 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2585, R²: -0.0203

📊 Round 194 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2585, R²: -0.0203

📊 Round 194 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2585, R²: -0.0203

============================================================
🔄 Round 200 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 200 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0356
   Val:   Loss=0.0735, RMSE=0.2710, R²=-0.0102
============================================================


============================================================
🔄 Round 201 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 201 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0259
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0520
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0203

📊 Round 201 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0202

📊 Round 201 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0201

📊 Round 201 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0201

============================================================
🔄 Round 208 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 208 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0339
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0270
============================================================


============================================================
🔄 Round 209 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 209 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0395
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0155
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0201

============================================================
🔄 Round 210 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 210 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0343
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0269
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0201

============================================================
🔄 Round 212 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 212 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0380
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0103
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0202

============================================================
🔄 Round 214 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 214 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0308
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0486
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0201

📊 Round 214 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0201

📊 Round 214 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2584, R²: -0.0200

============================================================
🔄 Round 219 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 219 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0289
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0380
============================================================


============================================================
🔄 Round 220 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 220 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0293
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0438
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2585, R²: -0.0200

============================================================
🔄 Round 223 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 223 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0325
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0420
============================================================


============================================================
🔄 Round 225 - Client client_89
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 225 Summary - Client client_89
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0337
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0223
============================================================


❌ Client client_89 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
