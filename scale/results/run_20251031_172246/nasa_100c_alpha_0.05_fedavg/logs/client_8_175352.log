[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa02d3c7-9ad1-450b-a010-094e054b28d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2158a61-117d-4d4a-84ca-e33150f274a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e23d4e-ceca-422e-861d-2ae0febe1c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea2847f4-5d8e-471a-8b87-ee326272d215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a432e25c-f5e4-40d5-8c64-48209cef756e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac1a310b-6c1b-44e6-a2ff-d239997b6686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 144e89c4-ab83-45b6-9961-f887930ad2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4c4c97-a38b-45dc-a160-baf6bb242dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3925da4d-7339-4beb-9ece-a36e84c4a084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d9ef42-5fa1-4e97-9981-55ee15ec07a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d72bbfbc-3d70-4fca-91a2-1c2fdb0a291c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a30b7de-0fa4-4b7a-a3cd-e08b0d5690a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5258ca1f-e340-4525-a5f8-3e1b666899e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03b0e0b7-f397-4486-8714-13b5ce1655b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92023f36-6c4f-42e5-ac1f-b8ab4cb55a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ff8113-795d-419c-94b8-6ec5ed5c7be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc926ac5-dfb4-41b4-8340-1093ebd6180e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b9e606-e06b-4fe8-bc3b-fc6babacee5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37621227-2b24-42ba-af17-06d344bfa5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 519a6f01-e3c8-49fa-809f-69992fd5b143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74aca79a-bf43-49c4-ba9b-938a078d9e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1030038c-c46c-4ff4-b178-e1fdb861fb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117bf25c-32f6-4d23-8db7-43b92fcb59eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28742da0-2d9e-4949-9f14-984e237dd3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9187912-57cc-47d2-9666-d2c123773d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c883694a-55c9-49d7-bf47-c514d2f2bb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c38358e-7c57-4329-b12d-40574ec07aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e9400d9-b48a-4b91-bef6-0b58511b3597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c17c34-8f3d-4917-b4f0-be101bc67314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49f123ab-7149-4332-9ab2-95b117c82d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 150d26b3-c6a1-4d21-b90d-f9b853c0e5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22201a81-c0ab-4e76-b976-1d4c5f78fb76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70d211e3-4817-499b-932a-a803bd0ca37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4f6e416-18c6-41e9-8eb9-950a8ef40ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d5376b-3fef-486d-93c4-d98c11d29cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7183f636-f5cb-482c-8bdb-2547a49ba693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cb03b79-32b0-49cf-b9af-6403a795c9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dddb511-5309-4312-a89a-340e82787e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1469b97b-d430-4e18-be41-a94ba540bdb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11b9b344-f0ae-4b6f-81be-9420ac614cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07baecc7-15e9-4ce0-a32c-5039b520ee8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2bbdc5-a578-4001-bc8e-58dd93c34780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae30fef-f253-409b-95ce-45f5a6319172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 333baac3-f4c1-45e8-867a-2767c3e05dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1ecfcb-175d-47bf-bff7-f9089b5689e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d83f5e8-a1d5-48fb-b9a0-c557bbdde653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab3dd7ba-ac53-460f-bb56-f41d08d0c0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4b6b72-e14d-4451-bd5f-db71dfc5efed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e52ab70-d0f9-4f41-bcfc-d9fa0d577082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0306faa-de95-4819-b772-0927ab02c183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e01df8d-d336-4176-8be8-46c93b8c4137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b576a8-6287-4497-820c-098fd4b14482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 848545ab-1413-46ef-b5b0-741ed7b6cfd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee806dd-04ee-43ec-a39a-64c24ef7c8d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66263bb6-3321-449f-800a-73283e74865a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf560825-4847-4404-bb6d-fa2bde34e3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12797003-440b-4519-a4d8-e13497e7490f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae8e362-a326-4349-971b-916b2e252ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab9b8d0c-ca22-4f12-86f3-5d2b48f8cb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a0672c-7c30-4f14-8f9e-97b0d7e863ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecfd1110-f819-4399-88ef-a8688ed50762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e966b7a5-8129-4a71-ba5f-99f9fdb2217a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a63142db-4a8a-4278-a347-640c9f859583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a40dba34-5a36-4eee-9f11-e5100eea9571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12081baa-f439-4719-8b7a-54b062d655d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a45745-caaf-410e-90bd-6d5810651e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c0a1975-81fd-4203-8ce5-8c3b0e59c498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfaf2e91-2a2d-4d88-a418-a64714b3c0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9bbfad5-c148-420e-81ee-adcf050e15e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cbceef8-8773-4713-9d95-912df54bbfdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 866ac4a3-a7a1-42e9-a629-d3f091613750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 747d4722-55c4-456e-8419-d7b8126c393b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13391950-a5d2-4471-84d9-8788ea8a5301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf3d644-0483-4913-ba55-610e3001803e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e133af-0c7e-4c9d-b5b9-00cdb5ee9492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53bb4324-e56a-4b16-9bbb-7f72fb2d69ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462c794e-40f8-4556-88f4-c685cd6ec2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c72c26db-8a6a-44a5-aee8-f67929dd7057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8cd886-a737-4e0d-82cf-d99b32774d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 265ef62f-fa46-4081-9332-960b9e75310d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f11b1f49-fcff-4dd0-9751-f6178b274ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ed86416-a52b-42b2-830f-2cee2e3518ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61488be0-7c00-43d1-85ed-a956a949ef2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efdb22ce-7d1c-4cea-b493-3795f7bbaf6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63f29f8-e4ff-4e6a-8610-f29b2132a52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d0657b-8f2e-4526-a3aa-9bfc7c920a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b15641dd-ef83-47ab-b936-e162bedd953b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef9ab4e6-7d04-4a78-ac04-f6c1a51715b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd56504b-9927-40cc-87b2-23e4877d8577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad380cb1-4c99-4d22-af40-cd3a56cd906f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6bde880-81da-4584-965a-a9fcaad401bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e29138-1452-428c-9e73-dc271c6774b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c76670d-3044-407b-abc8-2b6798e62fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fecc6577-3e13-4a2a-8c5f-6cba476d90c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b91e6525-3ad0-4cc5-9d21-42e6eab73c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de5cebf-4f6a-4894-a074-1a1323488751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6932cd-cf89-480e-8861-129203fa4be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 955e884f-821a-4f5e-81ca-1be309fc4f46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d999f7-1b52-4872-a7b2-65d98823e0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4679ca92-dab1-4b01-970b-e4375d3c4e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e47e71-faa2-4799-a725-c94616ae5ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2df3bb33-dc65-4379-b122-7af0f0a26e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58845215-7afe-4370-9c8c-52f9971be0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42fbf093-de7e-48cb-abac-b578e45b0e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcfbcac7-f28d-44ad-83b5-f1861c006719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c5fa44-340e-42f3-a23b-fb0e9ace5771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c74de654-3079-47c0-922f-eabd99f7a97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3bcb2da-7789-4a86-8b94-49de17e8f0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d3ceed-3102-4e27-bf09-a83a7c56cd79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0083a0fc-5d4c-46c0-b3d4-0cee182b67c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a85e11b8-eb1c-4e44-8150-020728c21dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7bd2826-75e0-4868-a5e5-6583da07d534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad7323e-6e59-4a14-98d5-49f1a777baa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae64cf6-a397-4e1b-bc3a-4bdef26d91bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29c2db07-ed5f-46b0-83a6-30d3b35c6bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fa6dd60-5ac5-439f-8ea2-25c769b0a626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d66991c8-e8c6-47ab-8f5d-ff5f9f5e0861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ccce552-8ebb-41cb-9231-04428f678c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c4f786-0189-46e0-a8ee-75cc3c307b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1f4b1e7-b2ea-4d7d-aeb6-73bd26ab6ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55ba649b-13bc-4298-9f29-e195c360dd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b0e0c8f-2f88-4384-829d-c89364628ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7d3a4e-9d88-4f92-a529-7fb43fabdc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e3769ce-3afe-4a4a-b37f-9bc3a0e86a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6b5c180-47ad-4792-8c26-6f84fe257f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f24826f5-8f74-4b4d-bc28-f492107b97c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4910df04-1178-4c76-886c-a9ebaf5bfc0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f61b76-9d2e-465a-8060-9a8893a9706b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3731b4-4589-4976-a868-b7a6d6ca15d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e9ff3b0-2877-4b97-87f2-c57f6e03baaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a11d36b-8883-4e04-8223-8165a8e23bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9033a16b-fded-4f99-94c2-66f994dc0c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed806c8c-9b77-4a45-9f93-795fe912f054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d6b8f76-4cb5-45bc-9ae1-1d3362c392b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bfbff36-58fa-44ca-a701-2e81497f0b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf354c89-9700-406d-b32f-7d2dfafaf261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c6bf59-ecc5-4d69-9710-974e8bb1e3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6309a66b-586b-4dc0-8f08-52b6cfa5a2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b06db113-86d2-471d-bde9-edb6153fa184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5058df1-3a5a-4e98-9397-fffd972c791a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9745296-7e83-4282-9651-507f24f87955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfbd2c46-4c9b-4cd8-b194-05b1b161eb41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc1ebcbe-eb9f-4310-af95-718d2325270c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37e88f26-5925-4ec8-b450-b85269996b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d410c71e-4be3-43e8-a3cc-15a29da7f4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 466237a4-78d9-4e98-b113-7895237bc164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f338081f-9cff-4f38-9e7a-a7bf449f36e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92957b3d-4861-4e3e-a515-5ad89d55f6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0d8c49-b353-4b1d-b101-537ed0c1daf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a37f9a-6033-4e0a-8421-3e5b10bb67f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c246e84-921a-40d9-9276-fa31ad614cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f815f3-eda8-4550-b63c-d087725efa70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ac89ed7-0930-4103-b92d-994ca0a57262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36622567-8623-4f2e-a180-f2d3bb4c3613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a5dbd6-3a1c-4b84-abca-53d13d1ce7ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19669f42-fbaf-40e9-851f-85d07622146f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb29117-846a-4aef-b762-64668bfaab69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3560228f-7cee-4c0f-80ca-57ffe225e05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edc42445-9739-435d-b81e-bca420125cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0cd29cd-e1f7-4369-ae1d-c3d94c39bef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d8275b3-be53-44dd-87b6-5605ee5cec9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e949ddd2-c24c-4a21-b6ba-06e87d6bca82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4eb6f5-0130-459b-b9df-1ea55413c343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c14503-99ae-4d36-bf84-705e5b01a0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e2990b-ffb0-4ab5-83e5-f4991e6a8bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a93fef43-5f88-4260-b178-a19160297ea6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_8
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_8/test_labels.txt

📊 Raw data loaded:
   Train: X=(1156, 24), y=(1156,)
   Test:  X=(290, 24), y=(290,)

⚠️  Limiting training data: 1156 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  281 samples, 5 features
✅ Client client_8 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2548, R²: -0.0081

📊 Round 0 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2550, R²: 0.0050

============================================================
🔄 Round 3 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0923 (↓), lr=0.001000
   • Epoch   2/100: train=0.0774, val=0.0922, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0773, val=0.0923, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0771, val=0.0922, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0769, val=0.0920, patience=4/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0755, val=0.0909 (↓), lr=0.001000
   • Epoch  21/100: train=0.0697, val=0.0921, patience=5/15, lr=0.001000
   📉 Epoch 22: LR reduced 0.001000 → 0.000500
   📉 Epoch 30: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0621, val=0.0959, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 3 Summary - Client client_8
   Epochs: 31/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.0771
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0325
============================================================


============================================================
🔄 Round 5 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0795 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0798, val=0.0788 (↓), lr=0.000250
   • Epoch   3/100: train=0.0798, val=0.0789, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0796, val=0.0789, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0795, val=0.0789, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0789, val=0.0791, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 5 Summary - Client client_8
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0138
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0209
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2543, R²: 0.0226

============================================================
🔄 Round 9 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0752 (↓), lr=0.000063
   • Epoch   2/100: train=0.0796, val=0.0750, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0794, val=0.0749, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0792, val=0.0749, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0790, val=0.0750, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0783, val=0.0749, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 9 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0259
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0337
============================================================


============================================================
🔄 Round 10 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0795, val=0.0763 (↓), lr=0.000016
   • Epoch   2/100: train=0.0792, val=0.0763, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0790, val=0.0764, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0788, val=0.0764, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0787, val=0.0765, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0782, val=0.0768, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 10 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0342
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0041
============================================================


============================================================
🔄 Round 11 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0794, val=0.0776 (↓), lr=0.000004
   • Epoch   2/100: train=0.0793, val=0.0776, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0792, val=0.0776, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0792, val=0.0776, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0791, val=0.0776, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0789, val=0.0777, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 11 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0215
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0388
============================================================


============================================================
🔄 Round 14 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0794, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 14 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0232
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0355
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2526, R²: 0.0307

============================================================
🔄 Round 16 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 16 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0253
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0363
============================================================


============================================================
🔄 Round 17 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 17 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0273
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0283
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2527, R²: 0.0308

============================================================
🔄 Round 18 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 18 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0277
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0222
============================================================


============================================================
🔄 Round 19 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 19 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0267
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0287
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2525, R²: 0.0313

============================================================
🔄 Round 21 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 21 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0321
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0156
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2524, R²: 0.0329

============================================================
🔄 Round 23 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 23 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0281
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0303
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 27 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 27 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0288
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0346
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2523, R²: 0.0331

📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2523, R²: 0.0331

============================================================
🔄 Round 30 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 30 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0291
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0311
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 35 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 35 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0313
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0248
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2523, R²: 0.0331

============================================================
🔄 Round 39 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 39 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0337
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0122
============================================================


============================================================
🔄 Round 42 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 42 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0337
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0118
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 44 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 44 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0259
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0391
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 46 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 46 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0345
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0103
============================================================


============================================================
🔄 Round 48 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 48 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0291
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0344
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 52 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 52 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0308
   Val:   Loss=0.0669, RMSE=0.2586, R²=0.0146
============================================================


============================================================
🔄 Round 53 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 53 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0341
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0222
============================================================


============================================================
🔄 Round 54 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 54 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0318
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0090
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2523, R²: 0.0331

============================================================
🔄 Round 57 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 57 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0231
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0261
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2523, R²: 0.0331

============================================================
🔄 Round 58 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 58 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0310
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0090
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2523, R²: 0.0331

📊 Round 58 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2523, R²: 0.0331

============================================================
🔄 Round 65 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 65 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0295
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0271
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 66 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 66 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0267
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0335
============================================================


============================================================
🔄 Round 67 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 67 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0328
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0184
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 68 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 68 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0346
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0153
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 71 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 71 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0281
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0390
============================================================


============================================================
🔄 Round 73 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 73 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0282
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0379
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 74 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 74 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0292
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0336
============================================================


============================================================
🔄 Round 75 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 75 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0307
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0200
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 76 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 76 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0324
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0233
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 79 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 79 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0337
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0134
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 81 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 81 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0294
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0228
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0330

============================================================
🔄 Round 85 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 85 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0299
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0324
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0330

============================================================
🔄 Round 93 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 93 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0323
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0215
============================================================


============================================================
🔄 Round 94 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 94 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0331
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0189
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0330

📊 Round 94 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0330

============================================================
🔄 Round 96 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 96 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0240
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0141
============================================================


============================================================
🔄 Round 98 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 98 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0259
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0511
============================================================


============================================================
🔄 Round 102 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 102 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0330
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0000
============================================================


============================================================
🔄 Round 104 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 104 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0313
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0271
============================================================


============================================================
🔄 Round 106 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 106 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0345
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0185
============================================================


============================================================
🔄 Round 107 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 107 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0381
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0000
============================================================


============================================================
🔄 Round 108 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 108 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0302
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0316
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0330

📊 Round 108 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0330

============================================================
🔄 Round 112 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 112 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0380
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0052
============================================================


============================================================
🔄 Round 113 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 113 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0297
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0353
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0330

============================================================
🔄 Round 116 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 116 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0327
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0254
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2525, R²: 0.0331

📊 Round 116 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2525, R²: 0.0331

============================================================
🔄 Round 120 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 120 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0294
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0392
============================================================


============================================================
🔄 Round 121 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 121 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0284
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0376
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2525, R²: 0.0331

============================================================
🔄 Round 127 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 127 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0331
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0254
============================================================


============================================================
🔄 Round 128 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 128 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0310
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0335
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2525, R²: 0.0331

📊 Round 128 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 132 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 132 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0333
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0226
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

📊 Round 132 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

📊 Round 132 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 140 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 140 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0307
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0344
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 141 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 141 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0352
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0102
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

📊 Round 141 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 143 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 143 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0330
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0244
============================================================


============================================================
🔄 Round 145 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 145 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0275
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0482
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 147 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 147 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0268
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0504
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2525, R²: 0.0331

============================================================
🔄 Round 149 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 149 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0323
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0182
============================================================


============================================================
🔄 Round 153 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 153 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0330
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0253
============================================================


============================================================
🔄 Round 157 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 157 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0367
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0052
============================================================


============================================================
🔄 Round 158 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 158 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0334
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0225
============================================================


============================================================
🔄 Round 159 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 159 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0305
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.0222
============================================================


============================================================
🔄 Round 160 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 160 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0329
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0260
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 161 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 161 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0331
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0254
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 163 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 163 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0310
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0283
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 165 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 165 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0331
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0251
============================================================


============================================================
🔄 Round 166 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 166 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0338
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0244
============================================================


============================================================
🔄 Round 167 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 167 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0311
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0233
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 168 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 168 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0339
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0189
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

📊 Round 168 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

📊 Round 168 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0331

============================================================
🔄 Round 171 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 171 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0269
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0431
============================================================


============================================================
🔄 Round 172 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 172 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0290
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0425
============================================================


============================================================
🔄 Round 174 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 174 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0381
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0049
============================================================


============================================================
🔄 Round 175 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 175 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0354
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0192
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 175 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 175 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 175 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 175 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 181 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 181 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0279
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0367
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 184 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 184 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0373
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0092
============================================================


============================================================
🔄 Round 186 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 186 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0348
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0137
============================================================


============================================================
🔄 Round 189 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 189 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0228
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0673
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 189 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 196 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 196 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0270
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0526
============================================================


============================================================
🔄 Round 197 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 197 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0269
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0496
============================================================


============================================================
🔄 Round 198 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 198 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0372
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0062
============================================================


============================================================
🔄 Round 199 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 199 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0403
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0196
============================================================


============================================================
🔄 Round 200 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 200 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0323
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0251
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 200 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 200 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 206 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 206 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0221
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0022
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 206 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

📊 Round 206 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 210 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 210 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0318
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0338
============================================================


============================================================
🔄 Round 211 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 211 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0345
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0223
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 213 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 213 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0334
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0264
============================================================


============================================================
🔄 Round 214 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 214 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0354
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0181
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 216 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 216 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0325
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0187
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 217 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 217 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0321
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0310
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0332

============================================================
🔄 Round 219 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 219 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0285
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0346
============================================================


============================================================
🔄 Round 220 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 220 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0343
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0249
============================================================


============================================================
🔄 Round 224 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 224 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0305
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0327
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2524, R²: 0.0333

❌ Client client_8 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
