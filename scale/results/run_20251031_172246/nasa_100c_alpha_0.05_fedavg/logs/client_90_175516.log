[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 664571b9-991a-4c65-b78e-d4607459f098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5198e102-d29d-4464-bb67-2f37ff17661c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a7fd1e-2960-47c4-8e12-2cc4addaf843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d33df8e-dc95-4000-b249-764511b89a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ba336ee-ed38-4e8f-b841-b30ed376e357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b089f7cd-81f5-42a6-8972-57d0213c823d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15186a2a-845f-4a32-a71e-9d0c8de3222d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6220ce7d-c9f7-4404-969f-fe7954fb37ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a85cd9fa-9771-4799-b107-e8a1a22ffd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d2c4af-2373-456b-bd47-61dd2776d5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d93d40-c206-47ee-9ecc-297adcefa717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b60d28d-f86d-4d16-afde-eb64969518dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0862f527-ea43-4f1f-9e21-a1b615d451c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4950add-8e38-459c-9837-c82fe3e9dce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 400ca23b-9553-40f3-8fdc-d6f87fa28f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc96c4c-491d-4f83-8a69-c9747d3d025d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c6c08e-6826-4bb1-a3e4-aeb829451c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37aa318b-6349-44ae-ba16-9e01be0f0c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e75f72d-4ee1-4a7d-ba0b-02e73047e773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d691c7-3fc1-4a2e-9753-b1fff86bc426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceded2eb-150b-4b46-9d72-57ce6a74028e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57997f3c-43c2-4bbe-bf1c-85625878a3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33367caf-439f-492b-a4c0-9c7f9782cb4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecfefbca-a311-431b-8149-1ae3ecfa5710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0642c4b5-bf82-4db1-8567-20fd12957b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6306f42c-8e04-4b52-ad12-168ab6769dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80bf7d8-2b97-480c-a56e-b7230db55505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f789e245-0ea5-413c-8b3e-853040227975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07727cbd-18d5-4edc-9b55-457e27a0c57e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da1b44e-3465-4abd-a3fc-57493e56c7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c0b0941-09d3-494f-8e3c-b4bc3e1774be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80bb0df-8633-4dde-81fc-ec13cb6e98c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e1b091-c7ca-46c5-80b8-cde4060ede44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df5d1b6c-dd03-45c9-8745-2f8c23b552d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4acde0ac-5374-4b48-9d74-cc0bb5df169e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f4d207f-f586-4842-885e-27ed66bdbb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39859a70-4ff2-425e-99a1-30573d30f0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1386be15-aa45-477d-b12f-54a66c4e3968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84cde7c0-9779-4253-8920-ce10e7819fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af750e63-f0dd-4efb-8fa5-c859be15e30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c5464c-c911-4c81-8ab6-55837b566189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e246750-346b-4a44-a92d-4d1bffabb8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94250ee4-6d09-4dbb-8882-1dfde27238a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2903528b-c554-4177-851d-51c6e7f888a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bc5d2ec-3c5e-4616-b187-3a425cc8e53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd284d5-2abd-4fad-b55e-9e9ea3428bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe81546b-3492-4f72-9cea-ac991edd2993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd33b8dd-509e-445b-8811-f52a89bd1164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e61b0ee8-358f-45f7-bbc2-274980effce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 323457f0-b60d-4336-9656-78c9f9ae7162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30eb16ed-e7d2-41ce-bff9-9aef14c5e3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1249ba76-2702-4b6f-8b8e-79303cf788f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699cca11-843e-48aa-bbba-38056871ae96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2aaeb25-c325-4e9b-954e-c6be75520beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4cd4d77-dac9-415b-a32a-e5021eba20c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2f267f-afb8-457e-a510-3966900fd5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 589107a2-c4a0-433c-99c6-b4258475963b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c170dd-7da2-407d-bca6-4c6879e150b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20126100-d941-4574-8c37-bd52805b50e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d3af61-302e-4d88-a449-2dd6692cdaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04cdb878-5ebc-47c4-93c3-85a1dd4081d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c3245f-5263-404f-b36f-7ddd9ccb7468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d83939-2c37-4f01-ab2d-e8b2bdeed59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7abe6719-aad0-41e0-8070-fffdebfd5398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f02e3e60-dcb4-4112-b26a-292284bc4656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb8d163c-f131-4f6c-a25f-68dfaca6a3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 246f9c94-7ae7-4b68-a250-bd7b3a278601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a9ce3d-82fb-4ae3-b8be-dfa1d12033d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced4b487-4cc5-4ae7-9111-1138c10619eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f7c8495-fd87-4dc7-8a9c-f1b79508436e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f80870-86ef-4eb2-a726-be424a3fa9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9162ef3c-6c0c-4399-b10e-13b5731788d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8cf85a7-9852-41d7-af8e-a3c851976816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c304fe-c7f7-4c23-b3f1-2eb9dfb98168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd7784d2-a3b1-42e2-8378-efc4d380f82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10ee244-d1be-48db-beed-5a195967f28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eb71d05-cd95-44b0-8a9e-b5fca80b6cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6536fff0-0b82-4c1e-8870-0d1f55d61ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10239cc1-d41f-4212-8a46-3b97a15c085f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9458b0a-8e36-49c5-b591-cbebb367a7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05cab6a8-00d4-4bba-a08a-48d8962715ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aec2792-f44d-4427-8290-7061ce2dc139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16732fc1-0548-4bb1-a5b7-a78f22b22c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e558b5dc-c460-4cd5-8725-a9bb72fc0edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0033afc-32f3-4d13-b80e-6fbe534135a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bef390a-14c7-4cf8-9193-17049d6f4388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8aacc1-71e2-4442-a82f-2ca0039b037a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e9b893-78a9-4a62-8dfb-3c79b5c47e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4bbde6b-0ffb-40fe-85e6-90b13e50540d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8bfab0-6f2e-4704-ba05-9161a8392e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c1ecb1-7e90-499a-adde-f9cdbade8c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94934073-0bda-47c7-9aed-56718245892f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9055e19c-329d-4b89-b353-c7d7be88df80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fc11b55-9874-4fcc-bf7c-450ad506444f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5615e5-8e00-470e-bdbd-7ef4d647194f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1423e8-6129-4335-8be1-c9b53d9befeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95205a19-1046-457e-952a-2ab459176a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd858f14-38b3-4834-90a4-c4ee726b9ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9241da61-f332-41cc-b089-a41355b8e9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5f2211-9ecf-4d14-8cda-63fcfaac5677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5d3f3e-467f-49a3-b10a-d2b93cd98506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4c62427-e0e5-4b7b-a73a-54222a5cc611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 630233ef-231f-4952-bf3b-82c85536cd44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26296846-ba1d-4819-a381-6f5ff1e9e6c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e89299-cf12-4e55-b19a-063c2c5ef1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f4b0233-bcaa-41c1-a34a-8c9b1d9f5461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1e2055-56a1-4a31-993b-0776ed55ba0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e92820-14c4-4433-99f9-140254887800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54e6843-bcae-44e1-88e1-c1f5577caaef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f50e136-193b-4dd4-83c6-7178a039db71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f7cec8-38e8-4db5-9003-15acbc2a06ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5782d013-ac86-45c6-a6b9-563e523ff666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 765b8812-fbc7-4076-88c2-02f34aea096d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd7a5c0-1d67-42f9-9122-56509afb8e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92cdd1db-7b55-4fdb-80c9-8db013c6b032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4acb7e90-3657-4134-be88-294078ae5d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6134df64-e787-475b-a519-4b034e67bf1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44729995-f177-48d7-8dae-dbc99b4fb645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5b3699f-f27c-4907-9ffb-9d0e4c9a8c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5540ca-9fca-4c72-ae13-496e23b9dbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4079b6-3841-4e2a-9ca4-ac240da10572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65266a85-ddf7-4176-9b1e-05fee069f1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d615538-e8ea-438c-a9a5-9f5f45de074b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a61ba4d-742a-45ef-934e-99334be1efd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ab2c95e-3196-4973-b890-334fdc9ce14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad987b5-4080-4808-bd57-022e3ab03e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ccc4d0-03c1-4dc7-86e9-30fde1291f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da055316-7e8b-4415-a1b9-08569e69c609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bc4a6d7-4ddc-41fa-99be-cb88bf8c64b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3660f88-26ce-48fa-9e91-5a02335e5b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17f4d40-e93d-470c-89e1-62183f484b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d1c9331-68f0-4ae5-a731-9f890229d6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf80ddf7-d269-4710-8709-e445ad453dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd02aff1-c8aa-40be-a3b5-f60a7866ba6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0aa1703-752b-4774-a33c-24d45cad4f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8847858a-03e6-491f-904e-38be452927f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4eb9ae4-ff46-4dcb-b9d4-018872b28bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6cc1569-2c76-4892-89ee-0d4404435fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e950b45-9fe0-401f-a287-5d389e3f033e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a1ee2b7-b3b9-447f-a0e8-924581efde14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beb39d16-e9f4-401f-a2f0-dd0007fcdf9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a6d177-c38a-440c-be67-fea6a29b7822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5382a9af-08b9-4d0a-9e58-379ce7e397a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 271e400c-1276-4edc-9476-17db532255e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0440785-c621-4eb6-b957-56882235b842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ae68a5-1b4b-4d59-8b3b-3ca986adfff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0858dcc-60fc-4fe6-a6ea-08e8294a963c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b970dc-82db-47da-8566-7fc4d3c4d243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 953ff8fd-7ae6-4c27-b0be-30d71323669e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5621f090-685f-4f05-82f9-dffe9f137e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9054692-deb4-4322-b672-716070df97fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01e3a17c-9c40-4770-a39c-98a7f1ff413a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75e8572-02b1-4e98-8711-57f1920fd53d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b480ba0-3070-4933-aecb-30cbb391d373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1a2a077-2d2f-475e-93ef-d5fabfcfb2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d44caed-35e2-4909-ab78-064c0defa5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8efa3c3d-96e6-4cec-b9c3-b5f71fc8c142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f80ced-bf9b-4418-9e92-8a38c92b37d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f756fd4-8639-45da-b2d6-5c0f021a9d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 479303fd-cfac-42de-ba4d-b28579a0f1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7016c3-1720-48e0-be4d-2638eed84741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 246ccc63-dbbe-44bf-afb5-283928ddf2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94648807-88c4-4451-affc-0f05ca0f8ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d08ecfce-6fe9-4a86-ab48-acafa3e0291a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9f8545-0501-447a-bf17-836f938a2c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de8dfc14-bb83-4028-85e1-dbbc7230788d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a466e858-7255-4062-8524-17e4dc4bd541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a932cb-279c-4c64-9e16-9e9b62a69419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b9eef3-e6cb-4a70-81b6-4d1bcc3f5314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3745173b-fca2-47e0-a4ec-b5db00be4c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffda2e69-d102-4ec4-99a6-ceaae2b0ba78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ff660a-6bcb-4815-ad22-161b229d32d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 661e2df9-1db8-4d81-bb96-f3ea047dad08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f5eeeb-6781-4e6a-9217-f7fab5e94246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae31cb63-9791-4e63-b47c-d74248b446b0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_90
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_90/test_labels.txt

📊 Raw data loaded:
   Train: X=(2056, 24), y=(2056,)
   Test:  X=(514, 24), y=(514,)

⚠️  Limiting training data: 2056 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  505 samples, 5 features
✅ Client client_90 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2425, R²: 0.0145

============================================================
🔄 Round 8 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0726 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0856, val=0.0719 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0856, val=0.0705 (↓), lr=0.001000
   • Epoch   4/100: train=0.0848, val=0.0704, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0842, val=0.0698 (↓), lr=0.001000
   • Epoch  11/100: train=0.0825, val=0.0698, patience=6/15, lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 8 Summary - Client client_90
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0748
   Val:   Loss=0.0698, RMSE=0.2643, R²=0.0238
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2425, R²: 0.0141

============================================================
🔄 Round 10 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0743 (↓), lr=0.000500
   • Epoch   2/100: train=0.0833, val=0.0738, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0829, val=0.0738, patience=2/15, lr=0.000500
   ✓ Epoch   4/100: train=0.0827, val=0.0737 (↓), lr=0.000500
   📉 Epoch 5: LR reduced 0.000500 → 0.000250
   • Epoch   5/100: train=0.0824, val=0.0736, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0813, val=0.0735, patience=7/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 10 Summary - Client client_90
   Epochs: 19/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0577
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0587
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: 0.0159

📊 Round 10 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: 0.0155

📊 Round 10 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: 0.0152

📊 Round 10 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2411, R²: 0.0173

============================================================
🔄 Round 17 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0864 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   • Epoch   2/100: train=0.0797, val=0.0869, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0795, val=0.0868, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0794, val=0.0868, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0793, val=0.0868, patience=4/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0789, val=0.0869, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 17 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0538
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0247
============================================================


============================================================
🔄 Round 18 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0774 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   • Epoch   2/100: train=0.0826, val=0.0772, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0825, val=0.0772, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0825, val=0.0772, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0824, val=0.0772, patience=4/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0822, val=0.0772, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 18 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0438
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0493
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2411, R²: 0.0176

============================================================
🔄 Round 19 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0763 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0828, val=0.0762, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0827, val=0.0761, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0827, val=0.0761, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0826, val=0.0761, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0825, val=0.0760, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 19 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0416
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0507
============================================================


============================================================
🔄 Round 20 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0891 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0796, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 20 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0516
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0076
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2406, R²: 0.0190

============================================================
🔄 Round 21 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 21 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0379
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0705
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0190

============================================================
🔄 Round 22 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 22 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0409
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0591
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 26 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 26 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0563
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0023
============================================================


============================================================
🔄 Round 28 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 28 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0411
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0586
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 31 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 31 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0325
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0797
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 33 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 33 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0430
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0519
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 35 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 35 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0512
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0170
============================================================


============================================================
🔄 Round 36 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 36 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0496
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0216
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 36 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 36 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 39 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 39 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0375
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0701
============================================================


============================================================
🔄 Round 40 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 40 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0441
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0472
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 40 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 42 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 42 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0473
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0276
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 44 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 44 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0529
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0067
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0192

============================================================
🔄 Round 45 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 45 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0437
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0494
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 45 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 50 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 50 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0534
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0043
============================================================


============================================================
🔄 Round 51 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 51 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0404
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0314
============================================================


============================================================
🔄 Round 52 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 52 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0467
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0201
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0190

📊 Round 52 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0190

📊 Round 52 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0190

📊 Round 52 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0190

📊 Round 52 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0190

============================================================
🔄 Round 63 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 63 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0383
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0641
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0190

============================================================
🔄 Round 66 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 66 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0541
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0038
============================================================


============================================================
🔄 Round 67 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 67 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0405
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0407
============================================================


============================================================
🔄 Round 69 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 69 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0420
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0572
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 70 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 70 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0388
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0652
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 70 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 70 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 70 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 80 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 80 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0523
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0150
============================================================


============================================================
🔄 Round 82 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 82 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0521
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0058
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 84 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 84 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0465
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0387
============================================================


============================================================
🔄 Round 85 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 85 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0434
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0501
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 87 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 87 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0511
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0116
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 88 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 88 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0431
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0483
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 90 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 90 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0368
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0728
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 92 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 92 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0486
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0242
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 93 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 93 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0486
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0260
============================================================


============================================================
🔄 Round 97 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 97 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0362
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0463
============================================================


============================================================
🔄 Round 99 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 99 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0357
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0636
============================================================


============================================================
🔄 Round 100 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 100 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0463
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0291
============================================================


============================================================
🔄 Round 103 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 103 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0406
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0598
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 103 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 103 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 103 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 110 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 110 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0385
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0687
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 110 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 112 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 112 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0524
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0163
============================================================


============================================================
🔄 Round 113 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 113 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0483
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0250
============================================================


============================================================
🔄 Round 115 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 115 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0306
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0954
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 116 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 116 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0446
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0476
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 117 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 117 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0445
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0458
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 120 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 120 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0304
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0888
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 122 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 122 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0373
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0753
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

📊 Round 122 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 125 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 125 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0565
   Val:   Loss=0.0903, RMSE=0.3006, R²=0.0043
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0191

============================================================
🔄 Round 129 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 129 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0450
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0327
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

📊 Round 129 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 132 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 132 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0573
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0080
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 133 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 133 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0415
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0539
============================================================


============================================================
🔄 Round 135 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 135 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0410
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0487
============================================================


============================================================
🔄 Round 136 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 136 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0527
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0004
============================================================


============================================================
🔄 Round 140 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 140 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0474
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0302
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 141 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 141 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0434
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0474
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

📊 Round 141 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 145 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 145 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0549
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0039
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

📊 Round 145 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 147 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 147 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0444
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0497
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 150 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 150 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0566
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0002
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

📊 Round 150 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 156 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 156 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0425
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0553
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

📊 Round 156 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0189

============================================================
🔄 Round 161 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 161 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0545
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0047
============================================================


============================================================
🔄 Round 162 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 162 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0480
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0311
============================================================


============================================================
🔄 Round 163 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 163 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0390
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0715
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0188

📊 Round 163 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0188

============================================================
🔄 Round 166 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 166 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0344
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0846
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0188

📊 Round 166 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0187

============================================================
🔄 Round 170 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 170 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0385
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0456
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0188

📊 Round 170 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0188

============================================================
🔄 Round 175 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 175 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0472
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0329
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0188

============================================================
🔄 Round 176 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 176 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0364
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0557
============================================================


============================================================
🔄 Round 177 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 177 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0536
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0108
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0188

📊 Round 177 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0188

📊 Round 177 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0187

============================================================
🔄 Round 181 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 181 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0439
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0507
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0187

============================================================
🔄 Round 183 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 183 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0543
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0066
============================================================


============================================================
🔄 Round 185 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 185 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0310
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0854
============================================================


============================================================
🔄 Round 186 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 186 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0575
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0041
============================================================


============================================================
🔄 Round 187 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 187 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0378
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0598
============================================================


============================================================
🔄 Round 188 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 188 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0556
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0043
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0186

📊 Round 188 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0185

============================================================
🔄 Round 196 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 196 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0564
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0026
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0185

============================================================
🔄 Round 198 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 198 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0335
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0918
============================================================


============================================================
🔄 Round 199 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 199 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0471
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0371
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0185

============================================================
🔄 Round 204 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 204 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0394
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0655
============================================================


============================================================
🔄 Round 206 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 206 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0524
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0146
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2405, R²: 0.0185

📊 Round 206 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0185

============================================================
🔄 Round 211 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 211 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0562
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0037
============================================================


============================================================
🔄 Round 212 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 212 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0544
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0116
============================================================


============================================================
🔄 Round 213 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 213 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0493
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0247
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2405, R²: 0.0185

============================================================
🔄 Round 214 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 214 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0375
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0670
============================================================


============================================================
🔄 Round 215 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 215 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0429
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0546
============================================================


============================================================
🔄 Round 216 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 216 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0460
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0314
============================================================


============================================================
🔄 Round 218 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 218 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0500
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0254
============================================================


============================================================
🔄 Round 219 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 219 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0502
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0235
============================================================


============================================================
🔄 Round 220 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 220 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0390
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0455
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2405, R²: 0.0184

============================================================
🔄 Round 222 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 222 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0472
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0355
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2405, R²: 0.0185

============================================================
🔄 Round 224 - Client client_90
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 224 Summary - Client client_90
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0354
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0860
============================================================


❌ Client client_90 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
