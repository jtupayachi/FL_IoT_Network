[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f787a895-58e2-4284-863f-3c0f50d58794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1f44c7-7a9e-4ace-9cb1-2cb09aa26fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05009bd-a126-44ed-af45-ade338c6a057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34719f32-5f9e-4f51-9ad8-156466d9a969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bce30821-a272-463a-9878-52fd9f22f6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 894df057-b6d3-4969-8ecc-f35ee151ccd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72ac6ff6-8910-4b70-9ff4-a998dc7fca04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f314de-eac6-4fa7-82e4-1bcfb1685a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29764b1d-8c0f-4103-a03c-661647adb3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aeebc46-098d-409a-8ca1-a0ff6b7a45be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4bbaab0-906c-4b79-ab98-744dd69a7010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acdcce7a-62b5-4076-beeb-ff60ee26568a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cc99c59-39f6-4cd4-b661-b89df3d01fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44f38df1-d6df-4a16-a2fd-b8ff25a2ce19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d32a2d8d-3cfd-44fe-99bf-cbf06123d9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e78d21-8b26-410c-863b-1e625cbeb0e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09bea457-a9ab-4bd4-8ca6-0adb8867e5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c2f82c-6db7-4334-b1e9-08ad3e5d5416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cf428c-586a-4f74-a151-24c25c198605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a719339b-9f7a-44c3-a0ad-d61e5d48ce54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9cc70c3-d64e-49f4-93d3-05f032937f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16d748aa-5bb5-42c7-996a-10bf322e6680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf98153-6d35-4ca7-86dd-6c428b90110d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ce6a503-b272-4955-82bb-f5fa7de97257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45cb0e85-c9ff-4fb5-ba10-6d74f5f43234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad021aa-a155-4e3e-900e-519281cc60bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c090d37a-2b97-47e1-8628-1be05391c852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a7b5f18-b9db-4771-94b1-68c426661899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06352cd0-7c80-4669-be67-dcd0adb1d182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e9491c-f214-4e45-b42e-04d19fbbdf29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775c5afb-a077-419c-b6d8-ed8f400b181d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46875162-a33a-418f-9773-b17d18cb3627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9b0eaf-5d7a-4192-8941-9d5adfd2b4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73096dba-34f2-4d8a-9156-7a7b89e62f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38eb88df-3e9d-4834-84e0-7f234f38289e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cee4ef96-42ba-4595-9262-9640f407922e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef278c57-fb61-47f2-9994-68ec2151a3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25e2f86-e84f-4b7b-b07a-d2fe0718fed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a9ffd5-adef-40e4-9183-eca1487cf960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e3b98a-baed-4582-9148-2a98e6b2e799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3af383ba-e07e-4119-bfa0-2bfc899ec4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8ff3fe-e0da-4594-aca3-c3e96b60227e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8902899-d2b7-458a-a818-65d97f51c10d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca3d05b-4742-4a63-8bce-d7a4e9b275aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4c2fa8-d179-4215-9a1c-371f3abe3d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2a0b4e-2219-4dac-93e2-8ba93f5c52ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fc0506-652f-45a0-84c3-12a4c8530b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f48836e3-ab03-461c-b0fb-c16d3a54572d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acfafcd1-201f-4217-abf2-75bc6c1d08e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d785ad3-a940-42cf-ad6d-073efd0592dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437a3dc5-1e31-4594-85d9-3a4f3834f089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc9a997-db00-42fc-9d1b-78bd28c3ca45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db772248-308f-4456-a71e-80a70b7a9187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f2c7474-549f-4b7f-96f5-5f54025331ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6fbb252-6ea8-48d2-aaff-e69d34f9e904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4deb3ec-558d-4e8f-a6ea-36ae0440988b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5455cba7-6507-4d66-823a-ce0186ecccc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92203826-0b12-471c-91a1-35d63139ca27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c22b6d-459e-475f-9acd-44cc74e95b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d62d510-bfa7-4244-b481-de747a6617c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91295007-c388-4139-8267-9401a9f65f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc35def-f814-48ae-9a6d-47467e992641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a90891-b6d9-47aa-b0fd-af6e4dad329c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23e7ab8-415e-4205-be4a-010b6fcf07fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 986582b7-fb01-4eca-9b00-f30f43de5138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d378f7-d18e-4117-8d95-4e0397fb1cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62d1626e-5b45-4b76-88ca-a74318c0b92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b181c7-c5ce-4754-b6c2-e9677a292e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2dbdf63-17b8-49c8-a960-b88a07b9986c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f79ff55e-6c9c-406d-8137-a824ddf200b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f639da-00dc-4d1e-a3a6-9e8cb493ec81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5485a8b-a8ed-40f0-8445-6cb8ff389b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eea8e8f-7778-4f14-8181-443d67d3ef71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b9fa79-f4e9-487d-982b-4dbdfbe91461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e90e70-dc00-4bd6-9d9a-0c08fbf9baf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085546aa-d7f3-4035-a437-898f8c7bdb18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a47e405-7819-4a61-812e-cf1a20116abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c61175b-f459-450f-9eff-e3fb2565333a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac8a17b7-fb6c-4990-9817-f1495bd09e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b52db9-85a6-4df1-ad26-8380a6be253c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ba4156c-b66d-4e3d-9d25-82928439b632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1220d6-0b11-4a19-ab2b-29e58fa57cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ef93d8e-edc4-4704-abd7-4f71231a5807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7001644-3f95-4a6e-a22e-926a8c5f099e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fec89a6-6b33-4fa9-99d0-7c0811646d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7299b9c-9f5b-4be2-892c-9c22c50297b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd772f6e-9cd3-433f-b27c-f7dd49c375c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 677a5a55-5e35-4243-bcb2-af5478894b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a40322a-59ce-4f87-a8aa-9a0901ddbbb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f2e9d1-e76e-4b7b-8e51-d6f16eb3917e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40538bc7-e78d-43fe-b400-97e1e2d37370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77ad0224-bf7d-4e92-ac82-c248e8709ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dbfc951-06bc-4fe0-8ea7-838190987c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb16581-7516-47f9-8080-6841bb943fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbbf3d24-5405-4210-b467-4c7ba96df066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce8154f-c0ef-4781-a13b-6c787130a15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70bddad3-5ed0-435c-a811-ba547c3fa1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6879376d-faf5-4b1c-b05f-1b96a62739e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104633b7-e358-4c43-9396-c7270f673cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022d38b5-3ad7-4507-ad64-33cd4fc882e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a9af36-f46a-4898-b6be-ecadf58cec28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71683a18-220d-449b-8f93-dbcd1b56dee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7574123-63fd-46bd-87f8-8b97e45c6e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3924f410-89a6-4ae5-8b3d-a05e9ce81ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d872d0d6-df0b-4e9a-885d-b528cd56dab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37eb45ac-eeab-41c5-8cdc-d3b43876b73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc2d2c5-359f-46e5-8c5c-88931b432389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091e36ce-5e68-492b-8090-0cda837a53c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e027c59-6df0-47bb-8a53-62acfb7501a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 452b4606-1161-47e8-a15a-0c6931fdfa4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82c4c16-e500-43fb-8c8b-af1cfea3066f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c085de45-9d68-471c-8517-4323e82bfef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 220f1e03-c3ec-4e07-9c37-33151bd2bbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5bc4ad7-1987-44fc-a137-24f3553429f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52fda127-fd2f-4b58-8000-a848b8c2e2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 167a871d-f954-49f5-b2d6-f78132c0eb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1740642-d45a-4d32-a9ac-46cc9b617068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d33ce8e7-b39c-4731-a301-3a2f17159850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0bd808-8a77-4224-93e8-a80d4ab7e2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c801c3fe-8a65-4f15-8e20-2a801f968018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 800239cf-a721-4935-976a-3909d6301140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba2dff84-fc34-42c8-93ab-0169717f092a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdad9681-3a06-4602-b476-b5ca7b540822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 006e62a7-30f4-4d2c-92e3-cdc8b01032e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10aa0534-154b-459c-b209-4fac97b54b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cb4d392-4f0a-42c5-a8ba-576d5b2f5ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e32f321-35ef-4cd0-98d6-91a2db5a65c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5cfa98d-985e-4711-baff-92a83eb5b958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f6d31ec-df09-4ef8-895e-3fe7fbeeda61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 270b6325-575b-4388-9d33-d00f8b1e79b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5874a01e-b205-4145-9693-229cf0ba7567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60c0e8c-b6ed-45b4-9db7-e5c89ddb3a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567ec95a-d1d1-46ce-a115-ea2c04c507e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927b2bd7-11d5-476e-bb03-884056fb299e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c44b420e-663c-4b00-9bd2-4e5f3f17393b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02142ef0-605d-403a-a242-2ec1c0c03bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ce18a9-0226-4fd4-ade8-1a0bce5844d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82c3c09d-a2b3-4f5e-9426-c0eb3aff60a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d84dcfe3-8905-4718-9e03-e4e37bb9c966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb72b91-dfd9-4d92-94a8-018d7bb02e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c741f7ab-523d-4890-a96e-d38daae49d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95526c45-8b02-4f17-8ed5-678d6e32db4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23636733-cc08-4378-9a45-877c3c18ad3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc6b0ec-402e-444c-a246-82bf64f07a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb55b9ff-992d-4d09-8b80-a7e222509fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef6bf1f8-44c2-4a62-aae9-9f5c214f30b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb818ad1-4711-4130-b5b3-b86315ee7929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1deff3b-af70-42b5-8b48-df4fad2de993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751e6471-d058-4194-89a5-2c5a79baf4fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11efe2ec-a645-49a0-9835-12098ba4229f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53895f40-6899-4a11-b5e1-37c19f602880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1acdf9fd-ea69-42ef-b358-e460a1381299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe11acd3-b787-46dd-a138-783b902249fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1337327a-fdec-40ee-b576-2955e9b06760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def4ef30-ef5b-4481-8fec-00641031b36b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de1d8b33-9140-4b0c-8f81-a162bc937b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e9b34f5-003e-405c-9c6e-3cb2b54df256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68ddc93-b9c0-49bf-9b43-98ab3070454a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6be5b14-a621-4a5f-bf67-2b1dd3ab183d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4f67a76-284a-425a-8f5f-8d1aec47adc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545e2c14-9605-4e39-8f21-a9689d236ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbad05bd-bc0d-4fa8-92a9-2c174bd71714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e2573b7-cf9b-45ec-8ae9-76780be0b04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cbf3bf3-1a82-42b0-b015-a4fe4be85019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460b5220-e0d6-426e-966e-66b172e350e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80e93f4-a8cd-4259-ba84-f22a5e3cda64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aac38d7c-73cf-45b6-adee-c52b7ed5dda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa17323d-85b2-487e-87f4-4511374b8b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54b9513-2fa3-4105-bed7-d051943766e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0098d1a-db13-4428-9fab-c918689df643
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_91
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_91/test_labels.txt

📊 Raw data loaded:
   Train: X=(563, 24), y=(563,)
   Test:  X=(141, 24), y=(141,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 554 samples, 5 features
   Test:  132 samples, 5 features
✅ Client client_91 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0820 (↓), lr=0.001000
   • Epoch   2/100: train=0.0824, val=0.0839, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0811, val=0.0857, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0799, val=0.0855, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0792, val=0.0856, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0762, val=0.0869, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 7 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0424
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0268
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2387, R²: 0.0274

📊 Round 7 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2391, R²: 0.0223

============================================================
🔄 Round 9 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0891 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0816, val=0.0875 (↓), lr=0.000250
   • Epoch   3/100: train=0.0812, val=0.0872, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0808, val=0.0873, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0804, val=0.0870 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0791, val=0.0866, patience=6/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0785, val=0.0864, patience=4/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0782, val=0.0863, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 9 Summary - Client client_91
   Epochs: 32/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0611
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0023
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2389, R²: 0.0255

📊 Round 9 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2388, R²: 0.0253

📊 Round 9 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2390, R²: 0.0244

============================================================
🔄 Round 13 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0792 (↓), lr=0.000016
   • Epoch   2/100: train=0.0835, val=0.0792, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0835, val=0.0791, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0834, val=0.0791, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0834, val=0.0791, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0832, val=0.0788, patience=10/15, lr=0.000016
   • Epoch  21/100: train=0.0828, val=0.0782, patience=7/15, lr=0.000016
   • Epoch  31/100: train=0.0825, val=0.0777, patience=9/15, lr=0.000016
   • Epoch  41/100: train=0.0822, val=0.0774, patience=7/15, lr=0.000016
   • Epoch  51/100: train=0.0819, val=0.0770, patience=3/15, lr=0.000016
   • Epoch  61/100: train=0.0816, val=0.0767, patience=13/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 13 Summary - Client client_91
   Epochs: 63/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0372
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0755
============================================================


============================================================
🔄 Round 16 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0859 (↓), lr=0.000016
   • Epoch   2/100: train=0.0821, val=0.0859, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0821, val=0.0858, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0820, val=0.0858, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0819, val=0.0858, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0816, val=0.0856, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 16 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0325
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0043
============================================================


============================================================
🔄 Round 21 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0784 (↓), lr=0.000004
   • Epoch   2/100: train=0.0836, val=0.0784, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0836, val=0.0784, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0836, val=0.0784, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0836, val=0.0784, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0835, val=0.0784, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 21 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0284
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0212
============================================================


============================================================
🔄 Round 22 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 22 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0233
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0380
============================================================


============================================================
🔄 Round 23 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 23 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0261
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0343
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0224

============================================================
🔄 Round 25 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 25 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0322
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0068
============================================================


============================================================
🔄 Round 27 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 27 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0228
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0432
============================================================


============================================================
🔄 Round 29 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 29 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0252
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0200
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0222

📊 Round 29 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0222

📊 Round 29 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0223

📊 Round 29 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0223

============================================================
🔄 Round 33 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 33 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0307
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0123
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0223

============================================================
🔄 Round 35 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 35 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0297
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0165
============================================================


============================================================
🔄 Round 39 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 39 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0367
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0119
============================================================


============================================================
🔄 Round 43 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 43 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0286
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0229
============================================================


============================================================
🔄 Round 45 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 45 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0263
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0236
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0223

============================================================
🔄 Round 48 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 48 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0249
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0202
============================================================


============================================================
🔄 Round 49 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 49 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0280
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0154
============================================================


============================================================
🔄 Round 50 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 50 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0219
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0216
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0223

============================================================
🔄 Round 52 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 52 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0335
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0182
============================================================


============================================================
🔄 Round 55 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 55 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0318
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0089
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0222

============================================================
🔄 Round 56 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 56 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0289
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0225
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0222

============================================================
🔄 Round 59 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 59 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0235
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0255
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0221

============================================================
🔄 Round 63 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 63 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0270
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0291
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0222

📊 Round 63 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2396, R²: 0.0223

============================================================
🔄 Round 65 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 65 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0248
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0301
============================================================


============================================================
🔄 Round 67 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 67 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0319
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0099
============================================================


============================================================
🔄 Round 68 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 68 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0263
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0234
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0225

============================================================
🔄 Round 71 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 71 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0291
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0190
============================================================


============================================================
🔄 Round 72 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 72 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0232
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0385
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0226

📊 Round 72 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0226

============================================================
🔄 Round 78 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 78 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0210
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0389
============================================================


============================================================
🔄 Round 80 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 80 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0329
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0056
============================================================


============================================================
🔄 Round 81 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 81 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0188
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0565
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0227

📊 Round 81 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0226

============================================================
🔄 Round 86 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 86 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0246
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0320
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0227

📊 Round 86 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0226

============================================================
🔄 Round 88 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 88 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0348
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0188
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0227

============================================================
🔄 Round 92 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 92 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0276
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0075
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0228

============================================================
🔄 Round 93 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 93 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0255
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0221
============================================================


============================================================
🔄 Round 94 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 94 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0255
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0341
============================================================


============================================================
🔄 Round 95 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 95 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0282
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0129
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0228

============================================================
🔄 Round 98 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 98 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0265
   Val:   Loss=0.0669, RMSE=0.2586, R²=0.0354
============================================================


============================================================
🔄 Round 99 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 99 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0297
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0078
============================================================


============================================================
🔄 Round 100 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 100 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0323
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0051
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0229

📊 Round 100 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0230

============================================================
🔄 Round 104 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 104 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0268
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0324
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2396, R²: 0.0230

============================================================
🔄 Round 105 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 105 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0226
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0479
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2395, R²: 0.0231

============================================================
🔄 Round 108 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 108 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0317
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0051
============================================================


============================================================
🔄 Round 109 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 109 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0208
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0337
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2395, R²: 0.0232

============================================================
🔄 Round 113 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 113 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0339
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0004
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2395, R²: 0.0232

📊 Round 113 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

============================================================
🔄 Round 118 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 118 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0256
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0195
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

📊 Round 118 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0234

📊 Round 118 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0234

📊 Round 118 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0234

📊 Round 118 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0234

============================================================
🔄 Round 127 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 127 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0303
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0110
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

📊 Round 127 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

============================================================
🔄 Round 130 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 130 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0268
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0327
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2395, R²: 0.0231

============================================================
🔄 Round 131 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 131 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0226
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0049
============================================================


============================================================
🔄 Round 135 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 135 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0190
   Val:   Loss=0.0787, RMSE=0.2804, R²=0.0609
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0230

============================================================
🔄 Round 136 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 136 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0254
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0368
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0230

📊 Round 136 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2395, R²: 0.0231

📊 Round 136 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2395, R²: 0.0231

============================================================
🔄 Round 142 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 142 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0180
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0415
============================================================


============================================================
🔄 Round 144 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 144 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0248
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0378
============================================================


============================================================
🔄 Round 146 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 146 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0301
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0206
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

============================================================
🔄 Round 147 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 147 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0231
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0407
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

============================================================
🔄 Round 149 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 149 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0238
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0265
============================================================


============================================================
🔄 Round 150 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 150 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0291
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0167
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0232

============================================================
🔄 Round 151 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 151 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0285
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0276
============================================================


============================================================
🔄 Round 153 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 153 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0353
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0219
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

============================================================
🔄 Round 155 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 155 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0277
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0268
============================================================


============================================================
🔄 Round 157 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 157 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0274
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0318
============================================================


============================================================
🔄 Round 159 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 159 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0340
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0053
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

============================================================
🔄 Round 161 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 161 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0274
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0327
============================================================


============================================================
🔄 Round 162 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 162 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0314
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0140
============================================================


============================================================
🔄 Round 163 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 163 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0260
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0306
============================================================


============================================================
🔄 Round 165 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 165 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0288
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0258
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0232

============================================================
🔄 Round 173 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 173 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0313
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0177
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

============================================================
🔄 Round 178 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 178 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0169
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0839
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

============================================================
🔄 Round 179 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 179 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0249
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0324
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2395, R²: 0.0233

📊 Round 179 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2396, R²: 0.0231

============================================================
🔄 Round 182 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 182 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0297
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0238
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2396, R²: 0.0232

📊 Round 182 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2396, R²: 0.0231

📊 Round 182 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2396, R²: 0.0231

============================================================
🔄 Round 187 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 187 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0323
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0108
============================================================


============================================================
🔄 Round 188 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 188 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0301
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0146
============================================================


============================================================
🔄 Round 189 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 189 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0193
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0206
============================================================


============================================================
🔄 Round 190 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 190 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0218
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0424
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0228

============================================================
🔄 Round 192 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 192 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0260
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0321
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0229

============================================================
🔄 Round 194 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 194 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0292
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0115
============================================================


============================================================
🔄 Round 195 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 195 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0271
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0101
============================================================


============================================================
🔄 Round 196 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 196 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0219
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0417
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0229

============================================================
🔄 Round 197 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 197 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0295
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0191
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0229

============================================================
🔄 Round 198 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 198 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0221
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0527
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0230

============================================================
🔄 Round 201 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 201 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0269
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0248
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0229

============================================================
🔄 Round 202 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 202 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0296
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0237
============================================================


============================================================
🔄 Round 203 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 203 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0248
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0375
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0228

============================================================
🔄 Round 204 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 204 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0280
   Val:   Loss=0.0967, RMSE=0.3110, R²=0.0288
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0227

📊 Round 204 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0228

============================================================
🔄 Round 207 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 207 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0275
   Val:   Loss=0.0932, RMSE=0.3052, R²=0.0313
============================================================


============================================================
🔄 Round 208 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 208 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0271
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0325
============================================================


============================================================
🔄 Round 209 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 209 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0293
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0254
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0229

============================================================
🔄 Round 210 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 210 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0306
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0120
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0229

============================================================
🔄 Round 211 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 211 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0316
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0029
============================================================


============================================================
🔄 Round 213 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 213 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0273
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0190
============================================================


============================================================
🔄 Round 214 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 214 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0265
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0378
============================================================


============================================================
🔄 Round 215 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 215 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0302
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0153
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0228

============================================================
🔄 Round 217 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 217 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0232
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0522
============================================================


============================================================
🔄 Round 219 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 219 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0311
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0180
============================================================


============================================================
🔄 Round 220 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 220 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0291
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0256
============================================================


============================================================
🔄 Round 222 - Client client_91
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 222 Summary - Client client_91
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0308
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0008
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2396, R²: 0.0230

📊 Round 222 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2396, R²: 0.0230

❌ Client client_91 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
