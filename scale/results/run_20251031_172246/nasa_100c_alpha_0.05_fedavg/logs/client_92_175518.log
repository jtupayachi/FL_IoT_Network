[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d65d30e-3db4-4347-ac29-e3f819f13a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c6940f6-1222-4d72-9143-92dacb351961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3adf14ab-a2a7-4653-b50c-8efe8d9d1157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6514bd45-bd87-4211-a71f-d0a6a31109c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 920e7b25-13a1-4043-a3a0-7e190829c6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3123c72a-88c6-4fed-a32b-3e8c8fe52024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 041151ef-f6dc-4ca9-aaa1-271a7e468056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8c5e2f-ee0c-42d5-849b-564c2dbc54ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b110ea5f-afee-4ba4-b5e2-ba6900b93b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1c0cc9-9596-4c49-a038-4ef891d73265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b67a22d-56a1-4728-b513-996ec4a93cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4ddbac-af33-444b-803c-2e697bf37b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6034153a-f807-4554-af33-327e5241dd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942665eb-d088-4e93-bb5c-2c3bf987431c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59cbdd59-d671-4ddd-b383-2f18726c0e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8f4b51-9c6b-4fa0-b686-7188b248561a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada0b045-9898-4a56-afcf-aea0223eae93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326c78db-ff7d-41ad-88e9-b9ba0f41b3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d55c03-90bb-40f9-b9bb-44c7907edc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e8d7b1-48ab-48fb-b7c4-88308e6cd28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6711eee3-1a8e-46e5-98f6-e7446e41516c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2121a44a-00ac-4e8b-8e5e-38a31a3e87b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 181488f0-8b59-4d39-a8b8-e0f8631d6237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd376bcd-b290-4997-8884-67a59f41b3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5fc56aa-6215-41c2-9c10-fb9b0c4443b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c7591c-9adc-4bb9-83f6-6051885a7061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 665ece6d-e25e-41e4-84db-6cd86546ce1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b52514-b6d7-4834-94ac-129d88e5e378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a1cb91a-ef8c-4467-85d5-a41ba1b21c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf34e3b-65dd-4cdd-b3e9-536b86c7c75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ed68f6-2a51-4d63-8159-6f3450b2dc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 492c5a0e-eb8d-4490-ab00-b70e4d79bb81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f961d47c-30e7-4255-92c4-d333f45ceeab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9874fe78-5f56-460b-8d67-21f2af423d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5bec153-fec5-4e38-8f8d-7ebf911ba081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe22d0e3-8e50-4f73-8287-f6cd623c2455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac6e698-108c-41d1-89c8-8b4225afdb54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7f34788-9b62-4a21-80e8-eed44da199df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f112ef0-6acd-458a-85aa-2f6d73276dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e41ec15f-66d9-4f29-a72a-bc3dcbc38774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e11067-766f-4713-9b7c-81e9c7a82851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 458448aa-7285-4701-9f06-41b6f04c3ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97e4a94a-d4c5-4aac-a4f9-7871a49b65f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d16b9613-ea0f-4370-b33c-114cd96c9324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73831e6-a0a3-4078-992d-2dceb0743279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3311da4a-15b0-4a38-b615-c0846d87957a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66e5b466-c63b-48a7-91bb-6f82b54b239e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05b0c3f-a330-4e45-aad0-a1859cd16524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d628b4d3-60d8-4a9d-810d-56cb76692061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22983ab2-2f68-43fe-b3c0-5ec855d9aca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebec9480-87fe-4f7e-940c-6f9e8b5d7828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971b52c5-3971-4076-9bf2-2c60f4a671ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ed3fbb5-9e57-4e06-8057-f777b4eee311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25db70c8-9ef3-4491-9fbd-519adfb281d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a839b1f-9162-47b6-9f77-1864b2a9c934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5818e34a-526f-47a5-a1a9-7c22487d5c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08034ebb-2488-45a9-b139-9948db2999a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3748a997-8621-4588-989d-0d1fbc11a52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd8c080-2f4a-4919-aea9-335aca245791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1894c6f-0ece-4e35-9099-68e2a7acfaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94bb9544-d6d1-4d4c-b68c-7c8b081062ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5976230-73ec-45c6-b73b-5d8ef564548e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e6272f2-2e15-494f-9990-faa3a1cbea2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206e409d-b901-493f-936a-0f621c4ca4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a0bf10f-a12f-4149-97d3-2f6ec0172b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf9c7e1-72e0-4f2e-a291-42439ca5e167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84393a6-5b66-4eef-80e8-c5e7c8d6686e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc53194b-dec4-4154-8b31-66acec1aa0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb4b6e5e-7017-44c5-895c-da19a2a3d542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c487458c-60dc-4c6d-adcb-633e9889e41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac3e4d19-7849-4603-82b9-0a4dbe70b7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59bea9c7-c8cb-463c-9ab0-dc202c6552ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c52d5c-b1d4-4972-a94d-2332b3e1dcea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e75401-38fa-487e-899e-dd1d311fb418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929c536f-042f-4fc4-ba06-a9081f5c2e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dc76c25-3293-4855-a75d-d3d852012f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ce0669-1ae2-423c-9a62-21ad12c67c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78605d8c-6de2-46c6-b046-81d7a3b105cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8efdbfdb-899e-4dce-8f9e-8157b2f9ec1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca28e95-d778-4006-ac3f-5035d620c1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46e3d2d6-bda8-45e4-ae77-2e2a35df562e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1e0ebb-52f0-4400-a3cb-f40746bd6818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0057f72a-a7a6-41f3-b4f6-0c34ca28de75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602e2eab-646d-43a8-93c0-4a5b57337c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff172cf2-d198-4d6b-93e7-4d4106ada0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb74e43-3db2-4fce-8656-a8e72877c18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f3d714-735b-4397-a73f-d97041826430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79cfe99-0773-468e-a089-f4a0a4bab35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9107980c-0757-4668-8e0d-d7e6307848fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a16ad960-4462-4b49-806e-7955c3d33f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf9f6490-0877-43e5-8268-8d063c010695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 868cc590-882d-4c34-b789-3a9fe1aad9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 155f4f00-01bd-4267-8d39-a1960f4240a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a9c843-4a5c-47aa-9c75-4bf8e5d6d77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098ef0ca-a0f9-4754-a801-5d043134993f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2647ba7b-549b-45f4-9323-fb4cb9206c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c7b319-4dec-4014-b6b4-899c4823c2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eabb696-e71d-4b45-b13c-6a46ed338e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27b3e9a4-9d0e-468f-a206-db5b437c8cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbc91bcf-af12-41b3-ae3f-b19a35549b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a812df-e292-4d64-ba1c-5d98a8a1ae57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a93c0168-9d49-470a-b3c2-617cb5a53258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a236e8da-a383-4973-b9ae-3142cef6d424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2424cf0f-9e48-429c-b435-0e994d970604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d613ccbe-4333-49e6-a56f-f6a50764565f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ccdb01f-0fc1-4861-a8e1-16afca6422bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db6280c-0d5e-49eb-b62c-d0c773e66348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de8e910-54ad-462c-906f-f61e45686315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b357e334-2a73-4b65-914c-35a9de8db1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1649e4f5-acb8-4c15-8309-d7d76abfa373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56f97ebf-6d73-4326-96a7-166edd9196c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a000c957-ecd4-44c0-a720-7d8ff89cf932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e36588d-73ee-4db7-adc5-45b71c670d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1266cb6-79a2-4353-80e1-56169e8f81f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceaea70a-1ed9-4eff-a6af-f392aa6abb18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1262f04-ad23-462c-a2d3-7cc1211b5a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95fe5953-0243-4c29-b509-25de7cb05a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03585e8-c437-4863-926e-542a984db470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ba1686-7604-4805-a25b-94645c04abf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f7e4b1-f3b3-44fc-8180-c47c93225b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43b4f158-29cf-4778-96de-225f3881ebaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 985a586c-c6ff-455e-8796-0f343dad8a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef40a39-3e5a-4bc5-b0b5-117622143199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a5dc91-4f2e-40e6-b192-8227445ecd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be7913b-90ee-4248-a852-a4a9372acd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112cf564-0cc2-4007-a25d-73a03e0f92fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0fbbd9-ae9e-4f37-b4cd-f0fc34e5227a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7985879c-397e-4e90-b78b-bd4bb75ff5aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c64852bc-2d52-430d-bddb-ab651fc8b4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4886374-780d-4012-aba4-1e234ceed40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c7b9e74-82f6-4c5d-8c62-9eb4dde7238f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed55ecaa-513e-4ac7-a684-e3ccb4e5b92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472cc8a4-08da-4430-9eb3-bfcc883b6557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b9b63c-b7ad-44db-b178-63abfe75ecf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b51c3b-f4b8-400c-b8fd-d167b126cfba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4fdfa23-7e70-42b5-87d4-bd90935f4c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c964fd89-84ef-42a6-bb36-e177d85f83e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8941b829-2e60-4948-bd97-200113d4b39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417843ca-a452-4f06-99dd-466ecb41c165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab20dcb-d919-494c-bf16-77eea19a444a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d195f3a-b714-495f-abdc-dd6e8ff325d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e25b666-7ba6-427c-8f68-01c4afdccb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97c18895-130d-4f89-aa08-f4664a84fab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27751f67-bb0a-498f-bb7f-385ac7ba2b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c54eccf5-81af-4fe5-b079-996cb5b5e7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4f741b-2c2d-44b7-86c0-091a306bea7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c763fd7-f245-4ba0-91fb-806096930ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a36227f4-7e85-45ba-ba4e-dc372ab0fce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71acfbc8-824f-4ad5-86b5-5ab8b7e8fc2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd822552-27ef-46f4-a9e1-ff25c1786919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d99b22d6-1114-45b6-a0ac-fe2e4a56bb65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c81f4f8-8ff1-472a-baef-4b50586db24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da179402-cf9b-48a9-8e68-0dcd2f9e1ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9623834a-60fb-47d4-afdd-bbaeb8591e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f36ef3f4-525d-4ce8-b685-e11d79cfeaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a41ff97d-fa49-4f2a-8af4-6f979e741dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536066ba-3aee-40dd-9aea-619b3ab91b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d297a2d3-8db8-4776-aa50-07741911b0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 793a3b07-bf4e-4a2f-9ef4-27b383a4b7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd381d92-0bb6-4041-b049-3f5458994b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bdde6ff-ee83-405e-90ed-38cb787dee87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc91a990-8736-4aae-86ad-b0d6c40c6699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c33be921-eac2-4367-97a2-6c3e416adc37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a72ae44e-0eb8-4280-804e-05c3fa74697f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e00dead8-f95a-4ed7-867d-54ff276b2722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a74267-8e62-432e-8b55-c22bf5756932
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_92
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_92/test_labels.txt

📊 Raw data loaded:
   Train: X=(1170, 24), y=(1170,)
   Test:  X=(293, 24), y=(293,)

⚠️  Limiting training data: 1170 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  284 samples, 5 features
✅ Client client_92 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2440, R²: 0.0022

============================================================
🔄 Round 8 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.1045 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0811, val=0.1020 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0811, val=0.0953 (↓), lr=0.001000
   • Epoch   4/100: train=0.0789, val=0.0949, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0777, val=0.0960, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0747, val=0.0949, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 8 Summary - Client client_92
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0519
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0532
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2441, R²: -0.0009

📊 Round 8 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2436, R²: 0.0028

📊 Round 8 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2434, R²: 0.0042

📊 Round 8 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2432, R²: 0.0057

📊 Round 8 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2432, R²: 0.0058

============================================================
🔄 Round 20 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0823 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0805, val=0.0815 (↓), lr=0.000250
   • Epoch   3/100: train=0.0797, val=0.0812, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0793, val=0.0810 (↓), lr=0.000250
   • Epoch   5/100: train=0.0790, val=0.0808, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0778, val=0.0802, patience=3/15, lr=0.000250
   • Epoch  21/100: train=0.0763, val=0.0793, patience=1/15, lr=0.000250
   • Epoch  31/100: train=0.0744, val=0.0786, patience=5/15, lr=0.000250
   • Epoch  41/100: train=0.0721, val=0.0781, patience=3/15, lr=0.000250
   • Epoch  51/100: train=0.0694, val=0.0772, patience=6/15, lr=0.000250
   📉 Epoch 59: LR reduced 0.000250 → 0.000125
   • Epoch  61/100: train=0.0660, val=0.0770, patience=1/15, lr=0.000125
   • Epoch  71/100: train=0.0641, val=0.0766, patience=11/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 20 Summary - Client client_92
   Epochs: 75/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0660, RMSE=0.2570, R²=0.1989
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.1049
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2428, R²: 0.0085

============================================================
🔄 Round 21 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0809 (↓), lr=0.000125
   • Epoch   2/100: train=0.0822, val=0.0806, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0818, val=0.0807, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0813, val=0.0807, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0812, val=0.0807, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000031
   📉 Epoch 19: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0801, val=0.0802, patience=6/15, lr=0.000016
   📉 Epoch 27: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 21 Summary - Client client_92
   Epochs: 30/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0429
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0248
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2426, R²: 0.0094

============================================================
🔄 Round 22 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0747 (↓), lr=0.000008
   • Epoch   2/100: train=0.0833, val=0.0747, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0832, val=0.0747, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0832, val=0.0747, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0831, val=0.0746, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0827, val=0.0746, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 22 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0122
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0287
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2426, R²: 0.0095

============================================================
🔄 Round 25 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0894 (↓), lr=0.000008
   • Epoch   2/100: train=0.0799, val=0.0894, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0798, val=0.0893, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0797, val=0.0893, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0797, val=0.0893, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0795, val=0.0892, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 25 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0190
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0065
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2426, R²: 0.0097

📊 Round 25 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2426, R²: 0.0096

============================================================
🔄 Round 30 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0796 (↓), lr=0.000002
   • Epoch   2/100: train=0.0825, val=0.0796, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0825, val=0.0796, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0824, val=0.0796, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0824, val=0.0795, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0823, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 30 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0148
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0090
============================================================


============================================================
🔄 Round 31 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 31 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0094
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0354
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2426, R²: 0.0097

============================================================
🔄 Round 33 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 33 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0146
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0010
============================================================


============================================================
🔄 Round 36 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 36 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0099
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0353
============================================================


============================================================
🔄 Round 37 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 37 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0176
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0062
============================================================


============================================================
🔄 Round 38 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 38 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0150
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0124
============================================================


============================================================
🔄 Round 41 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 41 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0158
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0117
============================================================


============================================================
🔄 Round 45 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 45 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0105
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0354
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2426, R²: 0.0099

📊 Round 45 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2425, R²: 0.0100

📊 Round 45 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2425, R²: 0.0100

============================================================
🔄 Round 50 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 50 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0134
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0245
============================================================


============================================================
🔄 Round 52 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 52 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0133
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0225
============================================================


============================================================
🔄 Round 53 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 53 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0196
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0054
============================================================


============================================================
🔄 Round 54 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 54 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0157
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0090
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2425, R²: 0.0100

============================================================
🔄 Round 56 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 56 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0088
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0384
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0101

============================================================
🔄 Round 58 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 58 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0180
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0023
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0101

============================================================
🔄 Round 60 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 60 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0241
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0219
============================================================


============================================================
🔄 Round 63 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 63 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0104
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0333
============================================================


============================================================
🔄 Round 65 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 65 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0113
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0351
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0103

============================================================
🔄 Round 69 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 69 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0132
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0204
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0103

============================================================
🔄 Round 72 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 72 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0128
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0268
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0104

============================================================
🔄 Round 73 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 73 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0187
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0376
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0104

📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0105

📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0105

============================================================
🔄 Round 78 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 78 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0159
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0165
============================================================


============================================================
🔄 Round 80 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 80 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0208
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0079
============================================================


============================================================
🔄 Round 81 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 81 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0126
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0255
============================================================


============================================================
🔄 Round 82 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 82 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0183
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0060
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0105

📊 Round 82 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0106

📊 Round 82 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0106

📊 Round 82 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0106

📊 Round 82 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0106

============================================================
🔄 Round 88 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 88 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0137
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0247
============================================================


============================================================
🔄 Round 90 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 90 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0184
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0042
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0106

============================================================
🔄 Round 91 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 91 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0089
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0346
============================================================


============================================================
🔄 Round 92 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 92 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0149
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0125
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2425, R²: 0.0107

📊 Round 92 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2424, R²: 0.0107

📊 Round 92 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2424, R²: 0.0107

============================================================
🔄 Round 98 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 98 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0234
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0257
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2424, R²: 0.0107

============================================================
🔄 Round 99 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 99 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0149
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0226
============================================================


============================================================
🔄 Round 101 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 101 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0140
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0221
============================================================


============================================================
🔄 Round 102 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 102 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0134
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0245
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0108

============================================================
🔄 Round 105 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 105 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0246
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0153
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0108

📊 Round 105 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0108

📊 Round 105 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0109

📊 Round 105 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0109

📊 Round 105 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0109

============================================================
🔄 Round 114 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 114 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0167
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0152
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0110

📊 Round 114 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0110

📊 Round 114 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0110

============================================================
🔄 Round 121 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 121 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0217
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0069
============================================================


============================================================
🔄 Round 122 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 122 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0121
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0148
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0110

📊 Round 122 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0110

============================================================
🔄 Round 126 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 126 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0156
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0128
============================================================


============================================================
🔄 Round 127 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 127 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0217
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0053
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0110

📊 Round 127 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0111

📊 Round 127 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0111

📊 Round 127 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0111

============================================================
🔄 Round 134 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 134 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0158
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0206
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0112

============================================================
🔄 Round 138 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 138 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0051
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0353
============================================================


============================================================
🔄 Round 139 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 139 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0140
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0257
============================================================


============================================================
🔄 Round 140 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 140 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0151
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0204
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0112

📊 Round 140 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0112

============================================================
🔄 Round 144 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 144 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0131
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0198
============================================================


============================================================
🔄 Round 145 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 145 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0148
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0156
============================================================


============================================================
🔄 Round 147 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 147 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0160
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0190
============================================================


============================================================
🔄 Round 148 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 148 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0175
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0096
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0113

📊 Round 148 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0113

📊 Round 148 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0113

📊 Round 148 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0113

============================================================
🔄 Round 154 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 154 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0176
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0122
============================================================


============================================================
🔄 Round 155 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 155 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0180
   Val:   Loss=0.0939, RMSE=0.3065, R²=0.0131
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0113

📊 Round 155 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0114

============================================================
🔄 Round 159 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 159 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0168
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0166
============================================================


============================================================
🔄 Round 161 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 161 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0124
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0345
============================================================


============================================================
🔄 Round 162 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 162 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0197
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0044
============================================================


============================================================
🔄 Round 163 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 163 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0246
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0242
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0114

============================================================
🔄 Round 167 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 167 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0178
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0143
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0115

============================================================
🔄 Round 168 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 168 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0160
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0051
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0115

============================================================
🔄 Round 169 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 169 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0184
   Val:   Loss=0.0986, RMSE=0.3140, R²=0.0045
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0115

============================================================
🔄 Round 170 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 170 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0176
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0108
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0115

📊 Round 170 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0115

============================================================
🔄 Round 172 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 172 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0200
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0057
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0116

============================================================
🔄 Round 179 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 179 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0268
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0314
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0116

============================================================
🔄 Round 181 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 181 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0163
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0154
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0116

📊 Round 181 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0116

============================================================
🔄 Round 185 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 185 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0181
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0012
============================================================


============================================================
🔄 Round 186 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 186 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0203
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0019
============================================================


============================================================
🔄 Round 187 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 187 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0215
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0060
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0117

============================================================
🔄 Round 188 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 188 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0134
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0320
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0117

============================================================
🔄 Round 191 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 191 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0164
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0173
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0117

============================================================
🔄 Round 193 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 193 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0135
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0164
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0117

📊 Round 193 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0117

============================================================
🔄 Round 195 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 195 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0133
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0329
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0117

============================================================
🔄 Round 197 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 197 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0235
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0066
============================================================


============================================================
🔄 Round 200 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 200 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0139
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0198
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0118

============================================================
🔄 Round 203 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 203 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0167
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0063
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0118

============================================================
🔄 Round 205 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 205 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0214
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0025
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0118

============================================================
🔄 Round 206 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 206 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0127
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0328
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0118

============================================================
🔄 Round 207 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 207 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0135
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0348
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0118

📊 Round 207 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0119

📊 Round 207 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2423, R²: 0.0119

============================================================
🔄 Round 214 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 214 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0129
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0224
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2423, R²: 0.0119

============================================================
🔄 Round 221 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 221 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0191
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0063
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2423, R²: 0.0120

📊 Round 221 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2423, R²: 0.0120

============================================================
🔄 Round 223 - Client client_92
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 223 Summary - Client client_92
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0197
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0062
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2423, R²: 0.0120

📊 Round 223 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2423, R²: 0.0120

❌ Client client_92 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
