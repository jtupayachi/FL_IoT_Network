[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4e0fc2-376f-4847-b178-db402ac14b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd5dc89a-3fc9-41e6-b7a2-6a9577363ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4966f9c0-3ab4-4e2c-bcf7-b4e452c885b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d9e013-85f6-4cfe-91f0-256891a4331f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb7b0d34-6905-40af-8d5c-4a0db0a96f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af5cf34e-cda3-4120-ba14-45ab1b25501e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc7528f9-3818-44fb-9e74-152b4907b5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51eeef44-2928-4002-bb00-5e36ba7a8d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f851bf-9c00-4807-bbf5-914be85c0399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c964c154-2462-484a-b2fc-16bdd7c719f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0977b2-100f-4139-98de-d7decda456e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057197c7-075b-41ad-bd3a-a4dd2e67e962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44772df5-e776-4037-ac50-935c37df23ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef73ad7-1df3-4a4e-ba56-efa0fba0fe84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56527232-ed6c-4b78-b864-4a8835a9cf8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd997270-816a-4206-8e97-326a857d92b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5bf3beb-80dc-42f9-88b9-2a1410807e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd94ad5c-0a4f-47d8-b56c-56c767500869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca7619dc-42d1-4de3-9018-b1156881bbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d81b704-717b-4cb1-a0c9-092254005b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ca3c76c-3237-460c-9d45-e0dd854cc0e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b61d670-a5a1-42d7-aecc-e7bb04d7def6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbeb2d69-75ef-46e8-8135-6c943eab8fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35fd5d1c-7ccc-4314-ba75-90595fc4c413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1d1953-b8ce-4d74-8b8e-50dbbae0c54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1b67842-a782-49f8-8738-de7d70593703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f85002f3-5533-473e-8004-0c740f288505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 278aac29-bb94-4974-aa8f-dd44d87d501c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e49468-38b5-442a-b2a3-73afa84b76e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 755b24f1-94ee-437d-8dac-e37acd9bac1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f602b296-7e41-4099-a553-d36656e43a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc0dea14-d275-4ed2-941a-e047495e5dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b610e3-87b7-4a27-adc7-22a8111f5e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea4cc7ec-11ed-4a45-a3d2-c6af4e1c7cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96421e1-158b-4800-a884-2cf298a956f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9dd501f-e611-4bbb-9afa-cbf7f0382087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2763ba75-559d-41a0-a6d2-e403135d2b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca83ee1-1723-4179-b9c8-bb41f9630539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eaf7b90-65f5-4c1d-b8b6-42685390f362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e83bc400-060c-4c74-a98e-3a71af0a7e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1810cc22-505e-4c22-ac2d-43321513a7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8193e70-84ec-468d-ad54-1b89e7542e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80fda3a-9ba7-43b9-a534-4363011e2c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ed76f86-c190-408c-a24e-6f5bd728d142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a7944d-14ab-44b3-afce-5f5fd5bd351f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fecf31e2-e68f-4d0d-b02d-ec993d0ee46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f4f95f4-a24e-4560-9fb1-49c216b8fe61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a5709ab-d842-43ea-b799-fcd2c729ee54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ccc7587-103f-4d63-b56c-79d382d0d0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd6040b-d887-48d4-8c83-4db74c6fe004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a3a96bb-229e-4481-8e47-5c1acd68bc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd66f8d-8b32-490e-8c3e-e45325319da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0025c531-f5f9-43d1-9397-ce1479ae0880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 859ed010-5216-4dc2-a50e-62ca274e64d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab1b5160-c5b0-4ff7-a3c1-148a92a83158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8690706-4aea-472f-b0cb-b2db35589b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89ee5dce-37dd-4513-aa11-00a04ee0146a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c64073-bd86-4d63-8b81-b2ade67872ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77e44953-f39f-41f5-89c5-ba6ec9528990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a08c1a9-c94a-4717-8500-07619f3b3b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f722fbe2-d79d-4fb6-ae35-bb789cc18edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec20fdb-4e6a-4fb4-b237-b5654136582c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b5a6be-a6f7-4cc1-941e-b6d5bc2e0bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8618f0-0ceb-49a0-bb84-619cbf45d2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a16606-5a54-4bf9-97a1-baa77feb54be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a566735-9279-4c66-9b80-9abb05a66295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98e0c9bd-a5a2-49f3-af5b-ebc3e2b7a9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8b937d-7750-42d3-a04c-aff18fc47e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbdea170-8f5e-4af8-85f8-13947a45e728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9379bc27-0556-44e9-a355-0b8696495601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d097ed5-d36c-4856-9d69-4981c0a655ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ba5219-adf2-4089-b226-7456fd98f241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b3d48d-c239-462f-9f11-bd2da9844e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94140d75-72d0-4a85-8638-4f2c1212733e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae238de0-4bd0-429d-950c-71ef3c427bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edadf117-c08d-4fc8-b939-a5f373edfeb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d88febe4-d21b-4c0e-ad34-f0c46998704e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffae067c-0826-4be3-8aab-653694a625e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9287c074-1bf0-439b-bcb2-79b86bdbc925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d5ead05-8ed0-4847-8300-b794a02724e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f316fc4-2303-4bcc-91f9-50b0c4e251e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48593306-5022-49e1-a185-deb80d3f43e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98cafbc9-0d4e-4a0e-9651-e6974fec21d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb8153d-ee09-4ade-b03c-3bd8149d76c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f357493c-b64e-4c33-82f3-eea5e34ad9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 655389a4-78ee-41ad-b9a0-93b3272ddbab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b3b279-1dee-4cc4-832d-d10f3ff937df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41e4085-e25f-451b-bcc7-9bc123050927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 428b9bc5-3c98-4a5e-b947-d955624290cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 882d39fc-7f1a-470e-86ee-498f33d9e34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be66227-705d-439e-951c-2910bdf003ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2be1f0-4ad2-4f57-833e-285871990d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309ee7e9-e05a-47dd-ab20-95b96277a8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be5982ed-e48f-4d15-9339-11ff97680e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 115f10e7-c7d4-4dea-bd85-2b2aae64deba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 319a58ea-cc33-4b8d-b779-96d24cab47ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536688f9-199a-4cc1-b8f5-e7027a970264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4eb9be3-baf2-466f-8d4f-e832be73fd79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f511476-82c4-4863-9f76-ac75817886e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adab0559-48f1-4940-9817-ad77d71ac86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f1649b-5263-4339-af3a-488e5a1f89f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9e0f729-fd8d-4b8c-948a-89c17a11209c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fcd3c09-aff9-41df-8aab-9a16d93274cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d13510-25b1-4ded-a566-13d20360a257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf715ef5-f092-4ea3-a390-a7b54551b194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d042f3a9-d314-4c30-b4de-11aaf0acaf67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c30337e-85ae-49a8-bea9-d93fdc121b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c390dcd-e53a-4505-b98f-a9bac4f7172f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22b5bda4-1f7d-4fb7-86a1-9e92a40c7c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb183b39-5744-4872-98b9-72c5646bc956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c36f5706-a0ec-4784-802c-91329b97a356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43eb74f9-d56b-44df-b69b-3de35e05b937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdda0ca1-8378-424f-9ffb-2a8b2e57e8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db66f20e-3ea8-423b-a20d-b22b2a96712b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724903f4-5568-488c-bfa3-5bc594232015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89da8b3-59e3-4c42-83f2-efb919a35a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1d851a-1978-4819-ab1a-c969e6b79069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2fdfed-8dd2-4cd1-804e-097900283425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a94856-f465-4cbd-be08-993b1b05f697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbb1f0c0-8c50-4984-b399-e6c6706a75e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3a77ea-e549-4fc3-88a5-b1003ac235d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac3f960c-aa9d-4ebd-a7f5-1aada5bfd5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52e863f5-5126-4dd4-8bb9-43ae01aa5d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4136bc4e-5b1a-4eca-8c5d-6e5889863425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 750ed75c-176c-4a91-a694-313f28e892ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd355c84-7364-4119-9dc4-ce85a617e558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b966ea5a-7db3-4be6-a419-3ca8283258fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca780e1-8bee-4d5e-87c4-d94525a0ecfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33d2d54-688a-4aa5-b2f7-d03e531be636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 672861dd-ef00-4dd3-b760-233c0d875631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a621c415-b57b-4537-bf91-6a0eda33f807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c180d700-1ea5-430b-a7eb-3611aa427968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c660db8f-cd6f-4533-a9a5-7de3eec90f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b1e0d1-1fdd-4a9c-abad-9a501249c082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9113e3f-0dad-4157-bae5-c88a3e3331f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7fa8617-f765-493c-973b-de3e340db99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ab56976-8e09-47c4-944e-215db1f676b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd457b2-4ac8-4ea3-a68a-30692595c97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1022362f-d250-407a-bd19-a122f56b59c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9079c6-1601-4b09-a1b1-dbd5064dc14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac8da195-651a-4975-8ba5-46d28e669a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cca3494-ba23-4dd4-8a34-608ce55e95fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50dc7b03-7320-4343-8a10-ebbbfd5773fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e24d774-d402-4c65-bddb-c88545220de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d02ff11-340a-4923-a5fe-4183ca16b735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c95bc1e1-796a-4519-ba0c-d9cf7f4ffdb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e56439b-ab99-4d00-bfac-92b5f0c3c2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0af145c-3ff2-41ec-a44d-7bdc3a265869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7b548d-e987-4f86-9bde-47528b71392c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e153f0c-25df-4076-a252-7bc4a76a3cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9c445aa-d2e5-40f4-a8bf-6622b3af693e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b36649-7918-4056-b801-8e238668780a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6a9fc99-2c25-4e82-b351-f0aa2cf96a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8a2386-79fe-4f06-b992-498863b2f47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfece4ff-3e9d-4cfe-b4b3-69df0b33c604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 323aa8b8-de68-4581-b232-8be7c28539c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f0db3d6-c427-4056-9a5d-33dd144f00af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b65cbc5-9543-4a5a-be89-3072a737a025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ddaa741-4ed0-4a42-b028-2141137e4d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d7b8a7-ca4b-4a3b-841a-3393511a1045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2eaa3b7-ba9d-48a2-812d-6e799374b190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d45932b3-c7cc-488f-98ac-cc6019bc51bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a12c734-97f3-4d93-8120-b1ef4b45b23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 139ca558-b07b-4846-b3f5-4a87913bf917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ea6df8-193c-482b-bbf6-df62ab7ff29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944d3f97-0b75-4b5c-9b9c-a18fa7c1f26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d6a900-d335-40c7-ab87-7275ed85dee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 041e26eb-9060-4951-87d2-cb27ffa98b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bdb80e0-ff25-477e-8bef-f46fe0f1aa34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5293aeb-118e-448e-92d7-1605d6ba253e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ab03c7-9572-4f19-8e8d-78670d3dc9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1154fb6-3400-42ac-8791-c4903a0c3db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6437f3-cc75-43a7-a0b6-fe929ce5834e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc83d487-05a0-49ba-9ea8-7e5a930928a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41efb362-9c12-432e-855f-2e8313c9d2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6853f2bc-82c8-400c-b272-f508d1371b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b0ec21-3f44-4b1e-a33b-de97d90914af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f045a50-5d02-47e9-8ce1-fecbbe891cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0e0adf-ab90-48c7-bc3e-9e5511422155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa7cd3b7-a794-4a04-af85-3d1aafda95f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2763f32b-8c8f-45dc-8b3f-e9c7ed9516ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba85449-cbf5-411a-a9ed-5ed98ebccfcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ffbd7cd-2379-4a2f-b569-e2e0e7ea844c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7545fce5-73ee-4e4d-a142-73dfc6626dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b207788-f2ec-4242-a83c-34b2874f9a64
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_93
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_93/test_labels.txt

📊 Raw data loaded:
   Train: X=(815, 24), y=(815,)
   Test:  X=(204, 24), y=(204,)

⚠️  Limiting training data: 815 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  195 samples, 5 features
✅ Client client_93 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0941 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0892, val=0.0892 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0878, val=0.0852 (↓), lr=0.001000
   • Epoch   4/100: train=0.0861, val=0.0852, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0858, val=0.0856, patience=2/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0842, val=0.0844 (↓), lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0773, val=0.0881, patience=10/15, lr=0.000500
   📉 Epoch 26: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 8 Summary - Client client_93
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0223
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0069
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2503, R²: -0.0429

============================================================
🔄 Round 9 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0933 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0854, val=0.0923 (↓), lr=0.000250
   • Epoch   3/100: train=0.0850, val=0.0923, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0847, val=0.0921, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0845, val=0.0921, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0837, val=0.0918, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0833, val=0.0917, patience=7/15, lr=0.000063
   📉 Epoch 24: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 9 Summary - Client client_93
   Epochs: 29/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0021
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0736
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2508, R²: -0.0474

============================================================
🔄 Round 10 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0941 (↓), lr=0.000031
   • Epoch   2/100: train=0.0864, val=0.0939, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0861, val=0.0937, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0859, val=0.0936 (↓), lr=0.000016
   • Epoch   5/100: train=0.0858, val=0.0935, patience=1/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0855, val=0.0932, patience=7/15, lr=0.000008
   📉 Epoch 19: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 10 Summary - Client client_93
   Epochs: 19/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0232
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0629
============================================================


============================================================
🔄 Round 11 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0863 (↓), lr=0.000004
   • Epoch   2/100: train=0.0890, val=0.0863, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0889, val=0.0863, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0888, val=0.0863, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0888, val=0.0863, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0885, val=0.0863, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 11 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0450
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0315
============================================================


============================================================
🔄 Round 12 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 12 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0408
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0352
============================================================


============================================================
🔄 Round 13 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 13 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0422
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0280
============================================================


============================================================
🔄 Round 16 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 16 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0475
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0556
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2512, R²: -0.0519

============================================================
🔄 Round 20 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 20 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0529
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0449
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2518, R²: -0.0558

📊 Round 20 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2518, R²: -0.0559

📊 Round 20 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0560

============================================================
🔄 Round 26 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 26 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0535
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0693
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0560

📊 Round 26 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0560

📊 Round 26 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0560

============================================================
🔄 Round 31 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 31 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0537
   Val:   Loss=0.0964, RMSE=0.3104, R²=-0.0875
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0561

============================================================
🔄 Round 34 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 34 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=-0.0577
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0517
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0561

============================================================
🔄 Round 35 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 35 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0569
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0562
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0561

============================================================
🔄 Round 37 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 37 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0625
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0473
============================================================


============================================================
🔄 Round 38 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 38 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0615
   Val:   Loss=0.0994, RMSE=0.3154, R²=-0.0578
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0561

============================================================
🔄 Round 41 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 41 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0552
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0582
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0561

============================================================
🔄 Round 42 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 42 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0500
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0806
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0562

📊 Round 42 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0562

============================================================
🔄 Round 48 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 48 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0590
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0447
============================================================


============================================================
🔄 Round 49 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 49 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0562
   Val:   Loss=0.0984, RMSE=0.3137, R²=-0.0545
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0562

📊 Round 49 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0562

📊 Round 49 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0562

============================================================
🔄 Round 52 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 52 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0562
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0854
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0562

📊 Round 52 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0562

📊 Round 52 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0563

============================================================
🔄 Round 57 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 57 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0574
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0616
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0563

============================================================
🔄 Round 59 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 59 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0506
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0781
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0563

============================================================
🔄 Round 62 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 62 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=-0.0574
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0519
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0563

============================================================
🔄 Round 63 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 63 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0546
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0642
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0563

============================================================
🔄 Round 64 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 64 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0494
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0880
============================================================


============================================================
🔄 Round 66 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 66 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0541
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0725
============================================================


============================================================
🔄 Round 67 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 67 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0616
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0664
============================================================


============================================================
🔄 Round 68 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.1053 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.1053, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.1052, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.1052, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.1052, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.1052, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1053)

============================================================
📊 Round 68 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0526
   Val:   Loss=0.1053, RMSE=0.3244, R²=-0.0682
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2518, R²: -0.0564

============================================================
🔄 Round 69 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 69 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0427
   Val:   Loss=0.0970, RMSE=0.3114, R²=-0.1080
============================================================


============================================================
🔄 Round 72 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 72 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0568
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0674
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2518, R²: -0.0564

📊 Round 72 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2518, R²: -0.0565

============================================================
🔄 Round 74 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 74 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=-0.0601
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0396
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2518, R²: -0.0565

============================================================
🔄 Round 77 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 77 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=-0.0554
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0666
============================================================


============================================================
🔄 Round 78 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 78 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0554
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0689
============================================================


============================================================
🔄 Round 79 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 79 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0564
   Val:   Loss=0.0958, RMSE=0.3096, R²=-0.0676
============================================================


============================================================
🔄 Round 80 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 80 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0532
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.1087
============================================================


============================================================
🔄 Round 81 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 81 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0566
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.0545
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2519, R²: -0.0565

============================================================
🔄 Round 82 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 82 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0580
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0489
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2518, R²: -0.0565

============================================================
🔄 Round 83 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0998 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0998, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0997, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0998)

============================================================
📊 Round 83 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0513
   Val:   Loss=0.0998, RMSE=0.3159, R²=-0.0733
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2518, R²: -0.0565

============================================================
🔄 Round 84 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 84 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0691
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0077
============================================================


============================================================
🔄 Round 85 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 85 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0631
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0349
============================================================


============================================================
🔄 Round 86 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 86 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0564
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0570
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2518, R²: -0.0566

📊 Round 86 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2518, R²: -0.0566

============================================================
🔄 Round 90 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.1012 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.1012, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.1012, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.1012, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.1012, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.1012, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1012)

============================================================
📊 Round 90 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0529
   Val:   Loss=0.1012, RMSE=0.3181, R²=-0.0730
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2519, R²: -0.0566

============================================================
🔄 Round 94 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 94 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0507
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0865
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2518, R²: -0.0566

============================================================
🔄 Round 96 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 96 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0671
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0425
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2519, R²: -0.0567

============================================================
🔄 Round 100 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 100 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0554
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0676
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0567

============================================================
🔄 Round 102 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 102 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0556
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0618
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0567

📊 Round 102 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0568

📊 Round 102 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0568

============================================================
🔄 Round 110 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 110 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=-0.0505
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0933
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0568

============================================================
🔄 Round 111 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 111 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0414
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.1782
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0568

============================================================
🔄 Round 112 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 112 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0577
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0540
============================================================


============================================================
🔄 Round 113 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 113 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0564
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0566
============================================================


============================================================
🔄 Round 116 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 116 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0564
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0588
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0569

============================================================
🔄 Round 118 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 118 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0553
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0634
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0569

============================================================
🔄 Round 119 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 119 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0548
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0681
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0569

============================================================
🔄 Round 122 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 122 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0591
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0661
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0570

============================================================
🔄 Round 123 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 123 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0463
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.1025
============================================================


============================================================
🔄 Round 124 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 124 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0559
   Val:   Loss=0.0970, RMSE=0.3115, R²=-0.0585
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0569

============================================================
🔄 Round 127 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 127 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=-0.0565
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0569
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0570

📊 Round 127 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0570

============================================================
🔄 Round 129 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 129 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0554
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0609
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0570

============================================================
🔄 Round 131 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 131 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0609
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0505
============================================================


============================================================
🔄 Round 133 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 133 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=-0.0612
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0485
============================================================


============================================================
🔄 Round 136 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 136 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0623
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0343
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0571

============================================================
🔄 Round 139 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 139 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0501
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0814
============================================================


============================================================
🔄 Round 140 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 140 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0499
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0821
============================================================


============================================================
🔄 Round 141 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 141 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0567
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0568
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0571

============================================================
🔄 Round 142 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 142 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0612
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0390
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0571

============================================================
🔄 Round 144 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 144 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0532
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0791
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0571

============================================================
🔄 Round 146 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 146 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0530
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0825
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0571

📊 Round 146 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0571

📊 Round 146 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0572

============================================================
🔄 Round 152 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 152 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0487
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0990
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0572

📊 Round 152 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0572

📊 Round 152 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0572

============================================================
🔄 Round 157 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 157 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=-0.0550
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0670
============================================================


============================================================
🔄 Round 158 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 158 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0540
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0722
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0573

============================================================
🔄 Round 159 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 159 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0671
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0192
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0573

📊 Round 159 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0573

============================================================
🔄 Round 161 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 161 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0561
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0596
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0572

============================================================
🔄 Round 162 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 162 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0922, RMSE=0.3036, R²=-0.0589
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0489
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0573

============================================================
🔄 Round 167 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 167 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0622
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0441
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0573

============================================================
🔄 Round 170 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 170 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=-0.0643
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0331
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0573

============================================================
🔄 Round 173 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.1046 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.1046, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.1046, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.1046, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.1046, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.1045, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1046)

============================================================
📊 Round 173 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0602
   Val:   Loss=0.1046, RMSE=0.3234, R²=-0.0477
============================================================


============================================================
🔄 Round 175 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 175 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0580
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0525
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0574

============================================================
🔄 Round 176 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 176 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0565
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0693
============================================================


============================================================
🔄 Round 178 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 178 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0476
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.1242
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2519, R²: -0.0574

📊 Round 178 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0574

============================================================
🔄 Round 181 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0923, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0923, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 181 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=-0.0620
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0331
============================================================


============================================================
🔄 Round 182 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 182 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=-0.0601
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0489
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0575

============================================================
🔄 Round 186 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 186 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0439
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.1146
============================================================


============================================================
🔄 Round 187 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 187 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=-0.0565
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0716
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0575

============================================================
🔄 Round 191 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 191 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0606
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0545
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0575

============================================================
🔄 Round 193 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 193 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0708
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0315
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0575

============================================================
🔄 Round 195 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.1005, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.1005, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 195 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0557
   Val:   Loss=0.1006, RMSE=0.3171, R²=-0.0732
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0575

============================================================
🔄 Round 197 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 197 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3026, R²=-0.0635
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0309
============================================================


============================================================
🔄 Round 198 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 198 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0673
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0159
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0576

============================================================
🔄 Round 202 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 202 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0530
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0743
============================================================


============================================================
🔄 Round 203 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 203 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0523
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0795
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0576

📊 Round 203 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0576

============================================================
🔄 Round 207 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 207 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0546
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0678
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0576

📊 Round 207 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0576

============================================================
🔄 Round 210 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 210 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0640
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0389
============================================================


============================================================
🔄 Round 211 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 211 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0654
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0360
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0576

============================================================
🔄 Round 212 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 212 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3034, R²=-0.0611
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0505
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2519, R²: -0.0577

============================================================
🔄 Round 215 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1005)

============================================================
📊 Round 215 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0499
   Val:   Loss=0.1005, RMSE=0.3170, R²=-0.0873
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2519, R²: -0.0577

📊 Round 215 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2519, R²: -0.0577

============================================================
🔄 Round 221 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 221 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0509
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0846
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2519, R²: -0.0577

============================================================
🔄 Round 222 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 222 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0595
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0631
============================================================


============================================================
🔄 Round 223 - Client client_93
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 223 Summary - Client client_93
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0580
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0558
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2519, R²: -0.0577

❌ Client client_93 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
