[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c990f8-9f84-40ce-8e31-e9ad80cb87f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929ea8ac-361a-40bd-9eb1-cada417e2352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 522b18d7-6b66-469d-b9e9-2a96ad8f5f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f91b87b-e5e2-4cba-b00a-98461f50e45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80f783c-4f1d-4982-a289-2f19939d2f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85302097-cf44-4963-a0c5-8d48d1bc4bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd30d3fd-2d91-40c9-bb6d-f32cfa7e9069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b611cd45-a919-4191-a26e-e19c1dfcbb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea95d843-638a-40ec-8e15-23213faf379d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 979231bf-d8d6-4b1a-99dc-a65ad77e6309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22fd8ffc-d9d7-4cb2-97ae-04c3c86e3b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f35b82-5997-4139-baa2-cb0644da03e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64805c32-018e-40d1-a7a5-826b27b5a451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a967b66c-fc0f-4940-bef7-8f2220dd5304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b766728a-d4e7-455f-baf8-298092884563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee9d832-2b52-4523-a1fe-3395204b43e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a02b7501-7c89-4ecf-86f5-5775d09b3600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd8fc356-4583-4269-94e4-0607131f9228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59c0fc32-0eaf-43dd-9a22-d1a1d0fbddaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb561afc-6901-4945-bce2-fbb1d3746cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d10d8f-111c-4236-bcb8-53729e99dd39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495f6f54-3f8d-4ea3-b5f4-80e571a5e9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8d9db2-9f79-4dbc-80d2-783a6bf8cc2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a21decb-0968-4651-8b28-daacbf3493a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e826b8-0171-45c6-bc67-3e8e9674da19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71f5a0b-05f8-4a6b-a79c-4722ac2a88e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e60fe03-a3f3-4c7e-86dd-1bf8fab2035f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 713bec0a-a9f6-410a-82cf-2981ff87d0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 421f8101-effb-4b26-a877-72265f2db9f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bf78b71-a4b0-452a-b0b7-094ef798f2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0f9e84-0197-48a1-82b5-c2be1f7fffb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3944ccc6-213b-4472-b09c-0a75a0755e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5450020-d372-483e-a16f-c0f3dfc854ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca221d26-980e-4c81-a713-9102f8353305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab19a32-34bd-42ae-9fa2-34eda14af2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6da96d39-1203-4cd6-8795-c4e48dcd293d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6a93c7-c5c9-47d3-af8b-d6a0269cfde9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd822b5-05f1-4212-959a-736f21d88170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5051d36-c5fd-4bf3-a29b-a5487ecc1321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 775b3b58-baf8-47b1-8126-58cc9c925f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c51bc617-9a19-4620-9807-9c7575f5287f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2bb5d20-59bd-47d8-99f5-5c1408b4ece0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f7192be-a231-4919-9617-bddf10cf7651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f552e93e-ce5c-4a15-93eb-bcab5a735c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bdcddd3-153a-4b69-97e9-63fdca269bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca1607c4-4aea-4eec-b3d8-6f62f8205ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 935b332a-ccce-43f0-8f69-78e73e9f5757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc352708-27c3-487e-b56e-01c1ed9a97fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5acd996-e1aa-4ea6-8211-b4b411613e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ac7740-5389-4f6c-bd89-df183ef7f232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63a44cc-88c9-4c8b-8c29-b7dcf6236615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162d8307-91e7-4942-b14d-802785b42489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bccd2d90-a707-40d1-8a37-3e082294bf68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb72b76-c4ff-44fc-89aa-253d831f1d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a99262-2408-4b0d-8cc8-bb1eb6112b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f895794-f141-421e-a279-e36782c09370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f31a5e-354a-460b-839a-6724d9556e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a348baa-4071-40b5-bfba-f1571271acb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0afaf05d-50c6-4ee7-8b54-69f11021e121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a28e1d5-373c-4b28-ad84-163b7ad304eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0239103-7977-427b-984c-b25d2ac54a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a975dfa2-97b8-4179-bf8e-0dbbb0448608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94adf0d6-0a25-4a27-8181-a6cd01ebff44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e41af789-2ce5-4e3e-abec-8dc1b2c6843f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8dd70a-31c7-4679-8401-817ff44535a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a54060da-984b-4d7f-818b-b58347c3dd25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ceb7e76-870c-4dfc-ae9d-da9310ad0516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0586a46-5e68-49d2-b095-4409684d229e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c843fc5-3a11-4777-b4e9-ab49cff9e84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5417d2e-58c0-4329-a25e-43c0d62875ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0329a78d-40d0-474d-b57a-c92ffde82cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e90bfb-7204-47e6-a5f2-4288434625fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a23e1c-4df8-423f-bc7d-d7a0e03cd917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9e0648-f5d5-4f4d-9847-37b1c8059777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd14df76-baf9-40ab-abf4-bc9fa27305d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 295f4f98-5ac2-4ff6-a5d6-ecd90f98b4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45504abe-df8a-4135-b3e9-5e41f409f294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5db72d-1edb-4f49-8cbc-5698aa7429ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e804025e-1f1f-4d07-9f86-90cb1dcfa843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87cd8dce-4dfc-4023-ad42-139f469a2e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bc7a67d-3bd1-4a39-8baa-da8e1c567382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbf87107-5669-4603-a5cb-001723eed09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95802603-8c89-4fe4-a73d-70daac8658d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b352d698-715f-4a9d-90aa-a5a497192acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8953f764-15d2-49c1-8718-a8ba40de4685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c8aaba5-be0f-4bef-8c73-41e86d49f096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 148b4db0-07cd-4c90-a0ff-62816777ab58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e4f1bb-ffed-40f7-a2bf-fe873bdb61c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7afd30a8-87e1-4c20-b3f8-deee141e6649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc82276-611e-4c9f-b342-2fde606b1673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69895b5d-6839-4283-b474-e85c01ee538d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8cad4f-ad8c-461c-8f52-76ca896059dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4636c5ee-ee40-4b00-881c-8e0412744f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be40e884-182c-4be3-83c3-99073d8485f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81523c85-0c32-481c-beda-8d9efbdce3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25351f7b-392b-4be5-85e5-fd79424155e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d12334fe-7799-4c3a-a4d7-6b773b402189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85bdca4f-9d65-4f68-ad03-6986f5aa447d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9165803-f7cd-47e2-8d02-9f0411aa13a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b53664-6ccd-4102-be40-9565ecd1ee78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea275675-9160-4395-88bc-ca2bc8e6bf77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37776d77-e9b0-4546-a17c-f3a3f2ff6699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f2d9c4-c981-485e-9128-3425b49faf84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb60603-6cb4-48ce-bb46-17bf88fccba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa9c4737-ecc7-428c-a2d4-f259b716833c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message decd13de-6f84-4263-94f8-8dc1e035292a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8740df61-0cb5-4f9a-b257-a18879aacde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45ec1f00-6c2e-4ddf-ba7d-b4975d5fea4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b293193f-b25b-41e1-83bb-9d0621decd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c16e4f-86a8-4f3c-aaec-2d34dd076fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a2a1db3-30ee-4c90-bf6e-c38f14bdb8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f20603-16e1-432d-a57e-1b2aa8995c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a603902-417c-4ca6-b6cb-bcdb9c120629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93107443-b8e6-4b28-9759-fe042ca3944b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f38fb24-af67-4e3e-9337-22b8943ecdd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b7a0fa-0975-47ac-bb7f-9800286d4574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79973b92-b218-4b91-a94d-fe0a58b8cab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce67674-6914-4922-8e7f-c023f0e43095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e98417aa-dd8f-4dab-abfa-6705218e6875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4833f774-29dd-455e-8f83-83458752b855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ce4a0e-abfc-4e51-9a73-5898c7618ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81197ce7-ae89-492a-8de9-f6d9d3fe39c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e9122dd-1281-4feb-b386-462754289b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a8ec0c4-49e2-4a9b-906d-3d6263c63e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01b94f2a-46d5-4e5a-bd15-dc9408f86ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6cad035-45af-452b-a888-3c96a536b94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d4ff24-6af5-4738-a528-070b42ad0678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 395505ba-5062-4492-9871-1cf289811b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eca4adc-6a38-4c12-b5d6-bb976c3ea6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2658dfd5-b593-4fcd-86ee-7611907ea245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58fa6a52-2c39-4e82-b6f7-018b7b219b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b0b86c-a347-4c44-a48a-e28bc6421efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c767e204-5395-4d80-be0c-17346adec7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4711c41c-fdff-4633-b75c-8aa6ecdbbb9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cdf4a72-1d79-4a70-8cbf-d53d1ea5c979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e4d966-7855-4fda-ac69-f65041cda715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36e49b64-953d-407c-a2f0-ada1e9188607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fed90967-d282-469b-ba47-1b89eb368208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7374f73-5713-4990-863c-e02bcf2df587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d466cc-6b53-4fcc-a3df-7db2713c6f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41f7cd4d-4810-43c8-a13d-dd62016c5480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f730343-3406-4520-949c-a4f7f852a43c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89f529c-ebd0-46a3-b509-d5c340fbd3b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35be0437-ef13-4a14-9d86-b750a892ee98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60857c40-23f1-4312-8554-5e2bfd560c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 263cb75b-0bf0-4c3f-8e8b-994f1e602a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0aab4f-be2c-4b7b-8d28-9dcf97b9d154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a55ab5d-94ea-4420-89e5-62d8d02d2b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360eb353-7664-44d8-9144-2ce70e3a5997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e31840-cb5f-4736-ab44-de44bd89cef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cc7ab5-163a-40c0-a564-3181e40d1141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c5a9802-e3c6-4530-ae5b-632413beb84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 196d6b47-fc27-4252-875b-e4245b5424d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d58fb6b2-af59-4618-b081-81cd9c21361f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3af1475-be0a-40cd-a63e-c7a17be912a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 150e2d5b-6060-4f53-94ff-8a8ea21b6129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1694a1ef-344c-41b0-9a8d-250f90a1f916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b74ab66-7de3-463e-a349-b64a83047a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ad70e9e-9d87-45b6-8baf-ff9ad5960222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06fd7ac6-1a7b-4ca3-a456-cf415f4bb801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac17ea69-d4cf-42d1-824d-fca6d7c0ec6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d9ab35-2a52-4991-8056-b79ffc512a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f33b745-310e-4962-a236-b62af01bfeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f8648e0-c8b0-44ef-a11c-8e9eb2b39e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07494f1b-0e97-48d1-ba05-8d34b6b91c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be28065a-55c6-4731-a702-f6008131513b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67bf947a-1e62-4a4e-bc5c-c1b4315e3852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9d0328-1fa5-4638-8fa3-f9ddcc2ff45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7491967-b605-46ee-bbc1-7f1e875568a6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_94
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_94/test_labels.txt

📊 Raw data loaded:
   Train: X=(860, 24), y=(860,)
   Test:  X=(215, 24), y=(215,)

⚠️  Limiting training data: 860 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  206 samples, 5 features
✅ Client client_94 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0875 (↓), lr=0.001000
   • Epoch   2/100: train=0.0843, val=0.0873, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0837, val=0.0863 (↓), lr=0.001000
   • Epoch   4/100: train=0.0830, val=0.0861, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0824, val=0.0861, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0790, val=0.0853, patience=4/15, lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0696, val=0.0891, patience=14/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 7 Summary - Client client_94
   Epochs: 22/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0502
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0273
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2426, R²: -0.0179

============================================================
🔄 Round 8 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0843 (↓), lr=0.000500
   • Epoch   2/100: train=0.0868, val=0.0848, patience=1/15, lr=0.000500
   ✓ Epoch   3/100: train=0.0857, val=0.0832 (↓), lr=0.000500
   • Epoch   4/100: train=0.0852, val=0.0836, patience=1/15, lr=0.000500
   • Epoch   5/100: train=0.0850, val=0.0838, patience=2/15, lr=0.000500
   📉 Epoch 9: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0830, val=0.0828, patience=1/15, lr=0.000250
   📉 Epoch 17: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0816, val=0.0829, patience=11/15, lr=0.000125
   📉 Epoch 25: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 8 Summary - Client client_94
   Epochs: 25/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0393
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0426
============================================================


============================================================
🔄 Round 9 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0855 (↓), lr=0.000063
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0832, val=0.0854, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0829, val=0.0852, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 9 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0102
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0188
============================================================


============================================================
🔄 Round 11 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0795 (↓), lr=0.000016
   • Epoch   2/100: train=0.0851, val=0.0795, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0850, val=0.0795, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0849, val=0.0795, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0849, val=0.0795, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0848, val=0.0795, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 11 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0113
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0138
============================================================


============================================================
🔄 Round 12 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000004
   • Epoch   2/100: train=0.0840, val=0.0828, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0840, val=0.0828, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0840, val=0.0828, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0839, val=0.0828, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 12 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0112
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0129
============================================================


============================================================
🔄 Round 13 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 13 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0167
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.1010
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2420, R²: -0.0167

============================================================
🔄 Round 14 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 14 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0155
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0025
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0195

📊 Round 14 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0194

📊 Round 14 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0195

============================================================
🔄 Round 20 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 20 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0089
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0152
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0196

📊 Round 20 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

============================================================
🔄 Round 25 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.1015 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.1015, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.1015, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.1015, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.1015, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.1015, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1015)

============================================================
📊 Round 25 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0110
   Val:   Loss=0.1015, RMSE=0.3186, R²=0.0012
============================================================


============================================================
🔄 Round 29 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 29 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0112
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0036
============================================================


============================================================
🔄 Round 30 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 30 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0081
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0163
============================================================


============================================================
🔄 Round 32 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 32 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0142
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0110
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 34 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 34 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0130
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0153
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

============================================================
🔄 Round 39 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 39 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0109
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0048
============================================================


============================================================
🔄 Round 40 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 40 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0064
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0178
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

📊 Round 40 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

============================================================
🔄 Round 43 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 43 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0054
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0269
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

============================================================
🔄 Round 47 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 47 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0123
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0065
============================================================


============================================================
🔄 Round 48 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 48 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0076
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0178
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

📊 Round 48 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

📊 Round 48 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 55 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 55 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0053
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0255
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 59 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 59 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0066
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0059
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 60 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 60 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0132
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0189
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 61 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 61 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0046
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0229
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 63 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 63 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0073
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0124
============================================================


============================================================
🔄 Round 64 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 64 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0075
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0129
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

📊 Round 64 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 67 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 67 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0076
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0185
============================================================


============================================================
🔄 Round 68 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 68 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0021
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0393
============================================================


============================================================
🔄 Round 72 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 72 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0103
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0057
============================================================


============================================================
🔄 Round 74 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 74 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0085
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0128
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

============================================================
🔄 Round 80 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 80 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0034
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0343
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

📊 Round 80 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

📊 Round 80 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 88 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 88 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0045
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0105
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

📊 Round 88 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

============================================================
🔄 Round 92 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 92 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0097
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0066
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

📊 Round 92 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

📊 Round 92 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0194

============================================================
🔄 Round 95 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 95 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0065
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0109
============================================================


============================================================
🔄 Round 96 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 96 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0155
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0161
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

📊 Round 96 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

📊 Round 96 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2420, R²: -0.0195

📊 Round 96 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0195

============================================================
🔄 Round 101 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 101 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0002
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0301
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0195

============================================================
🔄 Round 102 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 102 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0122
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0439
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0195

============================================================
🔄 Round 103 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 103 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0017
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0422
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0195

============================================================
🔄 Round 104 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 104 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0096
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0055
============================================================


============================================================
🔄 Round 106 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 106 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0057
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0200
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0196

📊 Round 106 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0196

============================================================
🔄 Round 110 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 110 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0115
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0391
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0196

📊 Round 110 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0196

============================================================
🔄 Round 112 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 112 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0004
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0441
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0196

============================================================
🔄 Round 116 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 116 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0094
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0117
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

📊 Round 116 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

📊 Round 116 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

============================================================
🔄 Round 124 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 124 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0040
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0582
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

============================================================
🔄 Round 128 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 128 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0119
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0059
============================================================


============================================================
🔄 Round 131 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 131 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0079
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0136
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

============================================================
🔄 Round 132 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 132 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0099
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0034
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

============================================================
🔄 Round 134 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 134 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0158
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0186
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

============================================================
🔄 Round 136 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 136 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0033
   Val:   Loss=0.0936, RMSE=0.3060, R²=0.0268
============================================================


============================================================
🔄 Round 137 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 137 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0099
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0000
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

============================================================
🔄 Round 139 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 139 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0073
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0117
============================================================


============================================================
🔄 Round 141 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 141 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0065
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0091
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0197

============================================================
🔄 Round 142 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 142 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0113
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0114
============================================================


============================================================
🔄 Round 143 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 143 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0114
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0029
============================================================


============================================================
🔄 Round 144 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 144 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0086
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0176
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0198

📊 Round 144 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0198

============================================================
🔄 Round 147 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.1001 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.1001, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.1000, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.1000, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.1000, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.1000, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1001)

============================================================
📊 Round 147 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0168
   Val:   Loss=0.1001, RMSE=0.3163, R²=-0.0261
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0198

📊 Round 147 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0198

📊 Round 147 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0198

📊 Round 147 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0198

============================================================
🔄 Round 153 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 153 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0099
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0019
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0198

============================================================
🔄 Round 155 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 155 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0119
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0081
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0199

📊 Round 155 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0199

============================================================
🔄 Round 160 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 160 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0064
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0175
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0199

📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0199

============================================================
🔄 Round 164 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 164 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0095
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0034
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0199

📊 Round 164 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0199

📊 Round 164 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0199

📊 Round 164 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0199

============================================================
🔄 Round 169 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 169 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0154
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0218
============================================================


============================================================
🔄 Round 170 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 170 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0010
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0360
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0200

📊 Round 170 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0200

============================================================
🔄 Round 175 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 175 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0151
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0356
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0200

📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0200

📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0200

============================================================
🔄 Round 180 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 180 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0003
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0338
============================================================


============================================================
🔄 Round 182 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 182 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0036
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0275
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0200

📊 Round 182 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0200

============================================================
🔄 Round 184 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 184 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0059
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0032
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0200

============================================================
🔄 Round 186 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 186 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0043
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0143
============================================================


============================================================
🔄 Round 187 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 187 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0004
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0379
============================================================


============================================================
🔄 Round 191 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 191 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0075
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0047
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0201

============================================================
🔄 Round 192 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 192 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0102
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0009
============================================================


============================================================
🔄 Round 193 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 193 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0062
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0042
============================================================


============================================================
🔄 Round 195 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 195 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0046
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0172
============================================================


============================================================
🔄 Round 196 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 196 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0048
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0115
============================================================


============================================================
🔄 Round 197 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 197 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0051
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0160
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0201

📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0201

============================================================
🔄 Round 200 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 200 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0063
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0081
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0201

📊 Round 200 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2421, R²: -0.0202

============================================================
🔄 Round 204 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 204 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0125
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0147
============================================================


============================================================
🔄 Round 205 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 205 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0058
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0081
============================================================


============================================================
🔄 Round 210 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 210 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0004
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0273
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2422, R²: -0.0203

============================================================
🔄 Round 212 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 212 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0083
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0020
============================================================


============================================================
🔄 Round 213 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 213 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0036
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0229
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2422, R²: -0.0203

📊 Round 213 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2422, R²: -0.0203

============================================================
🔄 Round 217 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 217 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0133
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0208
============================================================


============================================================
🔄 Round 220 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 220 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0044
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0226
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2422, R²: -0.0204

📊 Round 220 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2422, R²: -0.0204

📊 Round 220 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2422, R²: -0.0205

============================================================
🔄 Round 224 - Client client_94
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 224 Summary - Client client_94
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0002
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0347
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2422, R²: -0.0205

❌ Client client_94 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
