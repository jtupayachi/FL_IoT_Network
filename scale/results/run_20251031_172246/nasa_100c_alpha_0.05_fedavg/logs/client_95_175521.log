[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbedd27c-7a82-49fc-ae2b-ba18716b1f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 344a27f6-f7be-452c-a6d1-c25642d10c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f9da6e-7670-4d06-84de-491d3ee1ae2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a65c1f-df48-439d-873d-0ab2a7e0160d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 864f4dcb-9462-45fe-a174-e90f95f5262a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b06e62-8c1f-4ef8-ac22-9755c3cb26ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0f6182-548a-4792-b194-144544e33e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34626331-8678-4e15-92ed-bf7ca31b1dad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19b83f11-f281-4420-b858-2082ede89a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15206132-4f9d-48d5-b67f-0742fa1a79c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f50a2c1a-698d-408f-b6f2-0dd7f33b4ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c1e15a-378a-40f8-8e62-c52075acc8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d1f259-ce05-4416-ba8f-b8eec9e38dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869ada5c-7d7a-4f61-b4a3-a7e8a047fcb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49a5e479-1183-4f9f-82f2-3456da48fb87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d9504ff-0292-42cf-9db2-87418cd4611d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33987db-2fe3-4b68-8ff2-1d48b84a7557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e2513e4-c9f9-4e90-86da-54e2579d01ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98947b72-8753-4bc0-997b-66704a9ee454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a6d3227-66ec-4460-afa9-6ff5d022fa3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3ba42e-5679-433c-81c0-52bbb951f536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b504ba-fcca-49c0-ac02-83b77ad6707f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d61ae003-62ae-4f8c-a8bd-c1a9c884083f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7474c9f-f59a-4d14-86dd-0572b2e34f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc01884c-a350-408e-a5ec-c5f7830285a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db354b2e-1dee-48e6-a0c8-0dd59b51def8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aafcf3f9-660b-46cb-ba86-b3ac12755426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c608fc-c0e5-4b47-94be-20990adb43a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9470ef-ed82-49d3-9136-ca3172b58d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a16456ff-41f3-4ee8-8b03-7f41218dfa2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ccd5856-b911-4bf5-841f-3c014cee5f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee73cfc8-bcc7-41b2-96c8-004ac5ccd1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d830292a-a9eb-4430-8a05-f03ab0698d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c92969-8993-4170-9462-baef845de4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f39307-9f80-414f-9222-4bd81f7f7924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04773c73-b16d-4b50-b575-6a6d94e87f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecff7178-83a2-41b7-9aab-629a68cb9f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68885f03-9310-4d37-86ca-e0b0e8adcabd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cf1c156-17ca-4788-8a69-f68d1ac4e5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 454b8159-76dc-4851-a3c6-de9699da3f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8a872b8-8f64-4d15-8199-60d87ea6b9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51564785-08a2-4d5a-b60d-0a61b9c35a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 428b6836-5371-45bc-9580-372f04c2b5bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c933631-4914-4afc-b6a9-14ee5a22541e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432a0dd8-22d9-4164-9d97-0d125217c184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39eb8274-9ede-4d66-a93a-cbd7da0e02ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd315e5-c51d-4d61-9fe2-da02e37d8765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccdb3f75-d47c-4e07-8332-e9c65b978414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55a1b7d-57cd-4eb3-99db-c887f84bb1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d874d87-eb2a-43fe-80bd-840f1dd7d04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1300e6af-86a7-4471-a12e-2d550d691527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 824fd151-ed8c-47e9-a8c1-beb20dbe9c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d300f2ba-4bec-4a05-9fde-8b2a56bf288b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d5ea59e-7437-4c62-b091-ecdba98f3264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2652621-0c57-4a4c-be23-ec9b0ed8331e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ac1321-060f-432a-8e38-8496a122ea9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0277fc6a-3889-49de-bd1b-d161bb58cb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f093047c-7b3b-4efb-94aa-7b35d24f090c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c392a856-22f3-4522-8145-6e48cf91aae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfcf3d97-3ca9-409c-8b3a-40c85b4f4f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64954a14-5f73-43fd-b42d-00a78c2bd73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49b4cd2a-bb35-4150-ad56-4eed70359669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e307594-c264-443f-aec7-31dfbf819423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae951693-5858-485c-adce-896d39ece965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d15dc00e-d13a-4c80-83e6-54291086faf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57e381a-e9f9-449b-aad7-736eab3c9574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9038e7b5-d458-4609-86f6-5bfa0bcc9c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62bcff74-b0d9-489a-bd46-39289bf578d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2909361a-8eb2-4408-996c-cb3baae9a5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d221938e-5adc-428e-b8b2-ce74edc2e768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c584c23-1e37-4f3c-ba59-82c818d06656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cf9392-fced-493e-8322-b355324de90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f6735d-67a7-499d-b84d-f42101e5dd57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a86bd30b-3c5e-4f43-b54f-8ea47ffc8835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3937c235-7ecc-4346-ba2f-0e779f7aeebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e783780f-0894-48d2-991d-99b742bb7f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a002db8f-83f6-4f04-b73d-3a144067e91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d55449c-de80-4ab2-9151-9ad4200d7df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6c828fa-13c0-4386-bc1a-4dcc6eb279a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 246c92d9-ca9a-4b21-b968-3b6d683e401d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e657db-662d-40ee-a613-e635813c8750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0914cf05-fba6-4ad3-bbce-eb2d5c125fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33cc737b-c6a8-4617-9458-9a645ba8c0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02cb50cd-bfac-42e8-b321-4878b9a0b475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e3e59a4-a69d-4129-800f-4fdd28acf502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a7f9e4-fa62-4763-998f-6874bb8dd02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87c2a99-dd1f-44af-a379-ae03e6750fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ec4643-f479-49fd-b35e-d7e20a71d575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a622ede-1945-4d37-8c81-1621c26dc494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb59c28-e05f-4d6e-8a69-629a60a29212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d51155be-107a-4b97-a39c-c95b1603c191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591d3be6-d02d-4441-bdfb-9f8c4837a903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a52142-5b46-4f84-a640-df264e44be2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e65ce1-1066-4d9d-b0d5-fb7babf00257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c78fbd-8869-40f8-b291-c6505b2ee827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d1ff4a-3657-4801-aa0d-700192d4aa52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81bbefab-b718-41f1-b40e-8ca6fac1b7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32adb90f-82f2-416d-8073-21df216317ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3936e024-a976-4982-ac76-4dd761453044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 062b31b8-acb8-4142-987b-515cb67e5937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfa8a4c3-6150-4750-a55c-6cec0c17bea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a6e24ff-5fca-40f9-bfd4-d5de0e7a953e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbbbc504-04a4-42a8-877c-0fccba6c2268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc62aadd-5b20-497c-81ff-5c99b134bdfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79bc33d5-83ed-4b97-9275-9f65ef0084fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e426b51-bdde-4462-93c4-f39c6b56f9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92288ae8-3236-4cb9-a06d-ecf62d39c71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e36666f7-2b35-4ed8-bb5d-741b35508920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 323752d3-72c9-4fab-879a-2ce23d038111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dad15dd3-447a-45fe-8a57-0b749a1d10ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff7fa699-5c3f-43f2-a28c-0beeb8b42c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80528cc-235b-4086-8447-8c1126bbc775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e571c7-62a6-4c1e-a227-91bbb4a8344d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 146ed1ae-2c73-4d95-9610-82805344ea60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 865917bf-2ad7-42c6-8c03-10b40a878d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1208047-3618-41d0-a189-57b76a645b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06418826-e8c7-45ee-b499-5db7e4c298c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361e8e93-920c-4699-9d76-8d31364d360b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7e8bec-a7a8-44b1-9322-892832dbccaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acee0d8a-b076-4da5-aebb-8650a1351186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 385ae370-d3f2-4b9c-bddf-3ce6d032fcb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04da793-5e31-4378-8e65-15a47a8833dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93bbae0d-0b49-4662-b005-49ed902c3001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb36ccea-3e1c-4090-a7cb-8c2e2a7d84e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1f7b493-1938-45dd-b57f-c7e3060286f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 558bfa6d-24ac-4e58-9b63-f6f005b0a987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 823d8b16-cdeb-444f-87b7-4590277422e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9e4c97-887f-4f49-a46f-3cec3f4f5dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6664e09-5dea-478f-9d22-e31726863ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e478854-5320-4c47-856d-f1e0326d6e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a91cce-95d7-4d65-b484-6997f48defc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d61e19-3923-45a3-958f-aa39fcebf75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171960dd-23af-4fbc-a3c8-f4725eac67ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0e40d5-14d1-42ea-97c9-d23f70c29cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c90483-a643-45f5-af17-27f9c15dd3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5b9e79-7a1d-4219-8525-a74de7ccf7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b550fe46-e9be-4bc4-86ef-334e614e6498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a64b54b5-e921-4cde-b44e-03233b68c5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0700a8-3d91-4bff-95c7-882b2d15e5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ff2c53-8177-4973-ab7b-7626288383fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36924279-0201-4d6d-85bb-e49364207331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ccb2379-8140-41e8-b25d-45929eb006b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073c045c-3173-4617-bcdc-a88ade7ede93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9102d15a-407a-4978-a1fa-aed4e1dadbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 341bbd84-c6a2-43b6-ba46-40c334c77b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a646a3ec-bced-4763-874a-e2706adfe810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d9063c5-9fce-469c-946a-511033d537af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4360919b-5743-48a8-9cab-860c655fd335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a52fa6d-2360-47c1-bcbf-cf089f31a30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 747b4d80-9eeb-4283-a55b-b5652e2fa2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 860d4b15-e96b-4b14-b560-d2d44da2add4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06499154-c8b7-44da-a9cd-6b402a12def9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be02c82-cde0-49b4-aff9-43e437496b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35bcbc59-d461-4a14-b3e0-c049b7ce8878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ec5a7c-1573-4180-a06d-fc581c31de07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dec87331-5b2b-46cf-9841-f77394a080ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8434cfd1-7e7b-40d7-92ce-6ad68d328c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164690d6-6eb8-48c5-a0f0-d2020bd59deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ad8470-69e2-493f-a5b9-16a4bc20de94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19839bbc-57dc-400a-a918-3307ff0b8de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cf7051c-d9ef-4fe4-b3a8-1945c31978ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d86378d-c783-41e7-9151-423bcacf2b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7dff040-93ea-402c-9be9-1bc64e3878e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ae3f12-935d-49e3-9349-49dc63ed4940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e85c1f78-89a7-4989-8d9c-c510bfa6b5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab1d4e7-9619-4898-b864-44078b980544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c77a19d-39bc-4310-b935-53f1ff2c703d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 931fdb90-d538-40f8-841d-1373599e76c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c9572c-3440-4a8b-8b81-4686b2dd1a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 525b27c5-b528-4da2-b708-03049f4a31a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77b2d138-7481-41b4-bcd2-b7ec0d2d4dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4e77baf-dbf3-45ed-93c4-bc872ae08b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae3c1458-694f-4bd6-901b-d844f71186eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e8aa364-b61a-46f4-8380-d53769026b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ca5947b-5871-47d0-80d9-d8f014bed17f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_95
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_95/test_labels.txt

📊 Raw data loaded:
   Train: X=(1176, 24), y=(1176,)
   Test:  X=(295, 24), y=(295,)

⚠️  Limiting training data: 1176 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  286 samples, 5 features
✅ Client client_95 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2580, R²: -0.0329

============================================================
🔄 Round 8 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0869 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0819, val=0.0858 (↓), lr=0.001000
   • Epoch   3/100: train=0.0814, val=0.0858, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0809, val=0.0859, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0804, val=0.0860, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0777, val=0.0880, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 8 Summary - Client client_95
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0110
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0186
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2582, R²: -0.0349

============================================================
🔄 Round 12 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0980 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0799, val=0.0972 (↓), lr=0.000250
   • Epoch   3/100: train=0.0794, val=0.0972, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0791, val=0.0970, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0788, val=0.0970, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0777, val=0.0966, patience=2/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0771, val=0.0965, patience=12/15, lr=0.000063
   📉 Epoch 24: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 12 Summary - Client client_95
   Epochs: 24/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0024
   Val:   Loss=0.0966, RMSE=0.3107, R²=-0.0435
============================================================


============================================================
🔄 Round 13 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0937 (↓), lr=0.000031
   • Epoch   2/100: train=0.0819, val=0.0933, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0816, val=0.0929 (↓), lr=0.000031
   • Epoch   4/100: train=0.0814, val=0.0926, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0812, val=0.0925, patience=2/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0808, val=0.0923, patience=4/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0805, val=0.0923, patience=14/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 13 Summary - Client client_95
   Epochs: 22/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0205
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0770
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2587, R²: -0.0377

============================================================
🔄 Round 15 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0861 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0849, val=0.0861, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0848, val=0.0860, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0847, val=0.0860, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0846, val=0.0859, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0843, val=0.0857, patience=10/15, lr=0.000004
   • Epoch  21/100: train=0.0838, val=0.0854, patience=6/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 15 Summary - Client client_95
   Epochs: 30/100 (early stopped)
   LR: 0.000008 → 0.000004 (1 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0492
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0371
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2594, R²: -0.0425

============================================================
🔄 Round 17 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0859 (↓), lr=0.000004
   • Epoch   2/100: train=0.0856, val=0.0859, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0856, val=0.0859, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0855, val=0.0859, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0854, val=0.0859, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0852, val=0.0859, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 17 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0575
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0839
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0882, RMSE: 0.2971, MAE: 0.2595, R²: -0.0437

============================================================
🔄 Round 18 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 18 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0581
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0729
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2596, R²: -0.0439

============================================================
🔄 Round 19 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 19 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0577
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0756
============================================================


============================================================
🔄 Round 23 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 23 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0730
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0608
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0487

============================================================
🔄 Round 26 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 26 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0666
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0644
============================================================


============================================================
🔄 Round 28 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 28 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0699
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0540
============================================================


============================================================
🔄 Round 29 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 29 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0678
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0661
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0487

📊 Round 29 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0487

📊 Round 29 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0487

📊 Round 29 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0487

============================================================
🔄 Round 35 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 35 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0575
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.1272
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0487

📊 Round 35 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0487

============================================================
🔄 Round 39 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 39 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0776
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0253
============================================================


============================================================
🔄 Round 40 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 40 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0645
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0730
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0486

📊 Round 40 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2602, R²: -0.0486

============================================================
🔄 Round 43 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 43 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0681
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0602
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2602, R²: -0.0486

============================================================
🔄 Round 44 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 44 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0735
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0370
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2602, R²: -0.0486

============================================================
🔄 Round 46 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 46 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0575
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.1072
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2602, R²: -0.0486

============================================================
🔄 Round 47 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 47 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0807
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0160
============================================================


============================================================
🔄 Round 49 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 49 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0640
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0783
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2602, R²: -0.0486

============================================================
🔄 Round 50 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 50 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0715
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0442
============================================================


============================================================
🔄 Round 51 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 51 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0747
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0328
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2602, R²: -0.0486

============================================================
🔄 Round 52 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.1015 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.1015, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.1015, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.1015, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.1015, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.1014, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1015)

============================================================
📊 Round 52 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0562
   Val:   Loss=0.1015, RMSE=0.3186, R²=-0.1045
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2602, R²: -0.0486

============================================================
🔄 Round 54 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 54 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0606
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0914
============================================================


============================================================
🔄 Round 55 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 55 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0734
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0448
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2602, R²: -0.0486

============================================================
🔄 Round 57 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 57 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0763
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0263
============================================================


============================================================
🔄 Round 58 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 58 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0585
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.1003
============================================================


============================================================
🔄 Round 60 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 60 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0573
   Val:   Loss=0.0976, RMSE=0.3125, R²=-0.0987
============================================================


============================================================
🔄 Round 62 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 62 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0530
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.1167
============================================================


============================================================
🔄 Round 63 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 63 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0625
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.1088
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2602, R²: -0.0485

📊 Round 63 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2602, R²: -0.0485

============================================================
🔄 Round 67 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 67 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0781
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0196
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2602, R²: -0.0485

============================================================
🔄 Round 69 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 69 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0647
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0859
============================================================


============================================================
🔄 Round 72 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 72 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0687
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0619
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2602, R²: -0.0485

============================================================
🔄 Round 73 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 73 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0580
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.1022
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2602, R²: -0.0485

============================================================
🔄 Round 77 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 77 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0682
   Val:   Loss=0.0984, RMSE=0.3138, R²=-0.0616
============================================================


============================================================
🔄 Round 78 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 78 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0677
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0757
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2602, R²: -0.0485

============================================================
🔄 Round 79 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 79 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0654
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0770
============================================================


============================================================
🔄 Round 80 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 80 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0631
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0848
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2602, R²: -0.0485

============================================================
🔄 Round 82 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 82 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0655
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0715
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

============================================================
🔄 Round 85 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 85 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0683
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0614
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

============================================================
🔄 Round 86 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 86 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0651
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0787
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

============================================================
🔄 Round 87 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 87 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0744
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0359
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

📊 Round 87 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

============================================================
🔄 Round 90 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 90 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0672
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0753
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

📊 Round 90 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

============================================================
🔄 Round 93 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 93 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0660
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0748
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

============================================================
🔄 Round 94 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 94 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0672
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0652
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0484

============================================================
🔄 Round 97 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 97 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0633
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0820
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

============================================================
🔄 Round 99 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 99 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0772
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0342
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 99 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

============================================================
🔄 Round 104 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 104 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0660
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0725
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 104 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 104 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

============================================================
🔄 Round 109 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 109 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0630
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0842
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

============================================================
🔄 Round 111 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 111 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0593
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.1050
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

============================================================
🔄 Round 112 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 112 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0737
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0435
============================================================


============================================================
🔄 Round 113 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 113 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0779
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0280
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 113 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 113 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 113 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 113 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 113 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

📊 Round 113 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0483

============================================================
🔄 Round 121 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 121 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0707
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.1003
============================================================


============================================================
🔄 Round 122 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 122 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0676
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0661
============================================================


============================================================
🔄 Round 123 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 123 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0683
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0708
============================================================


============================================================
🔄 Round 124 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 124 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0767
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0365
============================================================


============================================================
🔄 Round 125 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 125 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0572
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.1100
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0482

============================================================
🔄 Round 129 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 129 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0676
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0678
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0482

📊 Round 129 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0482

📊 Round 129 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0482

============================================================
🔄 Round 134 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 134 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0580
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.1145
============================================================


============================================================
🔄 Round 135 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 135 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0731
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0428
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0482

============================================================
🔄 Round 138 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 138 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0708
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0749
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0481

📊 Round 138 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0482

============================================================
🔄 Round 142 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 142 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0700
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0587
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0481

============================================================
🔄 Round 147 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 147 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0654
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0745
============================================================


============================================================
🔄 Round 151 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 151 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0599
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.1043
============================================================


============================================================
🔄 Round 153 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 153 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0673
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0677
============================================================


============================================================
🔄 Round 156 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 156 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0686
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0762
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0481

============================================================
🔄 Round 158 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 158 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0817
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0133
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0481

============================================================
🔄 Round 159 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 159 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0702
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0635
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0481

============================================================
🔄 Round 160 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 160 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0624
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0927
============================================================


============================================================
🔄 Round 161 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 161 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0697
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0577
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0481

📊 Round 161 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0481

============================================================
🔄 Round 167 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 167 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0655
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0783
============================================================


============================================================
🔄 Round 169 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 169 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0622
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0886
============================================================


============================================================
🔄 Round 171 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 171 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0627
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0870
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0480

============================================================
🔄 Round 172 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 172 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0622
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0989
============================================================


============================================================
🔄 Round 173 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 173 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0675
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0671
============================================================


============================================================
🔄 Round 174 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 174 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0671
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0715
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0480

============================================================
🔄 Round 176 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 176 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0744
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0401
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0480

============================================================
🔄 Round 177 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 177 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0574
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.1185
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0480

============================================================
🔄 Round 181 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 181 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0660
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0789
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0480

============================================================
🔄 Round 187 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 187 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0660
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0726
============================================================


============================================================
🔄 Round 188 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 188 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0596
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.1003
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2601, R²: -0.0479

📊 Round 188 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

============================================================
🔄 Round 193 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 193 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0800
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0155
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

📊 Round 193 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

📊 Round 193 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

📊 Round 193 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

📊 Round 193 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

📊 Round 193 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

============================================================
🔄 Round 203 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 203 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0690
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0681
============================================================


============================================================
🔄 Round 204 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 204 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0631
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0850
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

📊 Round 204 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0479

============================================================
🔄 Round 207 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 207 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0631
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0859
============================================================


============================================================
🔄 Round 208 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 208 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0512
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.1299
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0478

============================================================
🔄 Round 210 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 210 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0654
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0760
============================================================


============================================================
🔄 Round 218 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 218 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0656
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0782
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0478

📊 Round 218 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0478

============================================================
🔄 Round 222 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 222 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0653
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0786
============================================================


============================================================
🔄 Round 223 - Client client_95
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 223 Summary - Client client_95
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0824
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0105
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0478

📊 Round 223 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2601, R²: -0.0478

❌ Client client_95 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
