[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da2e3ee-dfc9-4be4-88e2-d97d458b4cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e5b56f6-4972-42c5-8673-616a9e176289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f93b77a-9b0d-4037-9c8b-6a806515ba91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e37c537-a7c8-4b06-a15b-556267e7efbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d515f17-0651-42c0-9036-15d86ee7b0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb55717-2219-49f4-b257-b47cc484640b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1071d2cf-9274-43e0-bca5-080a2f73b100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6ea6018-eff9-49e8-913e-a3555f3060b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2dc277f-0bca-49e5-a564-4d511921cb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c834991-d632-4271-b4aa-f94d15753208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1135477-fa94-4405-bf6d-fdbb96908829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ede6de3-fce1-49c6-894f-430c5dd01fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd77a01b-c287-4691-a9a8-f1243babf4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac4554d-4156-4c05-9584-5fbeee39f3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29994dd2-98f1-49b1-83cc-2333c2ebd898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f5d30e8-9aba-4c6c-9fc7-08c97b4ee832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1cee971-bac3-4566-a3e9-a6b93e31cd8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f5128a8-6e47-407d-90c9-bc0401f74839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0c5425d-4a35-4b2f-8f37-988fa3b9404c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b37c75bd-2264-408d-bd96-9fc946749e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91fe7215-a94e-4a57-9865-05a815036ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 966a4f26-1122-4a54-9ee2-1d846a656430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dbc5720-ad92-4be0-9ad1-d5697a8855cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f4cbbbf-727a-4fc4-9698-3d6aa63941c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d7de44-0a08-449d-8691-d8f70712e6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96581bd8-a5c5-40f1-bcfc-aefe301dff7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7302268-a4e2-4496-b1c4-194f40800195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb0db391-ccea-48e0-acf9-d9b7168b460c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b22813c1-41df-4a99-a9fc-c8d0396d9133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e91b00-6f7c-41e0-b328-5561485770f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbda9af2-a791-410a-b7f2-206fbce70336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f8b542-0f67-4fdb-b715-04d422f7e7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc15de5b-1512-480a-b393-cc5fcf5a4647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 618069a0-8683-4200-9703-1dfcfa06dbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b12bed-f9ab-4407-8ffd-21c286b38278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a7ff5f0-948c-41da-992c-42e256b61830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4955a2-c0b9-48c6-999b-b59c23c40166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72102f08-bcc1-4bf7-a263-25ad87c1934e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26079c48-7cef-4c62-966c-a1edb86e0ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c8f6adc-9cda-45bf-921f-c82a7aa5a131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a58ccce-f10c-4f35-90f9-adddfe68d991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d10ba5a-2aad-42c9-b4e7-19e9c1526878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee7497f-0112-4fc6-b5e1-b75b2ee87e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd87f46-0d74-4b0c-b1bc-8843eea502d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71841415-747f-48b7-a42d-4b7d930934cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c9ee5d-e594-4e6c-90dc-7a9d7860f7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8608398d-6eea-45f5-bf14-fd13b64fa49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a36fea-1159-470a-8c28-ff7a13401258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a245a2-1930-41b8-90b1-b310095bae96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb48d96a-061b-49e7-a214-b6bc7a902f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca326c3d-8508-48e5-9562-a85af7aac0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14242459-490d-4af4-b334-e06776054099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2300c36-02c4-41c5-9272-55a419c061c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d51a6734-9f17-403f-b02b-448d3f86a276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff4abcd7-a4fc-4d2c-bbeb-08c84919c796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d458e9b-81df-4952-9389-445b6cc2ffc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45b925a1-23c0-4828-844b-409753f920ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e9a5e01-a87f-4e89-80b9-3de71785170d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d578cfd-0528-4b17-8df9-6d6965dd5a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 248bfe97-c1f2-4059-ab10-d5c58ef6b850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de0be2f-e274-4d44-b78d-2a1012d49f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2467eb0-9380-456a-ba81-7727475b4a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff66440-344d-4b62-a168-901e109d493b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ddbd9b1-5edb-4c0c-a04f-1c5f3cf6399d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9916dabb-2c07-48e4-af51-f45e0c7de7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59efe467-7760-457c-a2cb-d90ffc0540c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 457d4944-e6cb-4122-850c-d9243808b252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7252b943-c874-4acf-9bbf-ab598a223f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c922a60e-bb2f-48f3-ac17-019cdf37f4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be408e09-27d1-4273-9335-83a1eaec6b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff65e29d-e03e-4e7e-8d65-606bdc0a1952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b450cd9b-27e0-49c6-a72b-8e191d0e0115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d656f4-0072-4dc5-9a7c-c86156c6d8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6569f7-58d4-40ce-b074-5e234640a115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92c9b271-1fd3-47d0-9725-823268da91ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74783f5a-003e-4ea2-82a6-a05f4f31eaa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e0ac08-d764-4d00-bc67-e5aaafee17d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f157a4-6fdd-42f8-8825-59235a3bc1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca14293-a09e-4e55-8b52-48c0ec63186e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abab63e4-f936-44a6-8898-7f93987e80bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f49d5ffa-14ca-4064-afd3-366685b9ad61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce7231c5-8dda-452e-9c66-1181610685eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78c5a950-d52e-496a-b8d1-fd8351e7e810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4865ee2-90cd-4ed3-8800-d61a12d85f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe38d30d-0189-4ad5-9944-cc8832caf70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08611a48-ee7b-43a5-910d-9a84af9b3217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3059c4-420a-4ca4-9377-b608ad4c6a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92db9e7e-2d3c-41b0-bb95-c2ca2b83947b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db4386e8-1c6c-4943-a107-045b513f7a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cac0acc-41b8-4e5b-8e9e-e594137ca9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c10b027a-aa8b-4d95-bdcf-992f4a932469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 420bbfcb-2d52-4d91-9f6c-3e19b82b7811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251612f9-b6a3-47ed-8490-034be3e79725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edf962d6-47fa-4b80-9c52-7f23a08a8c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1d2742-040b-4b78-9ab5-0c7c2841a939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 451dfdc3-0373-4d98-ac13-3bc875003dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f7205a-c437-4eec-ba02-cf7b899d2e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c12c4a-d9b6-47df-8e08-975c413d5af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8df1e302-e502-4f21-94ba-c99e4a3542c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7d81ce-aee4-45c0-bcfd-179ef4bafbf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b17c1cbe-d5c2-41cc-9844-d79ba0e53b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b21304-8829-4b9d-a3ec-cd8594ce948e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff886f29-8827-4a7d-a129-767e1035321a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 638430cb-6e44-41d7-b6b1-731fb9cecd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b39b3d-fe21-434f-ac90-2f4a1fd3aab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b259e9e-bbe0-49ad-b094-2b2be722a880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7194603-49c8-4025-b575-af110ad06d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b8e65c-c615-4c1b-aa5a-369f74c06bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a6a3052-8775-4f90-a064-0277f8e69566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0db68d1-a344-4d21-a94d-0ddcfda0fc21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21fbd2dc-dbaf-411f-b827-1dbf9164ef24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ef7abc-d9ed-422d-8f0e-344d01e1507e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65d252d2-855f-4e64-ac0e-6e30b9a3a6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a630961-082d-4281-b314-221a97f06bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9121f2f-83e8-4359-b95a-63f72494adf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe7d9db-d865-4c40-b7b5-81e01af2bb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 559ba699-26c7-4b01-a125-54e4abc9d668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a744a7e-bcc1-4693-9a7d-35b5715e5eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea1e5c4-21a9-4782-905b-ca49bf9a91c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375e2b2d-f3f0-4dcb-b0d9-12e873061a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ea3680-4b9c-4c6f-8fc1-ffdf5b06da1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdea4d0f-e38c-4a47-b58b-7c7e7436688d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33812cb-348f-4552-ad01-1901e1788844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed087795-c478-4152-922b-f8d098af23f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1cd479b-d023-4ee7-adfe-e7a54c06cd87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dfc6ded-e391-4342-a4fd-48e5cfc12027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9572488-35a0-43bb-86cd-0672f6091bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd1eec7-4cc4-4e5a-8ebd-23e1d2d33142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a07ecc3-6fb2-46ba-a208-315cfd24b288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef68ce71-b1f4-445f-be04-b53b6be43104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa27beb6-bf1e-4c02-94d8-e1a16e907650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24078d8b-4e59-4934-a1ca-d011a9d82e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9878a4-d79a-45da-b694-f6a8c8e48c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e6c54f-abb9-4a05-a1dd-0d827351f8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd44d656-9745-43ec-8caf-972a0694b01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01c4a384-b094-46bb-bd98-49b6b608eb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1c0e7d-66aa-4edb-b2e3-94c5fa731c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4e68f4-08d5-4f63-aca0-47f7f33e991c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f37ecb5-4d05-4540-8da6-03eb436ac1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2cb3996-bf40-4bae-abd3-1901596072d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8638d7-998b-49ba-be19-b371d4e9e5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3aabe1e-8e80-4209-88fd-b05088c3f65a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8059d0ab-c114-4fe5-a199-99d1fdd47547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b882ccb0-f412-4e8f-a468-8f844e805d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f3a3604-ff5c-484a-ac2f-8f712d5695b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06afc432-d472-4522-a2af-e0826e64cb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5250278a-0967-43c1-bee5-ebe51f92e291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d86b4b75-9874-4bd8-a32b-d76c4304cf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4883ba35-e660-4433-889c-3c50dea7b769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88af779e-4ca0-4c00-aee8-f061b1997c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161dc368-a974-4f42-95c4-e282c4499fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c626d0-a6bf-4c62-8c87-5a2b37d30c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c279aff4-6717-4ada-8ac3-54d1bd4774bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ced1917-f207-4b7d-b0e4-c998bab5ef87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9f2cd2-49fe-411a-8aa5-6d21df1b745f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49595cac-e9e1-4930-8056-b87c47062ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d298f0d-8679-4368-9740-6f47d078aed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e32e58c2-a0db-4be4-9ad6-a91b00ca960b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1b25d93-eed4-4b6f-b277-ffdec1814324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5b150f-ad0f-47c1-beea-223f188258bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eba16ce-0381-4b77-9ee4-c77779301c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf6e4eb6-f466-4190-8ec8-2fe60fd7beaa
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_96
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_96/test_labels.txt

📊 Raw data loaded:
   Train: X=(1516, 24), y=(1516,)
   Test:  X=(379, 24), y=(379,)

⚠️  Limiting training data: 1516 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  370 samples, 5 features
✅ Client client_96 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 8 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0862 (↓), lr=0.001000
   • Epoch   2/100: train=0.0820, val=0.0884, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0818, val=0.0829 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0794, val=0.0819 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0783, val=0.0808 (↓), lr=0.001000
   • Epoch  11/100: train=0.0733, val=0.0782, patience=1/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0657, val=0.0809, patience=11/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 8 Summary - Client client_96
   Epochs: 25/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1292
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.1086
============================================================


============================================================
🔄 Round 9 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000250
   • Epoch   2/100: train=0.0797, val=0.0822, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0790, val=0.0823, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0786, val=0.0822, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0782, val=0.0823, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   ✓ Epoch  11/100: train=0.0759, val=0.0816 (↓), lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0743, val=0.0811, patience=1/15, lr=0.000063
   📉 Epoch 25: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0736, val=0.0808, patience=11/15, lr=0.000031
   📉 Epoch 33: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 9 Summary - Client client_96
   Epochs: 35/100 (early stopped)
   LR: 0.000500 → 0.000016 (5 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.1082
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0181
============================================================


============================================================
🔄 Round 11 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0849 (↓), lr=0.000016
   • Epoch   2/100: train=0.0797, val=0.0849, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0796, val=0.0848, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0796, val=0.0848, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0795, val=0.0848, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0794, val=0.0846, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 11 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0380
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0314
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: 0.0068

============================================================
🔄 Round 12 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0846 (↓), lr=0.000004
   • Epoch   2/100: train=0.0799, val=0.0846, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0799, val=0.0845, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0798, val=0.0845, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 12 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0304
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0509
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2472, R²: 0.0066

============================================================
🔄 Round 13 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 13 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0310
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0505
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2473, R²: 0.0057

📊 Round 13 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2475, R²: 0.0030

============================================================
🔄 Round 15 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 15 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0339
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0346
============================================================


============================================================
🔄 Round 16 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 16 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0431
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0029
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2476, R²: 0.0026

============================================================
🔄 Round 21 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 21 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0297
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0450
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0005

📊 Round 21 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2479, R²: -0.0003

============================================================
🔄 Round 26 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 26 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0314
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0161
============================================================


============================================================
🔄 Round 28 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 28 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0321
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0355
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0008

============================================================
🔄 Round 29 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 29 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0303
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0442
============================================================


============================================================
🔄 Round 30 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 30 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0322
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0304
============================================================


============================================================
🔄 Round 31 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 31 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0318
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0322
============================================================


============================================================
🔄 Round 34 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 34 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0318
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0361
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 36 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 36 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0393
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0136
============================================================


============================================================
🔄 Round 37 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 37 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0357
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0179
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0008

============================================================
🔄 Round 38 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 38 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0255
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0541
============================================================


============================================================
🔄 Round 40 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 40 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0356
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0161
============================================================


============================================================
🔄 Round 41 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 41 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0357
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0209
============================================================


============================================================
🔄 Round 42 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 42 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0347
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0215
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 45 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 45 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0343
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0277
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0007

📊 Round 45 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0008

============================================================
🔄 Round 48 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 48 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0337
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0274
============================================================


============================================================
🔄 Round 49 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 49 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0344
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0280
============================================================


============================================================
🔄 Round 50 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 50 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0395
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0002
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0008

============================================================
🔄 Round 52 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 52 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0315
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0387
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 53 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 53 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0298
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0381
============================================================


============================================================
🔄 Round 54 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 54 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0375
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0143
============================================================


============================================================
🔄 Round 55 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 55 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0376
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0141
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0009

============================================================
🔄 Round 56 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 56 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0307
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0337
============================================================


============================================================
🔄 Round 57 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 57 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0407
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0156
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0010

============================================================
🔄 Round 61 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 61 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0329
   Val:   Loss=0.0746, RMSE=0.2730, R²=0.0336
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0010

============================================================
🔄 Round 63 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 63 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0382
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0072
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0008

============================================================
🔄 Round 70 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 70 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0374
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0059
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 71 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0650, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 71 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0345
   Val:   Loss=0.0650, RMSE=0.2550, R²=0.0255
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 75 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 75 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0327
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0347
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 78 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 78 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0296
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0457
============================================================


============================================================
🔄 Round 80 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 80 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0268
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0550
============================================================


============================================================
🔄 Round 82 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 82 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0248
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0486
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0007

📊 Round 82 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 85 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 85 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0223
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0687
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 88 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 88 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0212
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0822
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 89 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 89 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0311
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0375
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 93 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 93 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0305
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0442
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0007

📊 Round 93 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 98 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 98 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0339
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0239
============================================================


============================================================
🔄 Round 103 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 103 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0232
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0647
============================================================


============================================================
🔄 Round 104 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 104 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0354
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0202
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0004

📊 Round 104 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0004

📊 Round 104 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0004

============================================================
🔄 Round 109 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 109 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0375
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0143
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0004

============================================================
🔄 Round 110 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 110 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0348
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0262
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0005

============================================================
🔄 Round 112 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 112 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0389
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0061
============================================================


============================================================
🔄 Round 113 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 113 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0408
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0056
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0004

============================================================
🔄 Round 117 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 117 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0339
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0271
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0003

📊 Round 117 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0003

📊 Round 117 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0003

============================================================
🔄 Round 126 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 126 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0387
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0180
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0003

============================================================
🔄 Round 130 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 130 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0321
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0301
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 132 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 132 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0337
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0256
============================================================


============================================================
🔄 Round 133 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 133 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0309
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0422
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 136 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 136 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0392
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0019
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0008

📊 Round 136 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0008

============================================================
🔄 Round 139 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 139 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0366
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0086
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 143 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 143 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0289
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0476
============================================================


============================================================
🔄 Round 144 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 144 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0364
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0112
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 146 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 146 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0344
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0249
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 148 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 148 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0366
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0052
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0005

📊 Round 148 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 150 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 150 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0282
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0495
============================================================


============================================================
🔄 Round 151 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 151 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0293
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0468
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 153 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 153 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0327
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0352
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 155 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 155 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0319
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0198
============================================================


============================================================
🔄 Round 156 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 156 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0344
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0201
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0005

============================================================
🔄 Round 158 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 158 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0403
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0018
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0005

📊 Round 158 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 161 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 161 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0284
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0504
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 162 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 162 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0337
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0278
============================================================


============================================================
🔄 Round 165 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 165 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0368
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0166
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0006

============================================================
🔄 Round 168 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 168 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0364
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0181
============================================================


============================================================
🔄 Round 171 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 171 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0340
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0296
============================================================


============================================================
🔄 Round 176 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 176 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0312
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0421
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2480, R²: -0.0007

============================================================
🔄 Round 177 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 177 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0357
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0227
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0007

📊 Round 177 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0008

============================================================
🔄 Round 181 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 181 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0303
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0405
============================================================


============================================================
🔄 Round 184 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 184 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0405
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0031
============================================================


============================================================
🔄 Round 185 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 185 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0287
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0476
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0009

📊 Round 185 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0010

📊 Round 185 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0010

============================================================
🔄 Round 191 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 191 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0372
   Val:   Loss=0.0887, RMSE=0.2977, R²=0.0133
============================================================


============================================================
🔄 Round 192 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 192 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0316
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0302
============================================================


============================================================
🔄 Round 194 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 194 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0332
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0327
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0011

📊 Round 194 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0011

============================================================
🔄 Round 196 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 196 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0353
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0183
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0011

📊 Round 196 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0010

============================================================
🔄 Round 198 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 198 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0325
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0260
============================================================


============================================================
🔄 Round 200 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 200 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0301
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0443
============================================================


============================================================
🔄 Round 201 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 201 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0394
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0105
============================================================


============================================================
🔄 Round 202 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 202 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0381
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0115
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0010

📊 Round 202 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2481, R²: -0.0012

============================================================
🔄 Round 205 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 205 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0377
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0148
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2481, R²: -0.0012

📊 Round 205 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2481, R²: -0.0012

📊 Round 205 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0011

📊 Round 205 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0011

============================================================
🔄 Round 211 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 211 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0257
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0635
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0011

============================================================
🔄 Round 214 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 214 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0343
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0022
============================================================


============================================================
🔄 Round 217 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 217 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0340
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0269
============================================================


============================================================
🔄 Round 221 - Client client_96
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 221 Summary - Client client_96
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0355
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0206
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2480, R²: -0.0010

❌ Client client_96 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
