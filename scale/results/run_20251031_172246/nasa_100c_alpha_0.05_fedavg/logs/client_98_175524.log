[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfcaeded-6bf4-48fc-8cad-0f3f049f2cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14527d33-33da-4b88-9035-6613d92710ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4249751d-e49d-45b2-a276-1cc18a5e36d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48683c97-0818-44aa-a1ba-f417b00fdbfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d699cc40-dd03-4a02-a0ef-270b38e399fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00858bc-85c2-4863-aeb3-7a0de2e85594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e369d8b-4604-4c09-92bc-c21f9b89e394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6a83f6-7f0e-4ecf-8937-698553bafeaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95bfe086-e2a1-407b-9399-d776b420f68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2081bd3-6353-431f-ba77-042b1699a4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2730bb7-24a7-4624-8231-7f80c318c15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a5d9e96-adb0-479a-bfac-9b60dbdeb373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e54c3c1-7d00-4dae-a58a-fa26f3762ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26bf1e30-d42b-4266-9d26-d744a24f2e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d46410-87f9-46fd-852e-38e9f0725815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe677e80-a495-402a-bb3e-dfc2bc39466e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f6e2e4f-2287-45f2-af96-53aa0cc986e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46371b5-7c9d-4984-8ce9-a155891b106f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b8fba1f-9662-4df1-883a-03e25f431222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa321d6a-0080-4e4d-af55-894e20576607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2abf2b-6829-4ef5-9366-97ec64bd65d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 024d99e3-2a78-4d3f-82af-5c6b6f98e5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 057448a6-33c1-4b3b-bced-1385cb92def1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56fe9ff2-437f-496f-806f-99f8d16c960e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03340fa-cdbf-4829-b0dc-ca7b363729dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de53cd40-3e7b-4b2e-b518-be5698636774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a5745f-1188-4e40-9819-0a6efcbd360d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f58e84-3a84-4354-bd5b-44f19cb25d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baaaaba7-7a6f-4cc5-962e-033ea1167c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6d051e2-f240-47c2-97ab-90d0e9788c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25675f68-e86e-4460-884b-d562020630e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a129d0-abf4-4941-ad19-69420026d8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef3cc7c3-419f-4b35-9a10-f63ed06393b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74288a9e-8537-4abc-a212-0034b2a90d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f11b396-c1b6-4e2b-af21-4cf2ebd3581a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8393d4fa-5c9d-452b-8762-de32e419f284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33550cc0-6d2c-44c1-8576-988124f983c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946c5c0c-8417-436b-8746-6b10dd9f119f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a77c8cc-6abc-4268-bcec-d314f3425a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4d32f21-cbea-48a2-8c61-b57c7d741fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 035d511d-7e57-4895-bcaa-30bc73a30b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ca2a11-3175-4670-9867-6c37b3d0891d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9fe19f9-de84-4d07-9445-31ee040831bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ed3b0e-eea8-4526-87f6-5774aac94fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f83e933-9797-4c53-a109-b6ddc2b620d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46807c4d-7533-452c-b1cd-42b1364238cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831d2fd7-a415-43b7-809d-3084350e1e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff50978-9aba-4b38-b19d-832b8c13fb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d9a056-3d5b-4ef5-ac9b-53b380af20fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c7eef0-7f56-444c-bbef-ce478ea147cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd77987c-ccca-4f22-b3e3-120cbab4e7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89d8d3e1-623f-4f9d-b58a-5f77fd6527b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6929567f-0842-4ccd-8dd2-7fcfa6ccb3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb0d670-3761-459f-8506-075f34f1fa39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b24b54a8-1a45-438d-8d06-965060679771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdce635-e5f0-4233-a2e9-f48bc66f8843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f4ed949-3be9-415f-8c5b-6ff70c612261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ec6ce8-978c-422b-a293-31c944bc41da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7605b51-76ac-4f7c-aed0-0b17fd41160b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f99adfd-905b-4757-a81e-f181bc90dfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60181db9-b51f-443b-84f0-37e9995d7bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ff2e1c-2cde-4319-9a42-ee2add13ac9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c078adb6-adb9-4694-83bb-3e49fac0d508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 063a76e3-53a7-453b-9484-bff3a9c3b14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86fc3997-fe24-47c3-a29a-82fec57f0dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52744948-1fd3-4f32-80f3-b35be97b4016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f9bd98-f0f3-4c87-b58f-8974e135ae4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c84f261-c039-4db5-8d13-272748c39489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9da0f45-e209-4f5d-a72a-23beac14fe4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 371c6817-3cbb-447b-96db-2660a608cdfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3066afb1-1d63-4133-ad71-5dc50df044e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a02e5e6b-c12c-4308-8bf3-f372db0686cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81b7c3ff-3387-4a79-80f6-773f656df7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7843903a-2110-493a-abfc-0da6c6df9bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39204269-52c6-416a-924d-db8721aa4558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206110f3-9dad-4b7f-a3ab-e872a0b125a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f5f05b-1a99-437c-a80c-e4fee5542806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da251416-d16a-4334-8d7e-5b51fb82f4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e1c81d-f3dd-46eb-a325-43e25acf5f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9680b5bd-1778-48f9-b278-e3b00cac52d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 008b266b-b4a9-465c-a2e5-b1058543e78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ecccdd-f97f-4a6a-a6c4-0953fe52d9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdea9c9a-95ab-49b5-89e4-dbe0cce33285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ccd3b9-3e43-4ea8-86e1-28082de63bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff68ef1e-ae13-4534-b468-7fe8f2f890dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc6b3de-7096-4ce1-bdab-dbd9b8a8f7ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48fe9f5a-f49c-4a42-8e76-554e0796506b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 043a2a56-c202-40ec-a36f-4e22d669bf06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2424003b-4513-493f-90bf-170173e8e440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e2000f5-c697-45c7-b863-dfc025dc3a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb25c4d-6b03-4082-b311-38f6abf2fa2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f48f81fb-f5d4-46a7-a511-bb71dd98c2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 566616f1-f2ba-4f3c-897d-be8a66397aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87235835-9bd7-4be6-84cf-904c17c0fc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42dda763-c346-43f8-9d76-6a18d646bd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a84b177a-897c-4ea6-b980-5df66b1fe173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c670906-55f9-474e-93dc-f29805651f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb2b996b-09f3-4f4b-8169-5f38cd8313e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8cd354-290b-4a40-a70e-769f1186046d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a72716f-2bf8-4296-86ee-9593e73e632e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39a1b6b1-7681-4a9f-99d3-28e0c4ec4bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7190551-04dc-4fff-a821-2923ab8780cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68eb0b1c-b061-45c9-ad4b-63eb77f3751f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca3d50c0-273f-4205-98f3-c02ffc1d09ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08cd517b-a554-43b1-be4a-2570b12bc4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f3384a1-0498-4294-840c-8c296b50e69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5ab050-649d-49dd-85ed-8f30a02eee92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d527db-a277-48e6-a913-2264f6e9726b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5200a411-4a79-4683-a4b4-aaa95d93abeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2df3a23d-2f0d-4075-8cb4-508a2a8c0f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7bc982c-fe89-4a3a-b83d-6df871054841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925e5bb1-7b19-4916-a751-68c15df27604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5103cb-6fe7-43b6-8305-c120a383e636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 577487a5-4b23-493f-97c1-613bcdb8f754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d10354-9f25-46d2-9aea-5d5d78f70313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c28e5c-1c88-4b65-96ed-e95a34e16102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60b66a7-a311-4cd9-8551-765546dbec57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e722de-8c83-48e5-8567-2ac01e0340a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a18ef3a-9815-4436-9223-034d78cd8755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce24cdbc-8ecd-4ff6-965a-598ec3eb7e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cbcc9d0-2245-494f-969a-2e17276634f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24a14cf1-e05c-418a-a59c-56fe7e1704b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2034b9-c4d6-4552-98ec-73741a92f7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dba8430c-4647-40f8-9389-6d68fa3e2127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f04fb013-8e39-496d-a7ee-c50d8eac429c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 623d1496-5527-4a62-9822-f00be704efdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f018dad6-30d0-4506-bb5e-714bd0d44b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8b16dc-d9dd-4ec8-a4bc-443e571ae2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 143b8182-b8f3-4bb6-a2e3-3e7c681b9bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef2cb5b-73c5-46fb-9dfb-b087348bee42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224a8c22-4c36-4f38-8497-84eada776f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef0a1adb-eadf-4f89-8cbd-31f07bed4125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ca2a25e-931b-441a-8bc4-248820776468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f1a211-24bb-4b98-bd80-bd2517d43527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d7c586-f32a-4bba-8c13-2da87dd735bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6057bf-83bc-43fc-9982-4df7dcc74e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc37b36-145c-48a3-92df-0a8d54892a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d59324-7a7d-40fd-9454-97f00985690d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39beb49-391c-4205-a6d7-2c20d62368ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb8545b-079b-4f3d-b283-8c4bbf7acd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e597c142-00d6-4916-be7e-ae9a4f4adf17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f146abd1-93e0-4ea3-a68b-0222a1dbdc2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26625be9-7007-4fae-a739-b08b16af576e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9a17e9d-7ee3-4fc5-bcd5-ecdf833304ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61831fc9-a3fc-439b-8d66-94354d9296ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde8100a-3351-4f31-9c0c-fd61047cc83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c68dee-4105-4179-b299-646d2d001d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c451d1c6-0e74-4604-98ca-16dc479282c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5460a98c-17f5-496d-825b-4b6d9740773e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 000a8583-5162-4a51-a761-fd0715957dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2594e0aa-0805-4915-a599-3eb8a8c33abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43089733-49df-4be4-989f-bfe542e53793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f59c76f-d9d6-40bd-9746-1713180b2096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d161fa58-ba62-448e-8c4a-8eff37096118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8429d963-39fb-42fd-8b08-51cd85289202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23fb1340-bb2f-4896-b0c5-57a3a4d5be03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b834bc05-8180-4dc8-aa07-99cda755c3ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c4c59d-cdba-4782-98ed-ebcfa52fcd70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5057b53c-77ed-438c-b5e2-6d87a59b2243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b23f77-77f0-4bbe-984d-fd25a35d2635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf2787e-2820-4400-9049-28b2ffd75e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961bf10a-8826-4752-9c0f-f4a5c0db906b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 826e9cf3-b80b-48e8-81c8-d0d9da417272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 230e9947-1463-4641-ad07-74c3ac86ce2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed3b406-885b-4d79-ae51-d1b61aeebed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4226512c-0f49-4e22-932f-8b79bc566fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af663ec3-ae73-4197-9521-b32a79fb0fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed995871-e2b9-4fac-b3be-fd0efd1ffb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9cb54d8-d1fa-4869-8b3a-0c5982a089f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9d52de-02c3-49cf-8c73-b9af7434ffde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1275ee1b-02e6-4fa8-b11f-1cc29d2ad4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a37b239d-a937-496b-be7b-6d6964d3ff20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f92ca2e6-2a5b-4557-b0d2-62a97f98001f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d71526fe-d426-431c-a55c-886bb85b7f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06aba66b-2fbe-4a44-b5fc-6b23bcb38c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ac63aa-2e3f-4935-9e71-4f552c0e0f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bbe39b7-5bd4-4d6b-9f83-17b1f7cf9b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3897b329-8741-4a22-9302-f2b83228aa2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f137676-7f68-4cb5-86b9-174294121fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15779a9a-bf35-468d-bd5d-a3f4e51893e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c929d0-c2e2-48ac-89f8-adcbd878e59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26127d1a-14e8-4738-9e74-cf37a7ee4b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0afa2a2-06a9-4f6d-99e2-b283057f8aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e4edf72-d790-4e89-832e-c1dc1d1753bf
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_98
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_98/test_labels.txt

📊 Raw data loaded:
   Train: X=(1000, 24), y=(1000,)
   Test:  X=(251, 24), y=(251,)

⚠️  Limiting training data: 1000 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  242 samples, 5 features
✅ Client client_98 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0696, RMSE: 0.2638, MAE: 0.2259, R²: 0.0799

📊 Round 0 Test Metrics:
   Loss: 0.0690, RMSE: 0.2628, MAE: 0.2242, R²: 0.0869

============================================================
🔄 Round 8 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0828 (↓), lr=0.001000
   • Epoch   2/100: train=0.0748, val=0.0851, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0743, val=0.0836, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0736, val=0.0820 (↓), lr=0.001000
   • Epoch   5/100: train=0.0729, val=0.0818, patience=1/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0673, val=0.0833, patience=7/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 8 Summary - Client client_98
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0701, RMSE=0.2648, R²=0.1601
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0867
============================================================


============================================================
🔄 Round 9 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0829 (↓), lr=0.000250
   • Epoch   2/100: train=0.0750, val=0.0830, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0743, val=0.0827, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0738, val=0.0825, patience=3/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0733, val=0.0824 (↓), lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0714, val=0.0819, patience=6/15, lr=0.000125
   • Epoch  21/100: train=0.0702, val=0.0815, patience=9/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 9 Summary - Client client_98
   Epochs: 27/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1487
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0872
============================================================


============================================================
🔄 Round 10 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0847 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0747, val=0.0833 (↓), lr=0.000125
   • Epoch   3/100: train=0.0743, val=0.0831, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0738, val=0.0832, patience=2/15, lr=0.000125
   • Epoch   5/100: train=0.0734, val=0.0832, patience=3/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0723, val=0.0829, patience=9/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 10 Summary - Client client_98
   Epochs: 17/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1109
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0325
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0690, RMSE: 0.2627, MAE: 0.2240, R²: 0.0874

============================================================
🔄 Round 12 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0823 (↓), lr=0.000031
   • Epoch   2/100: train=0.0759, val=0.0826, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0757, val=0.0827, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0755, val=0.0826, patience=3/15, lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   • Epoch   5/100: train=0.0753, val=0.0825, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0746, val=0.0823, patience=10/15, lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 12 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0954
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0184
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0691, RMSE: 0.2628, MAE: 0.2240, R²: 0.0867

============================================================
🔄 Round 13 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0769 (↓), lr=0.000008
   • Epoch   2/100: train=0.0776, val=0.0769, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0775, val=0.0769, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0775, val=0.0769, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0774, val=0.0768, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0771, val=0.0767, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 13 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0867
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0883
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0688, RMSE: 0.2623, MAE: 0.2236, R²: 0.0898

============================================================
🔄 Round 14 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0857 (↓), lr=0.000008
   • Epoch   2/100: train=0.0750, val=0.0857, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0750, val=0.0857, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0749, val=0.0857, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0749, val=0.0857, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0747, val=0.0856, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 14 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0968
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0533
============================================================


============================================================
🔄 Round 15 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0864 (↓), lr=0.000002
   • Epoch   2/100: train=0.0748, val=0.0864, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0748, val=0.0864, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0747, val=0.0864, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0747, val=0.0864, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0747, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 15 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.1009
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0542
============================================================


============================================================
🔄 Round 17 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 17 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0948
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0801
============================================================


============================================================
🔄 Round 19 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 19 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0898
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0977
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0685, RMSE: 0.2617, MAE: 0.2228, R²: 0.0939

📊 Round 19 Test Metrics:
   Loss: 0.0682, RMSE: 0.2611, MAE: 0.2222, R²: 0.0983

============================================================
🔄 Round 22 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 22 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.1006
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0652
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0682, RMSE: 0.2611, MAE: 0.2222, R²: 0.0984

============================================================
🔄 Round 24 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 24 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0913
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.1005
============================================================


============================================================
🔄 Round 26 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 26 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0948
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0892
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2222, R²: 0.0989

📊 Round 26 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2222, R²: 0.0988

📊 Round 26 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2222, R²: 0.0987

============================================================
🔄 Round 29 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 29 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0969
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0820
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2222, R²: 0.0987

============================================================
🔄 Round 30 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 30 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0967
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0811
============================================================


============================================================
🔄 Round 31 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 31 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.1046
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0420
============================================================


============================================================
🔄 Round 32 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 32 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0946
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0903
============================================================


============================================================
🔄 Round 33 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 33 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0926
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.1001
============================================================


============================================================
🔄 Round 34 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 34 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0942
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0896
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2222, R²: 0.0989

📊 Round 34 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0989

============================================================
🔄 Round 36 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 36 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0892
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0992
============================================================


============================================================
🔄 Round 37 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 37 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0887
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.1136
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2222, R²: 0.0988

📊 Round 37 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2222, R²: 0.0989

📊 Round 37 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0990

============================================================
🔄 Round 43 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 43 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0915
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.1038
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0991

📊 Round 43 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0990

📊 Round 43 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0989

============================================================
🔄 Round 48 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 48 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0896
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.1071
============================================================


============================================================
🔄 Round 49 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 49 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0866
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.1196
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0990

📊 Round 49 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0990

📊 Round 49 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0988

📊 Round 49 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0989

============================================================
🔄 Round 55 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 55 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.1062
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0443
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0989

============================================================
🔄 Round 56 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 56 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.1067
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0452
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0989

============================================================
🔄 Round 57 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 57 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0999
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0670
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2222, R²: 0.0988

📊 Round 57 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0988

============================================================
🔄 Round 59 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 59 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0899
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.1044
============================================================


============================================================
🔄 Round 61 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 61 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0914
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.1052
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0989

📊 Round 61 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0989

============================================================
🔄 Round 68 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 68 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.1008
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0661
============================================================


============================================================
🔄 Round 72 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 72 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.1046
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0470
============================================================


============================================================
🔄 Round 77 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 77 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0808
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.1355
============================================================


============================================================
🔄 Round 78 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0639 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0639, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0638, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0638, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0638, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0638, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0639)

============================================================
📊 Round 78 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0887
   Val:   Loss=0.0639, RMSE=0.2527, R²=0.1199
============================================================


============================================================
🔄 Round 80 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 80 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0915
   Val:   Loss=0.0682, RMSE=0.2611, R²=0.0935
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0995

============================================================
🔄 Round 81 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 81 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0839
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.1216
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0995

============================================================
🔄 Round 82 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 82 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.1007
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0605
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0681, RMSE: 0.2610, MAE: 0.2221, R²: 0.0994

============================================================
🔄 Round 85 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 85 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0854
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.1245
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0994

📊 Round 85 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0994

============================================================
🔄 Round 87 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 87 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0907
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0894
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2221, R²: 0.0994

============================================================
🔄 Round 88 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 88 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.1016
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0457
============================================================


============================================================
🔄 Round 89 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 89 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0970
   Val:   Loss=0.0714, RMSE=0.2671, R²=0.0801
============================================================


============================================================
🔄 Round 93 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 93 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0907
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.1084
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0995

📊 Round 93 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0995

📊 Round 93 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0995

📊 Round 93 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0996

📊 Round 93 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0997

============================================================
🔄 Round 101 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 101 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0897
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.1118
============================================================


============================================================
🔄 Round 105 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 105 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0936
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0901
============================================================


============================================================
🔄 Round 107 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0634 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0634, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0634, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0634, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0634, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0634, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0634)

============================================================
📊 Round 107 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0909
   Val:   Loss=0.0634, RMSE=0.2519, R²=0.1096
============================================================


============================================================
🔄 Round 108 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 108 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0926
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0966
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0999

📊 Round 108 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0999

============================================================
🔄 Round 110 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 110 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0908
   Val:   Loss=0.0740, RMSE=0.2719, R²=0.0807
============================================================


============================================================
🔄 Round 111 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 111 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.1015
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0582
============================================================


============================================================
🔄 Round 112 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 112 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.1026
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0619
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0998

============================================================
🔄 Round 113 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 113 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0863
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.1154
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2220, R²: 0.0999

============================================================
🔄 Round 115 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 115 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0873
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.1231
============================================================


============================================================
🔄 Round 116 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 116 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0943
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0954
============================================================


============================================================
🔄 Round 117 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 117 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0942
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0930
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

📊 Round 117 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

📊 Round 117 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

============================================================
🔄 Round 122 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 122 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0957
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0900
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

📊 Round 122 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 125 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 125 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.1011
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0697
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

📊 Round 125 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

============================================================
🔄 Round 127 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 127 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0921
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.1029
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 129 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 129 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0894
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.1098
============================================================


============================================================
🔄 Round 130 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 130 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0915
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.1073
============================================================


============================================================
🔄 Round 131 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 131 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.1070
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0407
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2219, R²: 0.0999

📊 Round 131 Test Metrics:
   Loss: 0.0681, RMSE: 0.2609, MAE: 0.2219, R²: 0.0998

============================================================
🔄 Round 137 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 137 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0903
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.1107
============================================================


============================================================
🔄 Round 138 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 138 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0941
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0766
============================================================


============================================================
🔄 Round 139 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 139 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.1019
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0639
============================================================


============================================================
🔄 Round 140 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 140 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0966
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0871
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

============================================================
🔄 Round 143 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 143 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0877
   Val:   Loss=0.0653, RMSE=0.2556, R²=0.1252
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

📊 Round 143 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

📊 Round 143 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

📊 Round 143 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

📊 Round 143 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 151 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 151 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0908
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.1075
============================================================


============================================================
🔄 Round 152 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 152 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0913
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.1044
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 153 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 153 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0962
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0835
============================================================


============================================================
🔄 Round 154 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 154 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0908
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.1105
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

📊 Round 154 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

============================================================
🔄 Round 158 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 158 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.1000
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0716
============================================================


============================================================
🔄 Round 159 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 159 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0896
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.1063
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

📊 Round 159 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

📊 Round 159 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

============================================================
🔄 Round 163 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 163 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.1026
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0607
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

============================================================
🔄 Round 164 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 164 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0914
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0943
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 167 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 167 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0929
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0918
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 168 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 168 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0936
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0962
============================================================


============================================================
🔄 Round 169 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 169 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0864
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.1277
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 171 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 171 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0985
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0565
============================================================


============================================================
🔄 Round 174 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 174 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.1059
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0581
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1003

📊 Round 174 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

📊 Round 174 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1003

📊 Round 174 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1003

============================================================
🔄 Round 181 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 181 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0998
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0744
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

============================================================
🔄 Round 184 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 184 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0884
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.1188
============================================================


============================================================
🔄 Round 185 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 185 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0843
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.1347
============================================================


============================================================
🔄 Round 186 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 186 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.1027
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0517
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

📊 Round 186 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

📊 Round 186 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

============================================================
🔄 Round 189 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 189 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0926
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0962
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

============================================================
🔄 Round 191 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 191 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0914
   Val:   Loss=0.0670, RMSE=0.2588, R²=0.1111
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

📊 Round 191 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

============================================================
🔄 Round 193 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 193 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0932
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0840
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

📊 Round 193 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 197 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 197 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0962
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0862
============================================================


============================================================
🔄 Round 201 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 201 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0874
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.1111
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1001

============================================================
🔄 Round 203 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 203 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0905
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.1123
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0680, RMSE: 0.2609, MAE: 0.2219, R²: 0.1000

============================================================
🔄 Round 208 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 208 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.1031
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0612
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2219, R²: 0.1002

📊 Round 208 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2218, R²: 0.1002

📊 Round 208 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2218, R²: 0.1003

============================================================
🔄 Round 215 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 215 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0972
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0866
============================================================


============================================================
🔄 Round 218 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 218 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0997
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0610
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2218, R²: 0.1002

============================================================
🔄 Round 220 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 220 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0889
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.1151
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2218, R²: 0.1003

============================================================
🔄 Round 222 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 222 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0919
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.1044
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2218, R²: 0.1004

📊 Round 222 Test Metrics:
   Loss: 0.0680, RMSE: 0.2608, MAE: 0.2218, R²: 0.1004

============================================================
🔄 Round 225 - Client client_98
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 225 Summary - Client client_98
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.1040
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0554
============================================================


❌ Client client_98 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
