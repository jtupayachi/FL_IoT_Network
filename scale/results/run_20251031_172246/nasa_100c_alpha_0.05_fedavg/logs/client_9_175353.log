[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e9dfa5-39ab-4558-ab94-8bba0edf782e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5901b339-f167-4917-a3fb-33e42b672c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 243e9237-a7d7-46f0-a9ea-7a3b3c9a8243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b6bb591-e61f-476e-944a-d9c0fabb925b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7cb65f-78c6-4e1e-8dde-ac2153475d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f8123e-cb09-4a23-bf03-dde66db122bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6805fb67-0fb0-47ea-b6be-d126473d178e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb076127-4577-4691-8ca4-81968271f164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d8b48e5-2719-4383-93c9-72b4bc374ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b880ab1-f622-45c6-ac33-4213ae69308e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 188d96ac-7f81-401a-b560-34ef4881ad3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0fc3df0-b9e2-44d1-9b31-536f7e1c7b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b578fc34-5963-4c2c-99c0-40995bef56f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d76e1074-621b-4e0d-a402-7c3b7e134b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4586f758-e2f3-462b-82a0-324f4a89453c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18570601-905f-45a3-ae1e-b48d985cadb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3723722-7464-4896-a248-8297d75f8ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a99acc-c17b-412b-ae3b-edce8e0eb9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2143e3ae-489b-4364-8c7b-6d7cb7509918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0f765d2-af52-4470-8f0f-517c3ddeb3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa373fc-f347-4a88-88a2-db68a360e687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f2e079-a486-4c10-8768-e567b29c4d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e0893f-f9ad-43c7-951c-20db797603c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d64a7b-a43a-4c63-884a-e090bcd7e2e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60e4c5c5-0696-49b7-9d25-a3dcd9f7922d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43168eec-b873-443b-a338-faa9c246a289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60ac460-f794-4407-a1a2-0f943cfbbe42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b1adea4-c479-4d6d-85d2-9cc949a3de92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac26891-daa2-40fe-b9eb-e7faf75c006f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35048ef7-15db-411e-a6b7-15ff8e7678fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3841f2-60a1-44e5-b758-9eace4f484d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 225915d6-19e3-4edc-8009-ce97abceb206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2304caef-0e93-4695-8faa-6f24b0f0df4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead2d18d-d1a1-4230-9632-7b693a7d315a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f2584f-5a81-4aaf-a594-ea0a2a71430d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed86061d-bdf7-404f-9a7c-ac714be3afad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4073e7b-d8cb-4d90-936e-0a36805cb6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deb85e29-b1c3-40c4-ac22-691bb6005eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efbfb96e-0081-4a75-aa5f-dd8ac9840489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d73baa37-3eda-4a99-8c07-8b544261ddf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb6077e-230c-4ac4-97b5-faf296862ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5cfe03c-d676-4bf5-9442-c6772f5ec921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d838c586-5778-403c-9276-47f09547a285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b45f69-af1f-4e66-9048-7a8c706126f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0bd2181-4611-458d-9dab-c1edd39e1b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef2625f-cc54-4092-81a3-7168bc8022af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e546ca67-88d7-4979-b466-8a89595f52da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32482b25-d40c-45f9-b78a-b838c489df12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06730ff6-937f-4461-89dc-b9d49ce6b1b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c02cc97-1b32-41c9-8218-2e7399b17282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666567c8-9ecb-4d0e-9176-951be6ff9b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a014a99d-b0e1-418d-a420-22df08dd5aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54209db-76b6-485a-8ca4-c0f32316f0de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bda3838-95c2-46f0-84e2-8d704599087b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b83698a3-b69e-4232-80d9-b8fef8217a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1773f0c7-2233-4b48-bdca-354a9d237ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c1dadfd-1e7a-4cb3-8129-61bab3be1361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a1e0086-0925-40cb-af4d-773559c065a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3085b28e-a8a6-4a0a-a6f1-f324b07b4821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9199ecf-59b6-4ae7-8de5-c20a0bec2695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3f697c-fba6-4a77-b774-f15fe32a140a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4130a40b-1e1d-43f4-9436-17a89249b1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36cbac48-9795-4f3d-8809-f0a7c541b8c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795b895f-3731-4b60-ba01-c55e6e2020d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c6c500-b0c1-47a8-a3c3-0e3403b93763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b35def-660c-49a1-aa64-072e8e0d3dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f81d49-6fa9-480d-982d-27d8328a91f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a76dac-4560-4c9b-a25e-a002d04041fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d206fb0-15b9-4c1f-9277-d1e91430ca03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8269a115-54f7-42c6-8811-efdaf037d5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1e68ff0-8557-44c9-a4f5-2fb32428e4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992a96a3-c0f8-4b8f-9977-25c9da5a31d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3515b63c-43bb-4576-8ccd-97eb5ef504a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1867d62d-3b83-444a-91db-08cb4433fa2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ecf9c8d-bc96-4663-a159-01ba3d118bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9d62e4-a984-4dab-b1f4-af90de435209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de7234b-c8ed-4bd8-b151-2364fcb7be70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba5daf5-faed-4d00-abba-667dcdd11207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 613735b6-dfcb-433a-a970-9c3132521273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c700c51-8701-4339-be15-3a9ab5526964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8319fb84-17fa-46dc-9cfa-58cfa023a103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1750072d-d5aa-4d3c-b209-57737630746a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23542b2f-0886-4cf9-b7d2-975dcb946e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a23dd5db-0b17-4b00-867f-9e282869bce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 969267a6-5bc5-40b8-91ae-2ecbcf94d8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2e769a0-bbee-44c1-8fe2-5f5bfdbf9284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23aa474-f3d4-4fab-9333-b9958d7e95d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ffb4c1b-e1d5-4c7e-ba5a-b2f58d00e9ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73618f2-49a4-49f7-a017-020eaefb8d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79827b1c-95d6-4bcf-921c-c50d844c2a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d77161-d3fa-455c-ab12-7d5947cd0ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8adc5f4b-de1c-483c-94d3-e0555d4ca1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1028a52-e769-4812-bfb3-bd8dd185cb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 404e697e-7fc8-43d0-aa18-6f4f19a7822b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a599f434-d717-429d-ac96-d69bd0ebf213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c0fd79e-ee31-461f-ac33-969021afed64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae96c5e3-6c7c-46e1-baa6-9bdf69cca507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93c06c1b-5fbc-4c05-95a7-f9bbe517640b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb35f6a-e906-4c5f-9110-f16a3f009ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72452731-f777-4e59-9dda-55ef91953ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c10b4f5e-b4c0-459a-a2da-aa14f10df17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67a0293d-c251-407e-b185-23ccf3b06fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b37af3a-7a98-4a43-babf-ea8bfabfcd98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 407521cb-a1dd-42cd-a4ea-5c0ff11a42ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba9b17d1-a2a0-40ed-a684-24b6239fb39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2533286b-6937-4ee2-9ef1-afce532216e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e47f38-7ddc-47ed-870a-3e927bc5bd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980d2f4f-23d5-4055-98a2-46693b10b214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47bbe6c0-15d4-4058-a0d7-8a40cb42b23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f789f77d-40cc-4992-a7fa-e3a5dba2edb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f6c1b0-89bb-4a02-a127-542e5ed7137e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b242fa-26f7-431b-888c-85d2358c3371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5784cbd1-cb92-43fd-b0a6-326c623564e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea4cd94-f81e-4d13-bd23-16c6f2213b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6826000-557d-45dd-9de5-6b270bd1c493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c800002c-193a-4ad3-ad72-c1f18a0214a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33b5c97c-4c08-46d6-ad7c-205748669aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8013c9c6-09a9-40f7-bfaa-3ba2c3e5f577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98280f62-77f8-4d53-8c7e-f790d1aee979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b13ad3-6dae-4ec7-a455-9450163dd789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02330e55-c9f3-4970-a255-004f28edf049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69385f4b-54b6-4be4-a08b-8563b24a963c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d78116f-f4a4-40c3-b8a2-3f401e6347fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4085531c-ff82-4a0e-b7e0-7869cb0a6576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1319884-3946-42de-9603-f092c0ca3738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 265aab61-40b7-43b6-97af-0e0c1cfdcb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d2d7fe-864d-4f78-bcd6-41a0fb8c0b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2a0d9c-c93d-486d-ad0b-75e56d24eee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93847675-846e-4cfd-b3bd-877a67cd26fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a673f69c-c34d-49bc-9fb0-de35e1c68798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a89178e3-55fd-4c55-a551-6b3982094737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6501c3cf-ea5a-4844-a45e-0177cccf0d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 147ebbf7-d396-4db3-b2ad-2ba433777f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 285fc948-445c-41c6-bb1e-d8839e24f3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d094b61-8cc5-44f8-825e-54d8a16ac4cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d91dd346-ed2b-479d-93b8-5d0cc15c2324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf579dd-14ec-48c5-95a1-c3af361cfd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72a65589-8245-4288-81fe-53b709270ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad61de3f-a34c-40c1-b5e1-0f6dcbdea760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3146206c-ef63-4fc7-8067-1fb871b1770c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd7f9be-46ff-4b10-a32e-814968577cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe25ec44-fda2-47d8-b19c-8c1d175e1b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ae10bb-b9e2-4b76-926c-ea2abd36bf14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63d6ca6b-f5a0-4986-bcc9-ce00630e7e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24f5706-707a-43eb-bd37-846e3ff4e618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a518d497-e131-489d-8650-73bf77c2b316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c2a7551-4d2b-4a71-9a36-9a486e471b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003d9197-a956-483d-bc46-6d330826d0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 113c041f-ca6b-471b-8b59-f7860ceb117a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b0e1365-6515-4dfe-a58c-b8df2245cb9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a6a685e-2da0-431b-8fd2-70d770b587fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90dc37ae-d5ce-4a0a-93ed-d362542af7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c400ebc5-5278-4763-a487-156366115036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0084ed52-2ccc-4871-8475-bd5a09ca086a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a391fb48-0a06-4dff-9472-40b5813f3348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5d1e37-3d82-4fb2-8ab4-c44f76190082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d28714ac-79fa-4c15-b896-6cf14ecb5b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc76ed4-84f4-49e7-94eb-3c60916154c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ef7146-df49-435b-bae0-3087d7e0d5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60d194e-b714-4699-8a9e-72fe2b0ad18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11eebfe-7b2c-463b-816c-cec1558214b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6985dc5-c1f1-418d-97a6-27579308a6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e16ac3d6-1cbd-4433-a02f-69445434c42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818d3a2c-46f5-4763-8404-3233e2ff7406
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(755, 24), y=(755,)
   Test:  X=(189, 24), y=(189,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 746 samples, 5 features
   Test:  180 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2463, R²: -0.0304

============================================================
🔄 Round 2 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0852 (↓), lr=0.001000
   • Epoch   2/100: train=0.0856, val=0.0855, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0871, val=0.0849, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0859, val=0.0865, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0844, val=0.0863, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0823, val=0.0874, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 2 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0440
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0348
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2454, R²: -0.0014

📊 Round 2 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2457, R²: 0.0002

📊 Round 2 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2453, R²: -0.0037

============================================================
🔄 Round 6 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0812 (↓), lr=0.000500
   • Epoch   2/100: train=0.0844, val=0.0824, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0835, val=0.0830, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0832, val=0.0834, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0818, val=0.0849, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 6 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0013
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0067
============================================================


============================================================
🔄 Round 8 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0855 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0844, val=0.0849 (↓), lr=0.000125
   • Epoch   3/100: train=0.0839, val=0.0846, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000125
   • Epoch   5/100: train=0.0834, val=0.0849, patience=3/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0829, val=0.0852, patience=9/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 8 Summary - Client client_9
   Epochs: 17/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0021
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0413
============================================================


============================================================
🔄 Round 9 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0797 (↓), lr=0.000031
   • Epoch   2/100: train=0.0862, val=0.0798, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0857, val=0.0798, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0853, val=0.0798, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0851, val=0.0799, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0846, val=0.0800, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 9 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0245
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0186
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2447, R²: -0.0102

============================================================
🔄 Round 11 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0891 (↓), lr=0.000008
   • Epoch   2/100: train=0.0850, val=0.0890, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0849, val=0.0889, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0848, val=0.0889, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0847, val=0.0888, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0844, val=0.0885 (↓), lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0841, val=0.0883, patience=10/15, lr=0.000002
   📉 Epoch 23: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 11 Summary - Client client_9
   Epochs: 26/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0130
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0059
============================================================


============================================================
🔄 Round 12 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 12 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0200
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0041
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2451, R²: -0.0101

============================================================
🔄 Round 15 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 15 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0265
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0036
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2455, R²: -0.0155

============================================================
🔄 Round 16 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 16 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0168
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0649
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2456, R²: -0.0174

📊 Round 16 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2456, R²: -0.0169

============================================================
🔄 Round 21 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 21 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0155
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0808
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2459, R²: -0.0216

============================================================
🔄 Round 23 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 23 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0258
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0379
============================================================


============================================================
🔄 Round 24 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.1010 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.1010, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.1010, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1010)

============================================================
📊 Round 24 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0253
   Val:   Loss=0.1010, RMSE=0.3178, R²=-0.0345
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0219

============================================================
🔄 Round 26 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 26 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0283
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0287
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0219

============================================================
🔄 Round 27 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 27 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0317
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0434
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0218

📊 Round 27 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0218

============================================================
🔄 Round 29 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 29 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0350
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0068
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2460, R²: -0.0218

============================================================
🔄 Round 31 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 31 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0322
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0167
============================================================


============================================================
🔄 Round 32 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 32 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0317
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0088
============================================================


============================================================
🔄 Round 36 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 36 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0336
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0068
============================================================


============================================================
🔄 Round 37 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 37 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0413
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0133
============================================================


============================================================
🔄 Round 38 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 38 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0287
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0202
============================================================


============================================================
🔄 Round 39 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 39 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0209
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0565
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0219

📊 Round 39 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0219

📊 Round 39 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0220

📊 Round 39 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0220

📊 Round 39 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0220

============================================================
🔄 Round 48 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 48 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0404
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0196
============================================================


============================================================
🔄 Round 49 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 49 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0400
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0171
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0220

============================================================
🔄 Round 53 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 53 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0266
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0307
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0220

============================================================
🔄 Round 54 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 54 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0261
   Val:   Loss=0.0973, RMSE=0.3120, R²=-0.0317
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0220

📊 Round 54 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0221

============================================================
🔄 Round 57 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 57 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0268
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0313
============================================================


============================================================
🔄 Round 58 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 58 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0150
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0981
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0221

📊 Round 58 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0221

============================================================
🔄 Round 61 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 61 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0331
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0055
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0221

📊 Round 61 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0221

============================================================
🔄 Round 66 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 66 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0172
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0742
============================================================


============================================================
🔄 Round 68 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 68 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0318
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0104
============================================================


============================================================
🔄 Round 69 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 69 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0123
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0943
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0222

📊 Round 69 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0223

📊 Round 69 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0223

============================================================
🔄 Round 73 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 73 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0289
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0223
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0223

📊 Round 73 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0223

============================================================
🔄 Round 78 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 78 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0301
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0190
============================================================


============================================================
🔄 Round 79 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 79 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0220
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0576
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0223

📊 Round 79 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2460, R²: -0.0223

============================================================
🔄 Round 84 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 84 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0318
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0176
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0223

📊 Round 84 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0223

============================================================
🔄 Round 89 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 89 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0161
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0789
============================================================


============================================================
🔄 Round 90 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 90 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0290
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0238
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0224

============================================================
🔄 Round 91 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 91 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0279
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0332
============================================================


============================================================
🔄 Round 94 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 94 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0286
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0278
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0224

📊 Round 94 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0224

📊 Round 94 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0225

============================================================
🔄 Round 99 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 99 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0194
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0821
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0225

📊 Round 99 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0225

============================================================
🔄 Round 101 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 101 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0525
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0580
============================================================


============================================================
🔄 Round 104 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 104 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0082
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.1091
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2461, R²: -0.0225

============================================================
🔄 Round 110 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 110 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0276
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0298
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2461, R²: -0.0226

============================================================
🔄 Round 116 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 116 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0301
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0251
============================================================


============================================================
🔄 Round 118 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 118 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0282
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0711
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2461, R²: -0.0227

============================================================
🔄 Round 119 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 119 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0367
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0031
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2461, R²: -0.0227

============================================================
🔄 Round 121 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 121 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0124
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.1025
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2461, R²: -0.0227

📊 Round 121 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2461, R²: -0.0227

============================================================
🔄 Round 129 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 129 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0385
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0122
============================================================


============================================================
🔄 Round 131 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 131 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0202
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0655
============================================================


============================================================
🔄 Round 133 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 133 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0357
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0025
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0227

============================================================
🔄 Round 134 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 134 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0360
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0150
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0227

============================================================
🔄 Round 137 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 137 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0312
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0179
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0227

📊 Round 137 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0227

============================================================
🔄 Round 140 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 140 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0354
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0038
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0227

📊 Round 140 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0227

============================================================
🔄 Round 144 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 144 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0293
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0260
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0228

============================================================
🔄 Round 146 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 146 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0215
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0619
============================================================


============================================================
🔄 Round 148 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 148 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0263
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0367
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0228

📊 Round 148 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0228

============================================================
🔄 Round 153 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 153 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0224
   Val:   Loss=0.0978, RMSE=0.3128, R²=-0.0723
============================================================


============================================================
🔄 Round 155 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 155 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0304
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0255
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0229

============================================================
🔄 Round 156 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 156 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0164
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0774
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0229

📊 Round 156 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0229

📊 Round 156 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0229

============================================================
🔄 Round 166 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 166 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0219
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0656
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0229

📊 Round 166 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0229

============================================================
🔄 Round 172 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 172 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0209
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0829
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0230

📊 Round 172 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0230

============================================================
🔄 Round 176 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 176 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0299
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0614
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0230

============================================================
🔄 Round 177 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 177 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0211
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0625
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0230

============================================================
🔄 Round 178 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 178 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0402
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0122
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0230

============================================================
🔄 Round 180 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 180 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0264
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0504
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0230

📊 Round 180 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0230

📊 Round 180 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2460, R²: -0.0230

📊 Round 180 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0230

============================================================
🔄 Round 189 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 189 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0308
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0221
============================================================


============================================================
🔄 Round 190 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 190 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0264
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0397
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0231

============================================================
🔄 Round 191 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 191 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0198
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0731
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0231

📊 Round 191 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0231

============================================================
🔄 Round 196 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 196 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0260
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0489
============================================================


============================================================
🔄 Round 198 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 198 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0365
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0078
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0231

📊 Round 198 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0231

============================================================
🔄 Round 203 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 203 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0279
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0417
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0232

============================================================
🔄 Round 210 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 210 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0273
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0417
============================================================


============================================================
🔄 Round 211 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 211 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0293
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0280
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0232

📊 Round 211 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0232

============================================================
🔄 Round 213 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 213 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0256
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0466
============================================================


============================================================
🔄 Round 215 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 215 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0373
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0012
============================================================


============================================================
🔄 Round 216 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 216 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0315
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0190
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0232

============================================================
🔄 Round 217 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 217 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0350
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0082
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0232

============================================================
🔄 Round 218 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 218 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0430
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0300
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0232

============================================================
🔄 Round 221 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 221 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0317
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0266
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2460, R²: -0.0233

============================================================
🔄 Round 224 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 224 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0217
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0608
============================================================


❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
