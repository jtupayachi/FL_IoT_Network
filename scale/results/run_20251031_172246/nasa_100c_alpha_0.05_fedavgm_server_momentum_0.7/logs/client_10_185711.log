[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f565241-4793-4c2e-9db3-163c0e69fee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47de8369-8eba-451a-a68b-69f1b1ff9abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989b7c23-b01f-4201-9d71-64e9dd1d7436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b96cae9-fdc6-44b5-a1b0-6018d12761a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ae8ca7-51e6-4969-b980-f67ff3e377d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104b79be-956b-412c-9893-ce2e03086892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1ed997-f7ee-4920-b007-1199decafeb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95fc420b-0e14-4452-8bd5-616f1776a150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbd0e452-160b-4ba1-95f8-1eb879bcbf97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053a1d3b-7a83-445a-87a8-e2d4d9d47e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab8efcd-c0db-4065-a3d8-9930343fd33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b7f152-7396-4aa7-afd1-d3fbd19d79e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1000c2a6-b4cd-43f6-aa62-3fc2cdeb5c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 394deec7-916f-4424-a4d0-1c490714fcb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16396fd6-d412-469e-bbf7-47f37fe7bf50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b29b30-985d-4068-8edd-5205329668d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d88a522-57ae-4e09-a12e-9f623ab7d127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea4a92cf-72dc-4c9a-bb7a-ebcd285b36fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82eb3f56-3f76-4083-a6a3-bdf26903caf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a931dcb4-56ae-4574-a282-be2473105aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f53812-1042-4ece-b6b7-08c4f55e02a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691a082e-3c4b-4e0d-9e9f-f89ccd559008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cfba954-5cdc-4cfe-ae61-d0e3e896c0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a25d1e20-c6f1-4fe1-8f87-98457821068e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708fd670-7e0d-479a-ac29-6e61500bbd80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a4f8e7-a2d1-4c3d-a366-dab8da4a852d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c82b1374-0779-4315-96f7-1bee0aab86c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d500ed7-fbf5-4607-b07d-18cf9c1b06f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ce6950-7809-4645-9844-6a8311c804ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184a906e-f0e4-4ab0-a59d-887645ec6175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbcac68c-1738-41da-a036-3b7906cb9ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8220fea-f7f1-480f-a51d-817886859118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccd06c56-fca8-4b33-9273-29fb930733fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ef861f9-1b84-4ff5-ac7b-29fa70bc6438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b6ac244-fd64-4642-a1ad-a72dfb42174b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5485de78-e039-4ced-bc9f-36527d2813f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b57916-85dc-4062-a09d-60b935d84e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1049f8aa-1deb-4df7-a3fc-117d8dc21093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ef58ae-9e61-4dbb-a90c-67124ce8a17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a361782c-5734-40d4-84dc-81200609d377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf41f59-d1e2-44b2-aa21-0b41c75f4747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6e83fc-73b7-46f9-ab9a-8dc52c922f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60a79c07-db47-4d9e-9ba6-06aa6cad0317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3af9013-f155-4c73-9345-ed070b09b411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2daf582-022e-42c8-96e3-e246699d49da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a058e4a6-f09f-4ee4-948b-df4dfa0f8e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26e54799-c0cd-41dc-9981-c12db66389ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 846fca94-4a5f-4774-8183-cd78da56739f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de86c37-5e0e-4166-9d14-8822801e5fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2984584d-6470-4f07-b3c9-887f949df615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f77e6b9-77bd-41b5-b572-982b09deecb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 593fb52a-5e36-46c9-8c94-8dcc957bf0ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd06b561-be4b-422d-adb0-e3015b4acb34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b0e93f6-a745-42da-a893-2d942ecbac84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f14789f-fa02-4a48-977e-7e5f5fe3eb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52d7e803-51c7-4b62-b563-ec4ed6b49dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a97c34-7ced-4c46-b37d-1391ebf9d7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a373cf1-5632-4fee-8d05-3d6ed5e88ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efdce761-7abd-4695-be4d-4c95880e2f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90f1023d-9141-4cd1-b21c-316779aa6f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20789af6-3ba5-4136-a2ee-21e0d39a5cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc5a76f8-e58f-4d27-a877-fed9819dcd40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3460bf8c-706c-424c-a47d-de3ffaf035e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45a8a3b8-0ba6-49bc-9fe5-a55bc2a5ddd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd49b434-7e9f-471c-89c7-edbed844affe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937c264f-446f-404b-9f35-16cfca9f9925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c943a127-702b-4fda-b322-90f61da3810c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e00fe586-a4d5-4992-be88-17d4dd0c9069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 108c8377-a03e-47e8-8537-644b9d69abf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abcc02ed-b1f8-453f-a55e-d1acce076d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9f15c1-e0f3-49bf-b943-ab57c486409f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 839281cd-be86-4c18-ba08-60e929c8de6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 086b776e-3a20-4f3d-b684-71b02d4498a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2930be-87ba-48ee-bf43-e2260197283a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d373691-6294-49a1-a50c-4aea4d1aaba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 436969bf-d0cd-4da7-b2bf-10960a0bd882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18267735-b7e5-41d3-8527-edd7e26d1ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b28186-bcce-43ca-beab-621d9793bfdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d3ea6ef-2cc3-4a64-a585-057b786f0b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194b9e31-e90c-423b-88ae-bbbe83a3c9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c46cae-7019-4d00-9ce3-a7b12618630b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac84528-cac3-4e05-93d7-f77ab7875d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c3a5fab-88cc-4e66-b19f-88f06bd31012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76ca317f-ec86-42e7-9128-a8ae5ca23c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8279bbf9-a928-45c9-ba4e-bc1f971276f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f2ec32-78a8-4095-b220-ac3824d9a874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72d7d21e-f1b7-4d5d-84d9-4525f9cb185d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54ef0ab-a63e-4535-aeda-7903d50cfd38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d47d1c-f4df-49f6-bcc6-f3971ba3d177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4608ee-13cd-4c59-a1d4-80c377d5ac34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cad3cf2c-d88f-4471-b357-68db72e69ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d1b632-546c-4b89-8858-d16153639b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d4f2dac-acf4-4c34-93c6-49c03cb16235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06200e79-deaa-497b-975b-c13ce8c7b8d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 773260e2-3f7d-442f-b75f-0a4b1280c7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec68b59e-f84a-4309-ad61-f929953415a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc6831ff-4bd9-4502-aecf-d2cc499d2cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2df6c21-bee3-4076-942f-1c950a0d0fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 183d823c-cd11-48ef-9e11-003fc320d370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745e96de-92ea-4340-968c-c17352420a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 849ff4c7-d06a-4a34-a257-a2996ced13b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcc271b-a64f-4aec-b712-efa82b709b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987311a0-67f1-4f0f-ace2-54f00d52e368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 549f76fa-fe0d-4fe7-931a-340ba6197a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063a5128-265b-4014-b346-95600c9336a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4cccace-baf7-4b5c-8ee6-3ef8f48180af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c0f383e-c399-433b-bca1-b239f02db03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ce5454-19ef-4d0f-9bc8-9f538c0a557e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad92fb08-3e8f-4a43-8d37-aada224ba33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4b4b04b-161e-40d4-abab-2e1986b19776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 031bdb32-f173-4f67-aa3a-ff1e8b1d7c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22d35ad-8b80-4351-aac8-c24a28c57e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ced6f25-a201-4e66-8cdd-af857adc4685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae0d648-7d6b-4385-92cb-73ec29724921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2886dc9f-c519-4a62-9d8c-68340f8f3124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee55be70-279d-46c9-aa71-42831f35e8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3870e559-78b0-4838-9138-6b44cf693b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b2071c-66d1-4f00-99f1-8e00b86a3abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93e19603-d975-40d5-96af-e6681105db4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3721efb-588a-4e54-9593-39252e4ce09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca2496c-0544-4ee7-9644-2354fbe38380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7eaf5a3-1c61-4ebe-9ee0-56e6ce4ad312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa89f02-378a-41b0-8757-c235f6e9d83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37698e23-690e-4fdb-ae88-9cdcd9bdea77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a702b807-cb95-455e-a153-e413a1f33ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 975036e8-25b0-4072-95d6-932748844cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01e482d2-5d4f-4451-9946-82248603e091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13c61e79-342d-43e5-afd0-ddecce1a3861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e47434be-2e88-433a-8020-599784684ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c50c728-2448-4f39-a939-0a9a88abb64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39aa7cb7-b27d-4d76-bd59-04df33d2bc80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57c652ed-4a13-4758-b4f7-408ee0ecb569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5389f12-fedc-47e3-b814-4b2742875f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e0901e0-cb49-4079-a692-42ed5468f13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bcf4ccb-e7d1-4d39-8afa-2284963a5e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3949c5b7-c4ef-4925-848b-6fdb88c4e955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8ba26c9-d19c-48a9-bca5-140168b41111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4f91a2-1e78-4923-94a1-376586a3d8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e24fd6f7-2799-4b2e-8dfe-a71921215b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09857c56-73db-41c6-9721-d44e14914f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 870f6895-1abe-4ad7-8a1b-6db0aef813e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da779454-be9d-4956-ad65-0bbb29509393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f61eefa-5b45-465d-8ff7-410e3af26848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d02ef2e-aa95-4af2-9a5b-59556f57d829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82fdfa2d-2d91-44bf-8884-a2d6ff347e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38e9ddc9-9d64-4593-90c3-20e7ba8c2a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5b5c566-5d46-40cc-a3ad-13bb2e90e9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be77bfaa-e4af-4bee-84f2-3dd4bbc3cf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf6d4e2-23da-4838-819b-3797d4611521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49dd5351-32d2-49c1-9e6f-5413d2f3ec6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a5328b-3d91-4c22-a124-b0b1f3d93dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e49322-bcee-4c58-bbe5-057fb1fa6a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7251e41-54e5-4eb7-ab11-cd10a31bc497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9144755a-9d48-4a27-8c03-b69adf4ce399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4659ac07-decf-41e7-9de0-848f9889b74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab4c7a4-01d7-4008-9419-b7b3d2bca35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f178f814-a45c-430e-a589-60eed34ff867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 946ced1c-247d-462e-8024-5c6e8fa9c32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360c7a01-b1c3-4ce2-8202-a5df22405263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c507c92-708f-4782-b778-16901abc6f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67fa806a-4da8-44d4-bf28-8062a1fbaf0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4732c5e6-43ca-4ef4-8f6c-ce4e1e58c351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b2ff2e-3f4b-40bd-ae04-2baca03d5cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb92446c-d2e5-49a6-a5b9-20dcf16e0b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 841a8d13-08ec-4fcc-be83-63fb92ac2fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fc37568-802f-4a55-9541-0f2c08df319d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef2fd45-8472-4478-a4de-baed7d6afd45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f665694-14e9-4cc6-909c-83f5d9feff27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5e88c59-2009-48cd-96e9-7f3fb67e9745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75c86fc2-86ba-4074-90a6-3730ed42609a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d737be-11d3-4aee-b04e-4d938758d13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74bf715d-685e-490a-96c9-b170b3901afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 804434e2-c274-44c5-b40a-1082c485c492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6980d4a9-6119-4317-92f4-d1268d7dea29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b37dede-43ef-4620-b768-240047dddd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0957d219-1193-4428-9560-2fd09b2a3bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ca14ea1-6452-4008-9270-45d797c4d296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da1a96c2-7334-4b9c-a87a-47555550b028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f47ac1f9-b970-4be5-a7b9-176f0a6d4d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3799ba63-823e-4d96-bc63-d2850c18d03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fa76a89-537c-4fc9-9166-7ba7889cbd96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a93eba-6fae-49b8-9a0f-eb1f3090cc2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5722b0ef-a9a7-4fa5-9aa3-0cfaa4071f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5965d1d8-2530-4249-94bd-200f400b6cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88b08e81-3949-4b6f-bde3-1191be2fb416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 106fddf8-8e30-4c8d-8dd7-0a216dd4bfac
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(424, 24), y=(424,)
   Test:  X=(106, 24), y=(106,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 415 samples, 5 features
   Test:  97 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2879, val=0.1835 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1464, val=0.1093 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0894, val=0.0742 (↓), lr=0.001000
   • Epoch   4/100: train=0.0857, val=0.0757, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0819, val=0.0754, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0800, val=0.0733, patience=5/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0773, val=0.0736, patience=15/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 1 Summary - Client client_10
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0179
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0128
============================================================


============================================================
🔄 Round 2 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0889 (↓), lr=0.000500
   • Epoch   2/100: train=0.0776, val=0.0885, patience=1/15, lr=0.000500
   ✓ Epoch   3/100: train=0.0772, val=0.0883 (↓), lr=0.000500
   • Epoch   4/100: train=0.0768, val=0.0886, patience=1/15, lr=0.000500
   📉 Epoch 5: LR reduced 0.000500 → 0.000250
   • Epoch   5/100: train=0.0766, val=0.0884, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0757, val=0.0885, patience=8/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 2 Summary - Client client_10
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0191
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0078
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.3169, RMSE: 0.5629, MAE: 0.4776, R²: -2.5836

============================================================
🔄 Round 3 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2803, val=0.2491 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.1569, val=0.1455 (↓), lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   ✓ Epoch   3/100: train=0.1010, val=0.1041 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0851, val=0.0953 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0815, val=0.0906 (↓), lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0780, val=0.0830, patience=1/15, lr=0.000031
   📉 Epoch 19: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0779, val=0.0826, patience=8/15, lr=0.000016
   📉 Epoch 27: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 3 Summary - Client client_10
   Epochs: 28/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0066
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0284
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1279, RMSE: 0.3577, MAE: 0.2969, R²: -0.4466

============================================================
🔄 Round 4 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1344, val=0.1349 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1319, val=0.1322 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1289, val=0.1296 (↓), lr=0.000008
   ✓ Epoch   4/100: train=0.1260, val=0.1271 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.1234, val=0.1248 (↓), lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.1143, val=0.1175 (↓), lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.1088, val=0.1128 (↓), lr=0.000002
   📉 Epoch 23: LR reduced 0.000002 → 0.000001
   ✓ Epoch  31/100: train=0.1068, val=0.1112 (↓), lr=0.000001
   • Epoch  41/100: train=0.1054, val=0.1100, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.1041, val=0.1088, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1029, val=0.1078, patience=1/15, lr=0.000001
   ✓ Epoch  71/100: train=0.1017, val=0.1068 (↓), lr=0.000001
   • Epoch  81/100: train=0.1006, val=0.1058, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0996, val=0.1049, patience=2/15, lr=0.000001

============================================================
📊 Round 4 Summary - Client client_10
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0983, RMSE=0.3135, R²=-0.2605
   Val:   Loss=0.1041, RMSE=0.3227, R²=-0.1700
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1079, RMSE: 0.3285, MAE: 0.2756, R²: -0.2205

============================================================
🔄 Round 5 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 5 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=-0.1019
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0954
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1337, RMSE: 0.3657, MAE: 0.3059, R²: -0.5123

============================================================
🔄 Round 7 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 7 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0719
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0766
============================================================


============================================================
🔄 Round 8 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 8 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0262
   Val:   Loss=0.0675, RMSE=0.2598, R²=-0.0670
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2573, R²: -0.0059

============================================================
🔄 Round 11 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 11 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0004
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0386
============================================================


============================================================
🔄 Round 14 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 14 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0089
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0310
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0948, RMSE: 0.3078, MAE: 0.2612, R²: -0.0718

============================================================
🔄 Round 16 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 16 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0277
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0227
============================================================


============================================================
🔄 Round 17 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 17 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0249
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0401
============================================================


============================================================
🔄 Round 18 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 18 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0141
   Val:   Loss=0.0737, RMSE=0.2716, R²=-0.0393
============================================================


============================================================
🔄 Round 21 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.1008 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.1008, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.1007, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.1007, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.1007, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.1007, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1008)

============================================================
📊 Round 21 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0441
   Val:   Loss=0.1008, RMSE=0.3174, R²=-0.0487
============================================================


============================================================
🔄 Round 22 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 22 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0423
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0586
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0975, RMSE: 0.3123, MAE: 0.2663, R²: -0.1032

📊 Round 22 Test Metrics:
   Loss: 0.0980, RMSE: 0.3131, MAE: 0.2672, R²: -0.1085

============================================================
🔄 Round 25 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 25 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0376
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0306
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0978, RMSE: 0.3127, MAE: 0.2677, R²: -0.1059

============================================================
🔄 Round 26 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 26 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0345
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0189
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0972, RMSE: 0.3117, MAE: 0.2670, R²: -0.0990

📊 Round 26 Test Metrics:
   Loss: 0.0963, RMSE: 0.3104, MAE: 0.2660, R²: -0.0895

============================================================
🔄 Round 28 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 28 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0264
   Val:   Loss=0.0981, RMSE=0.3132, R²=-0.0217
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0944, RMSE: 0.3073, MAE: 0.2636, R²: -0.0681

============================================================
🔄 Round 32 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 32 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0147
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0151
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0940, RMSE: 0.3066, MAE: 0.2630, R²: -0.0632

📊 Round 32 Test Metrics:
   Loss: 0.0939, RMSE: 0.3064, MAE: 0.2628, R²: -0.0616

📊 Round 32 Test Metrics:
   Loss: 0.0938, RMSE: 0.3063, MAE: 0.2628, R²: -0.0611

============================================================
🔄 Round 38 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 38 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0130
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0251
============================================================


============================================================
🔄 Round 39 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.1066 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.1066, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.1066, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.1066, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.1066, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.1066, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1066)

============================================================
📊 Round 39 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=-0.0074
   Val:   Loss=0.1066, RMSE=0.3265, R²=-0.0342
============================================================


============================================================
🔄 Round 40 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 40 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0176
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0093
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0937, RMSE: 0.3062, MAE: 0.2627, R²: -0.0601

============================================================
🔄 Round 46 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 46 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0141
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0316
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2626, R²: -0.0590

============================================================
🔄 Round 51 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 51 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0073
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0461
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2626, R²: -0.0589

============================================================
🔄 Round 52 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0997, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 52 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=-0.0073
   Val:   Loss=0.0997, RMSE=0.3157, R²=-0.0808
============================================================


============================================================
🔄 Round 53 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 53 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0156
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0032
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2626, R²: -0.0588

📊 Round 53 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2626, R²: -0.0587

📊 Round 53 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2626, R²: -0.0587

============================================================
🔄 Round 57 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 57 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0097
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0244
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2626, R²: -0.0587

============================================================
🔄 Round 58 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 58 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0148
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0632
============================================================


============================================================
🔄 Round 59 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 59 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0122
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0169
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2626, R²: -0.0587

============================================================
🔄 Round 61 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 61 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0122
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0109
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0936, RMSE: 0.3059, MAE: 0.2626, R²: -0.0585

============================================================
🔄 Round 62 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 62 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0182
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0045
============================================================


============================================================
🔄 Round 63 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 63 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0092
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0253
============================================================


============================================================
🔄 Round 64 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 64 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0086
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0258
============================================================


============================================================
🔄 Round 69 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 69 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0124
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0057
============================================================


============================================================
🔄 Round 70 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 70 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0082
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0297
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0935, RMSE: 0.3058, MAE: 0.2626, R²: -0.0575

📊 Round 70 Test Metrics:
   Loss: 0.0935, RMSE: 0.3058, MAE: 0.2626, R²: -0.0575

============================================================
🔄 Round 74 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 74 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0113
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0130
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0935, RMSE: 0.3058, MAE: 0.2626, R²: -0.0574

📊 Round 74 Test Metrics:
   Loss: 0.0935, RMSE: 0.3057, MAE: 0.2625, R²: -0.0570

============================================================
🔄 Round 79 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 79 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0020
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0538
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0934, RMSE: 0.3057, MAE: 0.2625, R²: -0.0568

============================================================
🔄 Round 80 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 80 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0107
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0103
============================================================


============================================================
🔄 Round 81 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 81 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0121
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0540
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0934, RMSE: 0.3056, MAE: 0.2624, R²: -0.0562

============================================================
🔄 Round 82 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 82 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0103
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0111
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0934, RMSE: 0.3056, MAE: 0.2624, R²: -0.0560

============================================================
🔄 Round 84 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 84 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0091
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0133
============================================================


============================================================
🔄 Round 85 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 85 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0043
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0467
============================================================


============================================================
🔄 Round 87 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 87 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0155
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0121
============================================================


============================================================
🔄 Round 89 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 89 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0130
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0200
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0934, RMSE: 0.3056, MAE: 0.2624, R²: -0.0560

============================================================
🔄 Round 92 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 92 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0137
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0064
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0934, RMSE: 0.3056, MAE: 0.2625, R²: -0.0560

📊 Round 92 Test Metrics:
   Loss: 0.0933, RMSE: 0.3055, MAE: 0.2624, R²: -0.0556

============================================================
🔄 Round 98 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 98 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0127
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0210
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0933, RMSE: 0.3055, MAE: 0.2624, R²: -0.0553

📊 Round 98 Test Metrics:
   Loss: 0.0933, RMSE: 0.3055, MAE: 0.2624, R²: -0.0552

📊 Round 98 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2624, R²: -0.0552

============================================================
🔄 Round 101 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 101 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0089
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0399
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2624, R²: -0.0551

============================================================
🔄 Round 104 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 104 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0168
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0045
============================================================


============================================================
🔄 Round 106 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 106 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0068
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0231
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2624, R²: -0.0550

============================================================
🔄 Round 107 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 107 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0012
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0559
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2624, R²: -0.0550

============================================================
🔄 Round 108 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 108 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0104
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0122
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2624, R²: -0.0551

============================================================
🔄 Round 111 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 111 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0032
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0353
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2624, R²: -0.0551

============================================================
🔄 Round 114 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 114 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0105
   Val:   Loss=0.0721, RMSE=0.2684, R²=-0.0078
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2624, R²: -0.0551

============================================================
🔄 Round 115 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 115 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0159
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0134
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2624, R²: -0.0551

📊 Round 115 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2623, R²: -0.0551

============================================================
🔄 Round 118 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 118 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0128
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0012
============================================================


============================================================
🔄 Round 120 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 120 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0181
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0079
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2623, R²: -0.0551

============================================================
🔄 Round 121 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 121 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0049
   Val:   Loss=0.0676, RMSE=0.2600, R²=-0.0322
============================================================


============================================================
🔄 Round 122 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 122 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0075
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0272
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2623, R²: -0.0551

============================================================
🔄 Round 123 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 123 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0094
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0127
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2623, R²: -0.0550

============================================================
🔄 Round 125 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 125 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0067
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0377
============================================================


============================================================
🔄 Round 126 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 126 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0090
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0133
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2623, R²: -0.0549

============================================================
🔄 Round 130 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 130 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0097
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0225
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2623, R²: -0.0549

📊 Round 130 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2623, R²: -0.0547

============================================================
🔄 Round 133 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 133 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0079
   Val:   Loss=0.0689, RMSE=0.2624, R²=-0.0398
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0932, RMSE: 0.3054, MAE: 0.2622, R²: -0.0546

============================================================
🔄 Round 134 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 134 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0127
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0264
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0932, RMSE: 0.3054, MAE: 0.2622, R²: -0.0545

============================================================
🔄 Round 137 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 137 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0254
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0161
============================================================


============================================================
🔄 Round 138 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 138 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0043
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0827
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0932, RMSE: 0.3053, MAE: 0.2622, R²: -0.0542

============================================================
🔄 Round 139 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 139 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0144
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0007
============================================================


============================================================
🔄 Round 140 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 140 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0127
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0120
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0932, RMSE: 0.3053, MAE: 0.2622, R²: -0.0541

📊 Round 140 Test Metrics:
   Loss: 0.0932, RMSE: 0.3053, MAE: 0.2622, R²: -0.0540

============================================================
🔄 Round 142 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 142 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0052
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0253
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0932, RMSE: 0.3053, MAE: 0.2622, R²: -0.0539

============================================================
🔄 Round 143 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 143 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0133
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0159
============================================================


============================================================
🔄 Round 144 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 144 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0161
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0210
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0932, RMSE: 0.3052, MAE: 0.2622, R²: -0.0536

📊 Round 144 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2621, R²: -0.0535

📊 Round 144 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2621, R²: -0.0533

📊 Round 144 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2621, R²: -0.0532

📊 Round 144 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2621, R²: -0.0532

📊 Round 144 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2621, R²: -0.0531

============================================================
🔄 Round 156 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 156 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0060
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0252
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2621, R²: -0.0530

============================================================
🔄 Round 157 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 157 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0037
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0492
============================================================


============================================================
🔄 Round 158 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 158 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0086
   Val:   Loss=0.0668, RMSE=0.2584, R²=-0.0125
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2621, R²: -0.0527

============================================================
🔄 Round 160 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 160 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0120
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0031
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2620, R²: -0.0526

📊 Round 160 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2620, R²: -0.0525

============================================================
🔄 Round 165 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 165 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0169
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0003
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2620, R²: -0.0525

============================================================
🔄 Round 167 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 167 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0162
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0152
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0931, RMSE: 0.3050, MAE: 0.2620, R²: -0.0524

============================================================
🔄 Round 169 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 169 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0157
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0189
============================================================


============================================================
🔄 Round 171 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 171 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0099
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0006
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0522

============================================================
🔄 Round 172 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 172 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0003
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0392
============================================================


============================================================
🔄 Round 174 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 174 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0118
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0017
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0522

============================================================
🔄 Round 176 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 176 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0109
   Val:   Loss=0.0688, RMSE=0.2623, R²=-0.0629
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0522

============================================================
🔄 Round 178 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 178 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0109
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0099
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0522

============================================================
🔄 Round 180 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 180 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0051
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0224
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0521

📊 Round 180 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0521

============================================================
🔄 Round 183 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 183 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0039
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0354
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0521

============================================================
🔄 Round 185 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 185 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0041
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0478
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0520

📊 Round 185 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0520

============================================================
🔄 Round 187 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 187 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0122
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0071
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0520

============================================================
🔄 Round 190 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 190 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0068
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0145
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0520

📊 Round 190 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0519

📊 Round 190 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0519

📊 Round 190 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0519

📊 Round 190 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0519

============================================================
🔄 Round 199 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 199 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0080
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0594
============================================================


============================================================
🔄 Round 200 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 200 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0058
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0188
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0518

============================================================
🔄 Round 201 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 201 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0090
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0049
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0518

============================================================
🔄 Round 203 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 203 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0014
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0375
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0518

============================================================
🔄 Round 204 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 204 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=-0.0033
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0347
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2620, R²: -0.0519

============================================================
🔄 Round 205 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 205 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0097
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0021
============================================================


============================================================
🔄 Round 206 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 206 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0008
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0453
============================================================


============================================================
🔄 Round 207 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 207 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0092
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0299
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0930, RMSE: 0.3049, MAE: 0.2620, R²: -0.0517

============================================================
🔄 Round 210 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 210 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0062
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0177
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0930, RMSE: 0.3049, MAE: 0.2619, R²: -0.0516

❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
