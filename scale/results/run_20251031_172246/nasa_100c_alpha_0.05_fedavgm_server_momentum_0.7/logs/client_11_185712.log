[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0181fa79-e95e-4cb3-b12b-5e6808a5e96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c688cd6-e14f-42d2-b970-027ccbc8dcd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a09753c-aa2c-4d8d-841c-f72e5516c515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29ac34bc-7445-44a2-a96d-bfee1d6e9eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11e36342-9b9e-45e2-9086-6eb3655bc44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57e17e7-2cd5-4ef0-a58a-9c75cdffda4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011be31a-7e66-400a-a703-c181d35cd874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd727281-157f-41f9-b7c3-2f18a6cf434e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de26e440-3ad1-46db-ab3b-6f60a05c0ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ef0b6d-5d5f-44f0-8a7f-2044135f8371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c36f0b-fb5a-45b5-bc3d-a08d42f03484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 203d7b68-1ccd-4ca5-9399-e43d68b26319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0857d537-c567-4147-99aa-5785d32c5bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4315b69f-b8c2-4b13-ad35-b209f9e18cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92060ddd-d1d1-4ea5-8da5-efb5e69c3f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77c51399-24f9-4f16-8880-9f86958654b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 446182cc-5865-44c7-a066-de3955c7dc70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd913126-0d4d-4e08-a276-5e9de1b22e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe9bf92-8496-421b-b1fb-1054c0137174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06679e6a-6fd8-4d86-9fab-51fe9894d327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d841ce66-aba3-44eb-a787-ba70ecf7becd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40ae6b25-52c6-4ecb-bdbb-ca63ea464f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b3c2d64-ac8a-487c-a8e3-9a0bdc5e4cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eceb2a9b-f88e-4903-84b1-6e46c2d62873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc9178c3-8625-458d-8d94-938a1c5fa870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaba7d82-ba8f-46a4-8a94-13bc243cf182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b75db7-b61e-4b1d-af78-0939e7572112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d95d4ed9-a34e-4984-b8d8-91ad3c339208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6380fc58-86bc-4fca-b533-8afa6eae8b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8c898d-7095-42c2-938e-2596c0e9e63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b451ef4-f459-4065-8ec3-19ca6046443b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e37628e-5dfe-41d2-8166-264afa3859f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3115f4b0-9443-47c5-801a-2ea78fb44c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1906f853-516f-4d44-865d-689753fb773c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b503e46a-5e08-4bc1-b02f-e40e27ae22a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efa5f617-a48d-4292-ab25-b7d759ffe944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3dc3ae2-8f35-433b-bed0-09f3dce9e72e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82115db2-05c4-4e5c-88cd-5c1dac24b78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d83cfafe-57cc-4501-a8c1-b5a80190f5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca723f7-1a49-41df-8bbc-9eaaef3cedcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 883d76e3-6541-4ca5-bfb3-da2e8ec60f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ace1ee2-7957-4299-9b61-816e732fc957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e2870a-b473-4ec5-a899-bd1acba399ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce284f09-718a-444c-9bed-9390183a7365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d01cbd-81c8-4204-9d0e-83d876fda88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a84bb7f-201a-45b4-81c6-c5b2606ca08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 146c5a2f-b217-4cfa-bd86-2245e3a0e862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0b89ad0-fc98-4a94-81a9-964c44bff8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a95ca920-71d2-4d2e-8f53-0d5c58ad51a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a1b1217-ef06-4f74-a0c9-381c6d9e2ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec70506e-371e-4701-8f07-de03ba6601a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35125dd9-9b9a-4357-846e-ca4a9623ad19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0c6a352-0674-4a33-8138-7094fd67df9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a8bf78-46c4-40db-9285-61ce3affa639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f47cad9-1b9e-4c37-8ce7-2a0666e234b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee35e7dd-d6f1-481d-bad6-5115f0e236d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5728f4b-6881-457c-b5a7-1d4b248f8e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81a2c5ff-8eb7-4f49-b502-32a224901c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ab81be-b158-471d-be67-ee2bc25105d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73315386-82b3-42d7-a608-598de3301c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5aa1178-4836-4e0a-8e6d-41113be5cca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77e8fe5-e43c-463e-9ee3-51035668e976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8327e1e3-7501-45b9-a963-3fdbcafd123d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b954f62-a0bb-4778-9fdf-e17c1c952d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bfe4b24-a47c-4652-ad74-3dcb0bcc8f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9dbae74-f57c-4d69-9172-8e399d65ebd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d426a84-f31a-4b05-ad4a-0519889b43b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c2d914-de3e-44ea-8d68-48801d2abeb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3d2d16-dc5a-4309-9b6e-1dc9633c9b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc85d85-0a3c-47d1-8360-2d2755a2435d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc7e127-abb9-4e50-b0ac-244442c4f5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cfc93b1-581d-4a8f-be60-2e58ca54ffbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44efbeb-a4d3-43eb-aa01-156fbbc1453d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a5757d-5150-49a6-b708-a956b95fe77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fa3ecd1-f518-4e50-a762-c380f7e58568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2b709f-4983-46b0-992e-5459eae9e48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaf0eace-a1cf-47cc-afab-3331f4ba2b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9576ce2-c81d-4148-8d16-a5e14dc44990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e66416-f056-4349-a60f-630a5f5c73c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9ad3bbd-83c9-4a1e-9ce2-fce5db57b94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a57d40-a25f-482d-948b-b9c4ae8a81e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b82806be-9fa7-4b7c-9e07-d4a6c1212954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06387b6b-81b0-4f55-9e4f-19f0f78d8077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d8f39e6-6db9-4f63-9266-7fdf0ce23363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10448b6-09b4-4b87-85d1-c80729ed9361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0453914c-2300-444c-a3d5-acb7598b5e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d831cc-34b8-43f3-859d-43eebebc6505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91baebb5-b61e-4017-a350-b524d33df0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e621ee9-e349-44c4-8e79-2a92f6dfbb84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5addf943-ca64-45ae-a326-a122aa70490d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89797fa-50a9-4fed-87f2-09de504b3e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736c641f-a75a-44c3-86dc-93711ce4dd1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31890f1e-714c-4f89-ab92-dcff7503c88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e3070f9-6475-4f02-b75f-d2de6e536b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5873cd5-aa6a-4c0b-8e68-21d2e39985f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c53ea1e4-a2ee-42a9-8bbd-01430752c414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7371a88f-4830-42eb-b29a-a9f6e33cf0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0259a409-493e-4022-be5b-42e5023ae0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0269ebd2-9463-46c3-b762-afdd557d4200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78c576e0-e99b-4fc9-a436-9a5d3e81b362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ed266c-0cbc-4f4d-8b7f-cb7b36db8371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e23ddcfb-da2b-47c7-8025-ea93b780c853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e59a01-3fa5-4d73-aa49-3586c8f63101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9267b5b8-823d-45bc-b8b4-090aafa17b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737dec20-d684-45c0-a43e-39fc0e1001a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df797b93-e363-49b3-ad2c-f74b9780fe41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b82fa55d-b9ad-43a5-ac63-4c15f6e723b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc8d931-9611-484e-a8a5-fafac348c60d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b0b6638-53ca-4d74-afd3-2be2b0b16fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177e081d-c745-4049-a8a0-dedc30cf81fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51cb9147-ec34-4283-843e-bc4fa2b31cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd71d95e-1521-408e-8aee-a50d0bc74d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078875ae-ed26-42c5-a302-8285b154cd68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12fa0b2a-36ce-4be7-bddd-81fb72fa4bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b70a5b88-8cdc-4567-9af1-3333f8e76c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70aa7574-5fd4-4797-88c1-85d46fb7d6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a8a414b-cd7f-45ad-8c3a-dfaace04f392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f08f47e6-aa01-405f-9c97-661d1b038ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b878364-92fa-4dee-ae31-d78bb9114d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d98d6b-a5c9-4e60-8d3d-7f6fc5b904f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4423b99f-42ac-491d-9759-77363eeea9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33422dee-193d-43b0-ac51-24ad0674341a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7809df-05ea-4496-9f28-23a0a9443d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 594da468-f19b-422f-ad5a-0ead286693f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d8cff7-5738-4442-90cd-4b3beb3dfc51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d672eb-554f-4289-956d-2677f815af09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0c9a722-8b0a-4ab4-802f-71895bb366c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f158144-f190-447f-8517-c4d319218b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b084248-7bac-45db-90b2-75ce27da2987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e63e97b-9099-4d80-9b3b-5f12b5283cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1eec493-8563-486b-a714-e52e93785723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bca7373-7f1f-4d97-99bf-cf633a3f6f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a62be289-d038-4d5a-b6ff-fe54ac28e199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68c9de3-cd73-490a-8cb7-cb1619920e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8af277-69ed-4360-99fa-99f26e98fb79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252a2323-0d0b-4d49-ab4e-71a1e3ead313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0486af8-ef20-4079-9496-11a4516fb3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad06c40a-4bbd-45b2-b4dc-2a8d9ba9c2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc256903-c32e-4a04-a260-70e432f6638e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 715be10b-cb4f-4194-9a41-291f6d44455f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 138b4fc7-d612-4e5c-94a6-4d0992dd7578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e3f7ace-18c8-42be-9f4a-0fe7f7e13cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bfa7eae-644d-4435-8e49-9912fb52ac05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b443df0d-fe17-433b-bbdf-e36f2fde4fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fdb47e4-32f6-43a8-9b84-a6df182a1cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f0d9b7f-2131-49ca-97eb-73575efa1087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123231d5-cb47-4a6d-8175-a55b3a5eeadc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d142ce-07a3-4690-8877-fc77b99cb6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18c3fc0-0172-4e5c-961a-b90fa0ba80fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d85904da-01e7-4ee5-8c16-d3b09fa5ae94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473829ef-cc4c-497c-af1c-1d1f4cbfacc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4799fd9e-0e65-4fb5-b438-4bd38004e3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20a66124-c7fa-4c3a-9efe-8fade4bfc7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2991606-1b08-4848-bd8e-f8c5be4f5959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2af8562-a474-4c95-b785-24b316efce07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e488d6e-4512-4fc8-94e5-19baa9c3da9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7444e881-ca33-4921-a89a-4fd85d954cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dffd3fe-cf8d-44ac-96b3-6e378eb3d32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e57496-d231-4062-bf85-6d0f522d1f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c326c3c-b15f-48d1-9c20-890d451fc27c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b07b7f8c-c127-4cd5-a2c8-e4e4b9182f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a93a7c-8e40-40a9-8bf3-129cd3aa137b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ebdcf00-f287-4c29-b006-2cb2f2a8421f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 017c8a1d-1e59-4188-9dfa-f270df74d7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4461fe78-d7ac-490d-a4d0-4aea2f5053a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc1d354-681c-427c-bacb-4b3aac13a6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d43bf8-4750-474b-9946-4fbf279efa16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce5407b-ca82-49ec-8c1d-18158dc1522d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0526f78-84a7-41ee-97b2-1864fd14ef0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e94f77b1-5f7b-4cb9-8f78-b76f7f9e5982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cae7a7c-5800-4fe2-97d3-fbe6444b24db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b48892-2a7b-4436-b7ce-e1c9f1b66def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de2661a4-bc57-4bc8-b331-463bb723a4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e64ce6-7f44-406d-b7f1-be1670651f17
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(301, 24), y=(301,)
   Test:  X=(76, 24), y=(76,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 292 samples, 5 features
   Test:  67 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0698 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0895, val=0.0683 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0874, val=0.0658 (↓), lr=0.001000
   • Epoch   4/100: train=0.0864, val=0.0667, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0857, val=0.0678, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0819, val=0.0696, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 5 Summary - Client client_11
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0106
   Val:   Loss=0.0658, RMSE=0.2566, R²=-0.0046
============================================================


============================================================
🔄 Round 6 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1165, val=0.1047 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.1002, val=0.0892 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0897, val=0.0820 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0868, val=0.0801 (↓), lr=0.000250
   • Epoch   5/100: train=0.0870, val=0.0799, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0868, val=0.0793, patience=4/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0864, val=0.0789, patience=4/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0863, val=0.0787, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 6 Summary - Client client_11
   Epochs: 32/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0012
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0170
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2495, R²: -0.0538

============================================================
🔄 Round 7 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.1110 (↓), lr=0.000016
   • Epoch   2/100: train=0.0879, val=0.1106, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0875, val=0.1101 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.0871, val=0.1096 (↓), lr=0.000016
   • Epoch   5/100: train=0.0867, val=0.1091, patience=1/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0852, val=0.1073 (↓), lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0842, val=0.1061, patience=2/15, lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002
   📉 Epoch 31: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0838, val=0.1056, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0837, val=0.1055, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1058)

============================================================
📊 Round 7 Summary - Client client_11
   Epochs: 43/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0403
   Val:   Loss=0.1058, RMSE=0.3252, R²=-0.0661
============================================================


============================================================
🔄 Round 9 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0954, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0954, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0954, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0954, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0953, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0951, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 9 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0955, RMSE=0.3091, R²=-0.0965
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0676
============================================================


============================================================
🔄 Round 10 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0979, val=0.0585 (↓), lr=0.000001
   • Epoch   2/100: train=0.0979, val=0.0585, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0979, val=0.0585, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0978, val=0.0585, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0978, val=0.0585, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0976, val=0.0584, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0585)

============================================================
📊 Round 10 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0981, RMSE=0.3132, R²=-0.0828
   Val:   Loss=0.0585, RMSE=0.2419, R²=-0.0145
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2459, R²: 0.0251

============================================================
🔄 Round 11 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 11 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0286
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0932
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2445, R²: 0.0075

📊 Round 11 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: -0.0214

📊 Round 11 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2580, R²: -0.0449

📊 Round 11 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2574, R²: -0.0349

📊 Round 11 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2566, R²: -0.0293

============================================================
🔄 Round 19 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0988, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0988, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0987, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0987, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0986, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0984, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 19 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0986, RMSE=0.3141, R²=-0.1312
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.1710
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2577, R²: -0.0299

============================================================
🔄 Round 21 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.1273 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.1272, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.1272, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.1272, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.1271, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.1269, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0852, val=0.1266, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0851, val=0.1264, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1268)

============================================================
📊 Round 21 Summary - Client client_11
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.1007
   Val:   Loss=0.1268, RMSE=0.3560, R²=-0.3125
============================================================


============================================================
🔄 Round 24 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1041, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.1040, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1039, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1039, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1038, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.1033, val=0.0977, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.1028, val=0.0972, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1023, val=0.0968 (↓), lr=0.000001
   • Epoch  41/100: train=0.1018, val=0.0964, patience=10/15, lr=0.000001
   • Epoch  51/100: train=0.1014, val=0.0961, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 24 Summary - Client client_11
   Epochs: 60/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0979, RMSE=0.3129, R²=-0.1708
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.1997
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2615, R²: -0.0555

============================================================
🔄 Round 25 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1030, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.1030, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1029, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1029, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1028, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.1026, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 25 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1008, RMSE=0.3175, R²=-0.1876
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.1299
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2609, R²: -0.0497

============================================================
🔄 Round 26 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0983, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0982, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0982, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0981, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0981, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0978, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 26 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1022, RMSE=0.3197, R²=-0.1744
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.2110
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2589, R²: -0.0357

📊 Round 26 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2585, R²: -0.0338

============================================================
🔄 Round 31 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0962, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0962, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0962, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0962, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0961, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0960, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 31 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0971, RMSE=0.3117, R²=-0.1251
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0452
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2581, R²: -0.0323

📊 Round 31 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2577, R²: -0.0309

============================================================
🔄 Round 37 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0987, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0986, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0986, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0986, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0986, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0985, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 37 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0938, RMSE=0.3063, R²=-0.0973
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.1325
============================================================


============================================================
🔄 Round 38 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0933, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0933, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0933, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0932, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0932, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0931, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 38 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0954, RMSE=0.3089, R²=-0.1045
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0973
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2577, R²: -0.0310

📊 Round 38 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2577, R²: -0.0311

============================================================
🔄 Round 41 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.1071 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.1070, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.1070, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.1070, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.1070, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.1069, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1071)

============================================================
📊 Round 41 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0963
   Val:   Loss=0.1071, RMSE=0.3272, R²=-0.1096
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2577, R²: -0.0312

============================================================
🔄 Round 42 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.1159 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.1158, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.1158, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.1158, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.1158, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.1156, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1159)

============================================================
📊 Round 42 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0709
   Val:   Loss=0.1159, RMSE=0.3404, R²=-0.1902
============================================================


============================================================
🔄 Round 43 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.1016 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.1016, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.1015, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.1015, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.1015, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.1014, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1016)

============================================================
📊 Round 43 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0918
   Val:   Loss=0.1016, RMSE=0.3187, R²=-0.1339
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2577, R²: -0.0313

📊 Round 43 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2577, R²: -0.0314

📊 Round 43 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2578, R²: -0.0316

📊 Round 43 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2578, R²: -0.0317

📊 Round 43 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2578, R²: -0.0318

============================================================
🔄 Round 51 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 51 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=-0.1181
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0776
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2578, R²: -0.0319

============================================================
🔄 Round 52 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0964, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0964, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0964, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0963, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0963, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0962, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 52 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0931, RMSE=0.3052, R²=-0.1181
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.1019
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2579, R²: -0.0320

📊 Round 52 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2579, R²: -0.0321

============================================================
🔄 Round 57 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.1027 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.1027, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.1027, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.1027, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.1027, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.1026, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1027)

============================================================
📊 Round 57 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0972
   Val:   Loss=0.1027, RMSE=0.3205, R²=-0.1063
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2579, R²: -0.0324

📊 Round 57 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2580, R²: -0.0325

📊 Round 57 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2580, R²: -0.0326

============================================================
🔄 Round 61 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.1012 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.1012, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.1012, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.1012, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.1012, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.1011, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1012)

============================================================
📊 Round 61 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0865
   Val:   Loss=0.1012, RMSE=0.3182, R²=-0.1517
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2580, R²: -0.0325

============================================================
🔄 Round 62 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.1085 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.1085, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.1085, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.1084, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.1084, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.1083, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1085)

============================================================
📊 Round 62 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.1095
   Val:   Loss=0.1085, RMSE=0.3294, R²=-0.1059
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2579, R²: -0.0324

📊 Round 62 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2579, R²: -0.0324

============================================================
🔄 Round 65 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0937, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0937, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0937, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0936, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0936, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0936, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 65 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0879
   Val:   Loss=0.0988, RMSE=0.3143, R²=-0.1356
============================================================


============================================================
🔄 Round 66 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 66 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=-0.0924
   Val:   Loss=0.0992, RMSE=0.3149, R²=-0.1114
============================================================


============================================================
🔄 Round 69 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0985, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0985, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0984, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0984, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0984, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0981, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 69 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0957, RMSE=0.3093, R²=-0.1039
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0610
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2579, R²: -0.0325

============================================================
🔄 Round 70 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.1076 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.1075, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.1075, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.1075, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.1075, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.1075, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1076)

============================================================
📊 Round 70 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0855
   Val:   Loss=0.1076, RMSE=0.3280, R²=-0.2170
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2579, R²: -0.0327

📊 Round 70 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2579, R²: -0.0329

============================================================
🔄 Round 74 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0955, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0954, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0954, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0954, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0954, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0953, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 74 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0955, RMSE=0.3090, R²=-0.0804
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.1851
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2580, R²: -0.0331

📊 Round 74 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2580, R²: -0.0331

============================================================
🔄 Round 77 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0934, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0934, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0934, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0934, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0933, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0932, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 77 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0934, RMSE=0.3056, R²=-0.0869
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.1470
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2579, R²: -0.0329

============================================================
🔄 Round 82 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0982, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0982, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0982, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0982, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0981, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0980, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 82 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0950, RMSE=0.3082, R²=-0.1027
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.1129
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2578, R²: -0.0325

============================================================
🔄 Round 83 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0926, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0926, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0925, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0925, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0924, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 83 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0675
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.2134
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2577, R²: -0.0324

📊 Round 83 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2577, R²: -0.0323

============================================================
🔄 Round 85 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0947, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0947, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0947, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0946, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0946, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0945, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 85 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0961, RMSE=0.3100, R²=-0.1200
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0317
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2577, R²: -0.0323

📊 Round 85 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2577, R²: -0.0325

============================================================
🔄 Round 87 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0972, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0972, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0972, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0971, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0971, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0970, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 87 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0935, RMSE=0.3057, R²=-0.1031
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0476
============================================================


============================================================
🔄 Round 88 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0957, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0957, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0957, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0957, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0957, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0956, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 88 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0967, RMSE=0.3109, R²=-0.1090
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0135
============================================================


============================================================
🔄 Round 91 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0937, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0937, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0936, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0936, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0936, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0935, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 91 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0943, RMSE=0.3071, R²=-0.0880
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.1227
============================================================


============================================================
🔄 Round 92 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 92 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0952, RMSE=0.3085, R²=-0.0817
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.1898
============================================================


============================================================
🔄 Round 93 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 93 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3038, R²=-0.0950
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0999
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2580, R²: -0.0337

============================================================
🔄 Round 95 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 95 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0922, RMSE=0.3036, R²=-0.0925
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.1047
============================================================


============================================================
🔄 Round 97 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0949, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0948, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0948, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0948, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0948, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0947, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 97 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0950, RMSE=0.3082, R²=-0.0776
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.1886
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2580, R²: -0.0337

============================================================
🔄 Round 100 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 100 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0926, RMSE=0.3043, R²=-0.1234
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0046
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2579, R²: -0.0336

============================================================
🔄 Round 101 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0928, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0927, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0927, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 101 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0932, RMSE=0.3053, R²=-0.1103
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0270
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2579, R²: -0.0336

📊 Round 101 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2579, R²: -0.0335

📊 Round 101 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2579, R²: -0.0337

============================================================
🔄 Round 108 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0993 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0993, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0993)

============================================================
📊 Round 108 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0885
   Val:   Loss=0.0993, RMSE=0.3152, R²=-0.1103
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2580, R²: -0.0338

============================================================
🔄 Round 109 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0982, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0982, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0981, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0981, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0981, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0978, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 109 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0955, RMSE=0.3090, R²=-0.0990
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0672
============================================================


============================================================
🔄 Round 111 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0917, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 111 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0931, RMSE=0.3051, R²=-0.0985
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0774
============================================================


============================================================
🔄 Round 112 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0931, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0931, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0931, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0930, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0930, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0929, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 112 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0954, RMSE=0.3089, R²=-0.0972
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0719
============================================================


============================================================
🔄 Round 113 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0935, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0935, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0935, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0935, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0934, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0933, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 113 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0922, RMSE=0.3036, R²=-0.0948
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0953
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2579, R²: -0.0336

📊 Round 113 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2578, R²: -0.0334

============================================================
🔄 Round 119 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.1076 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.1076, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.1076, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.1076, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.1076, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.1074, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1076)

============================================================
📊 Round 119 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0687
   Val:   Loss=0.1076, RMSE=0.3281, R²=-0.1761
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2578, R²: -0.0330

============================================================
🔄 Round 120 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0990, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 120 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0880
   Val:   Loss=0.0991, RMSE=0.3148, R²=-0.0984
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2578, R²: -0.0329

============================================================
🔄 Round 121 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 121 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0951, RMSE=0.3083, R²=-0.1068
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0141
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2578, R²: -0.0327

============================================================
🔄 Round 124 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0926, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0926, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0926, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0926, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0925, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 124 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3042, R²=-0.0925
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0763
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2577, R²: -0.0324

📊 Round 124 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2577, R²: -0.0324

============================================================
🔄 Round 130 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0964, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0964, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0964, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0964, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0964, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0962, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 130 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0958, RMSE=0.3095, R²=-0.0883
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.1104
============================================================


============================================================
🔄 Round 131 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 131 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3011, R²=-0.0729
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.1548
============================================================


============================================================
🔄 Round 132 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.1062 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.1062, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.1062, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.1062, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.1062, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.1061, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1062)

============================================================
📊 Round 132 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0682
   Val:   Loss=0.1062, RMSE=0.3259, R²=-0.1705
============================================================


============================================================
🔄 Round 135 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0936, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0935, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0935, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0935, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0935, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0934, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 135 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0933, RMSE=0.3054, R²=-0.0829
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.1073
============================================================


============================================================
🔄 Round 136 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.1033 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.1033, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.1033, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.1032, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.1032, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.1032, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1033)

============================================================
📊 Round 136 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0849
   Val:   Loss=0.1033, RMSE=0.3214, R²=-0.0983
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0318

============================================================
🔄 Round 138 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 138 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0918, RMSE=0.3030, R²=-0.0725
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.1599
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2576, R²: -0.0316

📊 Round 138 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2576, R²: -0.0316

============================================================
🔄 Round 143 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 143 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0610
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.1982
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2577, R²: -0.0319

📊 Round 143 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2577, R²: -0.0320

============================================================
🔄 Round 148 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0925, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0925, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0924, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0923, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 148 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0863
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.1217
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0318

============================================================
🔄 Round 149 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 149 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0815
   Val:   Loss=0.0971, RMSE=0.3116, R²=-0.1227
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0317

============================================================
🔄 Round 150 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 150 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0759
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.1742
============================================================


============================================================
🔄 Round 152 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.1017 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.1017, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.1017, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.1016, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.1016, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.1015, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1017)

============================================================
📊 Round 152 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0695
   Val:   Loss=0.1017, RMSE=0.3189, R²=-0.1701
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0316

📊 Round 152 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0316

============================================================
🔄 Round 156 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0933, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0933, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0933, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0933, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0932, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0931, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 156 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0941, RMSE=0.3068, R²=-0.0981
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0343
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2576, R²: -0.0315

============================================================
🔄 Round 157 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 157 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=-0.0702
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.1371
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2576, R²: -0.0315

============================================================
🔄 Round 159 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 159 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=-0.0746
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.1163
============================================================


============================================================
🔄 Round 160 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0942, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0942, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0942, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0941, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0941, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0940, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 160 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0922, RMSE=0.3036, R²=-0.0774
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.1277
============================================================


============================================================
🔄 Round 162 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 162 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3045, R²=-0.0613
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.1872
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2576, R²: -0.0311

============================================================
🔄 Round 163 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0982, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0982, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0982, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0982, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0981, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0980, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 163 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0968, RMSE=0.3111, R²=-0.0931
   Val:   Loss=0.0677, RMSE=0.2602, R²=-0.0159
============================================================


============================================================
🔄 Round 164 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 164 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=-0.0934
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0576
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2576, R²: -0.0310

============================================================
🔄 Round 165 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0940, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0940, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0939, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0939, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0939, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0938, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 165 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0754
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0999
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2576, R²: -0.0311

============================================================
🔄 Round 167 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 167 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0575
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.2079
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2576, R²: -0.0311

============================================================
🔄 Round 169 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 169 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=-0.0875
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0556
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2576, R²: -0.0314

============================================================
🔄 Round 172 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.1031 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.1031, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.1031, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.1031, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.1031, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.1030, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1031)

============================================================
📊 Round 172 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0840
   Val:   Loss=0.1031, RMSE=0.3211, R²=-0.0753
============================================================


============================================================
🔄 Round 173 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0933, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0933, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0933, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0933, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0932, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0931, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 173 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3024, R²=-0.0921
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0421
============================================================


============================================================
🔄 Round 174 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0944, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0944, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0943, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0943, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0943, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0941, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 174 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=-0.0951
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0467
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0316

📊 Round 174 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0316

📊 Round 174 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0316

📊 Round 174 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0317

============================================================
🔄 Round 181 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 181 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=-0.0930
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0413
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2577, R²: -0.0318

============================================================
🔄 Round 183 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.1032 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.1032, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.1032, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.1032, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.1032, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.1031, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1032)

============================================================
📊 Round 183 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0762
   Val:   Loss=0.1032, RMSE=0.3213, R²=-0.1188
============================================================


============================================================
🔄 Round 185 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 185 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0640
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.1611
============================================================


============================================================
🔄 Round 186 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0940, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0940, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0939, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0939, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0939, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0938, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 186 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0932, RMSE=0.3053, R²=-0.0938
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0388
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2577, R²: -0.0320

============================================================
🔄 Round 188 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0940, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0940, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0940, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0940, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0940, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0939, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 188 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3044, R²=-0.0891
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0659
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2577, R²: -0.0321

============================================================
🔄 Round 191 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 191 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=-0.0757
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.1174
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2577, R²: -0.0323

============================================================
🔄 Round 193 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.1010 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.1010, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.1010, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1010)

============================================================
📊 Round 193 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0905
   Val:   Loss=0.1010, RMSE=0.3178, R²=-0.0659
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2577, R²: -0.0324

============================================================
🔄 Round 195 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0967, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0967, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0967, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0967, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0967, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0966, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 195 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0931, RMSE=0.3051, R²=-0.0750
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.1996
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2578, R²: -0.0325

📊 Round 195 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2578, R²: -0.0326

============================================================
🔄 Round 200 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 200 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0789
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.1272
============================================================


============================================================
🔄 Round 201 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0963, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0963, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0963, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0962, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0962, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0961, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 201 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0942, RMSE=0.3069, R²=-0.0966
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0269
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2577, R²: -0.0321

📊 Round 201 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2577, R²: -0.0321

============================================================
🔄 Round 207 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 207 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=-0.0878
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0615
============================================================


============================================================
🔄 Round 208 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0937, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0937, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0937, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0937, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0937, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0936, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 208 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0933, RMSE=0.3055, R²=-0.0736
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.1214
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2577, R²: -0.0319

============================================================
🔄 Round 209 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0944, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0943, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0943, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0943, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0943, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0941, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 209 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0969, RMSE=0.3113, R²=-0.0908
   Val:   Loss=0.0673, RMSE=0.2594, R²=-0.1027
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2576, R²: -0.0318

============================================================
🔄 Round 211 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 211 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0926, RMSE=0.3042, R²=-0.0914
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0866
============================================================


❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
