[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d30329b-51f9-4d7c-b44c-e4434c25b0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9a78e2-ff97-4e8e-8626-d31f7f049ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5135b1c-d362-4d6b-ad8d-8f661da734b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784c850e-1912-4383-9c23-d9e786fdd8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67a75df2-cad8-41b2-8de7-a2562fdac9bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88e7a4ff-7678-47b5-b43f-0ab8c6667286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5913d276-9045-4d2e-ae41-5f9cd03983f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c46b053e-8598-49c2-83ed-a4eec2d142af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9e4768-6f15-413b-ae1e-60266b1e977e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d00945b6-2e4d-4c90-9897-beea3f0adbdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f870293-e93d-4fa5-9cde-70a12174238c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33a89150-06a1-4cfc-bfb8-c0097f588138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ef02a03-a273-4d01-aeeb-aa83481dc3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2e27e8d-01c0-40f8-9e92-602754aa9cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ae384d-13d0-4008-b4aa-5d63cdefebc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e0d0117-2e4f-4982-b21b-aa3a36a27670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c16386dd-e3f6-4553-9e23-a39cb0cfb900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb126f0d-4805-45c3-b319-b7d39854a7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7002f38-e4f7-47fe-847c-a76c711139f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e3fb18-b31f-414c-af95-82915e909fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fb5b74-fb0e-4df4-b09d-15ac506af73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c5394a-1e59-4e82-89d0-05c13bf8e5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdea4558-1ee7-4982-9133-714d2e67fece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5159add4-c170-4b85-98a3-6757ec9bc13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f6ecd4-5254-4887-bb64-4886ac6245c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10d6c8cd-14ee-4abe-84ce-f09dbda5562c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51281701-0fce-4762-b54c-391053f4a1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d15a464c-29af-43ea-bca4-4fbfc8cc609c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486df0b4-868c-47ad-baf3-8ed1ac21fa55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd006a6-88c9-4af4-9b25-f66a2985792e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7900f1-ec66-4135-b820-276f494e288b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a0aa59f-d81b-42d2-a662-aef2f7c9a583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd0f566a-d7b1-4e23-8587-393da2d09c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a2514c0-2d3e-4eef-beab-cfe76a9c5a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5922722-76c3-4e00-9d1b-9fd04a71c2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74715061-b6ae-41d2-98f1-1fea7dc15efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dff0735-7580-47b9-b7b8-3be34ede677a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdebcf7-9536-4b08-b0b3-e25bc6e86fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94c284ee-978f-49ba-b467-02bb9d5c99b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3f1dcf0-2330-4f01-9a0a-08112354c29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 075a515a-8967-4121-b0d1-5b64e47180d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73fc1d97-b73a-469f-a194-d6bbd6d1d0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58a73e0-bff1-4b69-b08f-c6fa1de857a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fce6122-3f8f-41dd-9239-61b1051e978b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 707a2ba5-5433-463d-a989-dffd7e66e335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f172b86-b80a-4e9e-8b79-bd6e2c272a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dae7d3f-69cc-47a0-9658-69590f652372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcb19826-647a-4be9-87de-7c5c338e9fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee86c40-7d28-41e5-bc6d-804b6574afba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aac05ea5-8d8e-4696-b45a-b76a6e64de7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da3c31a-4219-4f03-989b-18a831e0321c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3922d6dc-7ec3-4b77-a78b-7a2688addad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af983c1c-dba7-40bf-97b7-365b599bda4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b4ace3-0864-4369-ae66-7ecffca1ab05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5befa1f-8fdb-4139-9568-84fd2f823f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d61725a-95f3-47ee-9d3f-8bcff2b4d57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8fd6d48-07a1-42b3-a231-6aa1c8664b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8da43606-b65e-4f1a-88da-ec3c6623f934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 292671de-f661-4b56-9db3-2b7eb0f76b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b2ba6a-c62b-4b70-a5c1-19e35036ffda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0402ae-ac64-49fd-bba2-05b65d736741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c6bb764-721c-45bf-bc99-dd4101b037f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 274b5d53-a942-483c-a473-b2d8ede0d665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a15402-0b3d-436f-8fad-ce5ca0f2707e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc252616-0507-497d-9dd1-12c3e3fe8e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66b755b-db0e-4e9e-8415-556ff5da856f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de34ba51-0767-4d25-845d-91e9bf57a3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e948db1b-9a66-40fe-b320-de119ab13623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92d4ce50-1e61-4e0b-ae2d-6f9e430d2439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0b64bc-767f-4eb7-9690-ec153b256a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed59381-235d-41f6-967c-a696f208841c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fa14247-e18c-4c5f-8daf-33e47163be95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d24250e-6dd3-44b5-b73b-10de972857bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 387b35b6-d280-42eb-9db4-28de0b855eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92651fe-db37-4e24-a655-223fc6732c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60527ba0-a82d-4114-ac15-c0449803e160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a59c30-b0e4-4266-a4ab-29bf1358300b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3386e84e-6860-481e-8533-051b5188967f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa7cc5d1-7135-4b5b-84fc-2f15743a31e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fea075-f2f2-4de9-b869-c9258f795fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4876d9-8094-438e-b031-762858a8ec18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8064855a-f21d-4b87-bc17-b80b545c69e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f61436dc-56ee-48b3-907a-3b8e5774bf97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 489c5345-6c2f-4109-8782-e824d98a46dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff1dfc8-d6b3-4ade-8c9f-538683059587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b272f8cc-ae44-4641-b2c5-19b738ee8f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cc7f25-dccf-444f-8515-ee098b619980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6626a998-1fa2-48bd-b0e3-71b4aa0eb9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 591c9179-90c8-4277-83db-22eae5961d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc3485f9-6128-4e46-84c8-e8852ebb00e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3fcaf5d-c4a9-4e23-b8fe-e017f1b358ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f29646-ea31-4a5f-9a3c-6f5b1cf48fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae16e0e1-1d36-492e-9693-d3b5f81f8a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e330dcfe-2a5b-494d-9e35-4036b1708945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91db440-ec91-486d-955e-264276b8f6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8329e7-f7e6-4b2b-8a65-8369a00c0a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa180365-09e3-4e76-924a-a11518aa1fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9b64991-b1f0-468d-a133-b6505994d9b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a267f3-c859-4670-9cd2-5a06cd23cbd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f268dcb-2b42-4f36-9d9d-5991d341c68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c7a745-b857-46a0-a872-3475ab22c461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d51aa68a-1d0b-460e-a576-2b1dbe0a00aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dcdb5bf-27a7-4443-a51e-e5d788342153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8654cd89-1dec-4605-a7c3-c448160b904f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8631ea06-1bfd-4a26-81cd-3525179cc782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e74cfcde-3ac9-4f37-878a-b470ca6e68a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f31ddb-9045-463a-8891-726d39cfd00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4d2f7de-99fa-4f6f-9bba-d50d6146592a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c87c02b2-49cf-406e-a064-a1dc9745db04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aae4663c-ce5b-4b97-8427-7cc04d125321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a7dadf-8c27-4965-bc2c-abbaa664e084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e46e87-de92-42c7-8d48-f5aece3a308f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bacde93-9539-4180-8c21-27d067700fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee7dd63-5fcc-4436-9b88-225226f07e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b967753-990a-4fbd-9cbc-7befb37470ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65a8876a-b619-45dd-8b4e-788207d02f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3888d5-152a-46a0-84dc-bd8ac8fb4cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14b940a-effc-4dfc-9611-d92c0f597429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a1bf2f3-b117-4946-a0ba-5cc535484b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f398a39-542a-413c-b79c-2327e80d0c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc33146-1df0-494f-825d-8197f2d7e7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c3d26f-f9cc-4d6b-a482-5ecfcdc54840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9bb8d0-b3e7-4644-90fe-ae3aef1adceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 290cf371-7f4e-4527-a610-90e45322c1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 295f557a-529c-42f4-8adc-75f040291d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc43990-850b-4a23-bf5d-555dfa0143a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6308ce5b-cfe7-4eb8-aec7-8af686b18255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab056c4d-a674-4cf2-b6dd-0fd23bc4b162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7696e7a3-651a-4e2f-8eb7-5d8626eaf349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b93a5426-5a5e-4919-87a5-073de805453e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa5bcef9-170a-43ad-b6c7-f67f726230f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72ad170a-1d6a-44f5-abc1-d4a35be6fae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b7c0e7-383e-4fc8-b475-70e076b1cacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685a61f7-395c-4339-9251-2670407df192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 515a9c23-9111-4b96-be76-61ba589eab47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6fdc8a2-a366-45c4-a920-4639fb6de70f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4cd173-185b-4f6e-9b73-e6c7d2574dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8676e2f3-d91a-4a4b-bce6-c21b935c3ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f0ef060-8136-4445-8fbc-7da80c9f3bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a617314a-9c1e-4cb9-8a4a-77ceee259bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8003c3-ed3e-4e59-bc8d-6a4721d0791d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed57a4c-8507-4b88-9c30-965ff84942ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e07c7f-99ab-4e92-9b56-935663480b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefb59bf-eeae-4f4f-b7ad-447599699dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38fd4c72-a710-497d-b1bb-488116198693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 709bee69-f3f2-47a1-a3a2-1baf8e014373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57a1e01b-60df-4c47-936b-7375199db8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf88bbd-d4a5-4a96-81b2-47338d87da44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e71b47-d7c9-4a1c-a676-15dba2a2736c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 406c7ae2-c492-4322-a011-ec9085d60862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58888db8-8a89-4017-aa03-9d997717fe07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa3fc332-b00c-4175-bd2a-3b3a5f3b4a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f88bbd5-05ac-4cfa-a0f1-c0fd2a872979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494c7fac-a4c3-4d4c-8a80-5c745856be59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c267e40-b2a8-429e-b2c2-45a20dc7c525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fd09dd-f2ed-4977-923f-cdd5773989e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75d5de3f-16f9-462d-8581-7a2d14071b44
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(1530, 24), y=(1530,)
   Test:  X=(383, 24), y=(383,)

⚠️  Limiting training data: 1530 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  374 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0060

============================================================
🔄 Round 2 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0873 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0889, val=0.0806 (↓), lr=0.001000
   • Epoch   3/100: train=0.0853, val=0.0810, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0842, val=0.0815, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0846, val=0.0814, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0833, val=0.0815, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 2 Summary - Client client_12
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0036
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0038
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.3283, RMSE: 0.5730, MAE: 0.4958, R²: -2.9810

============================================================
🔄 Round 3 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1884, val=0.0824 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0858, val=0.0808 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0847, val=0.0788 (↓), lr=0.000250
   • Epoch   4/100: train=0.0840, val=0.0789, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0839, val=0.0789, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0837, val=0.0789, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 3 Summary - Client client_12
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0054
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0039
============================================================


============================================================
🔄 Round 4 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1271, val=0.1014 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0991, val=0.0899 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0864, val=0.0883 (↓), lr=0.000063
   • Epoch   4/100: train=0.0823, val=0.0892, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0811, val=0.0902, patience=2/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0806, val=0.0911, patience=8/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 4 Summary - Client client_12
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0280
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0017
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0951, RMSE: 0.3083, MAE: 0.2643, R²: -0.1526

============================================================
🔄 Round 6 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1092, val=0.1055 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1061, val=0.1018 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1032, val=0.0987 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1008, val=0.0960 (↓), lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   ✓ Epoch   5/100: train=0.0987, val=0.0937 (↓), lr=0.000008
   ✓ Epoch  11/100: train=0.0939, val=0.0884 (↓), lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004
   📉 Epoch 21: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.0909, val=0.0848 (↓), lr=0.000002
   📉 Epoch 29: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0900, val=0.0837, patience=5/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0895, val=0.0831 (↓), lr=0.000001
   ✓ Epoch  51/100: train=0.0891, val=0.0826 (↓), lr=0.000001
   ✓ Epoch  61/100: train=0.0888, val=0.0821 (↓), lr=0.000001
   • Epoch  71/100: train=0.0884, val=0.0816, patience=10/15, lr=0.000001
   • Epoch  81/100: train=0.0881, val=0.0811, patience=9/15, lr=0.000001
   • Epoch  91/100: train=0.0877, val=0.0806, patience=8/15, lr=0.000001

============================================================
📊 Round 6 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0277
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0825
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0910, RMSE: 0.3016, MAE: 0.2596, R²: -0.1029

============================================================
🔄 Round 7 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0921, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0858, val=0.0916, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0855, val=0.0911, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0853, val=0.0906, patience=1/15, lr=0.000001
   ✓ Epoch  51/100: train=0.0850, val=0.0901 (↓), lr=0.000001
   • Epoch  61/100: train=0.0848, val=0.0896, patience=10/15, lr=0.000001
   • Epoch  71/100: train=0.0845, val=0.0891, patience=9/15, lr=0.000001
   • Epoch  81/100: train=0.0843, val=0.0887, patience=7/15, lr=0.000001
   • Epoch  91/100: train=0.0841, val=0.0883, patience=5/15, lr=0.000001

============================================================
📊 Round 7 Summary - Client client_12
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0071
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0841
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2464, R²: 0.0147

============================================================
🔄 Round 13 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 13 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0101
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0379
============================================================


============================================================
🔄 Round 17 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 17 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0512
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0170
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2402, R²: 0.0489

============================================================
🔄 Round 20 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 20 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0537
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0354
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2383, R²: 0.0586

📊 Round 20 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2386, R²: 0.0569

============================================================
🔄 Round 29 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 29 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0504
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0333
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2389, R²: 0.0549

============================================================
🔄 Round 31 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 31 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0396
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0717
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2391, R²: 0.0543

📊 Round 31 Test Metrics:
   Loss: 0.0780, RMSE: 0.2794, MAE: 0.2392, R²: 0.0538

📊 Round 31 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2392, R²: 0.0535

============================================================
🔄 Round 35 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 35 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0330
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0908
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2393, R²: 0.0529

📊 Round 35 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0527

============================================================
🔄 Round 38 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 38 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0393
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0650
============================================================


============================================================
🔄 Round 39 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 39 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0538
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0104
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0529

📊 Round 39 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0529

============================================================
🔄 Round 43 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 43 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0427
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0509
============================================================


============================================================
🔄 Round 44 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 44 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0567
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0013
============================================================


============================================================
🔄 Round 46 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 46 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0340
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0731
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2393, R²: 0.0531

📊 Round 46 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2393, R²: 0.0532

============================================================
🔄 Round 50 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 50 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0407
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0577
============================================================


============================================================
🔄 Round 52 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 52 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0389
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0651
============================================================


============================================================
🔄 Round 54 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 54 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0475
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0167
============================================================


============================================================
🔄 Round 55 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 55 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0491
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0264
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2393, R²: 0.0534

============================================================
🔄 Round 58 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 58 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0537
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0053
============================================================


============================================================
🔄 Round 59 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 59 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0330
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0868
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2392, R²: 0.0536

============================================================
🔄 Round 61 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 61 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0458
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0385
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2393, R²: 0.0535

============================================================
🔄 Round 63 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 63 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0410
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0486
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0530

============================================================
🔄 Round 66 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 66 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0376
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0527
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0529

============================================================
🔄 Round 69 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 69 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0434
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0454
============================================================


============================================================
🔄 Round 73 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 73 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0499
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0192
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2393, R²: 0.0533

📊 Round 73 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2393, R²: 0.0534

============================================================
🔄 Round 76 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 76 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0415
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0542
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2393, R²: 0.0532

📊 Round 76 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0530

============================================================
🔄 Round 82 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 82 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0375
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0698
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2395, R²: 0.0523

============================================================
🔄 Round 84 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 84 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0389
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0558
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2395, R²: 0.0522

📊 Round 84 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2395, R²: 0.0522

============================================================
🔄 Round 86 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 86 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0402
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0591
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2395, R²: 0.0523

📊 Round 86 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2395, R²: 0.0524

📊 Round 86 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0525

============================================================
🔄 Round 90 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 90 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0416
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0504
============================================================


============================================================
🔄 Round 91 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 91 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0496
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0216
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0528

============================================================
🔄 Round 93 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 93 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0446
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0377
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0528

============================================================
🔄 Round 95 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 95 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0432
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0469
============================================================


============================================================
🔄 Round 96 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 96 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0425
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0263
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0528

============================================================
🔄 Round 97 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 97 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0370
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0710
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0527

============================================================
🔄 Round 99 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 99 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0482
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0238
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0526

============================================================
🔄 Round 101 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 101 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0454
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0321
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0525

📊 Round 101 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2395, R²: 0.0525

📊 Round 101 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0526

📊 Round 101 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2394, R²: 0.0526

📊 Round 101 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2395, R²: 0.0525

============================================================
🔄 Round 112 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 112 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0453
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0382
============================================================


============================================================
🔄 Round 119 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 119 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0437
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0165
============================================================


============================================================
🔄 Round 121 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 121 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0435
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0394
============================================================


============================================================
🔄 Round 124 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 124 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0516
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0103
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2397, R²: 0.0513

============================================================
🔄 Round 126 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 126 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0439
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0410
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2397, R²: 0.0513

============================================================
🔄 Round 128 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 128 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0377
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0520
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2397, R²: 0.0513

============================================================
🔄 Round 129 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 129 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0437
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0416
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2397, R²: 0.0514

📊 Round 129 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2397, R²: 0.0513

============================================================
🔄 Round 132 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 132 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0410
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0094
============================================================


============================================================
🔄 Round 133 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 133 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0369
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0578
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2398, R²: 0.0511

============================================================
🔄 Round 134 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 134 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0434
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0410
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2398, R²: 0.0511

============================================================
🔄 Round 136 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 136 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0377
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0591
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2398, R²: 0.0509

============================================================
🔄 Round 137 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 137 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0387
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0521
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2398, R²: 0.0508

============================================================
🔄 Round 138 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 138 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0490
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0199
============================================================


============================================================
🔄 Round 139 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 139 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0469
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0247
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0507

📊 Round 139 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0507

📊 Round 139 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0509

📊 Round 139 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0509

============================================================
🔄 Round 149 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 149 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0430
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0329
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0505

============================================================
🔄 Round 153 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 153 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0326
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0742
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0505

============================================================
🔄 Round 154 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 154 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0365
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0491
============================================================


============================================================
🔄 Round 155 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 155 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0468
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0064
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0505

============================================================
🔄 Round 156 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 156 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0394
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0540
============================================================


============================================================
🔄 Round 157 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 157 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0451
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0264
============================================================


============================================================
🔄 Round 162 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 162 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0382
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0484
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2400, R²: 0.0501

============================================================
🔄 Round 163 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 163 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0422
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0254
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2401, R²: 0.0500

============================================================
🔄 Round 167 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 167 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0469
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0004
============================================================


============================================================
🔄 Round 168 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 168 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0310
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0862
============================================================


============================================================
🔄 Round 169 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 169 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0343
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0731
============================================================


============================================================
🔄 Round 171 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 171 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0410
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0159
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2400, R²: 0.0503

============================================================
🔄 Round 174 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 174 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0478
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0169
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2400, R²: 0.0504

📊 Round 174 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2400, R²: 0.0504

============================================================
🔄 Round 178 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 178 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0339
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0780
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2400, R²: 0.0505

============================================================
🔄 Round 179 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 179 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0397
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0517
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0505

============================================================
🔄 Round 181 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 181 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0429
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0385
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0505

📊 Round 181 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0506

📊 Round 181 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0506

============================================================
🔄 Round 184 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 184 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0423
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0374
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0506

📊 Round 184 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0506

📊 Round 184 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0506

============================================================
🔄 Round 194 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 194 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0523
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0012
============================================================


============================================================
🔄 Round 195 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 195 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0447
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0295
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0508

📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0508

📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2398, R²: 0.0508

📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0508

📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0506

📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0505

📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2399, R²: 0.0505

📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2399, R²: 0.0504

📊 Round 195 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2400, R²: 0.0503

============================================================
🔄 Round 208 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 208 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0353
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0544
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2400, R²: 0.0503

============================================================
🔄 Round 210 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 210 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0324
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0822
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2400, R²: 0.0502

❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
