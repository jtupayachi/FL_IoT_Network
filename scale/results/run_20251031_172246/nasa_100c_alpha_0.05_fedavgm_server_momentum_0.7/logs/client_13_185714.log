[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff07cd7f-beda-4736-b313-35ca72035add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8269066-a9b3-48f1-8010-ad634fbbe70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 966cfe00-a765-4a54-9e53-2dc3282db256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0eaf74e-3e50-4635-b4e6-d8aa1b3a168a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be239b1-639c-4209-8903-a23fded0b384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fecfef-3443-49cf-b2a8-0e94594c695a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a42f372-5eff-44cf-869f-f72dba4ed494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3ad489-2258-4e04-a83b-7589e7292b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e899231-41c5-4ab0-9b3d-59a36389a433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a768710-4ceb-4118-803f-5cd90645e2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b6f389-5079-427c-8774-7f9e87d9f957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e28c0cb6-c8cf-41bd-97dc-bc0f2e3c036e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f9d063-d2ad-4c02-b4f1-d19ee13195ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 600d6363-0747-4bd1-bc43-7988de8fdb25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af2610a-332b-43e3-bf2a-cd2c95178d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257a1943-470b-45e9-acdb-32499fa10dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375300b4-9a6b-49e8-a1eb-5942ba287adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e059785d-12f1-4380-89d3-f27855bc9d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025030d5-dfd5-4a61-86a9-3cea6eaab194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215c1f8c-49e0-4363-96b1-daf70415d139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f8b2b6f-f073-454b-9532-29ed8d46c2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dad106f-871b-43f4-83a4-f5bdfb79103d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39dc65ac-573d-4fdb-b94e-e8624bd5c679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e877560-4d53-4097-9315-893eb31f228f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6991b3c-78f9-4702-9299-235eb4135fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b45a49-af1a-4d54-90d3-5e619fcbebb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78d7b943-7a26-47b0-aac2-b8785e7fcae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee33015-85a3-4d37-9da4-7e6de00a7d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 573fde50-c775-4b90-98a8-94e47790929b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4967ceeb-da59-4877-a513-9328344dd229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10efbf3-ef80-4fef-a0b5-b9a1f0694ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 762fecd2-6ed6-423a-bc21-f6723e3e46c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ec26f9-b601-4ccc-9b38-3e692f4a4c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message febe22d7-fefd-4a21-8f16-c1c72508ed1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e11343-b850-4ae8-9771-abe654286438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88dd0683-9e85-4bc9-bf0c-ddffe666dd32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 826c3a18-1a31-43ae-ae14-9a546c7f4e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb8b3927-b278-4ae2-a84b-703b10af435f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c173a4-2b16-4361-b316-8ed4342db85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb2b6dd-f39a-4def-b46c-747c6dfa32f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee4a2a9-e340-450f-b306-a9d9bab64377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d07154e5-b2c1-4f27-93c3-33e0aea10648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b98f5b66-fb37-4fba-9c7d-ae3d2cc5235b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1f870c5-3823-4043-8fe3-c107e8cbd21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0148d205-cdc8-4c4e-9df0-ca6f6a5dcb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54de2b0-ab1c-4834-bbac-eba65b04d662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fa890ed-36c9-4296-9bcd-c0e4f3835b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77cd65b4-610d-4eda-a61c-23cfab9a6bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa91d817-817d-4ae5-b63c-f062c3bb5911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5f4f284-07d8-40d1-8b7c-58b15117a45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cbf20b9-913b-42e6-aaa6-f9208f49a214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d975e59-a18a-4fc3-9a1d-99132d43f8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bec3b40-3e8f-404c-9003-75e2fd83dcdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81ea50d-4d81-45a0-8c9d-92d5282c388d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3fde1dd-0587-48a3-96fe-4a6d474a1276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457f1748-e579-45ac-b1e9-e0c44f38857d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ff9fbe8-fbc6-42e7-925a-ab5f1145631d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5906e292-3d55-407c-bbe1-f1165ba89160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21e68fa-3f6c-4a86-9a3c-5d3c34778514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58ed31cc-9718-4743-9bb8-d8d05056ea8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46400d2-5854-4893-a701-47f6f9c70c05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6eef1e3-c5f6-4c24-9405-e6af2614a937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfbc0233-62d3-4167-89f7-5aa130c8bd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48fe849d-9916-4251-9b6c-231e30703a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebba4548-15cb-4b62-8071-33ea5b15cdb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dba07c7-fa11-4d84-ae6c-ab51ec7340d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 313ecfb6-47fb-49a3-bd71-67aeeda5e1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caac81c6-cd71-451c-be29-f3b81e874c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7876b236-cfbc-4034-81ca-9b6e41067cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c33486dc-dae4-4db9-93d1-354766908012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f24281-dcfd-4696-b85b-79585bad306e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5bb180e-129a-409a-b65f-60a4195e1beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d129b99-379b-4e5e-aa03-95bf98583efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd264150-8d52-4cd4-b3a2-b01f69e7122d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e0a77e-d4c8-41ce-a375-cb5bdf71c01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d2046bd-1d71-4a8b-a365-d8de07da789a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530cb25b-56c6-4915-bf32-daa1b6e2ae2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d51ac74-7dc7-4cb4-b412-88c6df3ff32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d88d32ae-bed7-4e2b-a977-daf7ada31b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caf74fb1-3247-4fef-bc82-c90755944976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a3e50f-73f3-4bfe-9125-9237f1c42a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3129f59-bfc5-4eeb-9114-28edbb605ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad02aa4-254a-440f-99cc-388400aff04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d9e6d0-978a-4e96-af9a-257dcdc3171f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df8ef700-ef8e-42c5-ba9c-8f51deda448a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abc9954e-7ab5-4a26-8a9f-a856bcccdc0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c86b3d-a478-480c-94e4-84e2128b5e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61fccb5f-6259-488a-85ac-828add64fcd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 037213a2-26d9-4b02-be26-a4cdbb114daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e43a4f-da57-4080-9f46-e9c34bd8c00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b62c99f-91f2-4d5d-921c-0aebdd5b0b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9a6ea1-8b26-487a-9ba0-45569eeeef41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b42dc7e-aa59-48b6-8208-c01bab292555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4342a736-668a-4f8f-b79e-fe19f1ab381f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b65c69d-a7da-4249-b845-f91b553ab7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d9e410-c6f1-49d7-ad4a-2adb24b8d49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f224bf27-76f8-4110-bb9f-101ed5e887e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f098805f-bbd3-4be5-bbbb-de8ac6fa7461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c17cf5-fdab-40ae-b2e6-3891058eeb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0afad035-2e3c-4451-ab34-48ee0a63f66a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd905857-5008-4c87-9b98-a01bb0b42029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30ee5e2d-7169-4f82-925c-571271467047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4242e24-0275-4a39-938f-fe5fe1ad7fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dce3c1f6-89ee-4e7d-8cab-e575abd9cba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc1f630-5e95-43b3-99cb-6fde3fa4447f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef9eb701-2f12-42e8-9294-c8a11a7bb3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec8e828-92fd-4c6c-bb08-a14dfa5fef9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2da0a093-225c-4472-9873-a298f5799ed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a822fdb6-4fe0-43b0-9088-d2c34555e078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 541e6437-39cb-44ec-a7a9-6e5f8f10a62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8b80c0-5220-459c-a264-dea3ccbf561b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc1c0821-8c3f-44d0-aa9d-0043cabb6df3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8340962-c08a-49b3-adaa-ea05ce885edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1ba532-9a78-4b49-b14d-bf82132a27d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84438f7-38c0-4c3a-88ca-ce7a7ce700fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86314f7-8822-41b8-8f37-98b6b86249b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f7101c-1ada-45dd-bd84-e54f660e963b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bcfad36-98e1-42ca-a333-6591b01d8a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fab0176-265f-4fa3-8cfd-fb56521a859c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315949a7-97b9-449b-bcb2-1bba7df839c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfb71c4-bb3c-461f-a62f-bdf8ae028b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba45d249-a416-41bb-8bb4-efdfcba85a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d731aa4-e77e-4e9a-ab60-9c3cc8f72927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ad2b69-9ec4-4a98-aeaa-d23d95e9de9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24994aae-1169-4d6e-a650-697cab9002cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b425c206-c4c6-43ae-aa2e-f1a823c6ce93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86997b7b-9193-47bf-85e9-270dd0bb17c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 291084a5-8948-4ff9-8fdc-a170b87b6201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12522cb5-9b21-4805-986f-94eec1d9025f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0431ce-c552-41f3-ad08-8da6bd728b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c53738f0-67e0-461e-9545-af728211c0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16d5b522-8662-487e-b8cd-0af9492b2096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd697490-754b-47f6-bff8-9ec78ff960a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d8c754-5421-4366-9186-bd90e5ba1aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba089d49-e11f-45d3-88e4-e42c38b09b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f321068f-30a6-442d-a112-c10de54444bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 453c2bb2-d6fb-476c-a011-9bba3bb93b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c20e7c27-a884-49d3-b887-06057e51a885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3fcc88d-e096-4f8a-8e0d-2be49f9fd09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f800af2a-857e-4246-8d42-ff430cad7b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c461aa88-4941-47c8-ad59-436e0bff2ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eeb4d28-3ede-4857-912c-85a81b596461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b04fa4-fa48-4541-97bf-fa93f540d338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c48bc093-d652-4107-a679-05af4eeeb927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed51119e-888a-4e3c-8027-a178cd366abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b943b94a-44ae-4ad8-919d-6d8401c03194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e2c6677-a8cd-48d1-8d69-65d222b919a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed012bbf-6b84-4e5a-897b-fce8c9693aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc06637e-0dfe-4fbf-98d6-85630af80033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b554c95-b79f-4575-91b9-0c9e2d4af42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377ad765-5a35-4cb7-b266-182a1617f922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70662bc9-3f3b-4e14-97d5-67ba1ab43494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0afcadb-455e-4a31-81ba-5217e0a21540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d19553b-bdb3-4923-a4cc-e93a3034939f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65260f4-51e0-420c-a1c7-1e130fa3bf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc4a6ce1-7e5e-4b01-ae8c-58496b13b590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8c596b-8073-43a0-8a4b-03fb04bad9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69e33d34-2a8e-4e49-8284-dc69632217f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75190371-a87c-4801-832b-d37accc54804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1eb8810-f12e-456d-a35d-e271f0430c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2331e3f-521d-4dbc-a3eb-0bd6ad266065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da225bb6-ed22-4113-a23a-bb90afce9e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2623720-0d59-44d8-bdb0-46bf83aa8d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd004e17-5849-474c-b48c-961fe3b952c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eb441f6-1eaa-4231-a294-86e635eb6644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f1904b6-320f-4467-bd39-3c6c08f7ccf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c7f7bb-f25f-4a38-b494-f1a460713677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9642b718-ba20-4463-9209-4878e7759676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c8dd37a-b6fc-4039-95a7-7ea28562dbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10198e15-c3a7-41b2-82df-b40782ccb73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6775dc75-ed90-4bac-96cd-87f990ab6caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ce9457a-3cc0-48bf-9b90-42b44fdffeaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f729b77-57ac-49fa-ad2a-ac27fe89e48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d8f8d5d-8b4e-4bfc-b999-f0d112bd73a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a407082-a5ed-4b89-8b57-3ef288511f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1770c00d-703f-480f-aba3-bf16ec6919e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 803dc258-a2c9-4076-b437-98029d569305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cba26d3-2906-405d-88a7-e831ca47d161
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_13
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/test_labels.txt

📊 Raw data loaded:
   Train: X=(1098, 24), y=(1098,)
   Test:  X=(275, 24), y=(275,)

⚠️  Limiting training data: 1098 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  266 samples, 5 features
✅ Client client_13 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2678, R²: 0.0048

============================================================
🔄 Round 2 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0910 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0813, val=0.0841 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0822, val=0.0785 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0808, val=0.0778 (↓), lr=0.001000
   • Epoch   5/100: train=0.0799, val=0.0784, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0786, val=0.0780, patience=7/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 2 Summary - Client client_13
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0079
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0169
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.1449, RMSE: 0.3807, MAE: 0.3203, R²: -0.5884

============================================================
🔄 Round 4 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0930, val=0.0704 (↓), lr=0.000500
   • Epoch   2/100: train=0.0820, val=0.0715, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0813, val=0.0700, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0811, val=0.0703, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0809, val=0.0701, patience=4/15, lr=0.000500
   📉 Epoch 9: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0800, val=0.0702, patience=10/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 4 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0313
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0060
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1195, RMSE: 0.3457, MAE: 0.2837, R²: -0.3098

📊 Round 4 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2720, R²: -0.0225

============================================================
🔄 Round 12 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000250 → 0.000125
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000125
   • Epoch   2/100: train=0.0794, val=0.0814, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0792, val=0.0814, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0791, val=0.0814, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0790, val=0.0813, patience=4/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   ✓ Epoch  11/100: train=0.0785, val=0.0810 (↓), lr=0.000063
   📉 Epoch 17: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0782, val=0.0809, patience=10/15, lr=0.000031
   📉 Epoch 25: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 12 Summary - Client client_13
   Epochs: 26/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0070
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0175
============================================================


============================================================
🔄 Round 14 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0887 (↓), lr=0.000016
   • Epoch   2/100: train=0.0805, val=0.0884, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0802, val=0.0880 (↓), lr=0.000016
   • Epoch   4/100: train=0.0800, val=0.0878, patience=1/15, lr=0.000016
   • Epoch   5/100: train=0.0798, val=0.0876, patience=2/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0793, val=0.0870, patience=5/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0791, val=0.0868, patience=6/15, lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 14 Summary - Client client_13
   Epochs: 30/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0120
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0310
============================================================


============================================================
🔄 Round 17 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0804, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 17 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0306
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0110
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0951, RMSE: 0.3084, MAE: 0.2728, R²: -0.0424

============================================================
🔄 Round 18 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 18 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0306
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0212
============================================================


============================================================
🔄 Round 20 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 20 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0242
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0345
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0954, RMSE: 0.3089, MAE: 0.2732, R²: -0.0457

📊 Round 20 Test Metrics:
   Loss: 0.0962, RMSE: 0.3102, MAE: 0.2745, R²: -0.0543

============================================================
🔄 Round 22 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 22 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0253
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0088
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0964, RMSE: 0.3105, MAE: 0.2748, R²: -0.0570

============================================================
🔄 Round 24 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 24 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0230
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0090
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0953, RMSE: 0.3087, MAE: 0.2736, R²: -0.0446

📊 Round 24 Test Metrics:
   Loss: 0.0945, RMSE: 0.3074, MAE: 0.2721, R²: -0.0358

============================================================
🔄 Round 27 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 27 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0170
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0090
============================================================


============================================================
🔄 Round 31 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 31 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0120
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0207
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2705, R²: -0.0222

============================================================
🔄 Round 32 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 32 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0110
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0117
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0932, RMSE: 0.3052, MAE: 0.2704, R²: -0.0210

============================================================
🔄 Round 37 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 37 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0139
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0043
============================================================


============================================================
🔄 Round 38 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 38 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0085
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0196
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2704, R²: -0.0205

📊 Round 38 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2705, R²: -0.0205

============================================================
🔄 Round 43 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 43 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0125
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0222
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2705, R²: -0.0205

============================================================
🔄 Round 46 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 46 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0117
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0022
============================================================


============================================================
🔄 Round 47 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 47 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0092
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0117
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2705, R²: -0.0205

📊 Round 47 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2705, R²: -0.0205

📊 Round 47 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2706, R²: -0.0206

============================================================
🔄 Round 53 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 53 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0109
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0057
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0206

📊 Round 53 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0206

📊 Round 53 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0206

============================================================
🔄 Round 56 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 56 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0128
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0030
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0207

📊 Round 56 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0207

============================================================
🔄 Round 58 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 58 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0096
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0073
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0207

📊 Round 58 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0207

📊 Round 58 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0207

============================================================
🔄 Round 62 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 62 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0133
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0031
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2706, R²: -0.0206

============================================================
🔄 Round 63 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 63 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0083
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0273
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2706, R²: -0.0205

============================================================
🔄 Round 64 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 64 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0126
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0054
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2706, R²: -0.0205

📊 Round 64 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2706, R²: -0.0204

============================================================
🔄 Round 66 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 66 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0119
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0023
============================================================


============================================================
🔄 Round 68 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 68 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0064
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0284
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2706, R²: -0.0204

============================================================
🔄 Round 69 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 69 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0095
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0057
============================================================


============================================================
🔄 Round 70 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 70 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0123
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0079
============================================================


============================================================
🔄 Round 71 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 71 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0114
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0014
============================================================


============================================================
🔄 Round 72 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 72 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0118
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0143
============================================================


============================================================
🔄 Round 73 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 73 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0113
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0008
============================================================


============================================================
🔄 Round 74 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 74 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0106
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0038
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2707, R²: -0.0206

============================================================
🔄 Round 75 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 75 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0010
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0685
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0206

============================================================
🔄 Round 76 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 76 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0141
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0077
============================================================


============================================================
🔄 Round 78 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 78 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0109
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0004
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0204

============================================================
🔄 Round 80 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 80 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0005
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0486
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2706, R²: -0.0201

============================================================
🔄 Round 87 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 87 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0077
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0118
============================================================


============================================================
🔄 Round 88 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 88 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0122
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0010
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0202

============================================================
🔄 Round 89 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 89 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0123
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0078
============================================================


============================================================
🔄 Round 91 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 91 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0093
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0038
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0204

📊 Round 91 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0204

============================================================
🔄 Round 96 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 96 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0044
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0331
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0204

📊 Round 96 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0204

📊 Round 96 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0204

============================================================
🔄 Round 100 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 100 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0085
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0271
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0203

============================================================
🔄 Round 103 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 103 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0112
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0049
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0203

============================================================
🔄 Round 105 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 105 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0090
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0157
============================================================


============================================================
🔄 Round 106 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 106 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0064
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0148
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0203

============================================================
🔄 Round 108 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 108 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0124
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0121
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0204

📊 Round 108 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0204

============================================================
🔄 Round 111 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 111 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0122
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0013
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0203

============================================================
🔄 Round 113 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 113 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=-0.0062
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0269
============================================================


============================================================
🔄 Round 114 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 114 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0094
   Val:   Loss=0.0672, RMSE=0.2592, R²=-0.0046
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0202

📊 Round 114 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0202

📊 Round 114 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2706, R²: -0.0199

📊 Round 114 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2706, R²: -0.0199

📊 Round 114 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2707, R²: -0.0199

============================================================
🔄 Round 129 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 129 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0052
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0244
============================================================


============================================================
🔄 Round 130 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 130 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0117
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0078
============================================================


============================================================
🔄 Round 131 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 131 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0133
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0119
============================================================


============================================================
🔄 Round 133 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 133 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0069
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0479
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2706, R²: -0.0198

============================================================
🔄 Round 136 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 136 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0117
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0080
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2706, R²: -0.0197

============================================================
🔄 Round 138 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 138 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0035
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0419
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2706, R²: -0.0197

============================================================
🔄 Round 139 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 139 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0068
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0116
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2706, R²: -0.0196

============================================================
🔄 Round 140 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 140 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0087
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0128
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2706, R²: -0.0196

============================================================
🔄 Round 142 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 142 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0025
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0311
============================================================


============================================================
🔄 Round 143 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 143 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0094
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0011
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0196

📊 Round 143 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0196

============================================================
🔄 Round 145 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 145 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0052
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0316
============================================================


============================================================
🔄 Round 146 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 146 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0057
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0611
============================================================


============================================================
🔄 Round 147 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 147 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0110
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0049
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0196

============================================================
🔄 Round 150 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 150 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0114
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0055
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0196

============================================================
🔄 Round 151 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 151 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=-0.0043
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0214
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0196

============================================================
🔄 Round 152 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 152 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0077
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0150
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0196

📊 Round 152 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0196

📊 Round 152 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0196

============================================================
🔄 Round 157 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 157 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0058
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0129
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0195

📊 Round 157 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0195

============================================================
🔄 Round 159 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 159 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0091
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0028
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0195

📊 Round 159 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0194

============================================================
🔄 Round 162 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 162 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0050
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0355
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0194

📊 Round 162 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0194

📊 Round 162 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0194

============================================================
🔄 Round 168 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 168 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0066
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0233
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0195

📊 Round 168 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2707, R²: -0.0195

============================================================
🔄 Round 172 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 172 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0048
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0215
============================================================


============================================================
🔄 Round 173 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 173 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0014
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0428
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0196

============================================================
🔄 Round 179 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 179 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0095
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0009
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0197

📊 Round 179 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0197

============================================================
🔄 Round 182 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 182 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0051
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0131
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0197

============================================================
🔄 Round 183 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 183 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0081
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0033
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0197

📊 Round 183 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0198

📊 Round 183 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0198

============================================================
🔄 Round 187 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 187 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0053
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0134
============================================================


============================================================
🔄 Round 188 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 188 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=-0.0069
   Val:   Loss=0.0755, RMSE=0.2749, R²=-0.0092
============================================================


============================================================
🔄 Round 189 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 189 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0044
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0200
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0198

============================================================
🔄 Round 191 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 191 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0022
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0246
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0198

============================================================
🔄 Round 193 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 193 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0078
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0023
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0931, RMSE: 0.3050, MAE: 0.2708, R²: -0.0198

============================================================
🔄 Round 194 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 194 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0066
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0099
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0931, RMSE: 0.3050, MAE: 0.2708, R²: -0.0199

============================================================
🔄 Round 196 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 196 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0031
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0258
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0931, RMSE: 0.3050, MAE: 0.2708, R²: -0.0199

📊 Round 196 Test Metrics:
   Loss: 0.0931, RMSE: 0.3050, MAE: 0.2708, R²: -0.0199

📊 Round 196 Test Metrics:
   Loss: 0.0931, RMSE: 0.3050, MAE: 0.2708, R²: -0.0198

============================================================
🔄 Round 203 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 203 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0072
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0065
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0198

============================================================
🔄 Round 205 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 205 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0092
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0026
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0198

============================================================
🔄 Round 206 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 206 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0022
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0303
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0197

============================================================
🔄 Round 208 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 208 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0074
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0044
============================================================


============================================================
🔄 Round 209 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 209 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0082
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0232
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2708, R²: -0.0197

============================================================
🔄 Round 210 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 210 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0042
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0201
============================================================


❌ Client client_13 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
