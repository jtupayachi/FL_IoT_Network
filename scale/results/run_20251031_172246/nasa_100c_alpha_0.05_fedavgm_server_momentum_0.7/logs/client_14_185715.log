[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57a37f19-4594-4563-866c-0aaf469a79f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5589fe98-b9ed-4501-800d-85f98220c8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1a5ecf-e93f-4b9b-9fdf-0b0a478cc334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60a9a190-0b26-4930-8f59-bfe60232b8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e775828-f1b9-45ad-9f70-237a3b2e32b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d409a9-ee72-49a8-8b73-bdf1b75f806e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 962a5867-685f-4334-8817-ae3827fbe919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b730ee1b-7c00-4154-8425-08be39258ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17212898-c2d8-4bfa-b218-6d86bf6d5c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca4b128-7596-46a9-9d51-9ed32ea61ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d4d6a11-803e-4c30-9bd2-933292e0d49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12312f5f-268a-4c7f-8040-177183a3affa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98904db6-463f-42ae-933d-e543d8dfbcc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1f4e605-02a4-40d0-ae29-9df6212cf239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57a78543-84d9-468e-ba92-4fe796b20573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ea4a7fe-4a74-4842-9f7a-e5ff8ada6668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a110fc-109a-41b2-9a86-5d520436b9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b2a90e8-e9c4-4163-81ea-b4e8439fcf0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436f8cbd-6e07-46c1-96fe-df8fd6b3f753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95d37ec-66f1-425d-aa25-99df3c84b1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d7f5361-3003-4708-ada2-f8c7f1fce902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ec7b6e-9816-49fa-ae6f-bac5549f828b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b506815-c37b-4a0f-a717-888f5c05fe66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca90bafe-4c45-4512-ad3c-12962829c034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa62df9-363e-46d9-8d09-f04f62f04e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65ef7bf0-aac0-444d-be72-0a07fa802576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dbf0750-c14d-446b-bce3-f90da79bf7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79ed55a-7c67-42b5-8b15-d60136669a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b122c10-4aaf-40c1-bd5c-2a93ecbef371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df8e0f53-f443-4359-85e0-afb667563f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e40609-8f80-42a6-be68-20dd19247cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be73ff74-aefb-4527-9f0e-ed3be806af44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bd2f0ed-c3fa-4829-89b3-ca53b1a132b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aff53ec-4e52-4b42-b457-7a4626e85f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a58e76-c89b-4c18-a817-15e44b659709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5331fb0a-4ccc-4f58-9b32-282a2d63d4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a53ce25-0fea-4149-a010-3e8440c18e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e604e9-96e3-4b9d-8ed7-da68501e0f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63fc3d2c-93df-4c0b-a769-99a1190a63c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0621614-f744-46b3-8bde-e0ecd0237e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24dde380-1317-47e8-967f-7a4463750066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aeb8fc7-36fe-4146-a9c2-e912678d90f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689e6d41-2ec3-4b2a-8c48-50437d5b7846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2236c0-6acc-4773-ae0d-a67464c0d30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e501fd-cf58-4636-a3ab-78da29f103b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7364c5-c9a8-437c-b4d8-ce6d88ed2d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd6af43-70ac-477e-b2f1-b4dd9cad9dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2cc2581-1d0f-45c1-b256-4f4bb148a1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8c335d-f3be-4709-8e34-a87623e6e884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d05ada-78df-49e8-bdd1-af93d77e7fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f9f114-ade2-4a73-959e-f0cbc75960a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb92a58-804d-4e2d-b3a2-d23e29f29882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163aa679-eb09-4739-b6c0-a9f126308e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ede66427-5825-4d35-983f-6d7fde27533a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5fca03-3bf0-4775-8309-0771e851d6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c27f78-3c13-42b0-85ac-9ef63b203915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed5211e-03a6-4fb2-ad35-44416841d224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f65ecff-b21a-4d62-add5-dc8d2873f636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f808920-70ed-4e1a-ae50-b86cbb962849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba74241a-540b-4325-adbf-2974719a8433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba7358f-081d-4b78-89cb-d1e74c84b834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d977fb8-e1bb-4953-909d-598ef02144d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfdb9067-4b5a-4a94-84ae-26805caecc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9060daf-c84c-4e1d-a7df-a979dd086b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6412a18b-d2cc-4c68-b2f7-ba2c0344cce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed69864f-1883-4e9a-a9c4-9a0a0b34ff03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd0d141-1d74-424f-8ef0-c308dcf1b741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0630d39-2f80-4abd-985a-9bfe3dcb7cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a71667-3e97-467c-9773-d7a695079e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e17d638c-cdd9-40c4-b30f-1e6c555b4a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06324eee-f3ba-41d4-990a-c7a7f7fbd66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbfc3d28-7ad7-46ce-9854-99f54877ba8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e3ea067-be7f-436f-9127-29724f0136dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 625f1602-d1a7-4dcd-860f-e5a89b0b6db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed9f6b16-2c7d-4972-8944-9b992ef8a153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071b5953-d4e1-4f66-8806-45d521ef3634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d2cccd-644a-4b24-8872-9fbcedaef8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2205240-fac1-41f0-ad1c-2ddb78e7464b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17794760-d996-4ca3-87a8-8c8dd60d281a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4f2a81-34f5-4e8e-88e6-238355b78382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e613df-e8e5-4ed8-b3ca-39ce0f97bc99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb1e483-6546-4550-866a-b4d91d00b9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d826c3-206a-4c2f-837e-d8160c87142f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3938eabd-8897-4ec8-aaa5-171d032137a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de54053-a0c7-4685-bc80-4d94c49e2360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ef86bb-69bf-4f6a-a8af-f74e8a10a89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9117a933-6a55-4ce6-b3ba-7797dd99fd2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e4a1e53-e991-4352-a728-9c7dcb8de7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d590ac91-e815-481c-b9e3-4475f7b9f24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d3e88f-d6a8-480a-9c45-95afdd8b225f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c92677-2291-4c0a-9d83-bcb6dd3faff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d350561f-4972-4cd8-8ee7-2aa322eac3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1100ab35-10c7-4099-9af0-72cd0f4f4e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79219ce7-fbb4-4427-b110-407671fd3089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afedf3c8-df12-48f6-8c85-cdc655bb2bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47051a26-bb3b-430c-b918-136f59d79b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73361b8d-5b8e-4a16-b9c8-c45c6153b560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3a81e5-2d93-4c99-90f1-21ca440a32e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5842f7a-121e-4407-834b-e4c887774390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1fc1349-c506-4e80-896c-0655d3fdf222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5295f3a-fc33-4945-b198-be6d6e31ec1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06e5884c-8733-415b-b78e-728c635336e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 815f631c-2d95-4963-9e09-11688a29a949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fdadd56-59f9-4c67-85e8-0c2e53d41823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20424075-b9b8-45ba-b492-35a5c9ab9953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87307e09-14ad-45d1-a060-5756aed13ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a751d0-d999-4cb3-b8e5-111c86a1503b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d68256d-af51-4a20-9509-ae56b2621b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19b5e31f-c73d-492a-80ef-37475584885f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f8fd04-14ec-4a67-9cb8-45daeef419a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd41cdac-2edd-45ae-9eb1-4dc1106c4898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38076ef7-d938-496d-9d28-3ea1a8a8ebf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b49cbb6-88f8-4014-a487-17452adb59b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9acffd5a-b1ce-45fd-9dbb-27a4e7936e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3fbbd2-356e-4b8d-9e71-325dc7bcb45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c831aa9-e4e7-4de2-b6a3-4cc38fc71ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed528f1f-a79e-4b86-8ef7-6ad1c9391ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fd6d1e9-989d-4871-88ac-bf015a86c29f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a36596-61c7-4580-a51c-8054aef1c5c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d81f7b94-60cd-4c70-bfb1-08cc940c76a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a62317fe-f492-4850-8a46-1cb284fb5447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a81f575c-f30d-4c74-a96e-84d0619380ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9715b392-b614-4e5d-957f-0b954462d32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af4db8c2-ad95-43d3-94bf-236ce200a583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 826834f2-abc5-4e5e-9431-e55209d0d6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42faf30a-2bc1-438d-8964-1057f900486b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d45a5ab5-c6a5-49ba-ba50-94793637913f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 579809bc-0e77-4636-a91a-77b982e63ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d7dd32-00c3-44ac-ab40-60130c320c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe003ef-4010-42a3-a995-a53c571fd914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a5b689-5061-41b6-8d79-58de02f0eb85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da628c01-cb09-4d4e-9485-72581d43869d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e933f7ac-96aa-4e05-9122-209ae313f6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8ef3536-5cb7-4277-9c0f-2c64bd182f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be813012-7ea7-48a7-a6ea-4703fa66b678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a1a8695-e3a6-4108-af1c-41dc10dc562d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 391a018b-49bf-49b2-a898-f42c94d9cc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6846e9b7-8b44-493a-ab35-4094891c4edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38f314ac-9252-4328-b808-d1fd97e4d2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c46b16c8-2183-4c9f-b5b3-26ee17c6f551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c006130-d270-4131-a7e3-2960919c1065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d6e2f0-354b-411a-a95a-89b4f7438924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88608b31-0572-43c0-a9c6-e246b21f8bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7962658-1119-4911-a5cb-0ab83f41b98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8890234-48f4-4fd1-8d5a-3067920680ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b876335-99aa-437e-a2de-bfde340f83e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8b165a-c2a7-4e08-ac4b-4ca5958e4eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1afc3a78-726d-48e6-93b7-c4bf8173b387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3068f8d-849b-435c-8645-2804ee32e9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68898363-62bf-432f-83e5-c017fd6d7c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45bddad7-4f3b-4195-9c6a-4bd38e10419d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac6d113-9a6d-410b-b7e3-3fdd42b41ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 118eb7e1-71cf-415c-9658-9b42d46dee03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6ce02e-8ac6-4d41-8b2e-34808257c02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f22f1a4-4a1b-498b-b01d-0fdf221013d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc830bf-c3f9-4e94-8bcf-bc9bb7d33b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 062c04dc-f10e-4c9d-8709-41c52981eefc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14131c7a-0608-413a-b11e-2cb20960f242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b94a01-82d5-49b7-8545-212f223679a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbcf4a12-3931-4057-96bd-4abd2992068c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db312bbc-4c43-4c2c-99e5-cc928b315254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c64fff2b-9723-41a6-902c-3196c906a2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 007e2839-effb-4f89-a3e4-edc1645a1700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fadce22-c8c1-4168-9de1-cc8001ae14b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcf044c2-a112-4b73-ad09-2d89b750cc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f84a94-e601-423e-a5c3-f0286d32e5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d31ff72-be91-4a8c-ae62-fb23444c79f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c145a16e-8cbd-4a4a-bb34-b51345091a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 315043ca-d9e6-4e74-a883-5e26e6c91e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c701c82e-99c7-4b27-a908-ecc3419caa8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 242c4385-aec7-47c0-b4b3-9ac07451bf26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d25d2e9-e08b-406a-8076-7a8d01468a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b809a174-98bd-46c0-a69a-c9f2928e5eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb148853-e363-41c4-932b-1a2095bb0ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d3974f-296b-44d9-89bc-4cc521276e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0468f436-31ac-4828-b987-d0f494e1a2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 648df1de-75ef-4c58-8cad-f1a864dcf847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf14d5a3-0f9b-4ae6-9192-616cb8aa0c23
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_14
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/test_labels.txt

📊 Raw data loaded:
   Train: X=(601, 24), y=(601,)
   Test:  X=(151, 24), y=(151,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 592 samples, 5 features
   Test:  142 samples, 5 features
✅ Client client_14 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.3591, RMSE: 0.5992, MAE: 0.5252, R²: -3.3405

📊 Round 0 Test Metrics:
   Loss: 0.1384, RMSE: 0.3720, MAE: 0.3162, R²: -0.6729

============================================================
🔄 Round 5 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0908 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0827, val=0.0877 (↓), lr=0.001000
   • Epoch   3/100: train=0.0822, val=0.0876, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0820, val=0.0875, patience=2/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0819, val=0.0871 (↓), lr=0.001000
   • Epoch  11/100: train=0.0803, val=0.0875, patience=6/15, lr=0.001000
   📉 Epoch 14: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 5 Summary - Client client_14
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0084
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0204
============================================================


============================================================
🔄 Round 6 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0977, val=0.0827 (↓), lr=0.000500
   • Epoch   2/100: train=0.0857, val=0.0825, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0836, val=0.0833, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0837, val=0.0823, patience=4/15, lr=0.000500
   • Epoch  11/100: train=0.0832, val=0.0819, patience=4/15, lr=0.000500
   • Epoch  21/100: train=0.0826, val=0.0817, patience=14/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 6 Summary - Client client_14
   Epochs: 22/100 (early stopped)
   LR: 0.000500 → 0.000500 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0016
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0103
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2471, R²: -0.0620

============================================================
🔄 Round 7 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0824 (↓), lr=0.000500
   • Epoch   2/100: train=0.0843, val=0.0827, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0836, val=0.0821, patience=3/15, lr=0.000500
   📉 Epoch 5: LR reduced 0.000500 → 0.000250
   • Epoch   5/100: train=0.0835, val=0.0821, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0831, val=0.0820, patience=10/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 7 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0004
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0201
============================================================


============================================================
🔄 Round 8 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0868 (↓), lr=0.000125
   • Epoch   2/100: train=0.0831, val=0.0865, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0829, val=0.0864, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0828, val=0.0863, patience=3/15, lr=0.000125
   📉 Epoch 5: LR reduced 0.000125 → 0.000063
   • Epoch   5/100: train=0.0827, val=0.0863, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0824, val=0.0863, patience=4/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031
   📉 Epoch 21: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0822, val=0.0862, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 8 Summary - Client client_14
   Epochs: 22/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0018
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0171
============================================================


============================================================
🔄 Round 9 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0923 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0887, val=0.0917 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0875, val=0.0912 (↓), lr=0.000016
   • Epoch   4/100: train=0.0866, val=0.0908, patience=1/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0859, val=0.0906 (↓), lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0840, val=0.0904, patience=6/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 9 Summary - Client client_14
   Epochs: 20/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0396
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0366
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0913, RMSE: 0.3021, MAE: 0.2614, R²: -0.1033

📊 Round 9 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2484, R²: -0.0435

📊 Round 9 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2498, R²: -0.0574

============================================================
🔄 Round 14 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0930, val=0.0755 (↓), lr=0.000004
   • Epoch   2/100: train=0.0929, val=0.0755, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0928, val=0.0754, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0927, val=0.0754, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0926, val=0.0753, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0922, val=0.0751, patience=10/15, lr=0.000004
   • Epoch  21/100: train=0.0916, val=0.0748, patience=9/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 14 Summary - Client client_14
   Epochs: 27/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=-0.0678
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0408
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2598, R²: -0.1011

============================================================
🔄 Round 15 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0942, val=0.0786 (↓), lr=0.000004
   • Epoch   2/100: train=0.0940, val=0.0785, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0939, val=0.0784, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0938, val=0.0783, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0937, val=0.0782, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0933, val=0.0779, patience=3/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0930, val=0.0777, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 15 Summary - Client client_14
   Epochs: 23/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0934, RMSE=0.3057, R²=-0.0834
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0916
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0929, RMSE: 0.3047, MAE: 0.2630, R²: -0.1226

============================================================
🔄 Round 16 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0985, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0909, val=0.0980 (↓), lr=0.000001
   • Epoch  31/100: train=0.0906, val=0.0975, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0904, val=0.0972, patience=8/15, lr=0.000001
   • Epoch  51/100: train=0.0902, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.0900, val=0.0965, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 16 Summary - Client client_14
   Epochs: 62/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=-0.0875
   Val:   Loss=0.0970, RMSE=0.3114, R²=-0.1459
============================================================


============================================================
🔄 Round 20 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 20 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0582
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.1066
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2600, R²: -0.0961

📊 Round 20 Test Metrics:
   Loss: 0.0926, RMSE: 0.3042, MAE: 0.2636, R²: -0.1189

📊 Round 20 Test Metrics:
   Loss: 0.0932, RMSE: 0.3054, MAE: 0.2647, R²: -0.1272

============================================================
🔄 Round 23 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0938, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0937, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0936, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0934, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0933, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0928, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 23 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0936, RMSE=0.3060, R²=-0.1154
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0489
============================================================


============================================================
🔄 Round 24 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0885, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0910, val=0.0879, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0906, val=0.0875, patience=11/15, lr=0.000001
   • Epoch  41/100: train=0.0902, val=0.0871, patience=9/15, lr=0.000001
   • Epoch  51/100: train=0.0898, val=0.0867, patience=6/15, lr=0.000001
   • Epoch  61/100: train=0.0895, val=0.0864, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0892, val=0.0861, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 24 Summary - Client client_14
   Epochs: 74/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0522
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.1361
============================================================


============================================================
🔄 Round 27 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0915, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0872, val=0.0911, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0869, val=0.0908, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0866, val=0.0905, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 27 Summary - Client client_14
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0424
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.1038
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2586, R²: -0.0712

============================================================
🔄 Round 28 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 28 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0620
   Val:   Loss=0.0973, RMSE=0.3120, R²=-0.0354
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2564, R²: -0.0559

📊 Round 28 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2560, R²: -0.0536

============================================================
🔄 Round 32 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 32 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0326
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0648
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2558, R²: -0.0516

📊 Round 32 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: -0.0501

📊 Round 32 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2554, R²: -0.0490

📊 Round 32 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2553, R²: -0.0482

📊 Round 32 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2552, R²: -0.0477

============================================================
🔄 Round 37 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 37 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0370
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0152
============================================================


============================================================
🔄 Round 38 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 38 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0312
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0508
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2551, R²: -0.0474

============================================================
🔄 Round 40 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 40 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0477
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0192
============================================================


============================================================
🔄 Round 41 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 41 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0251
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0672
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2552, R²: -0.0478

📊 Round 41 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2553, R²: -0.0480

============================================================
🔄 Round 43 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 43 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0388
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0089
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2553, R²: -0.0480

============================================================
🔄 Round 44 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 44 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0199
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0828
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2553, R²: -0.0481

📊 Round 44 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2553, R²: -0.0483

📊 Round 44 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2554, R²: -0.0491

============================================================
🔄 Round 52 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 52 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0358
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0233
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2555, R²: -0.0494

============================================================
🔄 Round 54 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 54 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0270
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0589
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2555, R²: -0.0498

📊 Round 54 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: -0.0500

============================================================
🔄 Round 57 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 57 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0363
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0288
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2557, R²: -0.0510

📊 Round 57 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2557, R²: -0.0510

============================================================
🔄 Round 61 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 61 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0254
   Val:   Loss=0.0970, RMSE=0.3114, R²=-0.0680
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2557, R²: -0.0507

============================================================
🔄 Round 62 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 62 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0259
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0690
============================================================


============================================================
🔄 Round 63 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 63 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0330
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0371
============================================================


============================================================
🔄 Round 64 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 64 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0241
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0661
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2554, R²: -0.0491

============================================================
🔄 Round 65 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 65 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0363
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0174
============================================================


============================================================
🔄 Round 68 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 68 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0215
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.1326
============================================================


============================================================
🔄 Round 70 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 70 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0433
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0091
============================================================


============================================================
🔄 Round 71 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 71 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0248
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0679
============================================================


============================================================
🔄 Round 72 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 72 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0383
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0065
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2555, R²: -0.0499

📊 Round 72 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: -0.0502

============================================================
🔄 Round 75 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 75 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0199
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0894
============================================================


============================================================
🔄 Round 76 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 76 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0308
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0452
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2555, R²: -0.0499

============================================================
🔄 Round 78 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 78 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0379
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0190
============================================================


============================================================
🔄 Round 79 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 79 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0407
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0000
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: -0.0496

============================================================
🔄 Round 80 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 80 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0528
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0449
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2554, R²: -0.0489

============================================================
🔄 Round 82 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 82 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0370
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0494
============================================================


============================================================
🔄 Round 83 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 83 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0296
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0376
============================================================


============================================================
🔄 Round 85 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 85 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0329
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0180
============================================================


============================================================
🔄 Round 86 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 86 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0249
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0656
============================================================


============================================================
🔄 Round 87 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 87 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0305
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0326
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2553, R²: -0.0482

============================================================
🔄 Round 90 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 90 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0352
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0250
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: -0.0498

============================================================
🔄 Round 92 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 92 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0417
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0107
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: -0.0505

============================================================
🔄 Round 95 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 95 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0222
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0750
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2557, R²: -0.0510

============================================================
🔄 Round 96 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 96 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0251
   Val:   Loss=0.0990, RMSE=0.3146, R²=-0.0659
============================================================


============================================================
🔄 Round 98 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 98 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0260
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0711
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: -0.0503

============================================================
🔄 Round 100 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 100 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0174
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0966
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: -0.0500

============================================================
🔄 Round 101 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 101 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0364
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0208
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: -0.0499

============================================================
🔄 Round 102 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 102 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0299
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0392
============================================================


============================================================
🔄 Round 103 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 103 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0321
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.1037
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2555, R²: -0.0499

============================================================
🔄 Round 104 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 104 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0262
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0577
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: -0.0499

============================================================
🔄 Round 105 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 105 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0307
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0405
============================================================


============================================================
🔄 Round 107 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 107 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0392
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0088
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2557, R²: -0.0506

📊 Round 107 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2557, R²: -0.0508

📊 Round 107 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2557, R²: -0.0508

📊 Round 107 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2557, R²: -0.0506

============================================================
🔄 Round 112 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 112 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0319
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0332
============================================================


============================================================
🔄 Round 113 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 113 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0257
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0687
============================================================


============================================================
🔄 Round 115 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 115 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0501
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0377
============================================================


============================================================
🔄 Round 116 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 116 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0279
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0481
============================================================


============================================================
🔄 Round 119 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 119 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0268
   Val:   Loss=0.0970, RMSE=0.3114, R²=-0.0567
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2553, R²: -0.0488

============================================================
🔄 Round 120 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 120 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0289
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0380
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2553, R²: -0.0486

📊 Round 120 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2552, R²: -0.0480

============================================================
🔄 Round 123 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.1010 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.1010, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.1010, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.1009, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.1009, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1010)

============================================================
📊 Round 123 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0258
   Val:   Loss=0.1010, RMSE=0.3178, R²=-0.0519
============================================================


============================================================
🔄 Round 124 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 124 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0343
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0139
============================================================


============================================================
🔄 Round 125 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 125 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0518
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0538
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2551, R²: -0.0476

============================================================
🔄 Round 127 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 127 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0271
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0395
============================================================


============================================================
🔄 Round 129 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 129 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0332
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0154
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2551, R²: -0.0474

============================================================
🔄 Round 134 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 134 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0248
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0519
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2551, R²: -0.0472

============================================================
🔄 Round 137 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 137 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0293
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0278
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2549, R²: -0.0463

============================================================
🔄 Round 138 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 138 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0394
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0029
============================================================


============================================================
🔄 Round 139 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 139 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0207
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.0559
============================================================


============================================================
🔄 Round 141 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 141 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0283
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0333
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2549, R²: -0.0458

============================================================
🔄 Round 142 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 142 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0242
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0438
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2549, R²: -0.0458

============================================================
🔄 Round 143 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 143 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0261
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0365
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2550, R²: -0.0463

📊 Round 143 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2550, R²: -0.0466

📊 Round 143 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2549, R²: -0.0462

============================================================
🔄 Round 149 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.1007 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1007)

============================================================
📊 Round 149 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0172
   Val:   Loss=0.1007, RMSE=0.3173, R²=-0.0834
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2549, R²: -0.0460

============================================================
🔄 Round 150 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 150 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0222
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0530
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2548, R²: -0.0455

============================================================
🔄 Round 152 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 152 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0274
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0473
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2548, R²: -0.0455

============================================================
🔄 Round 153 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 153 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0219
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0490
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2549, R²: -0.0456

============================================================
🔄 Round 155 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 155 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0169
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0770
============================================================


============================================================
🔄 Round 158 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 158 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0245
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0435
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2547, R²: -0.0449

📊 Round 158 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2546, R²: -0.0444

============================================================
🔄 Round 164 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 164 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0261
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0252
============================================================


============================================================
🔄 Round 166 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 166 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0239
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0347
============================================================


============================================================
🔄 Round 168 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 168 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0358
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0140
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2547, R²: -0.0447

📊 Round 168 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2547, R²: -0.0449

📊 Round 168 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2548, R²: -0.0454

============================================================
🔄 Round 173 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 173 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0422
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0390
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2549, R²: -0.0459

📊 Round 173 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2550, R²: -0.0463

============================================================
🔄 Round 179 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 179 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0359
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0035
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2550, R²: -0.0464

============================================================
🔄 Round 180 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 180 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0248
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0360
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2550, R²: -0.0465

============================================================
🔄 Round 184 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 184 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0302
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0189
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2551, R²: -0.0471

📊 Round 184 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2551, R²: -0.0472

============================================================
🔄 Round 189 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 189 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0358
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0020
============================================================


============================================================
🔄 Round 190 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 190 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0286
   Val:   Loss=0.0703, RMSE=0.2652, R²=-0.0281
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2552, R²: -0.0476

📊 Round 190 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2553, R²: -0.0478

============================================================
🔄 Round 193 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 193 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0243
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0440
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2553, R²: -0.0479

============================================================
🔄 Round 196 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 196 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0365
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0072
============================================================


============================================================
🔄 Round 198 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 198 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0343
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0105
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2553, R²: -0.0478

📊 Round 198 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2552, R²: -0.0472

============================================================
🔄 Round 203 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 203 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0192
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0652
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2551, R²: -0.0471

📊 Round 203 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2552, R²: -0.0472

============================================================
🔄 Round 206 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 206 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0288
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0233
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2550, R²: -0.0465

❌ Client client_14 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
