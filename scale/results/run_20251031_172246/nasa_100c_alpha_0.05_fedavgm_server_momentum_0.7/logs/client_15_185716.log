[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68368b9e-720b-4e33-b32c-e63dc4c1c48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99157356-38a9-4b4b-aa19-48442e35abdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8bbac2-11d5-4ea8-8846-0697928f4142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b0ea2c-1c0d-458c-8586-3af2389201ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e7909b-d315-4f9a-8208-f914c89b3542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b07564ce-d9c3-435b-a658-080806c34c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a04e6770-a4ff-44d8-be1c-8bd57070a5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf43dbd-c9d5-4a14-97d7-8735d22c9d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf65ec7-de60-4de4-8db7-ccd8ddf311d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a546ba9-e08e-4b73-b570-38dfb8becd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dadf02d7-0e72-4093-bc2d-582a4fc91fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03bce52c-eabd-4b15-8a1d-4d611661fae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca89fa68-cd5e-4c10-8bd1-6c2b0aebfb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f8fe02-6533-4f3a-997a-a7ef436fb6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee254b02-9727-481e-a364-1c6d369817f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad5e7315-5c79-4507-bf75-d2f2a663aad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f565e457-ce66-46e0-94f7-202f9b4d4ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06336f25-3690-4ce2-a5f8-2de6e43aa1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e43f9b1a-4c0c-46e8-aea2-207b6542f62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb9881bc-683d-4697-98ac-6df58b7dfb42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b39bed-de53-4309-ae61-9d4edf7d883d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e869f586-eef5-479f-b9e3-4821112fd7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e2b1d9d-add6-4830-80ec-a71b055436fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25eb427c-75e7-488f-9ebc-2362ad4a362d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a451adda-8526-422a-967d-8beb980957ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d8055e-8642-4d23-9670-daf2cf4247e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 830c30a6-7005-4e5f-bbd1-19e92876f964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbacb0c0-3df7-479e-a259-ac5c69efe4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9220ad8a-c17c-43e3-a262-263951c5c165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f40d75-3b2f-49cb-b4b8-2f7cfec796b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b91883ab-b328-418e-98b5-72b6434e3e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4b5da3-2b73-4f68-a923-8a0985fd2669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca3cf523-accd-42d5-a41d-4180f62fa77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33fa07a8-e10b-426d-9bd7-8ec858ac9a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08044c64-5a92-49d4-9954-15ad9f268990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aefeff8-bab3-48a8-81a6-fedf5ffe74bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2388445-02c9-4930-bc97-47c4010a8554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84888f0b-2d67-4d6e-b73d-bede3abf389b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1881a5b2-1415-46bd-9a8a-8b1657f4ba52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8cf9173-3009-4683-a1db-94df926a9151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb3e567-f2d4-4628-9ded-82901845d0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f7d697-381c-4f03-b8d4-4d07fe59fc2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53c4c35-b55c-422d-baff-6445cf9a236c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f4e602-d07d-4bf4-ad0e-d1a12f86e8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1446c644-2076-42e6-9003-cb22c98d2f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd88997-5c23-4cc5-bb6a-f9c564395bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41021513-6c4a-4918-81ef-252977a06a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93960e5d-406d-4e2d-9d86-26049735f19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96943a26-d05b-4cd3-865d-0c5635a9b568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84bb0388-3e9c-43f5-b313-bb433fa8e9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75d98af5-bd2c-4901-82ec-3665df7f2444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad1aa64f-9545-4927-b130-e311d728a933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c99bb9e-4fad-4ec1-81c7-5be77a0ad36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b866e2fd-64a0-48b4-87f4-2a50b71b38b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f118fccf-6c5e-45f3-99c7-c7beb8391cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d298695-7869-4acb-a829-0b723680b41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 845dd915-8647-4f09-871d-3d6ca2567c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a0cc77-26e4-4303-9740-86c075d60dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751d025e-7e6c-45eb-9e78-8ab793e912e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6e632f-9e8c-4ca0-a6af-8b5a096e7889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5e93df-795e-49f7-9631-03c0c8916ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d85eb513-ce17-4631-ba80-3bc82406bc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e9e7f3-2d47-450f-a491-8fa67b41f55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad28e414-0e95-42da-8842-51f476477cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfce4fc0-b7e7-402d-a063-967d2b70c224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae5477f8-1986-4da1-a319-aba3eac70325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5da6c46-bde5-4ecd-9cec-8b55ba7685c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b7e4b2-5311-49f6-80f5-cf82e544df6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d86fe92-ca6b-480e-8910-007778600887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79d2fdfb-70b4-4f0d-939d-986183b40968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87027853-b910-46d5-b2a1-046891048d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b39972e-188e-445c-af34-b77463aca4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8acbda43-39f8-4d1f-a509-7e0287884696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb9ae0c8-f5cb-44a6-b570-311c9ef9157e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3995eb11-7aca-4613-86cb-2e43e2ebe2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f100c5c-8f93-437c-8cf4-8e71376c4de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a315cf4f-cf10-4564-ae77-3044e53b7d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ad34393-5742-44ae-8216-cce3ec60ad16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e5afe70-b99c-4e0e-a404-edeea50144fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d018a9-f24a-4756-affc-e6ad4022ff8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea344cf-3c03-494a-a675-da7db274ca08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36264eb9-087c-413f-88b8-e7b6b793e595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad92ed3b-5886-40b5-8365-08e9011cc8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7f9baf2-4631-4784-848b-1e5331f6cb41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde4b179-2262-4b7b-912a-51b88636d8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0170f9e8-f6a7-4cb7-a608-d96305052a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b0e1d7-b580-4015-811e-f0a4febc21d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de9d9822-4244-4f45-8049-cb576d8bebe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bf96c4a-fad4-4c0d-bc69-0673244b43da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17c4e0e7-2fe2-493a-81f2-cd4676304a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16595815-2177-4335-8b71-120ee624e12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d7b33c8-98ec-4857-be54-8689208ffb1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0ef5c6-8c84-412a-b194-7ace4eb78a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77c81c29-9307-41a6-9c85-2b2a030fb13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e312c4cc-384b-4594-be57-586a0082880a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ec09e6-e981-46ba-b4e0-0e156849b0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c3b9d1-cced-4bec-b7f6-efdfb1aced8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 232102e9-bf3b-4356-a1b2-c07cda80ca0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59e0dc82-2f01-47ff-adcd-588db086e7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa03a51-2029-4a74-9ce8-82bcb9c26dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38eee232-e7a6-46d3-bbe0-758f5e9a6a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6502742-b75e-4970-bd0c-5de302a89f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff73b8d-7b8c-45b8-af4d-e2e1c6002413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bab5befd-d58a-4d80-bd08-dc249f3046ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25ce10c-47c6-4039-99cf-d73c7f5bd3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bed14bd-11a7-4583-a680-1eee5ae6499a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a194181-bcbe-4965-9206-36a129a31e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11597f91-4acd-4bff-b6f3-2b79246248a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f730aeb-5e01-48b9-89db-0df0f9c17f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7427725b-555c-47b0-b100-94e9749445a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4a1f277-2e85-4352-9157-24f178a9b432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3fe9ddc-3785-4806-b659-0198c68a092a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5571e610-7f86-4e00-8817-cf8bd5da3d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f29c0ae-8f32-403b-8b3d-8accbebdf339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974e3776-e772-44dd-9083-5da16ca462cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35b203f-9b7a-477f-b6aa-1598802a4d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7754c29a-0cb1-45e8-b800-ce4b017dcdc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d057ecc8-f4db-4167-bd64-ba16af52f8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d607d52d-15e4-4198-bec6-a45ceed60e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5c5acc9-8d2a-4286-9b4a-90154813e482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfff6de5-e8e8-4df6-9149-88e5aab490cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ea8c231-3e4f-4d99-98ac-3b47315b425c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d79f3a-ddfd-419b-8d74-42efe77e8e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c625627-bb8f-417a-87f2-5627e695bdd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbb87e2-d036-4e3f-b707-454db62dabc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4521fac0-84ae-4f4c-82bf-e5f23067b366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f3c39ce-8be2-421c-9c3b-dbf5e4bdc954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c231c87-4eba-4057-b38e-27ef04ffc5f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1bdbbc-9ded-4cc0-9da3-4a48dd1128bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c6b2902-4949-4f68-bf5d-538fd241dfab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef36e31-aac6-48e8-9556-250344c5f8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d8954a-db1f-4efe-9335-1de2d7283346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa02b031-83f7-499e-8378-607a3b7c7697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 035ab08c-e09a-4f3b-9175-8f5075e321f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c4c8257-f0cc-48fd-be2a-2ddd1dd15d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d6df56-32ff-4e79-8ce6-3dcfb1024cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18fc867-3cab-49ba-8bb6-80366359d68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b925b18-2b91-48be-bc87-d814ab98ceb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bac1afbb-41ce-4026-af59-0336873f4fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab253d0-c091-4141-b946-437b0efcf365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76047d2f-5c14-4d17-adfc-7fe4f4d65e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da01e5f8-d4a8-4e85-958f-f84cafe853d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 144158e6-0942-4dae-b6ac-b7a0d2e2d0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c12fe36-3c3c-4d08-bc50-3d507849ec2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eff0eb4-be52-4dec-afa6-d4e5b3039bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 684c13d6-b60c-4a6c-acbd-6e5e8f3a640b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03fc5a0-6cf9-4789-a223-7ba0955b46b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c0f0ad-1920-449c-9de1-eedc511e902e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c0913b6-704d-4c53-a14e-58a51df94d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6210d4-a230-48ff-9019-962a44481a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b861b1-6196-47ae-af11-1821cb1634a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a82ef4-409c-4aeb-99f7-745a623f8333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9985a2f3-f40c-4bfe-8185-ce5b0eee52be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb336f93-18ee-4001-81b1-533f6e94967a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d37c90f2-3b06-4341-8a6a-5722016ea1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ae64ecb-d08b-48c6-9b3f-d9607122404a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7386f862-c03f-4c68-99b2-f633a9e2c1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 107f6ee3-5b2c-4a2d-b062-2288c3aa83d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c361ce86-f586-4bed-afc9-95a49de21d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90d584d6-a483-40e0-83ad-7b0dfe5fa4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce95457b-adc5-4324-87bb-90937d210639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db29bcd-4884-4744-a11e-e5cf28e59d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98e3e824-0d03-491d-bab0-c29a1e1d63fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b27ee6a-0cce-4691-8401-fbdb11db6587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dc4d7f0-f38e-476d-a37c-34ed8dd54245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d0a0ec-38fb-4ffe-8d98-d7db523ce50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b16f4974-afc6-401d-9bdc-fc54a37ca601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43a58b2f-6210-4025-8d37-7b8b8386a18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc8a5798-1331-43df-b022-28e5bf45127d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd769b17-c9b7-4244-9f0e-ebe5d1a1042f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_15
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/test_labels.txt

📊 Raw data loaded:
   Train: X=(875, 24), y=(875,)
   Test:  X=(219, 24), y=(219,)

⚠️  Limiting training data: 875 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  210 samples, 5 features
✅ Client client_15 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2426, val=0.0816 (↓), lr=0.001000
   • Epoch   2/100: train=0.0899, val=0.0863, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0852, val=0.0819, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0851, val=0.0817, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0817, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0833, val=0.0809, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0811, val=0.0791, patience=2/15, lr=0.001000
   • Epoch  31/100: train=0.0786, val=0.0785, patience=8/15, lr=0.001000
   📉 Epoch 34: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 1 Summary - Client client_15
   Epochs: 38/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0668
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0354
============================================================


============================================================
🔄 Round 2 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0834 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0844, val=0.0827 (↓), lr=0.000500
   • Epoch   3/100: train=0.0837, val=0.0826, patience=1/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0835, val=0.0826, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0830, val=0.0823, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0823, val=0.0820, patience=4/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125
   📉 Epoch 20: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0815, val=0.0816, patience=2/15, lr=0.000063
   📉 Epoch 28: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0812, val=0.0815, patience=12/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 2 Summary - Client client_15
   Epochs: 34/100 (early stopped)
   LR: 0.000500 → 0.000031 (4 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0281
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0139
============================================================


============================================================
🔄 Round 3 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2802, val=0.2877 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   ✓ Epoch   2/100: train=0.1993, val=0.2132 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1609, val=0.1909 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1458, val=0.1744 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1345, val=0.1613 (↓), lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.1012, val=0.1198 (↓), lr=0.000008
   📉 Epoch 18: LR reduced 0.000008 → 0.000004
   ✓ Epoch  21/100: train=0.0915, val=0.1046 (↓), lr=0.000004
   📉 Epoch 26: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0890, val=0.1001, patience=1/15, lr=0.000002
   📉 Epoch 34: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0882, val=0.0985, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0876, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  61/100: train=0.0871, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0866, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0861, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0857, val=0.0930, patience=2/15, lr=0.000001

============================================================
📊 Round 3 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000031 → 0.000001 (5 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0188
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.1799
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1416, RMSE: 0.3763, MAE: 0.3200, R²: -0.8283

============================================================
🔄 Round 4 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1276, val=0.1299 (↓), lr=0.000001
   ✓ Epoch   2/100: train=0.1271, val=0.1293 (↓), lr=0.000001
   ✓ Epoch   3/100: train=0.1264, val=0.1287 (↓), lr=0.000001
   ✓ Epoch   4/100: train=0.1259, val=0.1281 (↓), lr=0.000001
   ✓ Epoch   5/100: train=0.1253, val=0.1275 (↓), lr=0.000001
   ✓ Epoch  11/100: train=0.1224, val=0.1247 (↓), lr=0.000001
   ✓ Epoch  21/100: train=0.1186, val=0.1209 (↓), lr=0.000001
   ✓ Epoch  31/100: train=0.1154, val=0.1178 (↓), lr=0.000001
   ✓ Epoch  41/100: train=0.1127, val=0.1151 (↓), lr=0.000001
   • Epoch  51/100: train=0.1103, val=0.1127, patience=2/15, lr=0.000001
   ✓ Epoch  61/100: train=0.1081, val=0.1105 (↓), lr=0.000001
   • Epoch  71/100: train=0.1061, val=0.1085, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1043, val=0.1067, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.1026, val=0.1050, patience=3/15, lr=0.000001

============================================================
📊 Round 4 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1014, RMSE=0.3184, R²=-0.2197
   Val:   Loss=0.1035, RMSE=0.3217, R²=-0.2066
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0971, RMSE: 0.3116, MAE: 0.2491, R²: -0.2539

============================================================
🔄 Round 6 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1170, val=0.1168 (↓), lr=0.000001
   • Epoch   2/100: train=0.1168, val=0.1165, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1166, val=0.1163, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.1164, val=0.1161 (↓), lr=0.000001
   • Epoch   5/100: train=0.1162, val=0.1159, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.1150, val=0.1148, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.1134, val=0.1133 (↓), lr=0.000001
   • Epoch  31/100: train=0.1120, val=0.1119, patience=2/15, lr=0.000001
   ✓ Epoch  41/100: train=0.1107, val=0.1106 (↓), lr=0.000001
   • Epoch  51/100: train=0.1094, val=0.1093, patience=1/15, lr=0.000001
   • Epoch  61/100: train=0.1082, val=0.1081, patience=1/15, lr=0.000001
   • Epoch  71/100: train=0.1070, val=0.1070, patience=1/15, lr=0.000001
   • Epoch  81/100: train=0.1059, val=0.1059, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.1048, val=0.1048, patience=1/15, lr=0.000001

============================================================
📊 Round 6 Summary - Client client_15
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.1036, RMSE=0.3218, R²=-0.2418
   Val:   Loss=0.1039, RMSE=0.3223, R²=-0.2267
============================================================


============================================================
🔄 Round 8 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 8 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0059
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0218
============================================================


============================================================
🔄 Round 9 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0898, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0885, val=0.0894, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0881, val=0.0891, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0877, val=0.0888, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 9 Summary - Client client_15
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0656
   Val:   Loss=0.0893, RMSE=0.2987, R²=-0.0332
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2535, R²: -0.0951

============================================================
🔄 Round 10 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 10 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0458
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0587
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2411, R²: -0.0029

============================================================
🔄 Round 11 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 11 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0208
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0146
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2371, R²: 0.0102

📊 Round 11 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2399, R²: -0.0003

📊 Round 11 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2434, R²: -0.0214

============================================================
🔄 Round 15 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 15 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0144
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0065
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0772, RMSE: 0.2778, MAE: 0.2409, R²: 0.0036

============================================================
🔄 Round 18 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 18 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0053
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0144
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0771, RMSE: 0.2778, MAE: 0.2403, R²: 0.0040

============================================================
🔄 Round 19 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 19 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0107
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0269
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2401, R²: 0.0045

============================================================
🔄 Round 21 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 21 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0069
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0086
============================================================


============================================================
🔄 Round 26 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 26 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0147
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0033
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2407, R²: 0.0015

============================================================
🔄 Round 28 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 28 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0028
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0255
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2411, R²: 0.0000

============================================================
🔄 Round 32 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 32 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0054
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0078
============================================================


============================================================
🔄 Round 34 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 34 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0046
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0044
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2412, R²: -0.0009

📊 Round 34 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2413, R²: -0.0011

============================================================
🔄 Round 38 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 38 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0054
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0099
============================================================


============================================================
🔄 Round 40 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 40 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0099
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0276
============================================================


============================================================
🔄 Round 42 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 42 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0046
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0316
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2415, R²: -0.0018

📊 Round 42 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2415, R²: -0.0018

📊 Round 42 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2415, R²: -0.0018

============================================================
🔄 Round 48 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 48 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0058
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0060
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2415, R²: -0.0019

📊 Round 48 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2415, R²: -0.0019

📊 Round 48 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2415, R²: -0.0020

📊 Round 48 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2415, R²: -0.0020

============================================================
🔄 Round 57 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 57 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0108
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0213
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2415, R²: -0.0020

============================================================
🔄 Round 58 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 58 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0002
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0193
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2416, R²: -0.0020

📊 Round 58 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2416, R²: -0.0023

📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2417, R²: -0.0025

📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2417, R²: -0.0026

📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2417, R²: -0.0028

📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2417, R²: -0.0027

📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2417, R²: -0.0028

📊 Round 58 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2417, R²: -0.0028

============================================================
🔄 Round 74 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 74 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0072
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0122
============================================================


============================================================
🔄 Round 76 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 76 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0014
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0157
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2418, R²: -0.0030

📊 Round 76 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2418, R²: -0.0030

============================================================
🔄 Round 78 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 78 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0078
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0199
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2418, R²: -0.0031

============================================================
🔄 Round 81 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 81 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0077
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0235
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2418, R²: -0.0033

============================================================
🔄 Round 85 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 85 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0013
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0154
============================================================


============================================================
🔄 Round 86 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 86 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0105
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0335
============================================================


============================================================
🔄 Round 87 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 87 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0058
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0023
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2418, R²: -0.0032

============================================================
🔄 Round 89 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 89 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0052
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0120
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2418, R²: -0.0031

📊 Round 89 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2418, R²: -0.0030

============================================================
🔄 Round 92 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 92 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0075
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0060
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2418, R²: -0.0030

============================================================
🔄 Round 93 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 93 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0001
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0252
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2418, R²: -0.0030

============================================================
🔄 Round 96 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 96 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0009
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0193
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0032

============================================================
🔄 Round 99 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 99 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0075
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0050
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0034

============================================================
🔄 Round 104 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 104 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0048
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0061
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0034

📊 Round 104 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0033

============================================================
🔄 Round 108 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 108 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0059
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0476
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0033

📊 Round 108 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0032

📊 Round 108 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2419, R²: -0.0032

============================================================
🔄 Round 111 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 111 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0050
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0055
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2419, R²: -0.0031

============================================================
🔄 Round 113 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 113 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0012
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0202
============================================================


============================================================
🔄 Round 114 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 114 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0042
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0090
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0032

============================================================
🔄 Round 115 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 115 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0000
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0199
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0033

📊 Round 115 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0033

============================================================
🔄 Round 118 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 118 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0054
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0010
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2419, R²: -0.0032

📊 Round 118 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2419, R²: -0.0032

📊 Round 118 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0032

============================================================
🔄 Round 123 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 123 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0000
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0204
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0032

📊 Round 123 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0033

============================================================
🔄 Round 127 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 127 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0003
   Val:   Loss=0.0932, RMSE=0.3052, R²=0.0184
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0033

📊 Round 127 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0034

📊 Round 127 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: -0.0035

============================================================
🔄 Round 133 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 133 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0027
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0122
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2420, R²: -0.0035

📊 Round 133 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2420, R²: -0.0035

============================================================
🔄 Round 135 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 135 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0012
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0001
============================================================


============================================================
🔄 Round 138 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 138 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0019
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0073
============================================================


============================================================
🔄 Round 142 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 142 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0047
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0018
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2421, R²: -0.0043

============================================================
🔄 Round 143 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 143 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0074
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0129
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2421, R²: -0.0043

============================================================
🔄 Round 144 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 144 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0037
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0075
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2421, R²: -0.0044

============================================================
🔄 Round 145 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 145 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0027
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0056
============================================================


============================================================
🔄 Round 147 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 147 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0080
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0100
============================================================


============================================================
🔄 Round 148 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 148 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0067
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0091
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2421, R²: -0.0046

📊 Round 148 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2422, R²: -0.0048

📊 Round 148 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2422, R²: -0.0049

============================================================
🔄 Round 153 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 153 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0024
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0130
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2422, R²: -0.0050

============================================================
🔄 Round 155 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 155 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0019
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0132
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2422, R²: -0.0051

📊 Round 155 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0051

============================================================
🔄 Round 159 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 159 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0040
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0057
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

============================================================
🔄 Round 160 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 160 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0032
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0089
============================================================


============================================================
🔄 Round 161 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 161 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0072
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0127
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

============================================================
🔄 Round 162 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 162 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0033
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0080
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0054

============================================================
🔄 Round 163 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 163 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0002
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0193
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0055

📊 Round 163 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0055

============================================================
🔄 Round 166 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 166 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0042
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0045
============================================================


============================================================
🔄 Round 168 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 168 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0081
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0434
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0056

📊 Round 168 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0056

============================================================
🔄 Round 171 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 171 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0006
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0186
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0055

📊 Round 171 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0055

============================================================
🔄 Round 174 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 174 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0037
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0084
============================================================


============================================================
🔄 Round 175 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 175 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0043
   Val:   Loss=0.0926, RMSE=0.3042, R²=0.0064
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0054

============================================================
🔄 Round 178 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 178 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0033
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0100
============================================================


============================================================
🔄 Round 179 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 179 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0037
   Val:   Loss=0.0871, RMSE=0.2950, R²=0.0070
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0054

============================================================
🔄 Round 181 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 181 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0079
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0064
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

📊 Round 181 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

📊 Round 181 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

📊 Round 181 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

📊 Round 181 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

📊 Round 181 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

============================================================
🔄 Round 191 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 191 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0008
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0203
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0052

📊 Round 191 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0051

============================================================
🔄 Round 194 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 194 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0017
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0150
============================================================


============================================================
🔄 Round 199 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 199 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0101
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0333
============================================================


============================================================
🔄 Round 201 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 201 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0116
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0193
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

📊 Round 201 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0052

============================================================
🔄 Round 204 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 204 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0057
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0032
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2423, R²: -0.0053

📊 Round 204 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0054

============================================================
🔄 Round 208 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 208 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0010
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0233
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2423, R²: -0.0054

============================================================
🔄 Round 209 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 209 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0050
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0416
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2424, R²: -0.0055

============================================================
🔄 Round 211 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 211 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0061
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0001
============================================================


❌ Client client_15 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
