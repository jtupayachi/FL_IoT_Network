[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a773a464-7580-4543-a275-72e6b4ecdebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e64ab2-d3b7-4ac3-a07c-2498b0c9e08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80cfee6b-0ca7-4457-b755-7486f81c7f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f677c58-6782-4d4c-bca2-8fe0b63386b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b177e2d-77a9-491c-b1dd-da124495410b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb976ff8-98ee-4cf4-a0ab-0d7521acc3ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc2a7385-3f2d-4ea2-b246-70d7e150568f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9d1f18-5d90-4747-886f-535a0b31f6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a124942-e676-472b-9cd1-4207d615d2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b47be4e-cb17-48cc-b908-f543b6e33026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 153a6914-f72d-48be-bc57-15b18cc0d218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3d5183-31ee-45a8-aead-52c8854d5c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9febee2c-0b5e-4e79-8d14-ce3ba30fda07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ee5bcb-473f-42ff-8e2c-1c588896708c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b677e41d-4bc8-4545-9e4d-0b3aa6703c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed08d054-ff0f-44b2-8ec1-528561e4e01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bab4e494-3db8-46e6-b4b3-641a1515ec94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 842ed746-9197-4915-acaa-137114684dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c085bf5-72e1-4be4-b6d1-ac143b58550e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f39b14-753e-471b-9916-202549212798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aadaf58-ff51-46d2-993f-dfba61ad34bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf6fb5a-a59c-49a5-bb69-da4d96e21e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94c1dbad-21d4-451d-9b85-609784ffa2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e430e85b-484d-4a01-a292-abe3e4f2179b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7fea785-9738-4d68-ae6f-e763ea30f078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35b20862-81a1-4736-9295-9a4cc95f18cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3990ed9-3a92-40af-a036-777bfb80a8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797c414b-a7b7-4aaa-bfdd-57910e53762c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd8f2d6-2c1c-41c9-9e7e-979f8e10f59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611b4aa2-b8db-4fb7-9f67-95090e11cbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413addf2-1776-4c02-8e29-4d7739fdfc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca98ea5d-74bf-42b7-91df-587951b50e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ec27bbc-cd3f-4165-959b-308b3d06dac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba0122e-95fc-479c-ab80-697f43872fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38cd0a5e-0c93-419c-8152-713d0520e057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c53bfd0c-4f0c-4a68-ab0d-1cd43e3ca17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4dc1ee9-aaa4-4aad-8a33-3c1d0f200c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abfeee78-7fb4-47e1-b432-b4dd334e425a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9d8e82b-4748-4534-be45-28f6505e98b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a34dda6-61a8-4156-92fe-2cb7196644c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37b3d7cf-73e3-4737-8c72-eb8dfba25f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f741a6d5-9486-4675-9a00-057f3cac3559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c6c6e9-1629-4bc3-84ca-b5cfe73685bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b952760e-23c6-4190-9570-d0a1a697f618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4f9c61-2beb-434c-9ad7-632571b0714d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6604c2-59a9-4810-a00e-764edabcc4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 474c1026-c767-47a1-b00a-dfff0b4f0913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3dd7044-79ba-413b-9b84-8072a7051645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4416d838-bfa1-4d8f-9590-54b6290fb0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac40b602-cfbc-44d3-9e47-7db7e067b641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a05ac385-422a-4a8e-ba39-1b454dfe50e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac856c5d-0e2e-4f2d-a470-7579db45e0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 800fe6b7-9ab4-4765-8459-ef204281e278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7f12866-8cc5-40da-9fee-5c30a73081b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285fb829-53aa-466c-983b-f5b424011a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 443bec74-b220-4c38-8612-40ba4f68e4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927722cd-885e-4601-a8b3-e26138182cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda4a75e-8742-436c-bc00-d7fbfada7974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0daa6486-fd2a-46f5-8cca-21c0e30792ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ffbd31-c06e-4d23-907e-8094908c2ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d26b651f-441f-412b-aa7e-dc000260174b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d79aba-08e7-4482-b113-1759d2c2372b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b6d1711-fe00-402e-8008-488663126cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3afc1ae2-4709-4b78-bc0d-617d9a1a4e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6caef1d-a30d-4101-8792-91e3c7690e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f25c9b-8c5c-425e-9bc8-c036cb6cca0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ceaf170-57ef-4688-a05b-0f115be700e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11fe7194-8062-425f-8c2b-850aaa7d765d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1fe7b0-023d-4b03-9da1-21ad8d4f4312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa8532a-6f31-4d74-9cf2-be928b9a6903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9d6c4aa-b804-41db-ac1c-ac88b70e3097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2c8b270-e3c7-4898-aab4-71e0baaa791f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c9cddca-2049-46a0-b5d2-71734772c898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a73dd1e-a3ae-4b48-91d5-1f329611aaaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc8dee0-311f-48e2-950f-43772f1975f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 175f3d91-c00b-4d01-8b74-2cef2721f84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47c74383-8f54-4d9a-b46b-874382f2bb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e82f394d-15ea-4d47-807a-527c86d604ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41de009d-8687-417d-8237-92752bf37068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d119665-f535-45cd-b52d-6e900254c978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a15e48-fdde-4987-b650-702248695ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0db3131a-8120-46fa-9061-434d7c747aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea93fd1-893e-4831-b984-346c1f46091f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8ab5459-67f0-4b7e-9af0-b8e352bddaa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0209fa7a-96fa-4b52-899e-fd75715238e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8711597-b266-4752-8fa4-9335c729cf73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edee66a3-bef0-470b-9178-751ee84a4c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0348a741-12fe-4697-80c1-0457d676f8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820eda67-23a6-4456-8b9c-09d77e60ac4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b972fb7-6578-4953-8dd6-08f8ef84facf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 404f84a8-f67f-4fef-9177-4d100efb5967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3ccaf4-8770-4716-a479-cdf305971d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ebd9a9-1ac4-4479-a4eb-400f569b308d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc5ca994-ddd5-48a2-b852-4168aa0ec9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e6a721-71b3-465f-859e-5145c0d367f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2293abb-1dfd-4723-913c-5c446de54906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4384bac-a7ed-4994-9631-cac57115d967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7e1eb41-84c3-43e1-88c9-f57aa7a5bbc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8841b9d0-7e03-442e-87b2-bd20bd7a106c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11360d5d-bedd-459a-b4da-e72fd27f509c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb2caee-2e10-4494-bbc9-ecde5f4bc4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70171254-d3a6-4f91-bebc-d4e4a396b91e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b9f6d7f-0521-44d7-b0cd-df98f9871b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a597faf0-d1bb-40a1-ac17-df44224ed557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1bdaf20-61f7-4488-88cc-53717fc16136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56cb49fe-28d6-4907-b0b7-64ccbb6aa6f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5507a56b-989b-4dc4-8f68-b342f1888621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87403ee1-d3fd-4623-b8c4-c677b88e1cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af91b2b-f0e3-44bf-aadc-bf183c5d1b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bc9c828-106f-41d7-b818-29fb5437ada0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a27327f2-bbde-4442-9b0a-09f46434f569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f859a2-5464-42e8-bec4-5b89833ecabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788c51c9-8c9d-4d3b-922a-49fcfa7fc12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46a0c5ba-f428-4a0f-81e2-5d82b320faf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61efd72d-ee9b-4567-ba76-591bafb915db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1e06d93-1266-485c-acb9-0e8b41d2a083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4b35b8-6cd6-4172-8212-8e26b1ec4a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04833ec8-0fd7-4d32-9a19-86b675470d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee72b3b-2055-4a73-8d51-5297d1721fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed2f7c5-1a3b-466b-b417-ed34a6de2119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0229a0a-5cef-47ac-9bd2-3f84fb5a9bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d478e2-023e-457f-8c9a-24b2265d4563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 561de6eb-ca0f-48cd-b567-0348627f5dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e467f0-8667-4108-abc1-e2ef54761f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d482dba4-807d-4b98-85cd-1f8eabab7497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f882b17-d54f-4154-a673-9199d24e79eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef73c8a-824c-4ca3-bbb5-f5d27215b966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c3dc603-cd6a-4220-8ac9-f089b75d8650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e22b5ff6-0ba2-4e1b-b8d9-43c120b4bd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded12466-37f7-482e-8e41-7e548e361789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b93cdb23-d14a-441e-9a0c-d910644c570f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e549fe5-0db0-407c-abf6-6e4bd6c6c181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2010cc6-1440-441e-98bd-1615b43611dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c390d0-4c3a-48de-bd5c-1575475bcfdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f7338d-b293-49d4-a736-c7beeb3fc43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96daa522-10b9-416f-b51e-f40019906992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7e3049-e9e4-436d-85b0-ec311ec721c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae84e967-acb5-4098-beeb-90f2b61a33ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6fbde24-44bc-4268-800b-2e37c1b26fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 042147b4-d060-4d50-8674-0ca2a614ec71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbfc3f1b-c164-4151-b5f0-530b84729821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0481dd92-a2b0-414a-9d6b-d087eedc25fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c06c248f-a675-4b9f-8d08-424f8e2c789f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bddb7bde-63a7-406a-98ba-f4d7da181d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544b9318-6185-4a60-ba21-0f13148a8da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdce3c71-9981-4ffb-b676-5631642276c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050e2b62-50d3-45df-bedb-0a3f109b3417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d65f2276-dd66-4879-968d-411c107133ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e329d8-8c79-437a-8659-e912e0000ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d93dea-5605-4955-8e30-51886f7fc91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5be9982e-fd3f-40a6-83e9-fdfc84c1516a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded6851c-d3d8-4a29-967d-bacf40263114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c71066-e88b-4b2f-9082-1161d8ed60e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b24aa77-cc97-46b7-8e68-b2fe5eb0af2a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_16
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/test_labels.txt

📊 Raw data loaded:
   Train: X=(1530, 24), y=(1530,)
   Test:  X=(383, 24), y=(383,)

⚠️  Limiting training data: 1530 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  374 samples, 5 features
✅ Client client_16 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0820 (↓), lr=0.001000
   • Epoch   2/100: train=0.0829, val=0.0823, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0828, val=0.0826, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0827, val=0.0826, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0824, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0815, val=0.0813, patience=3/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0805, val=0.0812, patience=13/15, lr=0.000250
   📉 Epoch 23: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 2 Summary - Client client_16
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0090
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0010
============================================================


============================================================
🔄 Round 6 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1009, val=0.0936 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0844, val=0.0825 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0818, val=0.0810 (↓), lr=0.000125
   • Epoch   4/100: train=0.0817, val=0.0810, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0816, val=0.0812, patience=2/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0814, val=0.0811, patience=8/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 6 Summary - Client client_16
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0061
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0060
============================================================


============================================================
🔄 Round 7 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0950 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0819, val=0.0925 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0799, val=0.0917 (↓), lr=0.000063
   • Epoch   4/100: train=0.0791, val=0.0915, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0788, val=0.0915, patience=2/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0785, val=0.0916, patience=8/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 7 Summary - Client client_16
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0056
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0035
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2472, R²: 0.0022

============================================================
🔄 Round 8 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0832 (↓), lr=0.000016
   • Epoch   2/100: train=0.0811, val=0.0831, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0811, val=0.0830, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0810, val=0.0828, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0810, val=0.0826, patience=2/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004
   📉 Epoch 20: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0809, val=0.0825, patience=12/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 8 Summary - Client client_16
   Epochs: 24/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0104
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0063
============================================================


============================================================
🔄 Round 9 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0734 (↓), lr=0.000002
   • Epoch   2/100: train=0.0889, val=0.0732, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0888, val=0.0731, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0886, val=0.0729, patience=3/15, lr=0.000002
   ✓ Epoch   5/100: train=0.0884, val=0.0727 (↓), lr=0.000002
   • Epoch  11/100: train=0.0876, val=0.0720, patience=2/15, lr=0.000002
   • Epoch  21/100: train=0.0866, val=0.0711, patience=1/15, lr=0.000002
   • Epoch  31/100: train=0.0858, val=0.0704, patience=4/15, lr=0.000002
   • Epoch  41/100: train=0.0852, val=0.0699, patience=5/15, lr=0.000002
   • Epoch  51/100: train=0.0848, val=0.0695, patience=3/15, lr=0.000002
   • Epoch  61/100: train=0.0845, val=0.0692, patience=13/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 9 Summary - Client client_16
   Epochs: 63/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0045
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0274
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2496, R²: -0.0203

============================================================
🔄 Round 10 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0828 (↓), lr=0.000002
   • Epoch   2/100: train=0.0835, val=0.0827, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0834, val=0.0826, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0833, val=0.0826, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0832, val=0.0825, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0829, val=0.0823, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0825, val=0.0821, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 10 Summary - Client client_16
   Epochs: 29/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0126
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0075
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2423, R²: 0.0340

============================================================
🔄 Round 11 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 11 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0189
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0198
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2422, R²: 0.0198

============================================================
🔄 Round 12 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0793, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0825, val=0.0790, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0823, val=0.0787, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 12 Summary - Client client_16
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0031
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0193
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2414, R²: 0.0266

============================================================
🔄 Round 14 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 14 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0423
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0002
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2389, R²: 0.0637

📊 Round 14 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2388, R²: 0.0630

📊 Round 14 Test Metrics:
   Loss: 0.0755, RMSE: 0.2748, MAE: 0.2369, R²: 0.0684

============================================================
🔄 Round 18 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 18 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0455
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0154
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2365, R²: 0.0665

============================================================
🔄 Round 20 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 20 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0395
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0359
============================================================


============================================================
🔄 Round 21 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 21 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0507
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0340
============================================================


============================================================
🔄 Round 22 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 22 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0470
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.1060
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2341, R²: 0.0839

📊 Round 22 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2361, R²: 0.0709

============================================================
🔄 Round 26 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 26 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0451
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0612
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0755, RMSE: 0.2748, MAE: 0.2366, R²: 0.0681

============================================================
🔄 Round 29 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 29 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0375
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0421
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2375, R²: 0.0631

============================================================
🔄 Round 30 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 30 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0411
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0245
============================================================


============================================================
🔄 Round 32 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 32 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0357
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0126
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0601

📊 Round 32 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0600

============================================================
🔄 Round 41 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 41 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0301
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0416
============================================================


============================================================
🔄 Round 42 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 42 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0366
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0342
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0602

📊 Round 42 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0602

📊 Round 42 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0602

============================================================
🔄 Round 45 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 45 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0372
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0235
============================================================


============================================================
🔄 Round 46 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 46 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0369
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0345
============================================================


============================================================
🔄 Round 48 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 48 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0325
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0498
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0605

============================================================
🔄 Round 54 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 54 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0386
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0307
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2380, R²: 0.0609

============================================================
🔄 Round 58 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 58 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0297
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0649
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2380, R²: 0.0611

📊 Round 58 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2380, R²: 0.0612

============================================================
🔄 Round 60 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 60 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0458
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0013
============================================================


============================================================
🔄 Round 62 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 62 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0342
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0479
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2380, R²: 0.0608

📊 Round 62 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0605

📊 Round 62 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0605

📊 Round 62 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0606

📊 Round 62 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0607

📊 Round 62 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0609

============================================================
🔄 Round 74 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 74 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0413
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0178
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2380, R²: 0.0610

============================================================
🔄 Round 76 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 76 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0363
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0418
============================================================


============================================================
🔄 Round 79 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 79 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0356
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0435
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0607

============================================================
🔄 Round 80 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 80 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0333
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0460
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.0601

📊 Round 80 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.0600

============================================================
🔄 Round 85 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 85 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0374
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0245
============================================================


============================================================
🔄 Round 86 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 86 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0364
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0380
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.0603

📊 Round 86 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0604

============================================================
🔄 Round 89 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 89 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0316
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0291
============================================================


============================================================
🔄 Round 90 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 90 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0299
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0596
============================================================


============================================================
🔄 Round 91 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 91 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0355
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0432
============================================================


============================================================
🔄 Round 95 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 95 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0350
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0457
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0611

============================================================
🔄 Round 96 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 96 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0346
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0428
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0609

📊 Round 96 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0609

📊 Round 96 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0608

============================================================
🔄 Round 103 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 103 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0300
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0660
============================================================


============================================================
🔄 Round 104 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 104 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0348
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0423
============================================================


============================================================
🔄 Round 105 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 105 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0423
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0024
============================================================


============================================================
🔄 Round 106 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 106 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0385
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0292
============================================================


============================================================
🔄 Round 107 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 107 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0329
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0473
============================================================


============================================================
🔄 Round 113 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 113 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0374
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0349
============================================================


============================================================
🔄 Round 115 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 115 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0324
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0568
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0608

============================================================
🔄 Round 116 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 116 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0374
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0348
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.0608

============================================================
🔄 Round 118 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 118 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0404
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0198
============================================================


============================================================
🔄 Round 120 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 120 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0411
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0112
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.0604

📊 Round 120 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.0603

============================================================
🔄 Round 127 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 127 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0426
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0095
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.0604

============================================================
🔄 Round 130 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 130 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0420
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0170
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2381, R²: 0.0605

============================================================
🔄 Round 134 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 134 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0380
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0261
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.0602

📊 Round 134 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.0600

============================================================
🔄 Round 139 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 139 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0367
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0336
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0598

📊 Round 139 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0598

============================================================
🔄 Round 142 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 142 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0348
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0381
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0598

📊 Round 142 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0598

============================================================
🔄 Round 144 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 144 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0333
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0451
============================================================


============================================================
🔄 Round 147 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 147 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0329
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0472
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0600

📊 Round 147 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0598

📊 Round 147 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0597

📊 Round 147 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0596

============================================================
🔄 Round 152 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 152 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0369
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0244
============================================================


============================================================
🔄 Round 153 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 153 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0294
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0507
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0597

============================================================
🔄 Round 154 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 154 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0421
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0069
============================================================


============================================================
🔄 Round 156 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 156 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0376
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0305
============================================================


============================================================
🔄 Round 157 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 157 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0347
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0361
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2384, R²: 0.0594

============================================================
🔄 Round 159 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 159 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0361
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0365
============================================================


============================================================
🔄 Round 161 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 161 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0363
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0273
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2384, R²: 0.0591

📊 Round 161 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2384, R²: 0.0591

============================================================
🔄 Round 165 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 165 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0425
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0060
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2384, R²: 0.0591

============================================================
🔄 Round 169 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 169 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0378
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0248
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0763, RMSE: 0.2761, MAE: 0.2384, R²: 0.0593

============================================================
🔄 Round 170 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 170 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0403
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0202
============================================================


============================================================
🔄 Round 172 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 172 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0338
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0284
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2384, R²: 0.0596

============================================================
🔄 Round 175 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 175 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0352
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0413
============================================================


============================================================
🔄 Round 176 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 176 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0313
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0528
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0598

📊 Round 176 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.0599

📊 Round 176 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0599

============================================================
🔄 Round 180 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 180 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0395
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0219
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0600

📊 Round 180 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0601

============================================================
🔄 Round 183 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 183 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0394
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0221
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0601

============================================================
🔄 Round 184 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 184 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0340
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0365
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0602

📊 Round 184 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0602

📊 Round 184 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0602

============================================================
🔄 Round 188 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 188 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0422
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0070
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0602

📊 Round 188 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0603

📊 Round 188 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2382, R²: 0.0606

📊 Round 188 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2382, R²: 0.0607

📊 Round 188 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2382, R²: 0.0608

============================================================
🔄 Round 199 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 199 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0350
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0419
============================================================


============================================================
🔄 Round 201 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 201 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0275
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0680
============================================================


============================================================
🔄 Round 202 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 202 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0240
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0796
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0603

============================================================
🔄 Round 203 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 203 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0375
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0115
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0603

============================================================
🔄 Round 206 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 206 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0396
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0240
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.0601

❌ Client client_16 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
