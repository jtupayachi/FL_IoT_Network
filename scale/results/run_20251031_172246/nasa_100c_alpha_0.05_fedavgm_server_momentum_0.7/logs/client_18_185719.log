[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea148fb4-9479-49cc-b556-7ef5d6596641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a60c706-91d1-4c5b-ba4e-8d66c47d64c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401432c6-5848-48f3-966a-c15da536617f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e03823-b434-4b94-aa4e-f82a3355e2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a070ca54-f7dc-4a39-8429-356e2b0f0b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63782f73-5b18-41db-88b7-3f2626d58aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0666251-615e-4427-b947-307155a6473c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db2daaf8-ce80-4e9b-8cdb-84dfa01d3c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8712e149-d606-408b-a010-2cf21d0e125b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb1bdcdc-d606-4ee1-8227-f6933e27ba10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d02c6ad-76cc-486a-8d25-c539cabbe0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa304ad-d71e-4a89-a3e5-82b4d72a97e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc1d1f3-262d-4f1f-b801-ea8f621ff927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f709656-0a8d-4f40-bccb-7c2fc1cf1d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6429c47f-e689-4c18-859e-f0a8de854306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c5a7bca-0383-4a88-826f-ece7090c0c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e18364b8-496f-4bd2-abb8-e8f5f8801296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28cb8f87-0212-4429-9143-35be4c6aa02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c6ad3dc-ceb3-49e3-aee2-c73dac9a6b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26de9ef4-9817-45da-a2cd-1cf682bfadbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 225e3959-d6c5-4a5d-97a2-afad83c53417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf3720f-fcc2-4fb7-ae68-fba9fceff77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea013d35-15c4-49d6-8d16-b56a884a06e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fab183a4-59d8-48e0-b811-fb6abf9b9a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d22f2613-b854-4f6b-ab79-57d8a739df9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e4a64b6-6381-4f11-aa79-dbc307960a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f12e58c3-22f0-46a9-8990-797df752bb56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e626f2e-bd91-4d7c-973b-78a1448462ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 059081bc-d460-41d6-9a87-307a7984ac1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4418b7d5-4297-4ec7-80df-7c48469143df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dea1e14-d601-4769-8804-e3843c324796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aed5478-37c0-4fdf-9697-5afec352beec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b34a999-a079-42f3-8d09-fb39afb63a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8cb99f5-a69a-4902-b666-ebe4c28ac25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3379205b-0fbb-4534-8859-316c7c5398de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a083e49-8238-4577-8e35-64e2243742d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d34fe7a4-b195-4955-8c0b-439cbc77ddca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab30fad9-907a-4f77-a67e-4cabd9e1803f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a1a76fe-e482-4cce-94d6-0f54d8092dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a0cc496-6e13-4602-aa6b-7ef54dc6a76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94eaeea3-88af-43b6-99fb-fd60f4bc1cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3ba44fe-c927-4c28-bbf5-adc2dbc0b7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e62b067-3c07-4fa5-aeac-c7c516dbac45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b9ad33-daa3-44cd-94dc-7a2461da8931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdf726e5-277a-4b53-9a2e-bcc97e3052ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa55e050-c111-4a9f-86f2-edd042bc4df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0acc51d-bfa4-47a0-ae47-6331d0faeae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e8e75a-c3c7-480a-abd6-c911bf4781cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f4fe708-8f74-4ac9-b681-191b7782e543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be008d7b-b4ba-4998-966f-5a13b9d2894b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0fc177f-e24d-43db-a102-0355952519ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7f83b9-b069-4545-ba79-af6fdf12648f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3f560a-3e87-4016-9147-990f2066f2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c749ebe-4806-4163-a722-0e8682d63e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b46e36c-fd94-4cc7-a3cb-92ff689d0f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6c0ea5-5913-4b31-80d1-9a21e9a9d250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c26e0c-fcee-4945-9dfe-16de61c763a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a1ad68-2c4e-4313-89be-fa3f81aa9ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48aa63be-5ca8-4ac6-9c19-361e70edbab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 572020c9-b8c9-4728-bbbe-f33f87be0741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 951ea9f6-f8d8-4af3-9cc1-fd3a1ae02bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14a4ae38-11c3-443d-9f0b-8d399116b9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8203212a-7c4f-49d9-b414-24da3e9cda79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59bf3cdf-26ff-4377-a3fc-a7aa35da9ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d50e94-590d-485f-9e39-e1261b1c042c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73cea4cc-c200-4694-9418-f6446dfba2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be106888-527d-4f5b-9d12-640d39d0e8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d622752a-e63a-425e-84d6-493f19e7b5f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b8a125a-83fc-4466-8fa1-47f4ada7ce01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4326eb3b-692e-44b1-9c0e-fea252cef355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b05a46-8c7f-453d-8c5a-dcbbf0b0c467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d2cb681-f59a-4d19-aa6b-7c434fe7b175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccd57802-e788-4f8d-b56c-077947bd25d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a1aec7-e89d-4a8b-bdde-30035f911ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 141d9e77-0d9b-4809-9724-bbe5c5b7a553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff07458a-f51c-43ed-a91b-8b3561120969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90a39b64-cd70-4bc2-85f8-7ba64ebbb6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03b317ba-3702-423d-bc67-768768b28576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a376065e-38a4-45fd-b252-353101719f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aae160b-b804-4132-98a1-40a9cd33e5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2c3345c-24e9-4552-8cdb-f8bc5891da39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62b4c506-a1ee-470e-8b9a-da4d1d88a68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e225a6-d0d9-47c7-b890-1ddbb973e19d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a46c2ab-c7f3-4a6e-bd1f-07fb23e36fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a91933-db0b-475b-b9f1-66927c587e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 840d3c4d-6b37-4c0e-be55-7ae6addc6f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb317ee-6a69-4571-a4db-00b19d0e52fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3bbfffb-a681-45c8-ac51-cc6f8ac31df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d874287c-3ccc-411f-93de-7dad68ee2a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ad211c-522d-49bd-b571-f79109d9993d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89232f0c-c00e-407c-8e10-09feb634b7c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0b6d316-7da0-4360-9426-ca375bd8a892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a376039b-5074-4a35-8d69-34c2c3ac0b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e070307d-0d00-47e4-a98f-3a34bfb8105a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9c7cd1-b4fe-4735-a59d-ba71bdc96e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3853930-e562-477a-9844-871740664c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd3dd74-e49d-4e84-a798-f9e03829c146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec4c2ac-86e3-42cf-8ca5-7668e253df43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1e45f7-2e9a-4de3-9e0e-b3a9d75d2afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0dffff-2da3-41e0-96b4-d026bbe755ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73aef0e-4478-46fd-b508-e63f55b3afd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9960a4-1c3b-44a2-8aaf-1017c8e3d8b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ada94434-c01a-450e-ba2f-98fe141a6057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f990727f-90e5-4666-8da7-762d21b103e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444d3f0a-6c79-494c-937f-01f44a482604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb38442c-9ab2-4d5e-8958-6137acfba69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b335f40-e8e9-4f50-aede-817966985991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0730a4-4e7f-46d0-912d-db82b0a6b24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc371ae-c880-4b41-a9ad-8bc8415d389d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cfd5210-ad93-4556-bed3-5c0d45b8090b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bcb531c-b9a2-4e59-9585-54665d6a760b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9929158-5527-4e79-8203-33ec51ac863a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de03ac93-8975-4a97-a935-5fac65ace20b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de9db77-a5f6-4030-b8ee-82583b80f5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600bd202-54d1-485a-a27e-a5c7e2a967be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6732c50-0837-4144-a968-926d0a3eef64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a77b4f-dfef-4982-8625-dacae6c3888a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00eec467-77a4-4422-b9af-90a78cc8deee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf854d25-4cfa-49f3-bfa6-ebc5d88b0794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e99a02a2-d192-45b8-8d09-3ad6000a07b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25ba9523-1683-46cc-9b5f-cb13e7ab9c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7605c39c-fa67-4dd2-bd72-8af1a19b3701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f377c907-8737-4034-b14f-810942e10f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c67fa8-5165-434a-8df8-d82f34f17551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c3e1d18-d052-4215-83e9-6a06dd2d84f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9c52d2-78ff-4628-9e32-464854ed2514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71299d85-b112-4588-8c60-97e183ab411a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8baa46b4-229e-4942-9334-967317206ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffac2ae6-75ef-4231-ae52-23f279180b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d979c1fd-673f-4fa3-9cf2-24fb8dce13e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 342fd14e-7f5a-4aa0-97b0-263f0a58f1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3744fd2c-e5aa-472d-85a7-22f918631fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dbb7119-72c1-4d7e-8286-475acf80cae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1503dc-b16d-4a1b-acd8-55e0e616dd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e358163d-e173-47cb-8f88-1519df7610a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ed118c-7d1c-440b-95ec-3f4f01f7195a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c83451a1-866a-49fc-b090-4b0350a1ebd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00dee4e7-1884-478c-82fd-a0275147ccce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e66e897b-3f74-48c3-8d8c-87b338d92e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65eb18e-81da-44b6-b860-563200fe51d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dfdfdeb-6256-40a7-9908-ad803c640845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a520fab9-9336-4693-843a-e2f18b7df88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad8257c-ff15-4741-978a-0b0763c6a10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b411d527-9643-484c-99ad-06b05a932811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5244bc04-d875-4dd8-beda-9188b8302edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73ce5aeb-e63c-4df5-ae12-42cfbbaa467d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010e7835-5fb2-420c-a9f2-7040408a02c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07f2052-e496-49ef-b42e-c71c13140025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9906e4ea-524d-4e0e-9c45-bdf84932edd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b2cb2f-ac0c-47d0-97b2-975560c94686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3797b20-2c62-49d3-9653-6a314ba8c6c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7511ad48-26fa-445f-a4c3-791688e6a1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2cd718-f488-4cec-93cc-7fc9cc1727f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c491752-8c3e-4467-9779-cf7699671830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8126cbd3-ac90-4b27-b1f1-d22cfbe3339a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b88b3d21-c3fa-41c0-8bb1-d4ec632eefcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b6b2d4-47bf-4900-beac-7c5ddf403c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2b57dd-58e5-440b-9b4b-c2c9c0645882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e67a8b-c431-4cde-9702-280b018188e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bc697fe-3093-405c-b317-1d7058c008e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80eb9c49-ce20-4851-964b-c3f6f8f8d502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3bfabf7-b0e0-4d44-9856-e1e49128e013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b748ab-dfd9-4a1d-a1ed-6af0aecb5134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc7da2b4-22e2-4e1d-940e-e263e4b653a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ebc4fd1-5e12-4f60-98b3-315cddc9ed6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 394ab17b-62e8-4b13-b935-d8b189bfa17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bf4e053-f62b-4747-ad9d-a7a28e2eecf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e180120a-04b9-461e-b938-186530332375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9239fe4-5271-46d2-b5ec-468ab63e68e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff973370-2f5e-45a9-921e-1b28f8a44cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eebefcbf-601e-4548-91e9-8bc9e56b6dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69f4182-77d9-467d-b968-bcc88d21f3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98227db9-530f-4581-b594-8f45fdbf4877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9357972c-0ab0-4606-9b41-e625fbd7e9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb31b53d-5fe2-40e3-ad14-c65b5e881a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a7c1fe2-2e7e-4d34-a26f-d6ecc9c80dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82386b20-0dd0-4fba-808b-762051e4427b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61751819-206a-47d7-9063-79a3a9a67772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed5f6c7b-f8ee-4209-b1d5-2d8b9045b914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b4f140-b439-42d3-be9d-6a4ebeabb782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28157456-a5f0-4d43-8ea6-57f2e43292f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1dea3ab-363b-4efd-9fce-04927f7db739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f235d0c-905c-440a-a88a-15d7dbcd91b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fdd0077-e52e-4188-87a2-b8d484e36979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52cb8625-a658-46d3-ab5a-84cdadce4a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e29c38b5-fe2f-4f9e-8dc4-b6a1c42172ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a178b059-9e23-4485-9746-7f48ca749a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e16aa3-0546-4751-bb1b-32e0b87049e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81fab1e-a794-4e53-8c2b-3a0e987b4807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eeed854-b014-40d8-95c7-e0051a3e6b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67619620-b674-44bf-a6bd-a89eb7683507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ea02f7-aba6-471c-9366-5973597b1b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c5ce786-c5db-47fc-a777-172ffa2b1580
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_18
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/test_labels.txt

📊 Raw data loaded:
   Train: X=(1054, 24), y=(1054,)
   Test:  X=(264, 24), y=(264,)

⚠️  Limiting training data: 1054 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  255 samples, 5 features
✅ Client client_18 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0890 (↓), lr=0.001000
   • Epoch   2/100: train=0.0814, val=0.0888, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0813, val=0.0887, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0812, val=0.0887, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0809, val=0.0887, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0792, val=0.0885, patience=10/15, lr=0.001000
   • Epoch  21/100: train=0.0731, val=0.0861, patience=1/15, lr=0.001000
   📉 Epoch 27: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0676, val=0.0901, patience=11/15, lr=0.000500
   📉 Epoch 35: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 2 Summary - Client client_18
   Epochs: 35/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.1087
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0287
============================================================


============================================================
🔄 Round 3 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1845, val=0.0819 (↓), lr=0.000250
   • Epoch   2/100: train=0.0847, val=0.0899, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0836, val=0.0851, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0825, val=0.0839, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0824, val=0.0840, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0820, val=0.0847, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 3 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0258
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0078
============================================================


============================================================
🔄 Round 4 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1182, val=0.1110 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0948, val=0.0927 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0853, val=0.0867 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0827, val=0.0849 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0820, val=0.0843 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0815, val=0.0840, patience=6/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 4 Summary - Client client_18
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0058
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0085
============================================================


============================================================
🔄 Round 5 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.1005 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0891, val=0.0983 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0877, val=0.0964 (↓), lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   ✓ Epoch   4/100: train=0.0866, val=0.0948 (↓), lr=0.000008
   ✓ Epoch   5/100: train=0.0858, val=0.0941 (↓), lr=0.000008
   • Epoch  11/100: train=0.0839, val=0.0910, patience=1/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004
   📉 Epoch 20: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0828, val=0.0892, patience=2/15, lr=0.000002
   📉 Epoch 28: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0826, val=0.0887, patience=5/15, lr=0.000001
   ✓ Epoch  41/100: train=0.0824, val=0.0884 (↓), lr=0.000001
   • Epoch  51/100: train=0.0823, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 5 Summary - Client client_18
   Epochs: 56/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0033
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0532
============================================================


============================================================
🔄 Round 6 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1130, val=0.1173 (↓), lr=0.000001
   • Epoch   2/100: train=0.1128, val=0.1170, patience=1/15, lr=0.000001
   ✓ Epoch   3/100: train=0.1125, val=0.1167 (↓), lr=0.000001
   • Epoch   4/100: train=0.1122, val=0.1164, patience=1/15, lr=0.000001
   ✓ Epoch   5/100: train=0.1119, val=0.1161 (↓), lr=0.000001
   • Epoch  11/100: train=0.1104, val=0.1147, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.1083, val=0.1126, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.1065, val=0.1109 (↓), lr=0.000001
   • Epoch  41/100: train=0.1049, val=0.1093, patience=2/15, lr=0.000001
   ✓ Epoch  51/100: train=0.1035, val=0.1079 (↓), lr=0.000001
   • Epoch  61/100: train=0.1021, val=0.1065, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.1008, val=0.1053, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0996, val=0.1041, patience=4/15, lr=0.000001
   • Epoch  91/100: train=0.0985, val=0.1030, patience=4/15, lr=0.000001

============================================================
📊 Round 6 Summary - Client client_18
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0976, RMSE=0.3125, R²=-0.1927
   Val:   Loss=0.1020, RMSE=0.3194, R²=-0.1801
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0926, RMSE: 0.3043, MAE: 0.2581, R²: -0.0979

============================================================
🔄 Round 7 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0912, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0883, val=0.0909 (↓), lr=0.000001
   • Epoch  21/100: train=0.0878, val=0.0904, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0874, val=0.0899, patience=9/15, lr=0.000001
   • Epoch  41/100: train=0.0870, val=0.0894, patience=8/15, lr=0.000001
   • Epoch  51/100: train=0.0866, val=0.0890, patience=7/15, lr=0.000001
   • Epoch  61/100: train=0.0862, val=0.0885, patience=5/15, lr=0.000001
   • Epoch  71/100: train=0.0858, val=0.0881, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0854, val=0.0877, patience=1/15, lr=0.000001
   • Epoch  91/100: train=0.0851, val=0.0873, patience=11/15, lr=0.000001

============================================================
📊 Round 7 Summary - Client client_18
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0314
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0354
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2553, R²: -0.0332

📊 Round 7 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2515, R²: -0.0019

============================================================
🔄 Round 11 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 11 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0111
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0262
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2511, R²: -0.0125

============================================================
🔄 Round 15 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 15 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0125
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0288
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2508, R²: -0.0053

============================================================
🔄 Round 18 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0815, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0815, val=0.0811, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0811, val=0.0807, patience=6/15, lr=0.000001
   • Epoch  41/100: train=0.0808, val=0.0803, patience=2/15, lr=0.000001
   • Epoch  51/100: train=0.0805, val=0.0801, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 18 Summary - Client client_18
   Epochs: 54/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0222
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0244
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0854, RMSE: 0.2922, MAE: 0.2520, R²: -0.0122

📊 Round 18 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2495, R²: 0.0071

============================================================
🔄 Round 23 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 23 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0271
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0639
============================================================


============================================================
🔄 Round 25 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 25 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0250
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0333
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2510, R²: -0.0004

============================================================
🔄 Round 27 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 27 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0145
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0040
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2515, R²: -0.0073

============================================================
🔄 Round 29 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 29 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0116
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0049
============================================================


============================================================
🔄 Round 31 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 31 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0085
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0067
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2512, R²: -0.0056

============================================================
🔄 Round 33 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 33 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0108
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0037
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2512, R²: -0.0055

============================================================
🔄 Round 34 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 34 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0105
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0036
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2512, R²: -0.0054

============================================================
🔄 Round 35 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 35 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0096
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0042
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2512, R²: -0.0053

============================================================
🔄 Round 36 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 36 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0101
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0033
============================================================


============================================================
🔄 Round 37 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 37 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0071
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0153
============================================================


============================================================
🔄 Round 38 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 38 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0151
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0131
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2512, R²: -0.0049

📊 Round 38 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2511, R²: -0.0048

============================================================
🔄 Round 41 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 41 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0088
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0095
============================================================


============================================================
🔄 Round 42 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 42 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0053
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0170
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2511, R²: -0.0046

📊 Round 42 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2511, R²: -0.0045

============================================================
🔄 Round 45 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 45 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0153
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0134
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2511, R²: -0.0044

============================================================
🔄 Round 47 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 47 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0113
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0022
============================================================


============================================================
🔄 Round 48 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 48 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0077
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0172
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2511, R²: -0.0042

📊 Round 48 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2511, R²: -0.0039

============================================================
🔄 Round 53 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 53 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0112
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0184
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2510, R²: -0.0039

📊 Round 53 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2510, R²: -0.0038

📊 Round 53 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2510, R²: -0.0038

============================================================
🔄 Round 56 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 56 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0006
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0482
============================================================


============================================================
🔄 Round 57 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 57 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0119
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0150
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2510, R²: -0.0037

============================================================
🔄 Round 58 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 58 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0044
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0312
============================================================


============================================================
🔄 Round 59 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 59 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0093
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0140
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2510, R²: -0.0035

============================================================
🔄 Round 61 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 61 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0126
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0045
============================================================


============================================================
🔄 Round 63 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 63 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0030
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0307
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2510, R²: -0.0033

📊 Round 63 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2510, R²: -0.0033

============================================================
🔄 Round 65 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 65 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0004
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0491
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2510, R²: -0.0032

============================================================
🔄 Round 66 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 66 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0192
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0280
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2510, R²: -0.0031

============================================================
🔄 Round 68 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 68 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0018
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0425
============================================================


============================================================
🔄 Round 71 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 71 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0099
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0131
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2509, R²: -0.0028

📊 Round 71 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2509, R²: -0.0028

============================================================
🔄 Round 73 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 73 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0159
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0102
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2509, R²: -0.0027

📊 Round 73 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2509, R²: -0.0026

============================================================
🔄 Round 75 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 75 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0159
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0091
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2509, R²: -0.0026

📊 Round 75 Test Metrics:
   Loss: 0.0845, RMSE: 0.2908, MAE: 0.2509, R²: -0.0025

============================================================
🔄 Round 77 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 77 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0202
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0315
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2509, R²: -0.0024

============================================================
🔄 Round 78 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 78 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0084
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0216
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2509, R²: -0.0024

📊 Round 78 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2509, R²: -0.0023

============================================================
🔄 Round 81 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 81 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0097
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0082
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2509, R²: -0.0023

============================================================
🔄 Round 82 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 82 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0152
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0132
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2509, R²: -0.0022

============================================================
🔄 Round 84 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 84 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0042
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0657
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2508, R²: -0.0022

============================================================
🔄 Round 87 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 87 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0139
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0017
============================================================


============================================================
🔄 Round 88 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 88 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0163
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0148
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2508, R²: -0.0020

============================================================
🔄 Round 89 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 89 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0163
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0112
============================================================


============================================================
🔄 Round 91 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 91 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0219
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0437
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2508, R²: -0.0018

📊 Round 91 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2508, R²: -0.0016

============================================================
🔄 Round 95 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 95 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0089
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0204
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2508, R²: -0.0015

============================================================
🔄 Round 96 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 96 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0096
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0095
============================================================


============================================================
🔄 Round 97 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 97 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0124
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0078
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2507, R²: -0.0014

============================================================
🔄 Round 99 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 99 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0150
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0058
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2507, R²: -0.0013

============================================================
🔄 Round 101 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 101 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0086
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0235
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2507, R²: -0.0012

============================================================
🔄 Round 103 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 103 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0137
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0213
============================================================


============================================================
🔄 Round 104 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 104 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0103
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0143
============================================================


============================================================
🔄 Round 106 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 106 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0164
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0242
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2507, R²: -0.0011

============================================================
🔄 Round 107 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 107 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0111
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0118
============================================================


============================================================
🔄 Round 108 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 108 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0036
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0194
============================================================


============================================================
🔄 Round 109 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 109 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0098
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0172
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2507, R²: -0.0010

============================================================
🔄 Round 113 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 113 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0050
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0341
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2507, R²: -0.0010

📊 Round 113 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2507, R²: -0.0010

============================================================
🔄 Round 115 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 115 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0095
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0204
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2507, R²: -0.0010

📊 Round 115 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2507, R²: -0.0010

============================================================
🔄 Round 118 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 118 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0083
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0265
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2507, R²: -0.0011

============================================================
🔄 Round 120 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 120 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0054
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0049
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2507, R²: -0.0011

📊 Round 120 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2507, R²: -0.0011

============================================================
🔄 Round 122 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 122 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0085
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0227
============================================================


============================================================
🔄 Round 123 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 123 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0115
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0095
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0011

============================================================
🔄 Round 126 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 126 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0050
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0362
============================================================


============================================================
🔄 Round 127 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 127 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0071
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0262
============================================================


============================================================
🔄 Round 129 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 129 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0193
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0265
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0009

📊 Round 129 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0008

============================================================
🔄 Round 131 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 131 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0096
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0020
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0008

============================================================
🔄 Round 134 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 134 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0116
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0084
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0008

============================================================
🔄 Round 135 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 135 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0154
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0054
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0008

============================================================
🔄 Round 136 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 136 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0200
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0212
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0008

📊 Round 136 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0008

============================================================
🔄 Round 138 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 138 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0100
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0094
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0008

============================================================
🔄 Round 139 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 139 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0164
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0147
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0007

============================================================
🔄 Round 140 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 140 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0112
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0105
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2506, R²: -0.0006

============================================================
🔄 Round 143 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 143 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0161
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0053
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2506, R²: -0.0004

📊 Round 143 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2506, R²: -0.0003

============================================================
🔄 Round 147 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 147 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0184
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0354
============================================================


============================================================
🔄 Round 150 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 150 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0067
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0276
============================================================


============================================================
🔄 Round 153 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 153 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0052
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0365
============================================================


============================================================
🔄 Round 154 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 154 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0103
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0163
============================================================


============================================================
🔄 Round 155 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 155 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0102
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0201
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2506, R²: -0.0000

📊 Round 155 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2506, R²: 0.0000

============================================================
🔄 Round 158 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 158 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0119
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0070
============================================================


============================================================
🔄 Round 159 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 159 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0115
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0138
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2506, R²: 0.0001

============================================================
🔄 Round 163 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 163 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0174
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0159
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2505, R²: 0.0002

============================================================
🔄 Round 166 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 166 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0109
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0168
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2505, R²: 0.0003

============================================================
🔄 Round 170 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 170 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0120
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0117
============================================================


============================================================
🔄 Round 171 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 171 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0169
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0064
============================================================


============================================================
🔄 Round 173 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 173 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0157
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0037
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2505, R²: 0.0006

============================================================
🔄 Round 174 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 174 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0096
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0252
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2505, R²: 0.0006

============================================================
🔄 Round 176 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 176 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0124
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0131
============================================================


============================================================
🔄 Round 177 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 177 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0142
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0009
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2505, R²: 0.0007

📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2505, R²: 0.0008

📊 Round 177 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2504, R²: 0.0009

📊 Round 177 Test Metrics:
   Loss: 0.0842, RMSE: 0.2903, MAE: 0.2504, R²: 0.0009

📊 Round 177 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0011

📊 Round 177 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0011

📊 Round 177 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0012

============================================================
🔄 Round 191 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 191 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0071
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0345
============================================================


============================================================
🔄 Round 192 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 192 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0134
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0053
============================================================


============================================================
🔄 Round 193 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 193 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0161
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0019
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0013

============================================================
🔄 Round 195 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 195 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0131
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0082
============================================================


============================================================
🔄 Round 196 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 196 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0085
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0295
============================================================


============================================================
🔄 Round 197 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 197 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0104
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0135
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0014

📊 Round 197 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0015

============================================================
🔄 Round 199 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 199 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0072
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0381
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0014

📊 Round 199 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0014

📊 Round 199 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0013

📊 Round 199 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0013

📊 Round 199 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0013

============================================================
🔄 Round 206 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 206 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0095
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0220
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0014

============================================================
🔄 Round 209 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 209 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0130
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0136
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2504, R²: 0.0014

❌ Client client_18 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
