[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e51ac82a-b10e-47a1-809e-983ca1650808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95389f21-69d4-4878-9330-49d03ee5be60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0408dfc0-9f95-4af9-8f84-2123f0d68389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7da520f-88f4-4930-946c-12f273fb17b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb04523b-e6b2-4772-94ea-7e0d8fc07b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9340e3fc-c417-4bd4-b21a-4861a7788a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb56039-a697-479b-b980-f5d5467fce0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f40e6877-7385-4943-a81d-c2251604f002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c01cb6c7-1625-4762-bbc2-f5314fcfbd83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d297f2a1-b836-4dbc-b081-69015ceb0eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8e8c6b-39db-4d43-bda5-b69f88c5ccc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d849601c-0448-4045-8074-a717af1bc110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 132b796c-7124-4aac-b17d-4c39936aa3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24264949-73fa-4e28-a451-fb7bbc222be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a028edc4-0632-48f3-89a7-856140e5c20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f42f87-6c3b-474e-bb26-45dc6140cf84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202cdd88-46f0-4625-b54b-dd5e136a9ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b524ab1-851b-4c62-9351-4ee0f5ba4337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa1cb38-830c-4073-bebd-af19583086a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61763e37-e4aa-4e82-ba5f-4e1edea87b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6be2fbe9-0b21-43fa-81f9-59223482f6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaf10baf-fe0f-44e6-bd0b-704950b17476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f4833a3-584c-4aac-bbbf-331197a24b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4e1625-e1a1-494c-bfef-e405361f4ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77d3c243-a65f-40c4-a9ba-50263d0cfaf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e22d0d-ef9c-442c-9b2e-6f8f7960be8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c5d6ce7-1ddd-4f15-b611-eed6d6bb93d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774abcd0-7d2d-4884-b7a6-9c5a88b02d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 800c2fdf-fb2f-4f5b-be23-7f4dd1fd3533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a78804-2f99-4bbc-ba3e-ec24fc5ebc4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb871274-7109-47c9-9a21-cf103c14d877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2439e91e-686b-4cdc-accb-b36c92b24dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4983a711-934d-40df-9c99-cadf8f0a3c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4393224-8470-4d52-b74b-0432a77fc046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f289ce9-a0cc-4530-a82e-aeb75a342a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9422012-d057-43c5-a108-ec331abebe69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9600eed5-2f21-45d8-9bb5-ecdf1f918f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b8ae4f5-7daa-404e-9e72-37a71ca48aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9522cb88-8eb9-4766-9166-54026f66cc25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0824d7eb-e29b-4035-87d3-168da742985e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0e5616e-d0db-4943-9316-1d7bc2dde936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f76c63-9cc2-403e-8468-c366ef6644b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07330809-7c49-4ee4-96ca-01010e8c44a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5a1a25-bdbe-4cfd-89ca-059826d8f81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acaa94b0-854e-486e-a196-25356b96d303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f5cff81-f8a8-4093-aef8-518764926ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a79c51d-adc6-4437-81e6-5f2dbf6417f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34ff1aca-737c-4d9b-a331-b5ed2d5fb036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dc3ceb1-5ae6-428e-94ca-17c2f9abf2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a94d63f6-6c85-409b-904c-615ab887d936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f7da5c-7514-449f-9fb0-0b16d1fdecf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520f710d-edf7-4832-9ca1-8c8d4e8af48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4290c5-3964-4d6b-8174-c04fb6569a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efd6168-8799-4f73-a9d7-720ff8ea9b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99939427-c329-400e-ae94-543e228031eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 173cbe7e-740a-4ba9-9213-6da31a54203f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2d061c2-9991-4d2c-a190-74c131b82c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a7128c4-a9d3-46d1-80f8-f4875d72831a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0259f85f-fc99-43cd-9a46-1cc135f1de21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d104f6-5b00-40db-989e-848ceb93605b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d780f3-0bbf-4b58-9b30-b54dee8b25ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08a06ba0-fa8c-47a0-b62b-fd4f4664b551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31f64a4-8ab9-4c11-830d-c3068c89d11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8edec317-eb36-4a06-bf9f-483eae13c282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71077834-d4d2-4410-8734-65b83e59693f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a69fd4-63fa-4646-9093-db1dab4a084f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d99f8f3-d8aa-4eb2-a451-dab11b440e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b82327-7bfb-47ad-b0b7-e644f26e28e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fe7c275-3f93-4b00-bb96-594d39375fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8890a4-b527-4a44-b868-af1e3bf7162c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b036e9af-7f7b-4d4d-94d7-edee1c3e652b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0b143a-cbc0-403c-89db-dd8cca0e8d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61346a0d-1576-4b01-92a1-096084ae043f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d31c5936-531a-4c79-8b56-9ed16a57ba5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4219b89c-10ac-44c9-b53a-65cb29f45050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30bb886e-7fe7-4d1a-8761-fa5adad8a6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1a456a-0e4e-4f72-ae3d-9276a29471df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c052056f-b0ed-4439-8fdf-530072a7430d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f354f79f-235c-44db-8cf6-2c9479b615ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4af3b7-376d-434b-89ea-0787bf0e6e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d471553-b25a-4791-9939-0bbab0390218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a37a39-5f17-491c-acb9-413ea8f02931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f07176fd-da94-4af1-85cb-a62ac5a27846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d81f2e6-40f2-4961-904b-f1610b94c77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8939432-e857-44e6-9840-668eb3289f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5013b1-1bc1-4ad4-b720-2bb71279ad26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4a95c41-9891-4e74-9edb-1f78b48f6db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbf10d20-ecd9-49b6-a737-7b361e72168d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ac6cbf-95be-40d2-836f-43d24b9d5ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9333d616-6cd3-4bba-808e-0e06336cdd97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf55b93-7cbb-453f-9ccd-7d6bcfd1131e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b253d0a-8eea-4313-a184-84a524d82020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12b29077-8db4-4804-aed8-583eae8dd148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0378f034-a892-48c7-8aa0-78bd9fd8fb04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42acc2aa-9c2c-4d6e-ac5a-0e3d85999ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 417d5bf6-8012-4b5c-857d-43a7601499ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf4fee9-7aa7-4443-a2b3-e8cc3d79a29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f00a3f-6e4e-433e-bfdc-44720e01a5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bb44996-1e38-4f56-b682-3d5549770b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c910bd51-890a-4b4e-84a1-d0254db7e645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ed65db-035b-4dc9-a2ae-4a158cd2a576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa2b9c2b-254a-4db6-ab40-2ad88cd92b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a3fb2d-9627-45a5-a6e8-5846ae894e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a8a497-1408-4e30-9310-63d5da5e2175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee3dc98-0708-407c-94e9-b05ece1e4e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0667e4a2-f6ed-440f-b7a1-0e6ccbfd2839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 720110bf-d610-4466-b287-30f2613020b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff7bd89-7f00-41c9-907b-8f0dfe5069c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce895037-808a-43f3-9b9f-e5dbc04fbae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2becae55-5d54-4acc-bcd9-39ef3cbeb3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a0a43f-f1dd-4be3-be32-eec521f6ebe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec0b48c6-e38e-4e76-9ef9-b432fd7fbf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ed6199-3449-4862-b287-778be5ed2b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d52ec1c-9ef2-47c7-806e-43178434fdc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 363a0928-7533-478a-bdbc-e5813e75104d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a7ff398-0dee-42b9-9d87-2043eda1f068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be67516-646d-4901-ae44-56aa4e0cd528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 449936ca-8317-438c-8d58-104c10da8927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c0f5c9b-fefa-4b66-903d-3b9ec0ede626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a56a0d34-f545-4857-a004-919bf3f0b337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3735247f-cc41-4d2f-84f8-30b6ec832204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f985bc-3dd5-4b8c-9981-52402bde4753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b738fbb-489f-4cd5-86f6-a6391d5bb3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d4c7122-5b70-4703-905a-79958b0f6e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2de41a4d-5f91-457b-91d4-00282ff14f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f37de111-a014-453e-8667-6829bf3a8a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab267254-8ba7-454f-b440-94402174c7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f619116e-247f-4f9e-86e9-bad903e8ffc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72de7e34-6606-427a-a023-0fb7fc82a15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3f9a71-459b-443f-8c2f-de533873fc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c41e9513-c95b-4fe2-8868-0a5dc1118ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf20f0ad-67cc-4b1d-8911-e77bcd970fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e690c04a-2035-44f6-bb01-792ad0052407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a73897-736c-4cfb-affa-02367887c307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d81ca49d-5615-468b-9774-28eee6ec359e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642ce24a-86d1-4a7a-bffb-20cf064b7ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601e892e-40b5-4f72-8a4a-cea84b4f777f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b263ffa0-e6bf-4861-a389-3a718f651538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e84802d-1c9d-446e-a479-ca8082cf2c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3881df3d-a18e-4ee5-85d7-f0b416bc1109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19fa288b-10ca-4012-9344-c7591a5cb3e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2390cce9-7c5a-4793-8991-c08212768897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b8d963-fe26-4681-afec-5b8df49398b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4e2d906-fd77-445a-91b6-04ad9ee0c1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea36e13-6889-4201-b6f4-ad8a979c0888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 570f2462-5ce0-4cd4-a450-d1b0af20ce80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf1a7c84-103c-4840-9ae9-6906f927058f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9152ac10-8914-4453-a84e-212434425f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef9818a5-3b39-4d34-92b6-edc08ff0d42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a081c4ce-2853-4981-805a-c9ffb83eb46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e97ff9-80cb-4f5b-b60a-74b8dc239782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c8cb9e-18f8-45b4-8286-f5a890ffd5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c88f22d6-dfb4-4bcd-b331-e651c2df49a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b478f9c1-288b-41ea-ae93-382fa240754b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a222fa96-7065-4a5c-bc57-5bb7f7acdafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 972fc89c-ed3f-4aee-bbb1-31c36df79ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67186de0-eccf-4da2-bd42-e808a790f582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b35704f-5cfc-49cb-8e08-61f2ee51f950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fa7ad14-c015-40a3-b24e-9f8b589b7893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50192691-1cf1-4c6d-82de-db8d2a8fa390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5eeeb1-15a5-4429-8e63-7cb02fc3ded6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a670f505-6995-404d-a17e-e0c73d874e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee45584c-7987-41a4-87b0-7f0b53595689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3aafe3-a166-4814-b504-21e8433afc75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac83ec0-54a0-4150-a55b-838020d24958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a163825d-87dd-41be-a361-149a71e1f210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9ef1705-e607-404c-82d7-506aa5a66860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d02b7e8-4ff1-4f30-96ab-1006e1b9d957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f16d110-29de-44a0-b0cf-6c4ee7283e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac71ce3f-8dbd-42c6-bb13-060ee75ccc76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b53f4af-d1dc-47e7-9b26-13f799349099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e421ab09-0b26-459b-a8b2-411582702ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ac00243-bba6-40c6-aa25-03e0d0cc4bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3eda7b4-3c32-4d61-b927-7662873eb08e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47403d7-ddf2-4d0f-b818-3bfa4528d795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8325b14a-0abf-40d3-88fd-6d6fc580532b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8d6fd4-6692-44a6-942c-4b3110f27bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 992cc471-3bc4-4227-9b9e-96231b416724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf20d2f-29a8-4f86-9468-ef0f57a1f8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7958d5f-3f5b-4afa-9700-956da69d530e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_19
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/test_labels.txt

📊 Raw data loaded:
   Train: X=(1076, 24), y=(1076,)
   Test:  X=(269, 24), y=(269,)

⚠️  Limiting training data: 1076 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  260 samples, 5 features
✅ Client client_19 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2423, R²: 0.0095

📊 Round 0 Test Metrics:
   Loss: 0.3390, RMSE: 0.5823, MAE: 0.5104, R²: -3.3046

============================================================
🔄 Round 5 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0884 (↓), lr=0.001000
   • Epoch   2/100: train=0.0806, val=0.0890, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0784, val=0.0863 (↓), lr=0.001000
   • Epoch   4/100: train=0.0781, val=0.0858, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0771, val=0.0845 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0677, val=0.0742 (↓), lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0569, val=0.0761, patience=9/15, lr=0.000500
   📉 Epoch 26: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 5 Summary - Client client_19
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0633, RMSE=0.2515, R²=0.2128
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.1380
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1085, RMSE: 0.3294, MAE: 0.2707, R²: -0.3778

📊 Round 5 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2399, R²: -0.0065

📊 Round 5 Test Metrics:
   Loss: 0.0750, RMSE: 0.2738, MAE: 0.2351, R²: 0.0480

============================================================
🔄 Round 13 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0682 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0749, val=0.0668 (↓), lr=0.000250
   • Epoch   3/100: train=0.0738, val=0.0664, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0728, val=0.0656 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0720, val=0.0650 (↓), lr=0.000250
   ✓ Epoch  11/100: train=0.0682, val=0.0636 (↓), lr=0.000250
   • Epoch  21/100: train=0.0643, val=0.0624, patience=4/15, lr=0.000250
   📉 Epoch 26: LR reduced 0.000250 → 0.000125
   • Epoch  31/100: train=0.0620, val=0.0631, patience=14/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0625)

============================================================
📊 Round 13 Summary - Client client_19
   Epochs: 32/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0652, RMSE=0.2554, R²=0.2147
   Val:   Loss=0.0625, RMSE=0.2499, R²=0.1926
============================================================


============================================================
🔄 Round 14 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0776 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.0712, val=0.0756 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0706, val=0.0750 (↓), lr=0.000063
   • Epoch   4/100: train=0.0702, val=0.0746, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0698, val=0.0743 (↓), lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0682, val=0.0732, patience=3/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0673, val=0.0727, patience=9/15, lr=0.000016
   📉 Epoch 26: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0669, val=0.0726, patience=7/15, lr=0.000008
   📉 Epoch 34: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 14 Summary - Client client_19
   Epochs: 39/100 (early stopped)
   LR: 0.000125 → 0.000004 (5 reductions)
   Train: Loss=0.0671, RMSE=0.2591, R²=0.1771
   Val:   Loss=0.0727, RMSE=0.2695, R²=0.1148
============================================================


============================================================
🔄 Round 15 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0709, val=0.0743 (↓), lr=0.000004
   • Epoch   2/100: train=0.0708, val=0.0742, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0708, val=0.0742, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0708, val=0.0742, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0708, val=0.0742, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0707, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 15 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0708, RMSE=0.2661, R²=0.1336
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.1084
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0700, RMSE: 0.2647, MAE: 0.2253, R²: 0.1107

============================================================
🔄 Round 16 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0716, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0714, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 16 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1248
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.1740
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0703, RMSE: 0.2651, MAE: 0.2279, R²: 0.1080

📊 Round 16 Test Metrics:
   Loss: 0.0705, RMSE: 0.2654, MAE: 0.2292, R²: 0.1055

============================================================
🔄 Round 21 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 21 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1280
   Val:   Loss=0.0661, RMSE=0.2570, R²=0.0806
============================================================


============================================================
🔄 Round 23 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0711, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0711, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0711, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 23 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2668, R²=0.1450
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.1087
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0708, RMSE: 0.2662, MAE: 0.2303, R²: 0.1005

============================================================
🔄 Round 24 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0711, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 24 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1371
   Val:   Loss=0.0687, RMSE=0.2620, R²=0.1453
============================================================


============================================================
🔄 Round 26 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0709, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 26 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0708, RMSE=0.2661, R²=0.1456
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0662
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2319, R²: 0.0916

============================================================
🔄 Round 31 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0696, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0696, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0696, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0695, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0695, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0695, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 31 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0694, RMSE=0.2634, R²=0.1224
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.1061
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0716, RMSE: 0.2677, MAE: 0.2321, R²: 0.0904

============================================================
🔄 Round 36 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0712, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 36 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0713, RMSE=0.2670, R²=0.1061
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.1483
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0901

============================================================
🔄 Round 37 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 37 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1220
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0808
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0901

============================================================
🔄 Round 38 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0714, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 38 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2680, R²=0.1149
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.1189
============================================================


============================================================
🔄 Round 39 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 39 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2688, R²=0.1095
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.1413
============================================================


============================================================
🔄 Round 40 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 40 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2684, R²=0.1113
   Val:   Loss=0.0746, RMSE=0.2730, R²=0.1333
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0901

📊 Round 40 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

📊 Round 40 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

============================================================
🔄 Round 46 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0600 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0600, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0600, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0600, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0600, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0600, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0600)

============================================================
📊 Round 46 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.1143
   Val:   Loss=0.0600, RMSE=0.2449, R²=0.1261
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

============================================================
🔄 Round 47 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 47 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.0973
   Val:   Loss=0.0680, RMSE=0.2607, R²=0.1881
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

📊 Round 47 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

============================================================
🔄 Round 49 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0709, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0709, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 49 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2664, R²=0.1206
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0968
============================================================


============================================================
🔄 Round 50 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 50 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.1173
   Val:   Loss=0.0701, RMSE=0.2649, R²=0.1078
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

📊 Round 50 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

📊 Round 50 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 55 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0633 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0633, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0633, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0633, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0633, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0633, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0633)

============================================================
📊 Round 55 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.1022
   Val:   Loss=0.0633, RMSE=0.2516, R²=0.1752
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

📊 Round 55 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

📊 Round 55 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

============================================================
🔄 Round 58 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0716, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 58 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2679, R²=0.1171
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0945
============================================================


============================================================
🔄 Round 60 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 60 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1086
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.1499
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

📊 Round 60 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0900

============================================================
🔄 Round 63 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 63 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1236
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0842
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

📊 Round 63 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 67 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0714, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 67 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2673, R²=0.1199
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0997
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 68 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 68 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1192
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.1025
============================================================


============================================================
🔄 Round 69 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0650, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 69 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1076
   Val:   Loss=0.0650, RMSE=0.2550, R²=0.1528
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 70 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 70 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2690, R²=0.1117
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.1305
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

📊 Round 70 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 76 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 76 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.1268
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0715
============================================================


============================================================
🔄 Round 77 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 77 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2686, R²=0.1179
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.1099
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 78 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 78 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.1151
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.1175
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

📊 Round 78 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

📊 Round 78 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

📊 Round 78 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0898

============================================================
🔄 Round 85 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 85 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.1121
   Val:   Loss=0.0716, RMSE=0.2677, R²=0.1160
============================================================


============================================================
🔄 Round 87 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 87 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1133
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.1237
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 88 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 88 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2668, R²=0.1113
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.1300
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 89 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0714, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0713, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0713, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 89 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0713, RMSE=0.2671, R²=0.1163
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.1138
============================================================


============================================================
🔄 Round 90 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 90 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2688, R²=0.1228
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0706
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 93 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 93 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.1155
   Val:   Loss=0.0679, RMSE=0.2605, R²=0.1093
============================================================


============================================================
🔄 Round 94 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 94 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1079
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.1458
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 95 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0646 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0646, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0646, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0646, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0646, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0646, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0646)

============================================================
📊 Round 95 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.1181
   Val:   Loss=0.0646, RMSE=0.2542, R²=0.1075
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

============================================================
🔄 Round 98 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0652, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0652, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0652, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 98 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2727, R²=0.1087
   Val:   Loss=0.0652, RMSE=0.2554, R²=0.1472
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

============================================================
🔄 Round 99 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 99 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.1121
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.1196
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

📊 Round 99 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

============================================================
🔄 Round 101 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 101 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1187
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.1029
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

📊 Round 101 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

📊 Round 101 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0898

📊 Round 101 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 105 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 105 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1122
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.1195
============================================================


============================================================
🔄 Round 106 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 106 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2712, R²=0.1139
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.1256
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

📊 Round 106 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

📊 Round 106 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 110 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 110 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1097
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.1441
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 111 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 111 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.1029
   Val:   Loss=0.0647, RMSE=0.2544, R²=0.1733
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2321, R²: 0.0899

============================================================
🔄 Round 114 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 114 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1144
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.1221
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0899

============================================================
🔄 Round 117 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 117 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.1259
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0715
============================================================


============================================================
🔄 Round 118 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 118 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1133
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.1214
============================================================


============================================================
🔄 Round 119 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 119 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2690, R²=0.1220
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0902
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0899

============================================================
🔄 Round 120 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 120 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2690, R²=0.1148
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.1138
============================================================


============================================================
🔄 Round 123 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 123 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1041
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.1497
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0899

============================================================
🔄 Round 124 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0641 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0641, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0641, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0641, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0641, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0640, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0641)

============================================================
📊 Round 124 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.1190
   Val:   Loss=0.0641, RMSE=0.2532, R²=0.0938
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0899

📊 Round 124 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0899

============================================================
🔄 Round 129 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 129 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2694, R²=0.1184
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.1019
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0899

============================================================
🔄 Round 130 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 130 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2699, R²=0.1052
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.1519
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0899

📊 Round 130 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0899

============================================================
🔄 Round 133 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 133 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2684, R²=0.1013
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.1630
============================================================


============================================================
🔄 Round 135 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 135 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2694, R²=0.1250
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0683
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2322, R²: 0.0898

============================================================
🔄 Round 137 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 137 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2688, R²=0.1075
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.1305
============================================================


============================================================
🔄 Round 144 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 144 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.1091
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.1340
============================================================


============================================================
🔄 Round 145 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 145 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2684, R²=0.1177
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0899
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0898

============================================================
🔄 Round 146 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 146 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1108
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.1246
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0898

============================================================
🔄 Round 151 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0707, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0707, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0707, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0707, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0707, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0706, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 151 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0706, RMSE=0.2658, R²=0.1108
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.1220
============================================================


============================================================
🔄 Round 152 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 152 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2677, R²=0.1162
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0991
============================================================


============================================================
🔄 Round 155 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 155 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1078
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.1288
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 156 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 156 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.1180
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0957
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 158 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 158 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1173
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0999
============================================================


============================================================
🔄 Round 159 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 159 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.1186
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0904
============================================================


============================================================
🔄 Round 160 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 160 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.1105
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.1264
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0896

📊 Round 160 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2323, R²: 0.0895

📊 Round 160 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2323, R²: 0.0895

============================================================
🔄 Round 166 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 166 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2688, R²=0.1118
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.1184
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2323, R²: 0.0895

============================================================
🔄 Round 168 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0637 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0637, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0637, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0637, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0636, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0636, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0637)

============================================================
📊 Round 168 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.1139
   Val:   Loss=0.0637, RMSE=0.2524, R²=0.1066
============================================================


============================================================
🔄 Round 169 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 169 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.1177
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0946
============================================================


============================================================
🔄 Round 170 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 170 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.1060
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.1431
============================================================


============================================================
🔄 Round 171 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 171 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1153
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.1061
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0895

============================================================
🔄 Round 173 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 173 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.1164
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0620
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0896

============================================================
🔄 Round 176 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 176 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2664, R²=0.1137
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.1071
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0896

============================================================
🔄 Round 177 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 177 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1116
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.1181
============================================================


============================================================
🔄 Round 178 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 178 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1081
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.1339
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0896

============================================================
🔄 Round 182 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 182 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2676, R²=0.1161
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.1069
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 184 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 184 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2694, R²=0.1157
   Val:   Loss=0.0731, RMSE=0.2705, R²=0.1084
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

📊 Round 184 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

📊 Round 184 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

📊 Round 184 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 188 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 188 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.1255
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0604
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 189 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0707, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0707, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0707, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0707, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0707, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0706, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 189 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0707, RMSE=0.2659, R²=0.1233
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0815
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 191 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0635 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0635, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0635, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0635, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0635, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0634, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0635)

============================================================
📊 Round 191 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.1061
   Val:   Loss=0.0635, RMSE=0.2520, R²=0.1464
============================================================


============================================================
🔄 Round 192 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 192 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1194
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0833
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 196 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 196 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1103
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.1238
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0898

📊 Round 196 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0898

============================================================
🔄 Round 200 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 200 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2662, R²=0.1221
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0845
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 202 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0713, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0713, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 202 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0710, RMSE=0.2664, R²=0.1226
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0814
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0898

============================================================
🔄 Round 205 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 205 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.1141
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.1128
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

📊 Round 205 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 208 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 208 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.1178
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0958
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2322, R²: 0.0897

============================================================
🔄 Round 210 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0707, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0707, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0707, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0707, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0707, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0706, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 210 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0707, RMSE=0.2660, R²=0.1068
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.1200
============================================================


============================================================
🔄 Round 211 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 211 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1120
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.1213
============================================================


❌ Client client_19 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
