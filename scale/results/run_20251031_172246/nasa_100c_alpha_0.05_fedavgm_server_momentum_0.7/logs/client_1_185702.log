[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c10c2d0-030f-4d0c-9800-8ed20281fc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ac760f-8bcf-4786-83dd-99e82097f084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message febe7c69-13b1-4b02-923f-c62aa22b38e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00396582-f73e-44b6-b107-f81cb138469a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef12fa33-16b5-4ab4-bb89-b4cab1fc6515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b255e78b-ca56-422e-9dcf-e3c89d5a10cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6039713b-e46d-46d2-806a-b7e4a7479527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a14809bc-6350-49dd-8787-75eb31b48800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72aba58c-3df5-4c7d-9614-f65896c44500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2ed8ee6-62fa-4b06-9db8-5d01b5ece8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec273dc-f4fe-4e48-b0ff-dec0ba49a30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 350b98bd-9d8d-4d20-8c96-55fdb1b41dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b94c978-49b1-4f2b-8343-5602a1810877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c97022b-827a-4073-8225-f9c0ce53da57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df9dd613-483e-4fef-b1f0-26859b590cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e56876-7554-4871-8be5-037e83f69a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b9e1c5-c3ff-4386-b693-3c4dd0dcdce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4a5ec53-7d89-4978-b789-a911bfc3225d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6146e2-ac54-43c3-907e-ac41f7820eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46bd369b-4b52-452a-895a-ffeabdcebc9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dfd074c-ef47-44cd-bb07-ee77b7f316d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32eefeb4-d357-462a-8f19-7d65d4275600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee84047-eb60-4021-93a2-28181f1061cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204a46da-9d74-4e67-b3e8-98a50bceee51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97af4ed9-3ce6-4982-9c60-f598d413da84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7607b4-4eb5-4ba1-b867-70df6a799dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0069622b-95f7-43dd-b65f-c4551b3aa8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13645e9-64dd-474c-8759-a6f57d8cc4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8256f50a-f0a0-4c8e-884f-a4947fbf03f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59a785f-9cfb-4ffe-af0b-9e95e4f7a8cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c508855-57ef-4df6-8587-42306232fd96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a35ef67-4cb5-4bf8-92ca-7cd18e767067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1dc579-95e3-43bc-bc4c-b04ead45772c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 807b4645-a2c1-42ca-89bb-3924f938f1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d18c62-942f-4371-82c3-04c089951366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e17f75-56f8-46bf-8ef3-6f3f55f1b01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d69f6d-f9f5-4c84-bda9-5a6e3f0561d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c583cb31-caf4-416e-b085-ce9acb0bdc2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5d38cc-0738-49df-8a67-e480d6bc69f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a095c3-385b-48e6-80f5-f534d4834652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc181ad-117d-4019-b529-b9d86696c345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56c66706-45c0-4140-98a8-e755295c611f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b5b7d4c-0134-4573-a827-d234e8c9c953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d75898f5-a0ec-4d88-87ce-2bbe0cacf1b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65e9a69-71a5-4457-85af-43aead619e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 277f80ca-01f0-473d-8de7-e12e9ff106c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f32e913a-0b7d-40c2-870a-de26b431c10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb5d8da-df93-4790-80d7-f85c26299795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 268532ec-8133-4e6b-b632-213d606e3d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4848f27f-f4c9-456a-a871-0b3d94f67492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e000b3-7597-4d79-836b-1d05b72fb0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974a3fcd-734a-4fa6-acb0-6a8e665f11e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec58142-7140-43dc-bc11-8549f3b0c81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97982f44-0866-4934-afd3-1c06ef63fd96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c98256d4-88f2-4a50-976a-7eea5edfa3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4385f69-ab01-4a42-b7d2-73953a955d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f405e928-9795-471f-aa8a-56d0051b8a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e312908-6c89-41e7-8a03-5831ed426d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74fba88f-410c-4b03-be22-73bd93323c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7565fbed-804e-4ec9-b17c-6254f7016eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df639b75-db09-4365-b450-3c8e3974d090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae83704f-4d0f-4e9a-a934-20ecba5b7112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e86d6f97-dcef-4984-a7fc-fbfd0684af7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc359d24-11f1-423c-87da-205622881b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a7ccf40-a0e5-4d64-81e2-9d06648acdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9175c1a-61b1-492a-b7f1-3377f6766a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0878f82e-e54e-45e6-af89-08914796b191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc673398-b6d2-4fea-90d3-a96b9424b36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 048673d2-d795-48ac-beb5-3d796520af1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a63b275-b391-4b36-ba36-3467fa6877c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4abbbd85-5c57-43c0-b047-d111b0371e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd56ac0-f5c4-4136-8d14-1509a12fc118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd9a6e53-8284-48da-8b40-74b9c4b84cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8b4bf3-2303-4316-a8bc-616d4022f074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ae5b14-0020-4cd9-96e1-a05babbe5e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41571624-79c2-4f12-aaa3-698a34f6e260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a9aaaf-0e55-44fd-9dc3-03895d53ae50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77439b89-d206-48f5-86f6-ccd6d92c3a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b231db8-ab40-4756-b8ab-9ea7f0cafaf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb31e2f2-d4c4-4c4c-97d5-a143e210add8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4a179c5-345d-4087-a545-5c0e46de76fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348dc175-ac16-4d17-9ca4-62d346d6205f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16cc6e81-d664-49e7-b7dd-e62085f9a4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1a86169-8874-4956-ae6b-298a66bff5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d6d775-d8d0-4233-9a16-282608c5e32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6db2adc-4383-405d-96b3-1fd914a235ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816c7bf1-8c39-434e-9eaa-3678f7451844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ef94a2a-db5f-4ee4-ba18-6dceb77f148a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1205cae-ca08-4b95-9e36-e8756c122d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9782a45-3a3a-4120-9bae-3f9a9e255cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c9fdfca-debf-4eb5-a306-cf64ece8939d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 558c0240-1e27-43f8-a2db-57f96e2913d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59c6800-c71c-4f48-bc83-c5dab494f1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 767650e5-2cc6-4728-b9bb-e726eb56c77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822390e9-966b-44ac-85ef-b70eb0a85104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd37716-67d8-43c0-ac18-4e72969aaecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f87a996a-140e-4556-94d1-0f42223b2dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da75bceb-37c1-4f92-a42a-2d71167bdc4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7814b16d-0580-489d-982a-3a12d3d08754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99d4a3c-57d2-4c75-ad7a-2d09602ddefb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea4bd47-9b79-4aec-b7d3-3c4b7b3bbaf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05792cbe-7321-4301-83ea-81400e15c990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f000d7-07e4-4f76-90c2-f1cdc3e9cfe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c918b8a0-454c-4b52-b27e-b3fe8f0766c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98372ad1-1b92-4e42-a839-108a84e53c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17477909-efd8-4f80-bb64-2e77e58a860b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0267f0a1-9ef6-4240-8c79-3e884a92cdf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0675aede-3a17-4cb2-b6f4-74df0bccdaa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91b7afce-ef91-4e40-9ebd-7ffe0450b44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc34ba83-c7b0-4763-a6ff-5c9fba37f30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee9edce-0e21-4e31-89a0-6f442b007bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e4995a-26f2-41a6-8e39-37f02ad3ba76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a23da6c-3505-49bb-9955-febba8e56b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6139c3e-41b9-47aa-a6c2-b55867ca0c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ee8ae6-6670-43f0-89ae-64a771546ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b59cd0d8-c856-4b53-a082-20da88fe3cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5732735b-0ea6-46bf-88e3-915ad2400fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2761cc3-0849-4d19-b2b4-49f604ca80b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90639494-4c08-4fc4-8a1f-b9c1fb0c3a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c57d47b-1a60-4fe2-b332-b70fa8bf6ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b8f9f8-6acc-4dab-a3d5-b326554c04e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2297a76-d355-4728-9f14-24733ea21eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68fd9e2f-07ff-4ac2-9868-a6ce22ab4428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c93744d-b917-40f6-b6f4-54e0bf52c5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34e6d25-cdbd-413d-9390-acff1efce413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24fe263d-3a83-4606-980e-364605848a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2990770f-02ef-4ddc-a06d-0e435a1edc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80103fb9-9323-4be9-8d56-3a9f99e19e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc987369-f910-44ef-ae40-ce91de3a3eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e96d71c-de4e-4071-90be-bda6c9b95ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50fdb3b7-6f58-4e23-a448-7a9cf95be8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712b7101-e009-4cdb-b853-eb374d70abae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7632fb-6ec1-4444-984e-d55622053014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b828e86-55d7-4cda-9455-e4b234c816b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e8bb3a-8d28-4f18-b138-95c0d6deab84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31099449-26a8-4ed3-aec2-e1cdb93f1230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 144dda63-3dd4-4003-8637-89a3a0c89c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0af29727-be57-493b-bd5d-44e93850970c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8c02d82-9795-4df0-b88e-29f872444ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d46b1cd-c8ac-42e6-a7c7-b378c7f5777f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c0a3fd2-0eb5-4863-b273-fd4dc838c4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2da8dc2-d98b-4c47-8517-0b42dbca0369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ca076b-a02b-42a1-a34f-901df8c6ff34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53415ff0-6568-4522-b379-143538c57cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb84a91a-be29-48e8-a05c-46e61f94ce47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35cd87aa-2e56-46a4-9ca1-3a7f23b42384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07aaf32d-b317-43ec-9482-cb47296812cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e6144a-3a01-4cc9-87c8-109a77ebae7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c7ac242-8a72-47f1-9870-1f45f8349292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23686eb7-34f5-4650-83b9-00b5f3309173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d1dae2a-fa8a-48a9-949d-de4c2477aa75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbbd827c-7d69-4e8a-9b30-499af85ba0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89bf89a-f65b-447a-ad9e-8c7a4308b25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe45113-5fba-44e1-b307-f1196b963d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94eb879c-93a4-42df-ae2e-a70a1d241d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba6cee90-8a54-4966-b744-9a7722ace68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c23b75-7bb5-45ae-b688-3a76a4d492d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e6b0354-5b2a-4a71-a6ff-f778ff354d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ce17edd-69ec-4502-addc-38256febc5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c20e3333-1906-412a-9470-ca7c4fd98054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71737db5-b78b-42cd-ab2d-269e04b2c324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f2ee86-8850-48bc-a4b3-72a02ecb044b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af49fa5-773e-42ef-90f3-2ac9b2738d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823f068a-0758-4577-b068-44f8e6bd6012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f4139b-7cf6-4876-8843-a3cf6da108ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f79c0005-83e6-4be5-bf18-2a810724cd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f72e0f0-9df9-4c92-b6f8-605512c62ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea091cc6-e2ea-4402-9891-1ad9cdadcdc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 163e2fbb-5cd7-48b7-861b-089cb8e487fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecf64a3d-92b6-4c52-81ad-2d0def87a5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95830b2a-6b85-4ec7-acf9-e11293aafa85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d852bcfe-466e-446b-9c3e-ca77df603b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f41b404e-0556-4505-af17-dc25789aa1f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78925773-24e2-4305-abb5-17b3a2cdca63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaab92b0-93fe-4816-aa1e-f97f5c6ea586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 378cf40a-5544-4844-9088-b9491d563b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6dceeb-19e7-418f-ac76-3f82f49f884b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f7feb5-3403-44dc-a345-600577a59b20
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_1
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_1/test_labels.txt

📊 Raw data loaded:
   Train: X=(1650, 24), y=(1650,)
   Test:  X=(413, 24), y=(413,)

⚠️  Limiting training data: 1650 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  404 samples, 5 features
✅ Client client_1 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1309, RMSE: 0.3618, MAE: 0.2957, R²: -0.5816

📊 Round 0 Test Metrics:
   Loss: 0.0932, RMSE: 0.3053, MAE: 0.2612, R²: -0.1261

============================================================
🔄 Round 5 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0831 (↓), lr=0.001000
   • Epoch   2/100: train=0.0852, val=0.0834, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0833, val=0.0830, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0835, val=0.0833, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0834, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0799, val=0.0840, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 5 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0070
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0059
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1142, RMSE: 0.3379, MAE: 0.2815, R²: -0.3799

============================================================
🔄 Round 6 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0985, val=0.0729 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0884, val=0.0707 (↓), lr=0.000500
   • Epoch   3/100: train=0.0867, val=0.0703, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0866, val=0.0703, patience=2/15, lr=0.000500
   ✓ Epoch   5/100: train=0.0864, val=0.0701 (↓), lr=0.000500
   • Epoch  11/100: train=0.0858, val=0.0694, patience=1/15, lr=0.000500
   ✓ Epoch  21/100: train=0.0841, val=0.0684 (↓), lr=0.000500
   • Epoch  31/100: train=0.0800, val=0.0670, patience=1/15, lr=0.000500
   • Epoch  41/100: train=0.0735, val=0.0657, patience=5/15, lr=0.000500
   📉 Epoch 44: LR reduced 0.000500 → 0.000250
   • Epoch  51/100: train=0.0663, val=0.0685, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0657)

============================================================
📊 Round 6 Summary - Client client_1
   Epochs: 51/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.1318
   Val:   Loss=0.0657, RMSE=0.2562, R²=0.0714
============================================================


============================================================
🔄 Round 8 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000250 → 0.000125
   ✓ Epoch   1/100: train=0.0844, val=0.0802 (↓), lr=0.000125
   • Epoch   2/100: train=0.0838, val=0.0803, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0837, val=0.0803, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0836, val=0.0803, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0835, val=0.0802, patience=4/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0832, val=0.0801, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 8 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0035
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0096
============================================================


============================================================
🔄 Round 10 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0860, val=0.0826 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0845, val=0.0818 (↓), lr=0.000031
   • Epoch   3/100: train=0.0839, val=0.0813, patience=1/15, lr=0.000031
   ✓ Epoch   4/100: train=0.0835, val=0.0810 (↓), lr=0.000031
   • Epoch   5/100: train=0.0833, val=0.0809, patience=1/15, lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0829, val=0.0806, patience=7/15, lr=0.000016
   📉 Epoch 17: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 10 Summary - Client client_1
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0140
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0003
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2506, R²: -0.0022

📊 Round 10 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2539, R²: -0.0371

📊 Round 10 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2513, R²: -0.0109

============================================================
🔄 Round 14 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0837 (↓), lr=0.000008
   • Epoch   2/100: train=0.0821, val=0.0836, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0820, val=0.0835, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0819, val=0.0835, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0819, val=0.0834, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0816, val=0.0833, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 14 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0135
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0270
============================================================


============================================================
🔄 Round 15 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0830 (↓), lr=0.000002
   • Epoch   2/100: train=0.0818, val=0.0830, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0818, val=0.0830, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0817, val=0.0830, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0817, val=0.0830, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0817, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 15 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0197
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0237
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2504, R²: -0.0034

============================================================
🔄 Round 16 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 16 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0077
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0495
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2506, R²: -0.0051

============================================================
🔄 Round 17 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 17 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0111
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0462
============================================================


============================================================
🔄 Round 20 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 20 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0005
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0098
============================================================


============================================================
🔄 Round 21 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 21 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0095
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0043
============================================================


============================================================
🔄 Round 22 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 22 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0166
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0254
============================================================


============================================================
🔄 Round 24 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 24 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0159
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0143
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2525, R²: -0.0152

============================================================
🔄 Round 26 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 26 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0072
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0041
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2532, R²: -0.0211

📊 Round 26 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2531, R²: -0.0210

============================================================
🔄 Round 28 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 28 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0031
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0014
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2529, R²: -0.0193

============================================================
🔄 Round 31 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 31 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0046
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0084
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2528, R²: -0.0184

============================================================
🔄 Round 33 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 33 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0005
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0249
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2528, R²: -0.0179

============================================================
🔄 Round 34 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 34 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0107
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0235
============================================================


============================================================
🔄 Round 36 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 36 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0111
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0199
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2527, R²: -0.0174

============================================================
🔄 Round 37 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 37 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0058
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0086
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2527, R²: -0.0172

============================================================
🔄 Round 40 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 40 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0070
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.0053
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2526, R²: -0.0169

============================================================
🔄 Round 43 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 43 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0134
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0179
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2526, R²: -0.0168

============================================================
🔄 Round 46 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 46 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0026
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0186
============================================================


============================================================
🔄 Round 49 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 49 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0033
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0206
============================================================


============================================================
🔄 Round 51 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 51 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0062
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0114
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2526, R²: -0.0165

============================================================
🔄 Round 52 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 52 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0060
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0101
============================================================


============================================================
🔄 Round 53 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 53 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0084
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0014
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2526, R²: -0.0164

📊 Round 53 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2526, R²: -0.0163

============================================================
🔄 Round 55 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 55 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0053
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0139
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2526, R²: -0.0163

============================================================
🔄 Round 56 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 56 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0063
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0033
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2526, R²: -0.0162

============================================================
🔄 Round 59 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 59 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0051
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0153
============================================================


============================================================
🔄 Round 60 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 60 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0113
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0112
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2525, R²: -0.0161

============================================================
🔄 Round 61 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 61 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0144
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0272
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2525, R²: -0.0161

📊 Round 61 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2525, R²: -0.0160

📊 Round 61 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2525, R²: -0.0159

📊 Round 61 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2525, R²: -0.0158

📊 Round 61 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2525, R²: -0.0157

============================================================
🔄 Round 73 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 73 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0021
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0162
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2525, R²: -0.0155

============================================================
🔄 Round 76 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 76 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0147
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0188
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2525, R²: -0.0154

📊 Round 76 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2525, R²: -0.0153

============================================================
🔄 Round 82 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 82 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0118
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0102
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2525, R²: -0.0153

============================================================
🔄 Round 84 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 84 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0053
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0013
============================================================


============================================================
🔄 Round 87 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 87 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0086
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0052
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2524, R²: -0.0151

📊 Round 87 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2524, R²: -0.0150

============================================================
🔄 Round 91 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 91 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0072
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0050
============================================================


============================================================
🔄 Round 92 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 92 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0056
   Val:   Loss=0.0682, RMSE=0.2611, R²=0.0114
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2524, R²: -0.0148

============================================================
🔄 Round 95 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 95 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0112
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.0020
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2524, R²: -0.0147

============================================================
🔄 Round 97 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 97 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0087
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0017
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2524, R²: -0.0146

============================================================
🔄 Round 98 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 98 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0087
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0064
============================================================


============================================================
🔄 Round 99 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 99 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0038
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0031
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2524, R²: -0.0146

============================================================
🔄 Round 102 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 102 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0092
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0192
============================================================


============================================================
🔄 Round 103 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 103 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0142
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0175
============================================================


============================================================
🔄 Round 105 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 105 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0091
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0024
============================================================


============================================================
🔄 Round 109 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 109 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0089
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0056
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0143

============================================================
🔄 Round 111 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 111 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0111
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0081
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0143

============================================================
🔄 Round 113 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 113 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0139
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0150
============================================================


============================================================
🔄 Round 115 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 115 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0090
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0054
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0143

============================================================
🔄 Round 117 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 117 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0098
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0182
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0143

============================================================
🔄 Round 119 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 119 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0095
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0038
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0144

============================================================
🔄 Round 121 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 121 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0014
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0340
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0144

============================================================
🔄 Round 122 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 122 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0074
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0033
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2524, R²: -0.0144

============================================================
🔄 Round 123 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 123 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0041
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0250
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2524, R²: -0.0144

============================================================
🔄 Round 124 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 124 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0061
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0168
============================================================


============================================================
🔄 Round 125 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 125 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0074
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0102
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0144

📊 Round 125 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0143

📊 Round 125 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0142

📊 Round 125 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0142

📊 Round 125 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0142

============================================================
🔄 Round 134 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 134 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0090
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0023
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0142

📊 Round 134 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0142

============================================================
🔄 Round 139 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 139 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0064
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0152
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0142

============================================================
🔄 Round 141 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 141 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0066
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0159
============================================================


============================================================
🔄 Round 142 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 142 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0057
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0173
============================================================


============================================================
🔄 Round 144 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 144 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0020
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0318
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0140

============================================================
🔄 Round 146 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 146 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0100
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0027
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2523, R²: -0.0139

📊 Round 146 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0138

📊 Round 146 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0138

📊 Round 146 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0138

📊 Round 146 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0138

============================================================
🔄 Round 154 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 154 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0120
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0075
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0138

📊 Round 154 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2523, R²: -0.0137

============================================================
🔄 Round 156 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 156 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0113
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0205
============================================================


============================================================
🔄 Round 157 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 157 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0050
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0221
============================================================


============================================================
🔄 Round 159 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 159 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0081
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0066
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2522, R²: -0.0137

📊 Round 159 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2522, R²: -0.0136

============================================================
🔄 Round 162 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 162 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0105
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0027
============================================================


============================================================
🔄 Round 163 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 163 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0047
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0241
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2522, R²: -0.0136

============================================================
🔄 Round 165 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 165 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0034
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0263
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2522, R²: -0.0136

📊 Round 165 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2522, R²: -0.0135

📊 Round 165 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2522, R²: -0.0135

📊 Round 165 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2522, R²: -0.0135

📊 Round 165 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2522, R²: -0.0134

============================================================
🔄 Round 170 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 170 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0094
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0051
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2522, R²: -0.0133

📊 Round 170 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2522, R²: -0.0132

============================================================
🔄 Round 176 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 176 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0079
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0083
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2522, R²: -0.0131

============================================================
🔄 Round 177 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 177 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0138
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0091
============================================================


============================================================
🔄 Round 178 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 178 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0076
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0131
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2522, R²: -0.0131

============================================================
🔄 Round 180 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 180 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0107
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0022
============================================================


============================================================
🔄 Round 182 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 182 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0064
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0053
============================================================


============================================================
🔄 Round 183 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 183 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0112
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0003
============================================================


============================================================
🔄 Round 184 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 184 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0134
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0075
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0129

============================================================
🔄 Round 186 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 186 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0062
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0204
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0128

📊 Round 186 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0128

📊 Round 186 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0128

📊 Round 186 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0127

============================================================
🔄 Round 191 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 191 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0073
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0060
============================================================


============================================================
🔄 Round 192 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 192 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0050
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0222
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

============================================================
🔄 Round 194 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 194 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0038
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0230
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

============================================================
🔄 Round 195 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 195 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0053
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0244
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

📊 Round 195 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0125

📊 Round 195 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0125

📊 Round 195 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

============================================================
🔄 Round 201 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 201 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0070
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0106
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

📊 Round 201 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

📊 Round 201 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

============================================================
🔄 Round 205 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 205 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0068
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0050
============================================================


============================================================
🔄 Round 206 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 206 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0082
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0299
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

============================================================
🔄 Round 207 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 207 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0102
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0048
============================================================


============================================================
🔄 Round 208 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 208 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0108
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0031
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2521, R²: -0.0126

❌ Client client_1 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
