[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2704de66-4a94-4894-8fb5-d061dc0cf73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c54e88b-5a1e-4a60-93fc-37f515050e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126e8bad-339a-4bfc-b32b-c8ebea7fa98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f9ba81-cbfb-4f91-8a85-60963ac64d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b5c703a-7e64-4574-8b1f-73cc3835e045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 353b1336-48c6-4a59-b104-a6e1b1d2d2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f175aa-bc00-40a4-b44e-b1d098c40ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7dafe5-343e-4809-9c9b-eec1abef3aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8687b56-a3b8-42d4-aca5-0f3a3bd7d33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 708acd7b-5e31-41bf-a35a-1a2f95669c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eef59ca-108b-4796-a8d4-a62bf6ffab64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c4b86e-6993-46c3-b34a-bd6cfebf6512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e0e8bb-34ec-4b13-8692-c225f803e080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eb8ea5d-06ca-4622-9e36-773eecee1701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 710236d4-468f-44a3-a4dd-ffe9e423602f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ca965b-3173-4549-946a-e037dbc226ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a79fcd-bda7-43b5-8fb1-bfc85a27011c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb6e8e04-0b32-4840-98ed-bec41b107895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f18aa51-4373-4f51-9f64-3e962c58e5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64482d56-f6be-459a-b971-85e5cd167189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16d9c16-fa4a-4deb-af69-1e01dbeeb9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f668c2b4-c8fc-4613-bec6-5776e2350193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01afb544-edb5-48ad-81ba-a3fe49c8d7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b98c7b-4c9e-4f6f-82a7-6adbf2e2f36b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dac9cd6-37c1-49e8-8e9f-faa8428c3862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d477a196-08c8-48ff-8c37-6972efeabde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e6be472-cce6-48f5-9d07-360202730000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13736a48-8764-435d-b53b-877e49b9122c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5090e2b-9a7a-4df2-aed6-a7d00284f46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2e4d2a4-7f0e-42c3-a84f-1fec53bc853c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3aa052e-63bf-4dab-9e45-65d8c922fa7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab2edd9e-f325-402b-94e8-2b3cf85055dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17f67d17-75dd-4bf5-8240-ee0353483b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e187ce1-29e1-458d-80e8-15720849a564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a37da5b-19fa-4e65-a6a9-3661be77ce3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8c7195-0281-4875-afd0-5a06dcbdb0a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127a6186-05f8-41f3-ac72-13dda3bfe0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be8a50e-0d49-47fe-a06d-f49bfd167851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6bc3d7-caa7-44de-979e-fe373a90499e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 453f429d-0458-452f-aed9-e76873cefa7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 782c915a-d765-4692-957e-dff693b2c60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2265c321-40a6-4377-8c0d-6d589a885fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0b57401-6f5f-4eda-8247-b2246fd4e5af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f1129e8-aa02-4db2-b626-81edba78747d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361ff956-6159-4f6f-b358-6ccb7388b482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e784ec11-680f-4dcb-8412-9c4a129d4671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb8ceab-ad8e-4cf2-b522-0b6ce8ed884c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 210f8ad7-26ad-4262-8db7-df38cffdc476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfca013e-dafa-48e9-9dcb-d4ee58d7f737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58044269-6c24-4f2c-a610-da4804a83f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce10bd49-6b5a-49c4-8b76-d92b1c524617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c5305cc-08d8-408b-a6a4-9802ecea6078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78515db1-12d8-4e42-bf00-ca3f52685f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f211c7-1252-4f18-869b-8d9a47b850e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c9a294-0238-437c-8253-1d170c51c1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65e4599-c941-4fd0-b489-fde93aba4a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450ee26a-97a1-432d-bf23-50e8d3478278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a06ccc78-9629-4ce8-8946-ab8c04155969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d64ba75b-4438-40b3-bc67-4055f07e84c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ad50d4-3af6-4685-870d-17215d1b2a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d72e1c07-067e-4c65-bac4-9dadd6347db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message becdc312-f6c9-4a68-a4fd-0df3e3dc1fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6340b4c-deae-407b-9425-cdddb33bd896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c713965-4c56-4eb8-9abf-c22124d94d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d2d547-b347-43c0-b967-fd67a4eb9562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc944026-2866-4c09-9786-1a98db715b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f7120d7-e06d-4e9e-9a05-40a04d9b541c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58006187-2437-4e1e-b306-be7f0f8085b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 264155b8-2ac2-4bbf-9e42-0d1efe77fbaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733c96dc-d715-439d-a0bc-309d21502648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137ec236-c295-4ea1-b239-f04a6969e0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c8cd5aa-9fff-4e96-8cbb-8c28061d05a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c408cc9-50c8-4b0c-9c15-5594645e8dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f58e24-e7cd-40e7-b479-c2be1ed169a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf1cc63-43b5-40a9-84f5-340fddecb33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee044c4e-e748-497c-9f33-98f720a3bec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00527abe-b952-42e3-8013-bda960125273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ec2c43-c847-494f-837d-a143c790920d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ffd176e-7e10-457a-981c-5dba8b13e2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4405d5d2-efea-4105-b9c7-c39fb852aa90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ddaf1e-78f3-42e7-a13d-04f540e1f08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d08a196-90da-40bc-bc2e-017cb65dffb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b86e36-860d-469d-b5dc-e93eed861e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f24f96-f709-4dd6-ae2d-b9c169388b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5045aec3-155a-45a7-942b-f6a2130dee4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a72fa0-b528-4ea0-8708-253bdf2ec8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177f3825-1f46-4d37-b5c0-fa939e851a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e13f79d0-95f9-43d2-8351-9777f695036f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a967e1b3-e565-4e0e-8d46-01a632f620e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39cc1418-8884-4fca-9b30-f85184e4767a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df7901aa-026b-4677-83ae-acf070e785c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040364d4-df15-4047-9fe5-2c898ff7cf6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 283a3e9e-8775-424c-a310-26481def107b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5938219-7329-481e-8404-3a0a1e011d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0ba9fe-8fba-439d-8a8b-9d78ed3723d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6bdeb1-5efb-421d-a625-576d7e4b3094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585502e9-8f1b-47da-a583-a9fcea8b26bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55142da7-27c5-4924-9fca-4611f9205c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d574fe0f-0eca-498a-8158-462ac48d1a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 865ca063-a1ca-49df-8c11-2eca068b9f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4cd762-182c-4663-841b-4f874cd716fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 280d6e0a-fb9b-40e6-8fb8-92a85a3ea707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15cccbdb-fa53-464e-9982-804f33edc9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed4f93a-9e25-4d52-885a-492e7b4f7814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18480fed-f37c-467c-b9cd-1410df899e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05b0934-a070-4c7d-ad1f-a4526ae93645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeea9fb3-3e10-4261-ab0a-b4099f3a5137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d01d77a4-16ad-4f44-8a34-f52f6e831756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1322652e-d420-4d3d-b26f-85d4f290c4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f747c949-332f-49ee-ac24-711764b2bdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a87e85e-e8a0-49fb-9781-ad227b90317d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4e3d34-e5a5-4666-9d96-e267125b5237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2490b61a-b8ec-4bbc-b799-8dc9b31ae48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c546280-d5e1-403c-a480-f51c5df32ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f6e2de-9515-49b7-a0fb-4e4cf80ab255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192bc33f-0d31-4cb6-b4de-3c85479065a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42376b89-559b-47d8-bffb-7e2f50679ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a77b6cb5-afd5-4cbd-8ba2-90b1bbcb5afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417b3b94-6d40-4545-a607-6d3b65244138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb3ae815-882d-462e-a557-fb90c435c775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb76004d-95ee-4cc2-a7e5-08a0d691c590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a89b9714-e9a7-4fe8-9a78-a043d2aeea68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3668ed40-767c-4347-aa41-0f961024da7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 770fc2ae-82cb-4467-9dac-70720cf060ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d509824-2409-41ee-ae0e-574d737697d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee479e7-4ad8-4c17-a697-358613d94b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54cbc17c-e695-47ca-9133-a39d29fa655e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d8efd4-991b-45e8-ade0-f6b7193cb1b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bcbe489-f9a0-43d0-906f-c259b80db989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99cbcb5a-bf73-4dae-83f1-3be274ddec71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468ef2b3-41cf-4f81-9a7b-3d254089f5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec094058-b665-4568-a781-7099b459d654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c79d74-8731-4b92-a138-b253a164ba6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b5dcb5-b6aa-4cc2-bc83-3e53298e4f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2724064a-3f27-4def-a1d5-de57b30b3c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abda275b-609a-4857-824e-68f30e1f10e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a62fb0-743d-499e-884f-e30e942e868c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2243440f-3d19-4d56-a99a-9802a2e469df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a41481-d24d-4e02-b549-d3d80f657c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db28a6c8-32b9-4ef4-931a-e3d221e1230a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb7466c8-732c-4e66-bef2-7fb18af44c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486b288c-aeda-44fb-ab70-b2f66b1ec31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8f2333-2747-4ada-895c-7882d35137fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf104aad-ccd3-4395-9250-4ec512c1683d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c41089ea-bee8-4eeb-9129-c6a861262588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b98fb1ab-ce5c-4837-a8a7-0c20e74e0c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6d9293-1263-408f-a1f4-8ac44ccf6ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db3c2fa0-17c2-412c-a2cc-5c9de8e87c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0392d77-2e93-41e5-b210-ca90ffb08ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e81deca-646f-47c0-84b0-c64b504ed006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e49d39-5b73-46b0-be1d-b80202b8a1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26152a04-15d0-4fee-ad5e-a4472be49d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3167f5-baca-4883-a255-7f0fe987c2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffe8309b-82bd-4548-a69c-a70885c20e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fa1cd10-b437-4d53-8664-e2df18be6bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 373ecb23-f403-4ca1-98e2-09e2fa4bc1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 795ca281-3ac1-469d-bc67-50475155778c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997ba343-5990-467f-9f4b-7158a1ecd599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36eeff1-0a02-4cd2-955f-131be7cfd1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3e4ab5-42cc-42b5-b78c-93bc14da4221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8b3a53-1a10-4795-933d-a2ff2912d751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2520824b-aa1c-437f-a184-3093bb98cf63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c890c72-4f2b-449f-8ab0-ac5b0bc5e096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46b22c37-0db5-4ba9-9956-0ba88d02dab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe3e1ce2-81ec-4eae-97f4-659d24319f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea05e9b-fbad-47e7-a8aa-6d69ed165d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a91cd0-8fa3-490c-9810-5d789a39f59b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(2028, 24), y=(2028,)
   Test:  X=(508, 24), y=(508,)

⚠️  Limiting training data: 2028 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  499 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1364, RMSE: 0.3694, MAE: 0.3049, R²: -0.5989

============================================================
🔄 Round 6 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0898 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0836, val=0.0873 (↓), lr=0.001000
   • Epoch   3/100: train=0.0827, val=0.0877, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0826, val=0.0878, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0825, val=0.0880, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0809, val=0.0897, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 6 Summary - Client client_20
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0010
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0063
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2593, R²: -0.0228

📊 Round 6 Test Metrics:
   Loss: 0.0943, RMSE: 0.3070, MAE: 0.2660, R²: -0.1046

📊 Round 6 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2603, R²: -0.0300

============================================================
🔄 Round 11 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0826 (↓), lr=0.000250
   • Epoch   2/100: train=0.0856, val=0.0825, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0853, val=0.0827, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0851, val=0.0828, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0849, val=0.0830, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0842, val=0.0833, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 11 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0083
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0335
============================================================


============================================================
🔄 Round 13 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0907 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0863, val=0.0898 (↓), lr=0.000063
   • Epoch   3/100: train=0.0852, val=0.0896, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0848, val=0.0896, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0845, val=0.0896, patience=3/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0839, val=0.0900, patience=9/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 13 Summary - Client client_20
   Epochs: 17/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0244
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0454
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2621, R²: -0.0529

============================================================
🔄 Round 14 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0776 (↓), lr=0.000016
   • Epoch   2/100: train=0.0902, val=0.0773, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0899, val=0.0771, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0896, val=0.0770 (↓), lr=0.000016
   • Epoch   5/100: train=0.0894, val=0.0768, patience=1/15, lr=0.000016
   • Epoch  11/100: train=0.0887, val=0.0765, patience=7/15, lr=0.000016
   • Epoch  21/100: train=0.0881, val=0.0764, patience=8/15, lr=0.000016
   📉 Epoch 22: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 14 Summary - Client client_20
   Epochs: 28/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0371
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0012
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2653, R²: -0.0784

============================================================
🔄 Round 22 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0894 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0888, val=0.0894, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0887, val=0.0893, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0886, val=0.0893, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0885, val=0.0893, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0880, val=0.0892, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 22 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0688
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0472
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0929, RMSE: 0.3048, MAE: 0.2656, R²: -0.0885

============================================================
🔄 Round 23 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0946 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0878, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 23 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0627
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0727
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0926, RMSE: 0.3044, MAE: 0.2655, R²: -0.0858

📊 Round 23 Test Metrics:
   Loss: 0.0918, RMSE: 0.3030, MAE: 0.2649, R²: -0.0762

============================================================
🔄 Round 25 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 25 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0723
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0130
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2639, R²: -0.0613

============================================================
🔄 Round 27 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 27 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0518
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0549
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0893, RMSE: 0.2988, MAE: 0.2627, R²: -0.0463

📊 Round 27 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2626, R²: -0.0448

============================================================
🔄 Round 33 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 33 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0370
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0556
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0888, RMSE: 0.2981, MAE: 0.2622, R²: -0.0411

📊 Round 33 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2621, R²: -0.0407

============================================================
🔄 Round 37 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 37 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0438
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0204
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2621, R²: -0.0402

============================================================
🔄 Round 39 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 39 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0356
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0412
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2621, R²: -0.0402

📊 Round 39 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2621, R²: -0.0401

📊 Round 39 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2621, R²: -0.0402

============================================================
🔄 Round 43 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 43 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0431
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0110
============================================================


============================================================
🔄 Round 44 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 44 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0402
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0459
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2621, R²: -0.0401

📊 Round 44 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2621, R²: -0.0401

📊 Round 44 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2621, R²: -0.0402

📊 Round 44 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2621, R²: -0.0403

============================================================
🔄 Round 49 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 49 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0384
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0322
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2621, R²: -0.0401

📊 Round 49 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2621, R²: -0.0404

============================================================
🔄 Round 58 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 58 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0375
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0309
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2621, R²: -0.0405

📊 Round 58 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2621, R²: -0.0405

============================================================
🔄 Round 61 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 61 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0406
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0451
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2620, R²: -0.0397

============================================================
🔄 Round 63 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 63 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0352
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0483
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2619, R²: -0.0384

============================================================
🔄 Round 67 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 67 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0339
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0407
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2619, R²: -0.0385

📊 Round 67 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2619, R²: -0.0386

============================================================
🔄 Round 70 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 70 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0427
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0098
============================================================


============================================================
🔄 Round 71 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 71 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0297
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0645
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2620, R²: -0.0390

============================================================
🔄 Round 72 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 72 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0293
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0675
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2620, R²: -0.0391

============================================================
🔄 Round 74 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 74 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0321
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0483
============================================================


============================================================
🔄 Round 76 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 76 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0397
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0195
============================================================


============================================================
🔄 Round 77 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 77 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0321
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0970
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2619, R²: -0.0388

============================================================
🔄 Round 78 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 78 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0301
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0562
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2619, R²: -0.0386

============================================================
🔄 Round 79 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 79 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0422
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0401
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2619, R²: -0.0384

============================================================
🔄 Round 81 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 81 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0285
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0635
============================================================


============================================================
🔄 Round 82 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 82 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0349
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0321
============================================================


============================================================
🔄 Round 83 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 83 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0311
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0659
============================================================


============================================================
🔄 Round 85 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 85 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0381
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0218
============================================================


============================================================
🔄 Round 86 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 86 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0333
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0473
============================================================


============================================================
🔄 Round 89 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 89 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0402
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0464
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2618, R²: -0.0375

============================================================
🔄 Round 91 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 91 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0309
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0517
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0885, RMSE: 0.2976, MAE: 0.2618, R²: -0.0377

📊 Round 91 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2618, R²: -0.0379

============================================================
🔄 Round 93 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 93 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0387
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0189
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0886, RMSE: 0.2976, MAE: 0.2618, R²: -0.0380

============================================================
🔄 Round 96 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 96 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0334
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0415
============================================================


============================================================
🔄 Round 97 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 97 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0363
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0324
============================================================


============================================================
🔄 Round 99 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 99 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0312
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0493
============================================================


============================================================
🔄 Round 100 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 100 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0322
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0434
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2617, R²: -0.0372

============================================================
🔄 Round 102 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 102 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3021, R²=-0.0362
   Val:   Loss=0.0680, RMSE=0.2609, R²=-0.0227
============================================================


============================================================
🔄 Round 104 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 104 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0360
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0439
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2617, R²: -0.0370

📊 Round 104 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2617, R²: -0.0370

============================================================
🔄 Round 106 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 106 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0305
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0608
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2617, R²: -0.0372

============================================================
🔄 Round 109 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 109 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0348
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0313
============================================================


============================================================
🔄 Round 110 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 110 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0348
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0331
============================================================


============================================================
🔄 Round 111 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 111 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0221
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0860
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2617, R²: -0.0369

📊 Round 111 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2617, R²: -0.0367

📊 Round 111 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2616, R²: -0.0363

📊 Round 111 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2616, R²: -0.0360

============================================================
🔄 Round 119 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 119 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0353
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0284
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2616, R²: -0.0357

============================================================
🔄 Round 120 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 120 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0333
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0464
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0884, RMSE: 0.2972, MAE: 0.2615, R²: -0.0355

📊 Round 120 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2615, R²: -0.0352

============================================================
🔄 Round 123 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 123 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0269
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0620
============================================================


============================================================
🔄 Round 124 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 124 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0382
   Val:   Loss=0.0757, RMSE=0.2750, R²=-0.0170
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2614, R²: -0.0344

============================================================
🔄 Round 130 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 130 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0413
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0006
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2614, R²: -0.0345

============================================================
🔄 Round 132 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 132 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0246
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0742
============================================================


============================================================
🔄 Round 134 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 134 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0307
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0436
============================================================


============================================================
🔄 Round 135 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 135 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0302
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0439
============================================================


============================================================
🔄 Round 136 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 136 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0272
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0550
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2612, R²: -0.0332

📊 Round 136 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2612, R²: -0.0330

📊 Round 136 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2612, R²: -0.0329

📊 Round 136 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2611, R²: -0.0325

📊 Round 136 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2611, R²: -0.0324

============================================================
🔄 Round 142 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 142 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0418
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0036
============================================================


============================================================
🔄 Round 143 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 143 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0386
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0116
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2612, R²: -0.0326

============================================================
🔄 Round 147 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 147 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0371
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0125
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2612, R²: -0.0326

📊 Round 147 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2611, R²: -0.0323

📊 Round 147 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0318

📊 Round 147 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0316

============================================================
🔄 Round 152 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 152 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0293
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0382
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0316

📊 Round 152 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0316

============================================================
🔄 Round 154 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 154 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0237
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0604
============================================================


============================================================
🔄 Round 155 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 155 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0394
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0040
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0315

📊 Round 155 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2609, R²: -0.0308

============================================================
🔄 Round 161 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 161 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0338
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0153
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2609, R²: -0.0304

============================================================
🔄 Round 165 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 165 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0278
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0389
============================================================


============================================================
🔄 Round 166 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 166 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0334
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0139
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2608, R²: -0.0302

============================================================
🔄 Round 168 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 168 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0296
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0313
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2609, R²: -0.0304

============================================================
🔄 Round 170 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 170 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0294
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0336
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2609, R²: -0.0305

============================================================
🔄 Round 171 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 171 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0332
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0182
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2609, R²: -0.0307

============================================================
🔄 Round 173 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 173 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0368
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0015
============================================================


============================================================
🔄 Round 176 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 176 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0277
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0503
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2609, R²: -0.0309

============================================================
🔄 Round 178 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 178 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0357
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0477
============================================================


============================================================
🔄 Round 179 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 179 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0358
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0107
============================================================


============================================================
🔄 Round 180 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 180 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0307
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0287
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2610, R²: -0.0311

============================================================
🔄 Round 182 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 182 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0272
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0488
============================================================


============================================================
🔄 Round 183 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 183 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0357
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0121
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0315

📊 Round 183 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0314

============================================================
🔄 Round 187 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 187 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0326
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0265
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0314

📊 Round 187 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0314

============================================================
🔄 Round 190 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 190 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0308
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0297
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0315

📊 Round 190 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0317

============================================================
🔄 Round 196 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 196 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0308
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0292
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2610, R²: -0.0318

============================================================
🔄 Round 199 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 199 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0354
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0103
============================================================


============================================================
🔄 Round 200 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 200 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0356
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0107
============================================================


============================================================
🔄 Round 201 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 201 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0424
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0125
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2610, R²: -0.0312

📊 Round 201 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2610, R²: -0.0311

📊 Round 201 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2609, R²: -0.0310

============================================================
🔄 Round 206 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 206 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0382
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0062
============================================================


============================================================
🔄 Round 207 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 207 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0356
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0132
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2609, R²: -0.0306

============================================================
🔄 Round 208 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 208 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0321
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0217
============================================================


============================================================
🔄 Round 209 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 209 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0304
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0367
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2609, R²: -0.0304

❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
