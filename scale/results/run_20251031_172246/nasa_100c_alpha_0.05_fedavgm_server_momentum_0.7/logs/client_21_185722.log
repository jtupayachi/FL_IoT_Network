[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a81123-3860-4a9d-ae1b-19487767682e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71fe7fe9-755b-49d0-978e-97c6637ca739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e1a33b-6ea3-484c-b12f-28d40f9d4d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6369763-950d-4965-9e1f-c68bcaedfb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a59bf7-c82f-4262-9f18-9564affc4b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03bec3cf-9db0-411b-a8ea-a95c91014636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a47a09-28d3-40b1-abbf-3843ae844bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e7f685-a14b-4d07-8f13-1f0b382e2d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 133491de-eff7-44ab-b1e4-5d3eb316d2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a96fa74-43a3-4403-9c76-4b77a626ec62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b4bebf8-d27c-4e53-9d61-8ad0c825ce78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e6b57d8-a0db-4f18-b13d-d938ac7a9890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d3efab-96c8-496e-8179-02252680a8d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d67629-0e04-4052-8d43-1718fd311ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7bcf8c-d321-48b6-aebe-676182f8f2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a22f874-388e-43cb-a6a9-32b51c0a26ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c651c52f-8554-4316-9a1a-fb35f9df70fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2af8e1-fb5b-4fe4-a7af-0aeddbd95e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f915cf8f-2920-4caa-8280-84af79d05712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00809146-31c4-4a4b-b4e9-c647a08e1421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e31fec3-e1b7-429a-8189-8e44cad13232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fc7fb82-c67f-4f3a-95d5-b51206680d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2971f5ad-2533-4f94-91b0-aac423687e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aef90844-7be7-48c1-9400-e9680e3912fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2fb6e3b-cae2-433f-81e5-1adb25a29a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e305e5b-2278-48a9-9e58-e4fd45aeb612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9962fea-e533-40e7-bcf0-5c244b2d4b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a8a1b8-9dc1-474b-ac59-82f2cd892b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 753f14de-c062-4f47-84f3-eb813a49e359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56c0c1f2-578a-4168-ac84-d1505b0a473b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e5c6583-f5d9-46e4-aade-2a656d3dda41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b6a10b-6336-4e3e-8bea-aed90cd28343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26fcf1d0-7679-4df2-871f-16058966631a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 720da69c-37a6-4f60-849e-3b45382c3e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0305a98-7efb-441e-8bb4-259a30b51a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b423a0e-f0db-46eb-b611-31d457050ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb3855f-d22d-42af-b0d4-8cd2f56ffdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d49a9b-92ac-4e19-8853-1f3b65f33963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10cc122c-70d5-4dac-bfd1-3fdc070a94f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d59e23-d2f8-43b9-bc06-0778e68f2c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc280b9-07b5-43c7-81a3-7dcf0f74ff74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc66c9de-eeeb-453c-9bbc-4b73a5a61dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3344c0-762b-44de-bd5d-dbf1e9b20ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1d17d4-2e9c-4ae0-aa97-e77e93d28bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497493c5-40b9-4479-835a-b40b808fd56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd81e61a-937e-48c0-81e6-46439f7b727c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56c10f58-83fe-434a-be42-6859d31aa3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dab548d-3341-4cd9-bda1-f50cc42af9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0662dcdb-94b5-46c4-93e3-1839f1bf4656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d0d180d-c9dc-4ff4-8c71-cce8d149fb74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a328767-135c-4b47-a1ab-5e7b9738c035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c191875-de40-41b4-9499-2fc2fc605317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f759e17e-7d65-4e86-a16a-394619fc2feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f14ff4e-cf44-4bde-8607-de7ea12f3aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b16b03-6a70-480a-b6fd-b25a726f55fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cfaa259-62ca-463f-aa2c-b9024e9b9180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aeb62fe4-52ac-4abc-bfd0-682acf638a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ef63ae6-cf26-4188-b2c3-c0e065f53e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cf859ac-47dd-4a1f-af81-5027f3f80046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5118d2f-5302-4be0-99a1-f6f35792bee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9afd06c7-81b5-46d4-8d5d-13ce05e040ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2cc9587-2bc0-4b8b-a683-2c3da34626c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59080899-4cb8-4c13-a5f8-fcc591e2150f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6321e15a-ea26-4eb0-9ed2-2ef5fcced906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db42f53e-86bb-404b-87f4-cd48d195ebc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b6d0e97-7632-4907-84fd-8577aa2658e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe6140d-dbf0-40d1-9c26-de7586cf3c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd84eed6-578f-4718-b26e-243af7192bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 454756e4-4065-4c36-a5de-bff770c68771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 151fb408-311f-45a0-a9e6-0958845781db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be7ebdc-a49f-4292-899d-e1a697771a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba5afe40-cc1f-47aa-93dd-380ee43e356b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6826d950-03e7-481a-961e-e18d53e7b4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2585913b-d3fa-4218-a6a6-88110381ce0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5854aa86-9457-43ba-a352-beab7ba2f6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cba440f5-f9cc-41d8-ba4c-4530ab9f9a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd1c2e2-304a-495c-aef0-083e426f2e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de21f993-6105-46fa-a1be-21615c5e0afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6b088c-5b5c-4a3e-925e-24f2c836371c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7480d81f-1b6d-49cd-aeda-6c3c3a36a8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2ec9801-e639-4c34-b354-d32d2cfe5c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 920bef3b-835d-4b96-83b0-a461c40f00c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c10061-d591-4010-84ca-98341d465a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1de7d46-a610-47e4-aa22-b9f16fb4cb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a332f10f-f1df-4e64-bf9a-921d3e2b4a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e4c75b-ac40-461c-92bb-9cdd820be110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b6d01d-495b-446a-8de1-2a8cf64bd0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af2d84d-bca8-45cd-9b9c-afc48e82ad99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6af6cc2b-9737-405f-a65e-0e203b7f3757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f63d43f6-64de-4c1f-9bd2-3c0040635e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a4c183-4d07-47bf-85fe-89c41f94ac03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f0bacfa-9621-4b34-b078-1b654ac124d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a8a78d-d6a5-4a6d-88b7-cfe7d3772f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c524f6cd-5ef9-4984-8633-60a6f4f62934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39f8d07-a514-4d27-8f7a-8a411c418706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d85570b4-1f7b-4c50-9507-7547ad8d3d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9c62b7-903b-44ca-8640-c9f596363941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4602512c-6236-47fa-8bbb-9e21de816353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0148921f-1fa2-4540-acfc-e701b2406903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc1e95d4-9300-438f-a47d-6266891dc50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7761d5d-24c9-42b4-b5d9-8438c32b40af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f903bbc1-44d2-4682-813c-5aa5f8f3ad83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b66bba-e9c6-456c-ad88-bbdff3262e86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933946d6-1cb1-4290-82cd-60e10023cd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65d53c9c-770d-4ce2-85fe-35295a499d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fad9c7f-28bf-4ef8-83c1-385e4ce6ea61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ff1629-10c7-4fdd-9579-b5bbfbd8765e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633911a9-800d-4aa6-8c2e-645d53fdd100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad0a28ec-c40c-47fe-95cc-e71887b96457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae891c00-518d-4d8a-bde8-dbb3a77201cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09499f0d-7fb1-4df5-8851-7e0ca2e93c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54fc6f0-f404-4d64-948f-e1f5eb9ec4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28a1ad5-ca02-4fa8-89c7-584b2bffe803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c7666c-14b1-4835-9521-fc827c1c6c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66616295-4859-45b1-9e7c-3ddfe7934b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126d621e-294c-400c-8e29-dcb6499a7639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fdfdea5-b18c-4add-b8a0-a4d0824d5142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f090f32f-90a2-49f1-a797-8c864aeeab4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b42f2b3-6ce3-48bd-ae27-21441fc99587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e553238a-9925-46a6-9bb4-819534ba5e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406cd9a3-d4e5-4e65-a6c9-2c740bee1e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c0ddd9-75c5-48d3-84be-05a451569165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d86840c-f7fd-4eeb-a1e6-0e644097f884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1cbe903-6074-4398-8f8a-c5a068d55db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b3d065e-0549-4982-9dd1-ab826c5b68be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79bb04f6-2184-4cb2-b0b5-533f3ce9cb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68b5f62e-0583-4023-9d3d-f2b87c7c8ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e533d4-5829-493f-909d-a3908ebdca94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93b18529-6bf7-4497-9590-d7013edcb9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6bd5768-c939-4607-8f7e-7d43db439ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2038367-4277-4053-a6a8-dc4e6132e4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb69981-f6ff-4f39-9b7d-de3b4ab5ece0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090c37aa-86fa-40d8-946e-92cf2c383ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa1a129-8c12-4f01-8c65-bf2bad81e2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c96c547-ab29-49b8-a687-84d6f7a3bfd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75c190d0-dfd0-415f-899a-80cd13fa042c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 034d50c2-0a5e-441b-8505-f0d3e7c35239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43327ca8-5832-4e4d-a3e7-1abdf603e76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b887b5-d07e-49bb-b1bc-70e18c4269ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0c85644-ceb2-4ae5-add0-594d7a609cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a00112-07a3-49c8-8915-60482d88b553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8157f8-9a33-4013-9f20-47abea64c291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba4b386-4e3d-4536-b49a-3b005787e9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91ddad5c-d2ab-4ea4-a196-40a106244132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b945aa-eba8-4603-9c01-762bf3b79058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0231f8d-a700-47e1-a9ea-a09f06886d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a8bc42-d8db-4c0c-bbbf-00fe1b391b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c2db02-1361-4b9c-a5dd-042cb2a4941a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5edcce31-4084-4afc-a953-83cf4dcf7220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef860a0-74c5-4843-8fbd-bbf2a6217386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9ec5ba5-c6e6-4d24-9e61-f28d7a332bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b21a838-74f2-46ef-b867-046e93d573d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e32f2bfa-bf10-4014-ab48-6369733fedcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96850a12-f0bd-4462-bfc0-050314fad662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 043b9227-6746-4ee6-a2a3-983bfca9cbce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edffa005-be05-4731-893a-c69dd4296514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d973b7-d9cb-4036-bde5-a375a026c9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32120a38-059c-46a4-8860-d46abe2c049c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 758e3a66-2246-48ab-af92-0fc740898fcc
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(1494, 24), y=(1494,)
   Test:  X=(374, 24), y=(374,)

⚠️  Limiting training data: 1494 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  365 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2464, R²: -0.0036

📊 Round 0 Test Metrics:
   Loss: 0.3283, RMSE: 0.5730, MAE: 0.4968, R²: -3.0366

📊 Round 0 Test Metrics:
   Loss: 0.0948, RMSE: 0.3079, MAE: 0.2597, R²: -0.1656

============================================================
🔄 Round 5 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0847 (↓), lr=0.001000
   • Epoch   2/100: train=0.0839, val=0.0843, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0818, val=0.0845, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 5 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0034
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0138
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2465, R²: -0.0041

============================================================
🔄 Round 8 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0862 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0832, val=0.0857 (↓), lr=0.000250
   • Epoch   3/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0826, val=0.0868, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0820, val=0.0877, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 8 Summary - Client client_21
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0021
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0417
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2502, R²: -0.0574

📊 Round 8 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2478, R²: -0.0109

============================================================
🔄 Round 13 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0872 (↓), lr=0.000063
   • Epoch   2/100: train=0.0842, val=0.0868, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0838, val=0.0868, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0837, val=0.0868, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0836, val=0.0868, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0832, val=0.0868, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 13 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0202
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0250
============================================================


============================================================
🔄 Round 14 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0872 (↓), lr=0.000016
   • Epoch   2/100: train=0.0854, val=0.0871, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0852, val=0.0871, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0851, val=0.0871, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0850, val=0.0871, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0846, val=0.0871, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 14 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0274
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0248
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2498, R²: -0.0285

📊 Round 14 Test Metrics:
   Loss: 0.0844, RMSE: 0.2904, MAE: 0.2511, R²: -0.0371

============================================================
🔄 Round 20 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0921 (↓), lr=0.000004
   • Epoch   2/100: train=0.0859, val=0.0921, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0858, val=0.0920, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0857, val=0.0920, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0857, val=0.0919, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0855, val=0.0918, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 20 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0412
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0420
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2510, R²: -0.0264

📊 Round 20 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2509, R²: -0.0241

============================================================
🔄 Round 24 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 24 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0512
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0427
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2501, R²: -0.0226

============================================================
🔄 Round 27 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 27 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0325
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0728
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2498, R²: -0.0211

📊 Round 27 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2495, R²: -0.0195

📊 Round 27 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2491, R²: -0.0162

============================================================
🔄 Round 35 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 35 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0184
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0514
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2490, R²: -0.0155

============================================================
🔄 Round 37 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 37 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0318
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0001
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2490, R²: -0.0154

📊 Round 37 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2489, R²: -0.0152

📊 Round 37 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2489, R²: -0.0151

============================================================
🔄 Round 40 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 40 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0307
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0025
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2489, R²: -0.0150

============================================================
🔄 Round 42 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 42 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0258
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0179
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2489, R²: -0.0147

============================================================
🔄 Round 44 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 44 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0274
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0179
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2489, R²: -0.0146

============================================================
🔄 Round 47 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 47 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0185
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0516
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2488, R²: -0.0143

📊 Round 47 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2488, R²: -0.0142

============================================================
🔄 Round 50 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 50 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0221
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0317
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2488, R²: -0.0142

============================================================
🔄 Round 52 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 52 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0209
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0335
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2488, R²: -0.0140

📊 Round 52 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2488, R²: -0.0140

============================================================
🔄 Round 55 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 55 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0254
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0187
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2488, R²: -0.0138

============================================================
🔄 Round 57 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 57 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0239
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0258
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2488, R²: -0.0138

📊 Round 57 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2488, R²: -0.0137

============================================================
🔄 Round 59 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 59 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0264
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0220
============================================================


============================================================
🔄 Round 62 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 62 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0244
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0218
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2488, R²: -0.0136

============================================================
🔄 Round 64 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 64 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0194
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0450
============================================================


============================================================
🔄 Round 65 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 65 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0259
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0136
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2487, R²: -0.0134

============================================================
🔄 Round 68 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 68 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0226
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0295
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2487, R²: -0.0132

============================================================
🔄 Round 71 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 71 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2961, R²=-0.0227
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0420
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2487, R²: -0.0131

📊 Round 71 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2487, R²: -0.0131

📊 Round 71 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2487, R²: -0.0128

📊 Round 71 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2487, R²: -0.0128

📊 Round 71 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2487, R²: -0.0127

📊 Round 71 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2487, R²: -0.0127

📊 Round 71 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2487, R²: -0.0127

📊 Round 71 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2486, R²: -0.0127

============================================================
🔄 Round 85 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 85 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0235
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0215
============================================================


============================================================
🔄 Round 86 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 86 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0287
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0261
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2486, R²: -0.0126

============================================================
🔄 Round 87 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 87 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0240
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0172
============================================================


============================================================
🔄 Round 88 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 88 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0209
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0438
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2486, R²: -0.0125

============================================================
🔄 Round 89 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 89 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0269
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0110
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2486, R²: -0.0124

📊 Round 89 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2486, R²: -0.0124

============================================================
🔄 Round 92 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 92 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0230
   Val:   Loss=0.0945, RMSE=0.3073, R²=-0.0310
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0122

📊 Round 92 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0122

============================================================
🔄 Round 94 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 94 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0246
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0157
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0120

============================================================
🔄 Round 100 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 100 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0164
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0560
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0118

📊 Round 100 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0118

📊 Round 100 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0118

============================================================
🔄 Round 106 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 106 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0161
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0586
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0117

📊 Round 106 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0117

📊 Round 106 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0117

📊 Round 106 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0118

📊 Round 106 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0118

📊 Round 106 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0118

============================================================
🔄 Round 116 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 116 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0199
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0359
============================================================


============================================================
🔄 Round 117 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 117 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0218
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0381
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0118

============================================================
🔄 Round 118 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 118 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0252
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0193
============================================================


============================================================
🔄 Round 120 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 120 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0238
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0161
============================================================


============================================================
🔄 Round 121 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 121 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0244
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0220
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0120

============================================================
🔄 Round 125 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 125 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0228
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0218
============================================================


============================================================
🔄 Round 127 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 127 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0181
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0397
============================================================


============================================================
🔄 Round 128 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 128 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0276
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0374
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0119

📊 Round 128 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2486, R²: -0.0119

============================================================
🔄 Round 130 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 130 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0251
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0111
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2485, R²: -0.0118

📊 Round 130 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2485, R²: -0.0119

📊 Round 130 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2485, R²: -0.0119

📊 Round 130 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2485, R²: -0.0119

============================================================
🔄 Round 140 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 140 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0210
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0296
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2485, R²: -0.0118

============================================================
🔄 Round 145 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 145 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0244
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0387
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: -0.0116

📊 Round 145 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: -0.0115

📊 Round 145 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: -0.0115

============================================================
🔄 Round 148 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 148 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0187
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0336
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: -0.0115

📊 Round 148 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: -0.0114

============================================================
🔄 Round 153 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 153 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0213
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0229
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2485, R²: -0.0114

📊 Round 153 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2484, R²: -0.0113

📊 Round 153 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2484, R²: -0.0113

============================================================
🔄 Round 159 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 159 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0221
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0260
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2484, R²: -0.0113

============================================================
🔄 Round 161 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 161 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0187
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0638
============================================================


============================================================
🔄 Round 162 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 162 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0173
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0386
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2484, R²: -0.0113

📊 Round 162 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2484, R²: -0.0113

============================================================
🔄 Round 165 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 165 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0180
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0338
============================================================


============================================================
🔄 Round 166 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 166 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0216
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0506
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2484, R²: -0.0112

📊 Round 166 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2484, R²: -0.0112

📊 Round 166 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2484, R²: -0.0111

📊 Round 166 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2484, R²: -0.0110

============================================================
🔄 Round 172 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 172 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0221
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0200
============================================================


============================================================
🔄 Round 174 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 174 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0263
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0046
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0108

============================================================
🔄 Round 175 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 175 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0268
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0103
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0108

📊 Round 175 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0108

============================================================
🔄 Round 179 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 179 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0183
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0344
============================================================


============================================================
🔄 Round 180 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 180 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0236
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0124
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0107

📊 Round 180 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0106

📊 Round 180 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0106

============================================================
🔄 Round 185 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 185 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0191
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0483
============================================================


============================================================
🔄 Round 186 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 186 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0249
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0176
============================================================


============================================================
🔄 Round 187 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 187 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0250
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0202
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0105

============================================================
🔄 Round 193 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 193 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0221
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0193
============================================================


============================================================
🔄 Round 196 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 196 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0244
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0106
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0103

============================================================
🔄 Round 198 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 198 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0213
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0245
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0103

============================================================
🔄 Round 200 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 200 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0262
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0085
============================================================


============================================================
🔄 Round 201 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 201 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0240
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0115
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0104

📊 Round 201 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0104

============================================================
🔄 Round 204 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 204 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0203
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0255
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0104

📊 Round 204 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0104

📊 Round 204 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2484, R²: -0.0104

📊 Round 204 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2483, R²: -0.0104

❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
