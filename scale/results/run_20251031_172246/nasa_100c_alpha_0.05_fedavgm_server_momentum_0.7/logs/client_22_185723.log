[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e1c61c-2580-49f1-90b3-13294149ab70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc8e815-8a67-4257-9d24-bfe69754b7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9a57186-3ec4-49fd-8cc2-f23905b0e6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 725d0fcc-7ae3-451c-beeb-d667e9894010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6e69c3-6a4a-4c44-bac3-3e04766a4045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 412a3229-aa70-46a9-9c3c-2caaa58319c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b34fcc9-a9d3-49a1-9605-731e3a98c903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8803033-4a8a-4933-b564-bc4c0a09030a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c298cfe-f562-49ca-a9d6-2db9ce6647ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 808b841c-33fe-454f-af11-ba50591475fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6cee725-9ef6-460f-b3c0-b46b119b4a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 532702cd-a8f2-4b4e-a25d-474e795d6d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09df9960-a186-457a-82ab-f87cf6c7177d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc1959ad-adf8-4e73-9de8-2614c5f1a540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020a4cda-ef30-4dbd-8b82-6a6af61b6f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59340b0d-f418-4587-89aa-3bdee9a9aff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0f52f37-4dc5-46d2-b8f8-89e3e051695f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b9a5112-096c-4bde-93d5-685d1203b8eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4133097-77fa-4456-a640-085cd2f24fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03f1212-ac86-4007-ad41-534a5109ae97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26c3b3e4-a31b-4514-b01d-f1a0a377d5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c6fc12-1553-4865-b84a-4e7e4dd8efbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1722a130-b6a3-40db-8885-a858ad68b450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca99a18-4f37-4e50-a4bc-dae2e7aab710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 996b01b1-8bd3-460f-8404-a51a1f7e716d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ccc2e1b-8218-40a7-be75-b0bca9d5f498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4582a6b4-d0c5-47ee-9ca4-68dcd440f5a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dcfdf23-bbe4-4cea-b617-87d220be6525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453f483f-edd6-4af1-96a2-439032e91d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ebf162-4839-415b-ad5f-247f9e3e5da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1adf3ce-82dd-4124-b25e-6ff553750b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9645f5-4f2b-4084-9bce-dd85645d415a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1180a5ae-8bf4-4997-8a56-c94af49fe257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8b06d4-ed2e-4951-a2fb-8036fca743e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9878d5-6f3e-42b2-8d81-873b24aeb962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc2189a9-eff1-43bb-8ec5-8682a1f86a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37223777-8fce-4720-a5a5-322028380497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2235a7e0-1f14-4c1c-a4f2-d85b2d1d6e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57ffc929-45a3-4b8f-9666-fbb2f24fa865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bec0ed09-c0c1-4d6d-8396-93765f1b230c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2c729c-1a65-4f7f-a873-1e3070928abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b09aaa05-6844-46e4-b5df-a040ca74d487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7c93af0-39dc-4a02-b19d-d5a9f20e5c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53b6254-2275-4264-8557-16695733d325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b680ea-4f0d-4781-ab6a-0edb024d62cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26bfaddd-0cc8-43ca-9f3c-aa4fe1620257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccc56e6-b5ec-492f-ac24-dbbfef926772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e92f792-b4d3-468d-a130-bbb6860ac1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7394bf8c-39ed-4259-a7da-148a0d484ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602e5416-380d-4dd4-9e68-bd68e558946b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c7a996-e402-41f6-845f-8e72deda31e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6cd3bd1-bbcb-4552-8ccd-e6d19b9cd2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1c6279-ac06-411f-9c3a-ce0ea25c36f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43b84da3-19c2-4746-ade6-81c240425c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35645c98-f884-4176-ae5f-e6c75fe27cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fabeba-11a2-4fb2-be66-2d51185bc498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 168056d0-e648-42b1-b50b-e5c356b1c7bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b51d2f4f-352b-47d4-a6ba-5784adc91be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ff9782d-e241-484b-9b9f-c43e6797b982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01040c1-e225-407d-bdcf-a58629e62a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042a9023-4521-4df9-ab9b-a6fcecc50a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 066e0ae1-4c31-438b-b644-8aa1721efbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4344b81a-ba99-4518-8dd2-7a9c6b72c718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f4c1a0-0d51-485d-9452-28a9a4ae599f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80cb032b-0472-4e63-bccd-dc3d5e8f48bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad5f2c9-d052-46f6-a32a-dd52a8674967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e7f8366-503a-49f1-bd64-93eb2a488db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eba8fd3-6b99-45bd-9146-8eea37b4e541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7176291c-f91a-43f3-b8d3-4fc315801cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f04a6b-3daf-4c52-b6d6-7e41fd7c067a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8200d9ca-16a4-4a87-b048-35803511de7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfe196d-85e9-4413-afb7-dc1e35afce1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d2cd2fb-0022-4017-8f53-fd1bede15d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdef4c0b-3977-4257-baf4-90630aa808b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9583a446-2d76-4c07-b8a7-72cb7abd5e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af61ca2-6d6f-48bb-be3e-214fff0a823f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa18d945-3056-43dd-b6bc-fb5828f0adbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c047b7b4-efc0-406e-a538-9aa4293c44fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced05ab2-d47f-4d2b-aa40-a240f7646f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42693caf-ca4b-4641-b420-d978c0e9b7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb03f73b-a139-4667-9584-d6890d119517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8221547f-7d68-49c6-bd05-54b4c36befde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c3bb56-ba90-42fd-a111-cc7313f9f5bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eed27df-d909-458f-8cfa-1523598dbd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e75d31a-4f88-4af4-b863-74d05859dd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe78f26-64e0-41e6-a773-20d1bc0d3b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3038e5bc-181b-4466-b710-acbf241ea84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8890514-b249-49c5-a2d5-dd5656b13074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b0e479-69b5-41b7-b558-0164bd822cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd2c410-eeda-4fbd-9d4d-c4494739d287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4174e8e6-9626-4949-8f35-809a1201fc41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 955c546f-0506-44d3-9260-54baff26de24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8703069-af90-4f8c-9d7f-6c9902d56ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8746a61-ef23-4c89-a4d9-8ae6b0061850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611dcf86-2788-4934-b406-e508b20ce544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b31e6665-0b94-435e-87a1-e579429f0217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5ff35b-a730-4d19-9136-f97e20c3c277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eceddf21-ac45-4a75-a904-11e8b13f2f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f302c415-5e08-4bf0-818d-a5288ad18463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb057530-ee3b-41d7-ba6c-81de58607d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96fe1813-e91a-4541-8e5b-b3a81ad05e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4a29ff8-8d2a-4e38-8794-97f823c2c625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b3e376-c4c9-4fa0-a2c9-ba1a07fca30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236c711d-354c-47cd-b650-a60850827719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a844cef-141b-4eb7-8f13-2238d22be9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab60624-e231-430d-b7ea-8af7ad781d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8adf1abe-683f-451a-aec0-596c798876ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e37469-d412-4439-b4a8-81be1dd2acc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb52bfd2-f225-4366-994f-faa6e06bfe03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f088b59-ee92-487f-b5ef-2333c5118acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f44b46dc-ba3e-4834-83bc-9ade5a1f7392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd80aeb-a6a3-4bad-9f5d-fbc12fefff2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0334e99-201e-4272-975e-bd040ba503ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee560c5-4ed0-4f6f-8704-1cd4a25d96f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb9c020f-c36a-4a85-9436-14ed90c08683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f0216ae-6b04-43e4-8c90-a1d1fa32a40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1e66d3-652d-4137-81ee-7e19d100c3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010239ad-c404-4819-9c8c-3813f30d234f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3582034b-2794-4dd4-9213-6dc6916b2949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e737c376-cd06-4da9-95e2-79a4faf2fbab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85ea3dfb-6c96-4b21-bf44-b7a8043bd076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 343c0738-ad27-4bd3-a27e-039685260abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891b123e-00c7-4dc4-9583-39df82d78c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 048af656-59cc-4f9f-8b92-703772c0979e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a18936c-9881-453a-923a-5a91927e6056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe40582-75cb-4a16-9ae9-34eba0fec49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd9fcd2a-8303-49eb-80a5-e33482ae46f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6130f8-0d08-445c-b3a5-949bbeade4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8739a5-c813-4707-b042-889839ed66f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc9fce5-504c-4f97-bae9-f1197a58d035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e531006c-9aea-45f1-b5ce-12dc715475b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fecb423-6274-4957-9897-b53fc2d9df98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1705bd1-db30-4e73-842e-db7731f1bde5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec6fd69-8f5b-4fb5-91e9-8306477ca720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714e166d-c4f2-4ce3-9180-164d323aaab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b937b9ef-136f-45ab-a669-7c6257d09d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97ff477-4959-4e0a-962d-f5ac5d69b373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf9f768b-a84f-4e1b-8c20-c693ba54c074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19263e1f-f3db-44cf-9a08-37bbfa3fd202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c9cf90-a9c4-4a84-87d1-5788bd8eb91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67210062-554e-40ba-b325-2c678a1ea202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b54e44d-ec7e-4cf6-b284-30187019bf45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9517ab11-d41e-4392-a41f-0c197f1a06a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1004bc4c-83d4-4a55-b8cd-a1e404f64767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be00e63-cd6c-4147-b9db-3f95c7e9f762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02893af6-c53d-486c-b9b9-f709dd84a9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 540e0de9-bca8-4e5b-991e-df878672a04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091b1e38-f172-4d3c-a0b6-6622acd0ae60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90fb34e7-7c95-43c1-a161-571ee32497cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0acf2c3-014f-44a8-96b9-752df56c2149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122cc42e-588e-4107-828a-8fb66c4cd076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b35991f-c2b7-4711-bbfe-e2012a537c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b41d53-1f24-4ee3-9f61-27543dc98ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f08e61d-9ef0-44bc-95c6-57f0e2f50ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a80ea86-97ed-4d91-ad3c-f1e7388bd6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0256ef63-e703-49da-9e73-046f70fee2f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68450439-8470-4a5e-b6ff-7a422628e916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fdc519f-4644-4235-8726-64808d15e07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea78ad3f-10fa-4407-a1ac-c18d5231b79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a27c84-ff08-47b1-914f-410084c89f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e217c7a1-b396-4b1f-be30-0e95cd0ad62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db32a32d-d0d0-49de-93f3-55425c36335f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b647b58-f997-4159-8f7b-6607f5d2ccd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd87c03f-ea9a-4fcb-8bed-6b5dc3e47b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5bae333-13de-49b5-b050-a563cf0b8355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e49e4f4d-a992-4a56-a576-278799c2cdb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124f7048-574a-4c04-903f-95265548dd74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e96fcc-a091-47e0-97a7-5520748dc816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4284d70-425b-4a8d-ac38-63488d1804ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f02426-8022-4b0e-9448-b1a2c2f106df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 448a69a2-670a-47d1-a64b-cf8d798a3883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3962381-7d69-4b7c-97d6-a814fb3df261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63fc332-85ee-4d87-96cc-ff7e55cafb7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e280151f-1492-4602-a4ae-2337f665d84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d0faa9d-85e7-47e1-9067-e038fd9b4697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e648930d-ff67-4aaa-97da-e98fcdfbb4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e983d8-dc68-4f28-9eb0-65f9f60cae54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 954691b6-5de8-4d4a-b453-33635099133d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(1312, 24), y=(1312,)
   Test:  X=(329, 24), y=(329,)

⚠️  Limiting training data: 1312 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  320 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1373, val=0.0969 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0849, val=0.0864 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0809, val=0.0848 (↓), lr=0.001000
   • Epoch   4/100: train=0.0807, val=0.0848, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0807, val=0.0848, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0805, val=0.0849, patience=8/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 3 Summary - Client client_22
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0031
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0008
============================================================


============================================================
🔄 Round 4 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0758 (↓), lr=0.000500
   • Epoch   2/100: train=0.0843, val=0.0831, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0816, val=0.0810, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0815, val=0.0807, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0815, val=0.0812, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 4 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0461
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0005
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2490, R²: -0.1046

============================================================
🔄 Round 5 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0751 (↓), lr=0.000125
   • Epoch   2/100: train=0.0844, val=0.0748, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0832, val=0.0754, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0831, val=0.0754, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0830, val=0.0754, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0828, val=0.0755, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 5 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0328
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0026
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1063, RMSE: 0.3261, MAE: 0.2679, R²: -0.3427

📊 Round 5 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2468, R²: -0.0675

============================================================
🔄 Round 7 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0813 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0869, val=0.0799 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0855, val=0.0790 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0844, val=0.0783 (↓), lr=0.000031
   • Epoch   5/100: train=0.0837, val=0.0779, patience=1/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0824, val=0.0774, patience=5/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0822, val=0.0774, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 7 Summary - Client client_22
   Epochs: 21/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0048
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0032
============================================================


============================================================
🔄 Round 8 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0852 (↓), lr=0.000008
   • Epoch   2/100: train=0.0815, val=0.0851, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0814, val=0.0851, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0813, val=0.0850, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0813, val=0.0850, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0811, val=0.0848, patience=10/15, lr=0.000002
   📉 Epoch 19: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0810, val=0.0846, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 8 Summary - Client client_22
   Epochs: 29/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0002
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0028
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2536, R²: -0.0990

📊 Round 8 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2420, R²: -0.0058

============================================================
🔄 Round 12 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 12 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0192
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0228
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2445, R²: -0.0093

============================================================
🔄 Round 15 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 15 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0033
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0426
============================================================


============================================================
🔄 Round 16 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 16 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0080
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0153
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2415, R²: 0.0054

📊 Round 16 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2390, R²: 0.0170

============================================================
🔄 Round 19 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 19 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0054
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0100
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2378, R²: 0.0239

📊 Round 19 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2384, R²: 0.0210

============================================================
🔄 Round 22 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 22 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0240
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0010
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2386, R²: 0.0190

📊 Round 22 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2384, R²: 0.0202

📊 Round 22 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2381, R²: 0.0228

📊 Round 22 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2380, R²: 0.0233

============================================================
🔄 Round 27 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 27 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0103
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0327
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2385, R²: 0.0200

============================================================
🔄 Round 28 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 28 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0155
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0011
============================================================


============================================================
🔄 Round 29 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 29 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0053
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0405
============================================================


============================================================
🔄 Round 31 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 31 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0029
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0316
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2392, R²: 0.0163

📊 Round 31 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2392, R²: 0.0161

============================================================
🔄 Round 35 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 35 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0152
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0127
============================================================


============================================================
🔄 Round 36 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 36 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0087
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0106
============================================================


============================================================
🔄 Round 39 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 39 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0092
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0019
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2393, R²: 0.0158

📊 Round 39 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2393, R²: 0.0159

📊 Round 39 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2393, R²: 0.0159

📊 Round 39 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2393, R²: 0.0159

============================================================
🔄 Round 46 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 46 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0102
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0012
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2393, R²: 0.0159

📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2393, R²: 0.0160

📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2393, R²: 0.0160

📊 Round 46 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2393, R²: 0.0160

============================================================
🔄 Round 53 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 53 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0030
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0326
============================================================


============================================================
🔄 Round 54 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 54 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0158
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0151
============================================================


============================================================
🔄 Round 55 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 55 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0091
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0262
============================================================


============================================================
🔄 Round 57 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 57 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0139
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0541
============================================================


============================================================
🔄 Round 58 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 58 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0052
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0236
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2393, R²: 0.0161

============================================================
🔄 Round 62 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 62 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0099
   Val:   Loss=0.0723, RMSE=0.2690, R²=-0.0250
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2394, R²: 0.0159

📊 Round 62 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0159

📊 Round 62 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0158

============================================================
🔄 Round 67 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 67 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0139
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0433
============================================================


============================================================
🔄 Round 68 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 68 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0023
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0358
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0158

============================================================
🔄 Round 69 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 69 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0113
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0135
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0158

📊 Round 69 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0158

============================================================
🔄 Round 72 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 72 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0117
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0253
============================================================


============================================================
🔄 Round 73 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 73 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0074
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0047
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0159

📊 Round 73 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0158

============================================================
🔄 Round 76 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 76 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0081
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0190
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0158

============================================================
🔄 Round 79 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 79 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0083
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0154
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0157

============================================================
🔄 Round 81 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 81 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0082
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0120
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2394, R²: 0.0156

📊 Round 81 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0155

📊 Round 81 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0155

============================================================
🔄 Round 87 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 87 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0058
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0263
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

📊 Round 87 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 89 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 89 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0117
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0047
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 90 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 90 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0063
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0242
============================================================


============================================================
🔄 Round 91 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 91 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0109
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0097
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0157

📊 Round 91 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0157

============================================================
🔄 Round 96 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 96 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0084
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0061
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 97 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 97 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0045
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0327
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 101 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 101 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0106
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0047
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 102 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 102 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0059
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0245
============================================================


============================================================
🔄 Round 103 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 103 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0122
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0029
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 105 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 105 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0009
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0399
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

📊 Round 105 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 107 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 107 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0142
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0041
============================================================


============================================================
🔄 Round 108 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 108 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0128
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0015
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0157

============================================================
🔄 Round 110 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 110 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0075
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0233
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0157

📊 Round 110 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0157

============================================================
🔄 Round 112 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 112 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0098
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0127
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0157

============================================================
🔄 Round 115 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 115 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0107
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0107
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

📊 Round 115 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 119 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 119 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0123
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0078
============================================================


============================================================
🔄 Round 120 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 120 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0039
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0341
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

📊 Round 120 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 125 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 125 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0166
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0145
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 128 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 128 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0082
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0167
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

📊 Round 128 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0157

📊 Round 128 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 133 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 133 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0035
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0145
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0156

============================================================
🔄 Round 135 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 135 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0074
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0211
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0155

📊 Round 135 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0155

============================================================
🔄 Round 137 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 137 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0057
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0265
============================================================


============================================================
🔄 Round 138 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 138 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0103
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0099
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0154

📊 Round 138 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0153

============================================================
🔄 Round 143 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 143 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0094
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0126
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0154

============================================================
🔄 Round 147 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 147 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0058
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0277
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2395, R²: 0.0154

============================================================
🔄 Round 148 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 148 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0159
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0123
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0153

📊 Round 148 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0153

============================================================
🔄 Round 151 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 151 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0098
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0063
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0152

============================================================
🔄 Round 155 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 155 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0119
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0000
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0152

📊 Round 155 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0151

============================================================
🔄 Round 158 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 158 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0112
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0119
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0151

============================================================
🔄 Round 161 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 161 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0061
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0192
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0150

============================================================
🔄 Round 163 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 163 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0079
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0004
============================================================


============================================================
🔄 Round 164 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 164 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0108
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0026
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0150

📊 Round 164 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0150

============================================================
🔄 Round 169 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 169 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0110
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0277
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0150

============================================================
🔄 Round 173 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 173 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0109
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0032
============================================================


============================================================
🔄 Round 174 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 174 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0160
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0111
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0151

============================================================
🔄 Round 175 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 175 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0030
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0091
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0151

📊 Round 175 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0151

============================================================
🔄 Round 177 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 177 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0116
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0046
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0151

============================================================
🔄 Round 179 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 179 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0118
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0003
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0152

📊 Round 179 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0152

📊 Round 179 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0152

📊 Round 179 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2396, R²: 0.0152

============================================================
🔄 Round 183 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 183 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0091
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0072
============================================================


============================================================
🔄 Round 186 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 186 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0126
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0157
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0152

============================================================
🔄 Round 189 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 189 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0147
   Val:   Loss=0.0956, RMSE=0.3093, R²=-0.0032
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0152

============================================================
🔄 Round 190 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 190 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0085
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0033
============================================================


============================================================
🔄 Round 193 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 193 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0117
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0073
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0153

📊 Round 193 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0153

============================================================
🔄 Round 197 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 197 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0068
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0255
============================================================


============================================================
🔄 Round 198 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 198 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0105
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0118
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0153

📊 Round 198 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0152

📊 Round 198 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0152

============================================================
🔄 Round 203 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 203 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0102
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0100
============================================================


============================================================
🔄 Round 204 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 204 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0110
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0083
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2396, R²: 0.0152

============================================================
🔄 Round 208 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 208 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0135
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0045
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2397, R²: 0.0151

============================================================
🔄 Round 210 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 210 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0085
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0185
============================================================


============================================================
🔄 Round 211 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 211 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0060
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0281
============================================================


❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
