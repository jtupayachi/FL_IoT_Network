[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d519e221-eb13-462e-a10f-dcc6c4565fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b19b24bf-df65-4726-911f-c61c5b9b8140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9116fd39-b3af-4fc4-aede-5f30bde5eb01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829a2c49-9826-472e-8bdd-2fc3313f6061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3202495-26a8-4a20-a074-5188e48400c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71bde029-7a9d-46a4-bd04-18856c951d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d50a7db3-527b-462e-bd54-37311f0a1b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9eda8cd-278d-4e3f-aba0-0caebf5aa8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 892507c2-e013-495c-8fcd-d98ea3563ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac71f23-b680-418e-8453-fc9053ffa9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669c6789-98ef-47bb-ab1b-59639675d7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a2a0ea-2fbc-48b5-866b-c4df4d600b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8eeacf-025e-4d40-8b87-13786c027da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7637d4-9c32-4838-882d-6b0c2ca5ea08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db88502-d105-4fda-b69d-ff23793c786a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25cfbb39-97cf-4c95-8efc-446aa04c3bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c633ad-10af-49ee-adeb-629e948072ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ed4e35-163d-49ec-83b6-eb55e2094381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19ddf275-10f9-41d4-ae53-a54d3c7c7f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f055c4a-8c51-45f8-9d4b-a34d853adb4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d0de16-3e90-46bf-810e-d5edc3eb8a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee389d1-b692-47d4-888a-cafd3602fbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f28bef3e-5052-4f9e-8ea2-2ad1615caad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc24ab7d-3fa2-469d-a841-b20c2d47d944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3cc4569-bd78-48ca-9b5e-17952280e2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b8c8f7-2d63-49cd-8afd-07381522708b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c08dc0-dced-4f0e-8962-c08cd712e371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 951a7d0a-d2b1-49f6-a5f5-84d6a0a571d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a9dd78-5a02-4847-9cde-c6c8546590b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a4711f-93de-4d35-b656-a97189e1c037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12801175-2478-4b77-b723-af2888b897e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca5e92a-d19f-4d51-bcc3-b443eadd00a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77eaff4a-9ca1-4479-85b3-f9a193cfcab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d18bf7fa-8e20-40e1-97f4-36bf067908cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6869f008-0b0c-4efd-9bdb-d804234a4622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e18f7175-a1a2-4bf3-95bb-d4d259c01e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 039ecd12-a02e-4fc1-b90f-29c7a66f6e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 297c29d5-6e00-437f-9eca-834f25e8aafe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67bd7ada-639b-4ec4-af60-7880a5959b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51ae1be-26b9-4cdc-88c3-db2b56ad72f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c486a6-91db-4d75-9438-347ea3b5f7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efb43bd7-1b0f-491e-973b-310d4fcf16d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1cff56-b7b5-4e17-b3b2-eac194f22a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861d08c4-64e5-4ace-8886-49b6d0a058d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49fc3b6d-f18e-4681-a7d1-c4e02208b311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ded9467-bf76-4576-8aa5-e7d3a1185be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44c0d750-1f4a-43a8-a6ab-751a83a4c557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03f002af-b625-40b6-a85a-13d8915afb94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440e1668-6f77-4908-85eb-ee8656324cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94e1a847-0d92-4064-976b-660f462da6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7a79c25-50d2-4a81-bdbc-4cc1ccb76f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4ad497-63a3-4033-9619-f301d4355a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de529c81-e989-4589-82a3-5f072d73a043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7edd52a8-657c-408a-bde5-a77cd8355b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944b01f1-adfa-47e5-8af0-ea0c6685c5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df0af84-4deb-409b-91c4-0fa219a3d6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ae3736-b778-4bdf-b5f8-650acea1b620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b777465f-26b7-4280-8ef2-2d65787c4e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b8ca8d-4c49-43d4-83db-c2d0545b3015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6a289ea-ec7d-40fd-97a6-24bfc326d281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 780b4d91-e198-438d-b5d4-4123a067854a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd4579b-2c81-45ac-9d34-185b5602fcad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61676f9b-913a-43fd-9a16-00b6b6e047df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 208d955f-9762-448c-ad1e-f5802c13ce8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f8c666-1d31-4357-a50d-b0e610abcc39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95946f34-a463-4be4-a492-b26049f77ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d9c9da7-7916-4ec1-ae46-2680470d9df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f38abd5-3efa-460c-b0e0-70bab56ca892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faffe6e0-be5c-427a-8690-df58af9386b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c608172f-33a0-4db6-a84e-b5a6823839ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9793d59-0757-4669-a41a-5c7f56abc332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f5fd99-6679-4040-9dca-4058a8477c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453d5c0e-c78b-40d9-835c-8e9dba65208d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e40c5d9c-bc7c-4c29-b0ad-d3c07688133b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce42805-5423-4f8d-8ebf-cf9dea2125fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a3daca-327d-4455-94c7-082a31a63258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2937924-5b84-400c-b0fa-835eb64174fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f4eab6-1b9f-4cf4-86d7-83cd7ef180d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5080102-5dc5-4cdd-93cc-74c4f0c69e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d091de-33a0-490b-a8f0-654d18257019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fac1a96-a8b1-4e9d-9c92-134e5cbf025e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530401ad-60cd-4786-9d30-335bcadbc8c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef359bc-9ec7-48c2-b2db-43b02d09f6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23930139-b7b0-4740-9edc-627c12b3bcf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7956219b-c2e0-476d-a121-e85f12f3cd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f2cc15-44ae-4641-adb1-0dc1bc5ac82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f084ef6c-85f1-4d0f-950b-6d363778cebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb9b95a-1348-4081-8110-1d33600ff3ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef6dace0-ddb9-4fa6-ba91-08eaea62c91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c6eb9c4-ad38-47e7-81b2-bee31c1cd798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6da9e290-e654-4cee-bab7-fbf924787b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79d80fee-3d6e-485c-b015-3c6bbfd70d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1851cdb9-eb46-4131-90e7-eabc3cb52eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf44743-d0b8-4cc2-be4c-630cdcbe178e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1fc0437-8baa-4f48-a1b5-5066e8b2a7e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd59552-dc3d-4d8a-af4d-0c7ef21b16f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12936fc1-b448-4f60-a05a-a320f65a3b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c25a71-f940-4041-9180-48a4674527f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b30efe6-2fa2-4b93-9480-f196a9631a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f5ceac6-3f9c-46c4-8a2c-813c2ec8c686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e173fb01-76b8-4529-878b-3158792d80c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e78941f-b0d1-464d-bc72-180c31578cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e78615-0fab-4e9e-8fb7-cf88897bcb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf7e3bb-5374-4d2b-a138-200a0cf78ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0d85106-3e5d-4469-b5d1-27e8d84ee726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48a865e-631c-4fbd-8b6a-663453cb9674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e4d4865-d220-4a44-a047-d07324a14e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b6c1ded-783e-451d-988a-77849372497a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5edfa15-7f46-4aa9-95d2-0801691ebbeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d8d4f54-f0a4-4619-b364-31c5612999d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd632f29-870e-4713-b507-5efcc2ff0e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e27c8fa-ca71-4fdd-984e-d1e32725f17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d18607-a338-49b8-8d41-a2222ee9afe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec45d600-d33f-45f8-bffb-a1f64bd39b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2d6896-3d26-43e2-ad98-f113b5b169ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ddabde-f9d2-4523-b65e-e6ca0fc58ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42cb0cd6-decf-4f57-8442-559d2122b0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d97bcc4-9a0e-474f-996d-9d35ed1ea290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58edb19f-71f2-4a07-b59e-aab021418ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ea164b-9609-45ed-ba25-a62bef16a0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e5c4a3-bcc5-4163-83a7-baca24206638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530d1d85-4033-4ab0-a53c-c434b4db8a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be7fc88f-577c-4b6b-937f-a951b9004778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5cd6e2-5e24-43f0-8ef3-dd639e470ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c83ab2-081e-4ff7-ae8d-edd8ea71e286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dde4817-d3e7-459b-bb26-8319bf36a29e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9347b124-2050-49c9-aafb-9fc14c042192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44103e9b-45e8-4258-827f-c2ee796dd620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e196684-4ce0-4a18-8f1e-a1caeddac706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8d0de82-9c37-406c-8d71-20a00760cc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b69fa633-1f83-42a1-bf43-831741dcb26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc162190-153c-4032-8bd7-a6b4099377db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c3636c4-f37e-4f37-a1be-f249896133b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c04af18a-0ce1-4f18-a4cb-f13f30363f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef8d7636-56fe-4f16-adc4-87fcfb4fd928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5cb36e-182d-45d7-bc54-8042f7796769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878163c1-18d7-4ae1-8461-808f0fc9b8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f00c438b-32fb-4c6a-9190-8c29ff2dea2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4dd049-d5bd-400a-a772-8e6c7015fdfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc61b93-d573-4c33-9252-0fb1c2d46f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8366cb6c-8143-44dc-b4d4-84d4492162a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e6e6b7-b328-45f0-aae2-e983f0b8b94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba40f09-bb0d-460b-984d-a31a26dca6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5632b27-e699-43f0-b205-1e5833d7d458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726453f5-54e4-49e8-bb77-3a14ced653ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bf10012-ae2f-415d-8c9e-d6215506588e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e1dd2a-06fe-48f9-973a-c2d30f59e985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb50b04-2ba6-4902-9509-5edac12c1928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510d16c9-65ac-4058-830a-ee99a36f0827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 669df824-88c2-48ee-ab54-cef0e12dc21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d33337c-b25b-457e-a79f-60eb178dbe8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd3dd81-bcfb-45bf-9d59-dd6a704fef2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cbe4549-4f67-4bde-bdad-6db4e2f3ec08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1c7cbca-3d9e-43d3-8da9-bd8196bc38d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b4623b-48fa-425b-b006-1b6bf172e669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb07cfb-bd74-43d6-830e-e165a086d72e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19845ea2-6e4f-44e9-a0fb-ba2feb3a2dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f8bffcd-41c9-45d1-97d2-8c3d3d051744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81959946-1d1d-4f5d-bd72-6300dcd06b37
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_23
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23/test_labels.txt

📊 Raw data loaded:
   Train: X=(1172, 24), y=(1172,)
   Test:  X=(293, 24), y=(293,)

⚠️  Limiting training data: 1172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  284 samples, 5 features
✅ Client client_23 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0810 (↓), lr=0.001000
   • Epoch   2/100: train=0.0779, val=0.0812, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0780, val=0.0811, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0778, val=0.0810, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0776, val=0.0810, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0767, val=0.0806, patience=10/15, lr=0.001000

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 5 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.001000 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0033
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0015
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0938, RMSE: 0.3063, MAE: 0.2574, R²: -0.0719

📊 Round 5 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2664, R²: -0.0951

📊 Round 5 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2538, R²: 0.0013

📊 Round 5 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2541, R²: -0.0272

============================================================
🔄 Round 13 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0774 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0817, val=0.0745 (↓), lr=0.001000
   • Epoch   3/100: train=0.0799, val=0.0753, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0781, val=0.0757, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0776, val=0.0764, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0720, val=0.0805, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 13 Summary - Client client_23
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0307
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0267
============================================================


============================================================
🔄 Round 14 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0874 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0778, val=0.0867 (↓), lr=0.000250
   • Epoch   3/100: train=0.0769, val=0.0865, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0764, val=0.0863, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0761, val=0.0862 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0750, val=0.0861, patience=6/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 14 Summary - Client client_23
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0223
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0136
============================================================


============================================================
🔄 Round 15 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0885 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0804, val=0.0875 (↓), lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   ✓ Epoch   3/100: train=0.0797, val=0.0870 (↓), lr=0.000031
   • Epoch   4/100: train=0.0793, val=0.0868, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0791, val=0.0867, patience=2/15, lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0782, val=0.0863, patience=4/15, lr=0.000016
   📉 Epoch 19: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0777, val=0.0862, patience=14/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 15 Summary - Client client_23
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0049
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0772
============================================================


============================================================
🔄 Round 16 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000008
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0843, val=0.0822, patience=2/15, lr=0.000008
   ✓ Epoch   4/100: train=0.0840, val=0.0820 (↓), lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0838, val=0.0819, patience=1/15, lr=0.000004
   • Epoch  11/100: train=0.0833, val=0.0816, patience=7/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002
   📉 Epoch 21: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0830, val=0.0813, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 16 Summary - Client client_23
   Epochs: 27/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0456
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0715
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2564, R²: -0.0438

============================================================
🔄 Round 19 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 19 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0760
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0288
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0909, RMSE: 0.3015, MAE: 0.2575, R²: -0.0390

============================================================
🔄 Round 23 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0850, patience=2/15, lr=0.000001
   ✓ Epoch   4/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0828, val=0.0833, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0825, val=0.0829, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 23 Summary - Client client_23
   Epochs: 37/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0586
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0314
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2578, R²: -0.0409

============================================================
🔄 Round 25 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 25 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0684
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0010
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0909, RMSE: 0.3014, MAE: 0.2570, R²: -0.0384

============================================================
🔄 Round 26 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 26 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0611
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0069
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0909, RMSE: 0.3016, MAE: 0.2569, R²: -0.0393

============================================================
🔄 Round 30 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 30 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0224
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0771
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2565, R²: -0.0334

============================================================
🔄 Round 33 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 33 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0307
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0272
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2564, R²: -0.0327

============================================================
🔄 Round 35 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 35 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0368
   Val:   Loss=0.0686, RMSE=0.2620, R²=0.0068
============================================================


============================================================
🔄 Round 36 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 36 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0102
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.1188
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2564, R²: -0.0322

============================================================
🔄 Round 37 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 37 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0203
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0654
============================================================


============================================================
🔄 Round 38 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 38 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0295
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0261
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2564, R²: -0.0320

============================================================
🔄 Round 41 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 41 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0320
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0236
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2564, R²: -0.0319

============================================================
🔄 Round 45 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 45 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0337
   Val:   Loss=0.0703, RMSE=0.2651, R²=-0.0081
============================================================


============================================================
🔄 Round 46 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 46 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0272
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0423
============================================================


============================================================
🔄 Round 47 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 47 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0296
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0310
============================================================


============================================================
🔄 Round 48 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 48 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0285
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0299
============================================================


============================================================
🔄 Round 49 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 49 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0259
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0493
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0320

============================================================
🔄 Round 51 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 51 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0262
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0393
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0320

📊 Round 51 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0320

📊 Round 51 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0320

============================================================
🔄 Round 57 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 57 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0031
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.1443
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0321

============================================================
🔄 Round 58 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 58 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0323
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0548
============================================================


============================================================
🔄 Round 59 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 59 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0293
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0337
============================================================


============================================================
🔄 Round 61 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 61 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0027
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.1354
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0318

============================================================
🔄 Round 64 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 64 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0315
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0214
============================================================


============================================================
🔄 Round 65 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 65 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0301
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0227
============================================================


============================================================
🔄 Round 67 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 67 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0356
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0001
============================================================


============================================================
🔄 Round 68 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 68 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0157
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0874
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0315

📊 Round 68 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0316

============================================================
🔄 Round 72 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 72 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0204
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0614
============================================================


============================================================
🔄 Round 73 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 73 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0125
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.1021
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0317

📊 Round 73 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0318

============================================================
🔄 Round 77 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 77 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0313
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0176
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0316

📊 Round 77 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0315

============================================================
🔄 Round 80 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 80 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0325
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0188
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0313

📊 Round 80 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0311

📊 Round 80 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2564, R²: -0.0310

============================================================
🔄 Round 83 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 83 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0126
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.1269
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0312

📊 Round 83 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0313

============================================================
🔄 Round 90 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 90 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0414
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0235
============================================================


============================================================
🔄 Round 91 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 91 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0310
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0173
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0315

============================================================
🔄 Round 94 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 94 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0336
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0097
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2565, R²: -0.0316

📊 Round 94 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0315

============================================================
🔄 Round 97 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 97 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0021
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.1912
============================================================


============================================================
🔄 Round 99 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 99 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0464
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0298
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0314

📊 Round 99 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0313

📊 Round 99 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0313

📊 Round 99 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0313

📊 Round 99 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0314

📊 Round 99 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0314

============================================================
🔄 Round 109 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 109 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0248
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0469
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0315

============================================================
🔄 Round 112 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 112 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0284
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0304
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2565, R²: -0.0314

📊 Round 112 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0313

============================================================
🔄 Round 114 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 114 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0396
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0162
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0312

📊 Round 114 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0312

📊 Round 114 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0312

============================================================
🔄 Round 118 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 118 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0240
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0502
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0311

📊 Round 118 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0310

📊 Round 118 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2565, R²: -0.0309

============================================================
🔄 Round 123 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 123 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0276
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0285
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2565, R²: -0.0308

============================================================
🔄 Round 124 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 124 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0168
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0793
============================================================


============================================================
🔄 Round 126 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 126 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0357
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0028
============================================================


============================================================
🔄 Round 127 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 127 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0349
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0034
============================================================


============================================================
🔄 Round 128 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 128 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0335
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0059
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2565, R²: -0.0308

============================================================
🔄 Round 129 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 129 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0185
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0860
============================================================


============================================================
🔄 Round 131 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 131 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0366
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0077
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2565, R²: -0.0306

📊 Round 131 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2564, R²: -0.0303

============================================================
🔄 Round 139 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 139 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0254
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0303
============================================================


============================================================
🔄 Round 141 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 141 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0253
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0300
============================================================


============================================================
🔄 Round 142 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 142 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0220
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0532
============================================================


============================================================
🔄 Round 146 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 146 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0257
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0304
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2564, R²: -0.0302

📊 Round 146 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0302

============================================================
🔄 Round 149 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 149 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0351
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0132
============================================================


============================================================
🔄 Round 150 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 150 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0372
   Val:   Loss=0.0737, RMSE=0.2716, R²=0.0205
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2564, R²: -0.0299

============================================================
🔄 Round 151 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 151 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0317
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0124
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2564, R²: -0.0298

============================================================
🔄 Round 154 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 154 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0269
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0233
============================================================


============================================================
🔄 Round 157 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 157 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0163
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0747
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2564, R²: -0.0296

============================================================
🔄 Round 160 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 160 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0232
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0468
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2564, R²: -0.0295

============================================================
🔄 Round 165 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 165 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0252
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0297
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2564, R²: -0.0293

📊 Round 165 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2564, R²: -0.0294

============================================================
🔄 Round 169 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 169 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0219
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0405
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2564, R²: -0.0296

============================================================
🔄 Round 172 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 172 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0354
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0128
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0297

============================================================
🔄 Round 174 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 174 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0168
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0635
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0297

============================================================
🔄 Round 175 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 175 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0278
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0220
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0297

============================================================
🔄 Round 176 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 176 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0263
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0283
============================================================


============================================================
🔄 Round 177 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 177 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0298
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0160
============================================================


============================================================
🔄 Round 178 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 178 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0331
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0125
============================================================


============================================================
🔄 Round 179 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 179 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0240
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0380
============================================================


============================================================
🔄 Round 181 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 181 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=-0.0179
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0741
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0299

📊 Round 181 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0300

📊 Round 181 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0300

============================================================
🔄 Round 187 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 187 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0363
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0116
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0300

📊 Round 187 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0300

============================================================
🔄 Round 189 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 189 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0326
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0052
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0300

============================================================
🔄 Round 194 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 194 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0307
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0340
============================================================


============================================================
🔄 Round 195 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 195 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0184
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0687
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0302

📊 Round 195 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2566, R²: -0.0302

============================================================
🔄 Round 199 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 199 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0275
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0287
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0302

============================================================
🔄 Round 200 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 200 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0204
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0606
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0300

📊 Round 200 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0299

============================================================
🔄 Round 203 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 203 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=-0.0207
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0560
============================================================


============================================================
🔄 Round 204 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 204 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0424
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0332
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0298

============================================================
🔄 Round 209 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 209 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0179
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0654
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2565, R²: -0.0297

============================================================
🔄 Round 211 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 211 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0324
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0033
============================================================


❌ Client client_23 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
