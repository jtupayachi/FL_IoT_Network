[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f25929-3060-438d-8dfd-8df24b1ba387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae2b3029-6e16-42c6-b763-4bc0d869f9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 716f96d3-256b-4f2c-84bd-c0b26ab33e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64bcaa54-f144-41f0-b45c-ba783edcce05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa3fe1f9-702e-45c4-ade3-e4ca767381f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28fcfac4-429d-460d-8c8b-678de435f556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5356795a-7635-459c-ae46-df906f4528d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8232a06c-dded-4d0c-b51f-e8c0f8b17eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f61f5ae5-4cb7-4c01-88c4-4e91fd0bc84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b43420-d308-40d4-8327-57933bb65413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3942daa9-8c90-4d65-9e36-22549ac875bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bba21da-98d5-408b-9ea3-259f6818a7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84c28cc-51aa-43de-8db5-347ebd00f153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc84d945-b346-44c0-a07c-7aabf6445776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 441524dd-70ce-4d29-9cf1-e5a7a40cdc3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6499cfc-14cb-473f-bc0e-1beb2bd39339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424f8c88-4f0e-4e70-84ff-f145a392afba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3637ed01-4857-401c-af59-bcbb8f69a677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f794f852-489f-4bda-bb1c-8f80a4ec6d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 278b7642-103e-4b48-a233-ea833472ffa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 760fb33e-aa10-4756-9461-c29efe5be081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8240537b-1599-45cc-b827-eb31412b7a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d960226-ed8e-46ba-b7b3-3824946a922f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33e8e3f1-335f-499a-b5ff-403e318bd8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5989753d-aab1-4661-b0af-59a8e1fc6240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c008741-3206-441e-8cbd-da3dc6cdb689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f788a74-9be9-4b03-a4cc-8ae6ea0b23c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f6d0e1-1f9f-4668-b6a0-bba71952b4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3bf4ff0-0195-43ff-9073-2e4d283b735a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d64587d-f934-4f47-a42c-f96826583a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d0c245-e813-46a9-aa4a-df190d4e0057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 363fab65-28f3-429e-9701-e172d8ccb108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc182c9a-82bd-4dc5-890b-ca0a41fa226e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00548ef0-c007-4108-a8a3-8fc802d694ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56770cf1-3e24-49e0-82e8-27859a0a90d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9f0a4c-d662-4352-a93d-1b37bfe17296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6512174d-63ed-497b-b9dd-fc6be322c74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3595d4dc-65bc-4112-930c-4d2aad947b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d67407c5-7310-4c5a-a406-c0383d3c0e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53fb6af1-2bde-4956-af98-72bc7f406acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 677f4ed8-7c04-4503-ad2d-72c23628bc1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f14e34e-4ceb-4030-89bb-c2f05fdadc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d17ac6f-18e4-471c-95db-6c27b333380b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 596a93f4-377e-4c2a-80be-e59840ffb1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58ae863-2875-4005-8578-6d4c4b0c5c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f717d8d-7067-4aee-87fb-038d690885fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78bc5b2b-a64c-4484-9c00-eaf1c01078db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f7a3e6-57e9-4bd1-88c1-de5b8b5200f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ddc5812-4c0e-479d-91b0-d4dd0e5e8cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a56ed16c-b5e8-4621-93cc-fce4a444b3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5db055ac-078e-4239-8bcd-07fa80037be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daff1dc3-dc0a-4357-b643-70b10a39c242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a3366e-fb31-4991-b690-35d3151e299c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe15e78-763a-4581-b167-8095051b432a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98b20de-7d5e-4d32-b94a-b1ca1206e39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e993a5-8b0c-4936-b2ca-52133c7c55ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12eff888-9d76-4fd9-9614-b6021eb566a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7396d07-c862-4e78-9b66-1baa924984c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a3383db-0791-4245-be7a-c7996d01ba0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63703d2-52fb-4be1-8f2e-c63b13bac357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cb08e91-2f39-46a2-89d1-9ec1998207a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee1d594f-e909-4dc3-8960-f35747173412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 186bf69b-f406-43c3-a023-01286f3feb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9670083-3a34-4782-b0d6-219f7b67d9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7fdc55c-86ab-44c8-8ca2-6fcf159d0ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c477af9-2b47-4964-aceb-a04a8ca3d4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76d57dc0-2951-4fb2-81b2-add2512f26d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abad3076-4af4-4fef-843e-7365b01bc887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080961eb-7079-4a46-b494-578a4c098bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62036d03-f65c-44e2-84d5-8f699bcef989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49198ed-f23b-4a01-b51c-9a055c0a6d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1c25ef7-d72d-4490-9ef6-c15a4cf9632c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 746a5e24-604c-48a7-a286-ce47563885e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf9b0da-31b7-4f28-9ff7-6111e1a8762f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b62e5c25-143f-431f-b1b5-77c4e590bc45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e6cd2f-6c23-427f-b476-0cd511d28ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 930c5a24-c74f-4458-af5c-8554a2f3f1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68cf99c5-c3be-4b61-97ac-53066a57e6f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b4af8e-98c0-4b13-8bb7-2480fa47f4a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e07b29-72f2-4f17-974b-50a00f13a731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d14d5ba-b8be-4e83-b0c9-09683327eea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c63ba1-5695-470f-be3e-3944eab6ca1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee3bf9b3-c123-4647-8d8d-39a3021035f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078a5e97-546d-4416-a299-be824599b898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5964efea-a30f-4b84-926d-c4ba0f5466ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d574b590-50b2-48d4-a287-9dc63d59f189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b1ea2c-3f76-44d1-bc92-d6a7ae39c645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 834d359e-3e1e-49b2-9589-4ec20ac31f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e2b8ebd-f4e9-4513-9ad6-cd6d80598305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a687086c-06ec-4645-b1b7-db4c59dd1d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b14e5183-4f40-4d89-a0f1-3bcc934f7969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a881c77-44d5-4b80-8d71-cc5bafde6133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d66dcd69-b3ea-454c-aca6-a38db27386e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7ff47b-3080-4f83-9489-39dfcaf85fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9159af-c06d-4fac-9bfe-f89847a16bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d342d88-c8dc-45ce-a356-e680f785e0b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f63d0f9b-6a6c-4616-8382-5e11d20b36fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38878383-48a7-4d36-8bcc-e4c103346b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 294ab7cd-a6b8-4245-9791-b4de67457af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e3c66a-1828-4a73-8421-3906fe4360b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 923259d2-0eba-49b2-a762-f1cbbe9fe383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab2559e-f051-4893-8cb7-bb9e5a8a73d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f097851-e35d-428e-bfe6-a05fe74745c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bde3b9-b2a5-46e2-8b14-76abbb5a4a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c6936f-ef62-4b86-ae17-19acf21f18f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9584512-0c25-4a55-b611-0bb86962ea69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a136c75-9bcd-45c3-9d48-e2e65328e439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858ef4af-381f-46ac-8479-cbf2afe527ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f212170-e777-4c19-bd55-d924a485d4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb3211a6-ce18-4ac7-b945-115faf6eda55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0722325b-8fd7-4887-bc87-144e2f4ffee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 989693c8-61da-47ef-be4e-54de0e200c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43da6b90-0581-4975-b90c-f7cbe4b9aa20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50718b58-2ef9-4489-8a01-68ee3c85d6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db4bc17-3220-4644-88c0-1d25c285f5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b60b4f3-0cf7-4bb3-a35b-6625ccc66a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed7b1584-80c0-4f95-972c-fd0da8eecf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fd6f4b4-1632-4124-94d0-26e11fe6978c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9245584a-772b-471b-8565-fae21ee8de06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54a749ed-d38a-460b-b71f-5465704ba639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c2503c-1019-48a7-9764-09091a6a9777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e79868d-09cc-4d9a-ba50-fa35da603cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa9fd63-c877-4d9d-b0fb-118a8db99021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e81a2169-5fad-441f-98fd-722e727043dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4445b00-fd80-4650-a6da-244eb5ab0bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4fe8df-5774-4a4f-8abe-ffec46025437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c933afd6-ba8f-4683-bb52-c96d05e47b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fde80c0-901b-4ca7-a5fb-0e4f7c7c4902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b90ac2-a72c-4a3b-9085-d9dfa50ba976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce53b0b2-bb11-4b59-af9d-220c4c919606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eecfd151-d936-4616-ad56-864a8a41850a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f57ef80-24cb-4b6a-bdcb-38ae233efded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e94ba6-388b-46d0-bd3b-45b00788146a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d834132e-b2ce-425e-9c84-89698be74219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a16f3dad-44b8-4a1f-9091-94d32528522f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57b5e11-0acf-42ba-bd1c-02ba9dfa7e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5da9bd7-7cbe-4f24-8001-d4226f248ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380121d9-17ae-4909-972d-f85744df7d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92dce63-b42b-4d28-94e2-68d8adb5ff39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e429c224-0acf-45be-9e30-d7af2c9df842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3110f06e-8872-41c2-8fff-7a8122b639d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15ffd29-bd42-4e4c-96fc-f5af50e8c512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cd1b2a-ed94-48ee-a3af-683343d13640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba74671d-8078-442c-b100-3cc70fd6dff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec95c53-c57d-46a0-8363-b998ee3d0d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e7ef5a-1a81-4d36-a6b1-1b089b5a75d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e034d5fc-600e-46c4-ac18-942957adc0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e8299d-792d-48c6-be16-4eec6a5abb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906b7cb7-553a-4c8a-9a86-c2d67871eae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 755e274d-7e0d-4026-9c4f-071b61168e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f992d941-a74b-4a33-9287-46aa2f911bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd1b6da-043a-47d2-8c0c-2d85adf587c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631aa620-b47b-43bb-a73f-49a345e098c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b806467-0de2-484d-a6e5-c9781bb35bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6418ab92-c18e-46cc-9c2b-7c9842aa09bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5ffc5a-cb23-438e-a6e7-d2a4e0ea2d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eefc69ad-cb8f-4df6-86cb-207c04195afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f25f6dc-d126-448f-8b30-c0079286c471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6921a3f-1cbe-475c-9278-7fe7ac84469c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dda3423-d211-495d-a03e-c78261a9c093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2341b914-9a74-42f0-a34c-bfdf6f5d7356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0ef87a0-2373-4961-8287-15f863d254d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c9a6894-df8d-401f-a18b-704e4b4ecb1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71b2e795-eb6a-4333-9c52-d7fe7170f369
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(849, 24), y=(849,)
   Test:  X=(213, 24), y=(213,)

⚠️  Limiting training data: 849 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  204 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2480, R²: -0.1361

============================================================
🔄 Round 5 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0932 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0829, val=0.0921 (↓), lr=0.001000
   • Epoch   3/100: train=0.0823, val=0.0929, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0822, val=0.0931, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0819, val=0.0931, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0795, val=0.0937, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 5 Summary - Client client_24
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0092
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0142
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2435, R²: -0.0858

============================================================
🔄 Round 8 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0853 (↓), lr=0.000250
   • Epoch   2/100: train=0.0847, val=0.0858, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0845, val=0.0855, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0843, val=0.0856, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0841, val=0.0857, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0835, val=0.0860, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 8 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0065
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0522
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2408, R²: -0.0957

📊 Round 8 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2373, R²: -0.0586

📊 Round 8 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2350, R²: -0.0053

📊 Round 8 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2377, R²: -0.0238

📊 Round 8 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2393, R²: -0.0380

📊 Round 8 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2379, R²: -0.0309

📊 Round 8 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2383, R²: -0.0450

📊 Round 8 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2376, R²: -0.0395

📊 Round 8 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2375, R²: -0.0395

============================================================
🔄 Round 20 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0922 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0883, val=0.0911 (↓), lr=0.000063
   • Epoch   3/100: train=0.0874, val=0.0908, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0869, val=0.0907, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0866, val=0.0907, patience=3/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0855, val=0.0906, patience=9/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 20 Summary - Client client_24
   Epochs: 17/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0422
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0423
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2382, R²: -0.0407

============================================================
🔄 Round 22 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0897 (↓), lr=0.000016
   • Epoch   2/100: train=0.0911, val=0.0892, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0908, val=0.0888 (↓), lr=0.000016
   • Epoch   4/100: train=0.0906, val=0.0885, patience=1/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0904, val=0.0882 (↓), lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0898, val=0.0872, patience=3/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0893, val=0.0864, patience=2/15, lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002
   📉 Epoch 30: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0891, val=0.0861, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 22 Summary - Client client_24
   Epochs: 34/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=-0.0437
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0883
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2389, R²: -0.0414

============================================================
🔄 Round 24 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0924, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0924, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0923, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 24 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3039, R²=-0.0797
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0752
============================================================


============================================================
🔄 Round 26 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 26 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0591
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.0860
============================================================


============================================================
🔄 Round 27 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 27 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0506
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0794
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2360, R²: -0.0239

============================================================
🔄 Round 28 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 28 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0476
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0637
============================================================


============================================================
🔄 Round 29 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 29 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0460
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0559
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2352, R²: -0.0183

============================================================
🔄 Round 31 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 31 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0476
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0201
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2352, R²: -0.0168

============================================================
🔄 Round 34 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 34 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0384
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0399
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2351, R²: -0.0154

============================================================
🔄 Round 39 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 39 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0350
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0447
============================================================


============================================================
🔄 Round 40 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 40 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0378
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0377
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2351, R²: -0.0152

============================================================
🔄 Round 47 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 47 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0359
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0416
============================================================


============================================================
🔄 Round 48 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 48 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0368
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0375
============================================================


============================================================
🔄 Round 51 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 51 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0389
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0349
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2351, R²: -0.0151

============================================================
🔄 Round 53 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 53 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0361
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0396
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2351, R²: -0.0151

📊 Round 53 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2351, R²: -0.0151

============================================================
🔄 Round 55 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 55 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0327
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0546
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2351, R²: -0.0151

============================================================
🔄 Round 57 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 57 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0293
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0665
============================================================


============================================================
🔄 Round 58 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 58 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0430
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0157
============================================================


============================================================
🔄 Round 60 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 60 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0306
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0631
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2351, R²: -0.0151

============================================================
🔄 Round 64 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 64 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0348
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0430
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0147

============================================================
🔄 Round 67 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 67 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0394
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0246
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0147

📊 Round 67 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0147

============================================================
🔄 Round 69 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 69 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0364
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0360
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0147

============================================================
🔄 Round 72 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 72 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0402
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0227
============================================================


============================================================
🔄 Round 73 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 73 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0401
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0281
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0148

📊 Round 73 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0148

📊 Round 73 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0147

============================================================
🔄 Round 78 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 78 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0343
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0459
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0146

📊 Round 78 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0146

============================================================
🔄 Round 80 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 80 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0408
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0306
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2351, R²: -0.0145

============================================================
🔄 Round 81 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 81 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0378
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0362
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2351, R²: -0.0144

============================================================
🔄 Round 82 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 82 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0380
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0267
============================================================


============================================================
🔄 Round 83 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 83 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0325
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0484
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2351, R²: -0.0143

============================================================
🔄 Round 85 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 85 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0394
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0309
============================================================


============================================================
🔄 Round 86 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 86 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0270
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0673
============================================================


============================================================
🔄 Round 90 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 90 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0413
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0155
============================================================


============================================================
🔄 Round 93 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 93 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0365
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0366
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0144

============================================================
🔄 Round 94 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 94 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0316
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0568
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0144

📊 Round 94 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0143

📊 Round 94 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0143

============================================================
🔄 Round 100 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 100 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0346
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0406
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0142

📊 Round 100 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0142

📊 Round 100 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0142

============================================================
🔄 Round 104 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 104 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0375
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0590
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0141

============================================================
🔄 Round 106 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 106 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0365
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0482
============================================================


============================================================
🔄 Round 108 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 108 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0431
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0820
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0141

============================================================
🔄 Round 109 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 109 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0322
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0508
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0141

============================================================
🔄 Round 110 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 110 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0337
   Val:   Loss=0.0984, RMSE=0.3138, R²=-0.0431
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0141

============================================================
🔄 Round 111 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 111 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0401
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0268
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0141

============================================================
🔄 Round 113 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 113 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0350
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0438
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0141

============================================================
🔄 Round 114 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 114 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0297
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0593
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0140

============================================================
🔄 Round 116 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 116 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0393
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0244
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0140

============================================================
🔄 Round 121 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 121 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0365
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0314
============================================================


============================================================
🔄 Round 123 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 123 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0298
   Val:   Loss=0.0972, RMSE=0.3117, R²=-0.0560
============================================================


============================================================
🔄 Round 124 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 124 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0465
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0055
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0138

📊 Round 124 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2350, R²: -0.0138

============================================================
🔄 Round 129 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 129 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0333
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0593
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2350, R²: -0.0137

📊 Round 129 Test Metrics:
   Loss: 0.0776, RMSE: 0.2787, MAE: 0.2350, R²: -0.0137

📊 Round 129 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0137

============================================================
🔄 Round 136 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 136 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0308
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0538
============================================================


============================================================
🔄 Round 137 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 137 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0418
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0164
============================================================


============================================================
🔄 Round 141 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 141 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0335
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0909
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0136

============================================================
🔄 Round 143 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 143 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0293
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0599
============================================================


============================================================
🔄 Round 144 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 144 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0390
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0184
============================================================


============================================================
🔄 Round 146 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 146 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0361
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0583
============================================================


============================================================
🔄 Round 147 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 147 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0312
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0529
============================================================


============================================================
🔄 Round 148 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 148 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0429
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0057
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0136

============================================================
🔄 Round 149 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 149 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0362
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0416
============================================================


============================================================
🔄 Round 151 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 151 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0282
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0633
============================================================


============================================================
🔄 Round 152 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 152 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0350
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0419
============================================================


============================================================
🔄 Round 153 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 153 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0375
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0391
============================================================


============================================================
🔄 Round 154 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 154 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0341
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0384
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0136

============================================================
🔄 Round 155 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 155 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0424
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0299
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0136

📊 Round 155 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0136

============================================================
🔄 Round 157 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 157 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0349
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0396
============================================================


============================================================
🔄 Round 158 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 158 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0354
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0452
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0136

============================================================
🔄 Round 160 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 160 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0352
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0385
============================================================


============================================================
🔄 Round 161 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 161 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0307
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0492
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2351, R²: -0.0136

============================================================
🔄 Round 163 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 163 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0393
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0183
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2351, R²: -0.0136

============================================================
🔄 Round 166 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 166 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0421
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0216
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2351, R²: -0.0135

============================================================
🔄 Round 168 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 168 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0351
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0345
============================================================


============================================================
🔄 Round 169 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 169 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0291
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0547
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2351, R²: -0.0135

============================================================
🔄 Round 170 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 170 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0347
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0333
============================================================


============================================================
🔄 Round 171 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 171 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0362
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0297
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0135

============================================================
🔄 Round 176 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 176 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0287
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0608
============================================================


============================================================
🔄 Round 177 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 177 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0357
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0318
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0135

============================================================
🔄 Round 178 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 178 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0352
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0361
============================================================


============================================================
🔄 Round 180 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 180 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0277
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0609
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0135

============================================================
🔄 Round 182 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 182 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0313
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0552
============================================================


============================================================
🔄 Round 183 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 183 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0382
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0249
============================================================


============================================================
🔄 Round 185 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 185 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0402
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0300
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0135

============================================================
🔄 Round 186 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 186 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2977, R²=-0.0403
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0112
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0134

📊 Round 186 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0134

============================================================
🔄 Round 193 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 193 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0290
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0600
============================================================


============================================================
🔄 Round 194 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 194 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0369
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0270
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0134

📊 Round 194 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0134

============================================================
🔄 Round 200 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.1008 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.1008, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.1008, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.1008, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.1008, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.1007, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1008)

============================================================
📊 Round 200 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0302
   Val:   Loss=0.1008, RMSE=0.3174, R²=-0.0546
============================================================


============================================================
🔄 Round 202 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 202 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0391
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0158
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0134

📊 Round 202 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0134

============================================================
🔄 Round 205 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 205 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0284
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0642
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2350, R²: -0.0134

============================================================
🔄 Round 209 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 209 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0364
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0373
============================================================


❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
