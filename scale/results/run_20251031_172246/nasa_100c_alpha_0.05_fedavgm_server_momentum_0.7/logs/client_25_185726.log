[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df75117-41f1-4442-a7fa-3bfa4f36ee4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 037d639f-caac-47cf-a09e-88b7d8f6821c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 108a3098-c804-47a1-b5b8-bd4f4e8dc3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c317f501-c798-4b3a-8f90-12c664a99354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f3cd4e6-40fd-4d17-9714-b86e79eb84e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a3ea9c0-1a2b-405e-b3d9-5ebac501103d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d10678c-aca3-43b0-a368-22876e296dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b42a39-9d6d-4daf-bc3b-f123001e8827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68aad7ac-702a-4bba-a756-d6d9fe25b470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04aa8c8a-657a-4b46-b5a1-070c7f1b8fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e09d6d6f-ecc3-4999-a6f8-8ad5067beda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4711310-ea66-4b72-951b-05891c7fff1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb7e748b-249b-4d1e-9efc-99523cf1da54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6394742a-a8c7-4d66-877a-e5af945feb8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2fb2828-e87e-48bc-b70f-9a5238cf50dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170c3dcd-82e0-4bd5-af41-f12a5b964255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19667c9-6758-48f2-ba8f-74c339d7fbb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc330317-1095-4824-8a53-3e7b54e39034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5332d26-10d0-46d9-9c5a-3fff174814eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c058adc5-14c4-4224-8b2d-926721eb89e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82fcd9be-1d53-462a-bee5-0e4fa35972ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dd15611-da69-41e4-8a9d-cddfb709f5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d24909f-874d-4069-bf83-ebe4516a9cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47dd56d3-75ce-4897-8541-c1eb24fe4039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ab24eb9-938e-424b-9e4f-1336cc439b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06ac88f0-f86b-42cb-b9c0-bc4714fa0112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b3ddd74-e528-42b6-9a01-2d08452dcb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a603e84-e8b2-4196-9667-dcd4c4a84788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f375ad4-18c3-4a89-a7e6-97e25f7ccc15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a763529f-0b3d-464d-b58f-0b99225af31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e391e399-58d5-4455-b8ef-164c1ec2dcd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e97f9a-90f0-45ad-be97-d26647295224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd9ca05c-977f-4265-9a64-bee11591079d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2c8ddb1-b7d7-440d-828b-54175a63cd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b86b1544-e427-4015-a761-0401fa21c228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 322b6d69-2b81-4a59-97ea-b3f9493f514f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62cbb78f-fe56-41ed-b4eb-b685fefe5b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce154274-7c86-4a51-9c7f-7168ce17d534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff6a2cf-f718-44bc-aee6-26932549ff71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea439c4-a91e-46ea-bd15-979631a20b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae16a53-9b80-4b96-a56c-52e5d8aa3706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bacbff6-8145-402b-a2cb-49e9a32bc448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd222ac9-86ce-4189-bad8-29c92f1c4d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f46f37-a9a3-45a6-abb9-dc767593e1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be6131f6-47e9-467d-bf61-38062276ef39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d34d2f0-a9ae-42a9-9f24-6c0f2005045e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 415fdc7f-36b0-4496-bc4f-a910fec79db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c4ae8a9-7f95-49d7-9337-b0dd2828f573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2834572f-f478-4639-89c2-a010c8a26047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a7f418-f244-4dd8-bdd8-42f018d31d94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a3c66b-caf1-4f65-908e-faf80db1ba82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042ead0f-c7b6-404c-b624-18a8f90878b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55030a31-4d00-475e-8e43-4c47154f01c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b7bffb0-45c8-477c-a503-cd6966222181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63c89b2-f2b8-492a-8717-e0783b2c5d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fba431d-bee0-4e40-9b64-660f03801817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3e1543-f951-46af-841f-111fc68125fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2eefedb-a121-41e9-8e7f-ffac295f3d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d952b0b5-4290-4267-811f-d20d6cd1c199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2640a583-15da-401b-87f2-567e3b42ff12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66357d3d-033c-414f-9c36-d933d8666735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b4a4ff-d830-4e9c-af42-5b3cbb4d9b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bb70e28-e500-4582-ab72-149d798082e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28c2287-d6d2-4e74-955e-30736de31dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2354fb8e-ce13-4bf9-a4f9-c720a74287b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b41f24f-95f7-4c84-aa49-86aecddce8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b98fe56-8520-4d57-8cf2-4c1ff37f86f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35b687dd-2b57-4373-b956-d1e38a6d3bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae6ebdf1-d778-4c8a-b006-dc6cf449ba8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d470511-f064-4e12-a4dc-b3da39328ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a763fb7-33d4-4d49-9c1f-9f2798be2d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aaec9fb-6a37-40fe-b6ad-9bf52b29f7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc51481-54b4-488b-9533-d90d242e9ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1daed6e-84af-45fd-b6e0-b2932083f7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f1f391-a3a5-4b0d-98b9-97b43dfb2342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e61c1c3b-6c64-4a1d-a120-371bdd629c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d134043-128f-43cd-bdcf-fa8d161f6b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3d1242-f801-499d-8bd8-ad36399618b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be481768-55bc-44a6-8532-a78fb6eab93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f1e7357-32b7-4afc-877e-e617b1d6aef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaf72a9f-a27f-4762-95fe-b5932591b5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 489d4b40-9531-4191-a35f-51eb896b21af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9edc131e-6d4b-433f-9161-ef2d182ff967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02340aa-05fd-4de9-9739-19ee5f014543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb3834e-02ff-43b3-8d72-fe8c2c77f637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a091d9-50e0-4925-8ce4-f2f9b9ceb5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a245058-7f34-4beb-ad74-fdcfcf495c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4747baa4-7b49-4e27-9cd6-42c2d37d8443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b5707f0-0e5f-42f5-8c08-81d0a7b20363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859fbe1a-ce81-4df8-b437-5e7f6f448a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3996fe0b-aa7f-4208-b609-e533a7e1fff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1becc9-725a-4087-8ed2-704d90e105a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2dbbbcb-dfd8-4965-b6dd-043a374b352f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2483b3b1-4b9d-42a1-ae95-279a5e9cfe5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2941e41d-ce77-45e9-b4b2-1d4fd921510e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9122a6-ac57-4e71-b808-fb8c60492066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3552678-2257-4585-8700-a09a087637a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30096ad9-f12f-4846-b180-16f813b5e4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a21a8f-4bdc-4651-9486-410026c04023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5fe017-81e0-4830-90ac-f7e4d28292ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9016d9e-81a5-4356-b38b-8ca3cef9d6fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c90bff86-14c1-48a6-8477-cce535bb9759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18c8f1e0-776c-440c-a707-a0625e71e6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d263454-a310-4cbe-8569-e967ace45fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6230453-6baf-426d-b77d-1b0a5c09c462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a21b710-5915-4dbb-a3fd-43d31c3d4480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50ad29a-a118-49db-9370-49881131490b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b650561-5a0c-44af-b3b3-349850124600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54c1104-2c07-4318-8aa6-ceb28415f8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80824a1f-b58f-4bf7-9b65-13b4a3fc092b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 723d11f3-50ce-44b9-9588-4d612978ce23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2df05b9-f0eb-42df-a486-dfdcdfbc85c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9efd8a5a-b12e-433f-9d35-d5f260f00243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937c0868-1a0f-4ced-990c-e48ab3de5a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c2628f-523f-40eb-9678-e904e93465aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff639d69-254b-4d03-8f1b-41422e63649b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 749e3953-12c4-4b14-9c2b-601d6b13618c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9948d13-b3e1-47fe-a1d2-8ad2ae538338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7d2c10-fc75-49f4-b4bc-2e4941e08596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f644dbf6-9810-4eae-a168-4cc3acde49af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3cb4400-1eab-4e1f-ada2-f8778b0f3b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42fb678d-8873-4436-b64e-5df1739d15e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f28e6bca-d646-459a-9c80-a1e21f591cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd64202-eb38-4784-a26e-33f2521d1500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5441237f-2e4f-48b1-9c47-ff8e7dd2c99e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44228a75-81a2-41c9-924a-d0eb627b3b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4929af7-0bb1-4ad5-bdef-a2ad5ac8a4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21695705-6ebb-4aeb-8645-5c2073c48c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dafc643-d1e1-4ecc-a4e6-7c6a0eaa97f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9051ad67-3a36-4595-bf14-aff80b55f3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ade1bcc-456a-4191-a9d1-5960a6d4e058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72da7ab1-9062-4062-ae8b-8d2f379553fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70227c83-09ea-46c5-b449-54004ad1a939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61403071-2d9e-4a3f-8384-e3d4344b8ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98898280-19c0-4ef3-a719-3d8e8d4a5d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db03aa2a-632c-4fb0-b69c-104df59baa90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7523c88-cb0c-411e-ad04-1c5b1f08e05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd84771a-5114-43d8-83be-fbf0e8ed1fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 277e408b-5ea2-4dd9-8025-53d5e7277f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cba7821-bf3b-4b0c-b1af-79e0618db1c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61dbaa67-365a-4c77-ae97-b11b82b8f79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa239be1-f786-43a3-a12d-39a543174e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cc11ce7-9859-465d-b8ff-dea6c890030a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9a5d39-bd94-4a7d-a751-ddb34abf9708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 541584e8-1be8-47ed-979f-ad3076fae742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8fc3f42-7018-4e7b-8c1a-1ab4c109e88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea65b6ff-8f0b-4038-9650-7fa9aed7d795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fafa694-acce-4595-851a-71f7caafee30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21aa1e0b-b8bd-45f0-9635-5281b4472f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 796c2eb9-c97c-4993-b759-e2c676689ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2837b01f-db74-4515-9f72-1b8dd7797a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 335de5c1-1ab0-40d0-b9d1-9de9d7df3561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 712b395c-3426-4722-a9b7-fee957216717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0bdc2f5-f5a2-4ba4-ad54-cacc27024730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab77f62-d1db-490e-8b97-a0a6b2342a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2faeac04-fc4a-48a4-a6ed-76eff2b96587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39feb282-6abb-46c1-9e09-d4131c8914e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48830279-8d2b-4dba-9482-7e7a9ff5929a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64a1d44-885a-4ae6-b0e2-f8c5bbc36138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac776850-b233-40e7-8a03-821330b347f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4288f2c3-d317-4fb6-814a-6502ee4d1601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460852cf-a7b5-4baf-98af-066afd36c196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf3cce39-a728-4088-bccb-e0f85bbdbd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 185efe5f-c39d-4f84-800d-96d00d9d74bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795039c8-f5e2-4fbd-8feb-d763215e3545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 099bd062-c014-46bf-9128-5ee01cd20537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fbf338f-f247-47b8-8af3-ae11f62c3f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cd1fb2-4beb-47f6-b8fb-c065f9dbdab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b2ce21-1d84-4b0e-859f-2372baf32ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3446911-e1fa-41eb-bec1-de9255726af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ad63d0-c36a-4ace-b9f1-5711e1a70590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874a12b0-3213-4195-9e1c-cb0aa62a3286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1259f2-2bc6-4e64-afb3-08a6e8c3bcdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d6813c1-a5aa-4cb9-bb7d-a9f75ce454fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74948af4-d30e-48d2-aaaa-3fc562e9fb53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e596ef1f-3b91-45c2-b55f-b9289c6990ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 230a43e9-de6a-409e-92f8-79d16c6bbcc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dede1ae8-1fbf-4b86-81a9-f6785dcf7e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9fd136b-ab86-4452-b03b-e1afc7d7d026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374b5818-058d-4523-9603-a878c2c26f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 235026eb-4729-48a1-918f-3f74aeddee66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 622b1817-64f6-42f1-8f92-afb4cb49785c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_25
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/test_labels.txt

📊 Raw data loaded:
   Train: X=(1671, 24), y=(1671,)
   Test:  X=(418, 24), y=(418,)

⚠️  Limiting training data: 1671 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  409 samples, 5 features
✅ Client client_25 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2532, R²: -0.1401

📊 Round 0 Test Metrics:
   Loss: 0.1115, RMSE: 0.3339, MAE: 0.2752, R²: -0.4111

📊 Round 0 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2498, R²: -0.0931

============================================================
🔄 Round 9 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0906 (↓), lr=0.001000
   • Epoch   2/100: train=0.0830, val=0.0909, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0827, val=0.0914, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0824, val=0.0915, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0821, val=0.0920, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0790, val=0.0950, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 9 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0110
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0418
============================================================


============================================================
🔄 Round 10 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0823 (↓), lr=0.000250
   • Epoch   2/100: train=0.0851, val=0.0826, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0845, val=0.0822, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0844, val=0.0822, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0843, val=0.0823, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0836, val=0.0825, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 10 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0041
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0104
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2410, R²: 0.0070

📊 Round 10 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2436, R²: -0.0205

============================================================
🔄 Round 12 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0751 (↓), lr=0.000125
   • Epoch   2/100: train=0.0865, val=0.0747, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0864, val=0.0747, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0862, val=0.0747, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0860, val=0.0747, patience=4/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0852, val=0.0748, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 12 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0023
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0082
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2408, R²: 0.0084

============================================================
🔄 Round 16 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0831, val=0.0917 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0823, val=0.0910 (↓), lr=0.000031
   • Epoch   3/100: train=0.0818, val=0.0905, patience=1/15, lr=0.000031
   ✓ Epoch   4/100: train=0.0814, val=0.0902 (↓), lr=0.000031
   • Epoch   5/100: train=0.0811, val=0.0900, patience=1/15, lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0798, val=0.0895, patience=3/15, lr=0.000016
   📉 Epoch 17: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0792, val=0.0893, patience=13/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 16 Summary - Client client_25
   Epochs: 23/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0354
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0143
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2383, R²: 0.0283

============================================================
🔄 Round 17 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0799 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0853, val=0.0798, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0852, val=0.0798, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0852, val=0.0797, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0852, val=0.0797, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0850, val=0.0795, patience=10/15, lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0848, val=0.0793, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 17 Summary - Client client_25
   Epochs: 28/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0101
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0273
============================================================


============================================================
🔄 Round 18 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 18 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0048
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0209
============================================================


============================================================
🔄 Round 20 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 20 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0064
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0148
============================================================


============================================================
🔄 Round 21 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 21 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0049
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0072
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2378, R²: 0.0346

📊 Round 21 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2386, R²: 0.0284

============================================================
🔄 Round 25 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 25 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0134
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0120
============================================================


============================================================
🔄 Round 26 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 26 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0122
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0054
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2401, R²: 0.0153

📊 Round 26 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2407, R²: 0.0109

============================================================
🔄 Round 28 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 28 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0106
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0048
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2408, R²: 0.0096

============================================================
🔄 Round 29 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 29 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0141
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0055
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2410, R²: 0.0087

📊 Round 29 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0081

============================================================
🔄 Round 31 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 31 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0084
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0165
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2411, R²: 0.0072

============================================================
🔄 Round 35 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 35 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0059
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0038
============================================================


============================================================
🔄 Round 36 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 36 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0086
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0211
============================================================


============================================================
🔄 Round 37 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 37 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0032
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0407
============================================================


============================================================
🔄 Round 38 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 38 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0135
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0004
============================================================


============================================================
🔄 Round 39 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 39 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0139
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0057
============================================================


============================================================
🔄 Round 43 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 43 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0159
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0091
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2411, R²: 0.0069

📊 Round 43 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2411, R²: 0.0070

📊 Round 43 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2411, R²: 0.0073

============================================================
🔄 Round 53 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 53 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0089
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0223
============================================================


============================================================
🔄 Round 54 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 54 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0060
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0189
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2410, R²: 0.0082

============================================================
🔄 Round 56 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 56 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0114
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0044
============================================================


============================================================
🔄 Round 57 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 57 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0059
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0333
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2410, R²: 0.0087

📊 Round 57 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2410, R²: 0.0089

============================================================
🔄 Round 60 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 60 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0116
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0065
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2410, R²: 0.0088

📊 Round 60 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2410, R²: 0.0084

📊 Round 60 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2411, R²: 0.0079

============================================================
🔄 Round 67 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 67 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0094
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0056
============================================================


============================================================
🔄 Round 68 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 68 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0171
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0181
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2410, R²: 0.0083

============================================================
🔄 Round 69 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 69 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0054
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0427
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2410, R²: 0.0085

============================================================
🔄 Round 71 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 71 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0177
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0079
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2410, R²: 0.0089

============================================================
🔄 Round 73 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 73 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0192
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0209
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0092

============================================================
🔄 Round 74 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 74 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0174
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0190
============================================================


============================================================
🔄 Round 76 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 76 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0079
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0269
============================================================


============================================================
🔄 Round 78 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 78 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0084
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0117
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2410, R²: 0.0090

📊 Round 78 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2410, R²: 0.0083

📊 Round 78 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2410, R²: 0.0084

📊 Round 78 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2409, R²: 0.0099

============================================================
🔄 Round 91 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 91 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0082
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0307
============================================================


============================================================
🔄 Round 92 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 92 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0118
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0030
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0104

📊 Round 92 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0108

📊 Round 92 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0110

============================================================
🔄 Round 96 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 96 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0054
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0243
============================================================


============================================================
🔄 Round 97 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 97 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0141
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0021
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0107

============================================================
🔄 Round 98 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 98 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0084
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0289
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0107

============================================================
🔄 Round 100 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 100 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0091
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0160
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0106

============================================================
🔄 Round 101 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 101 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0165
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0205
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0106

============================================================
🔄 Round 104 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 104 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0138
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0071
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0107

============================================================
🔄 Round 105 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 105 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0072
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0381
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0108

📊 Round 105 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0109

============================================================
🔄 Round 107 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 107 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0156
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0018
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2408, R²: 0.0111

📊 Round 107 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2407, R²: 0.0113

============================================================
🔄 Round 110 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 110 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0069
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0228
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2407, R²: 0.0113

============================================================
🔄 Round 112 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 112 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0079
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0139
============================================================


============================================================
🔄 Round 113 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 113 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0111
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0208
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0108

📊 Round 113 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0106

============================================================
🔄 Round 119 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 119 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0104
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0238
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0104

📊 Round 119 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2408, R²: 0.0102

============================================================
🔄 Round 125 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 125 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0135
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0011
============================================================


============================================================
🔄 Round 127 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 127 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0141
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0042
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2409, R²: 0.0098

============================================================
🔄 Round 128 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 128 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0170
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0035
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2409, R²: 0.0099

============================================================
🔄 Round 129 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 129 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0105
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0170
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2408, R²: 0.0100

============================================================
🔄 Round 130 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 130 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0088
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0229
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2408, R²: 0.0102

============================================================
🔄 Round 131 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 131 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0136
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0092
============================================================


============================================================
🔄 Round 132 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 132 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0176
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0050
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2408, R²: 0.0100

📊 Round 132 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2409, R²: 0.0098

============================================================
🔄 Round 134 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 134 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0144
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0049
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2409, R²: 0.0097

📊 Round 134 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0095

============================================================
🔄 Round 137 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 137 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0162
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0001
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0093

============================================================
🔄 Round 142 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 142 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0096
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0147
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0091

============================================================
🔄 Round 144 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 144 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0169
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0053
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0095

============================================================
🔄 Round 147 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 147 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0137
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0086
============================================================


============================================================
🔄 Round 149 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 149 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0146
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0038
============================================================


============================================================
🔄 Round 150 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 150 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0060
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0074
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0093

📊 Round 150 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0092

📊 Round 150 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0092

============================================================
🔄 Round 153 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 153 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0090
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0246
============================================================


============================================================
🔄 Round 154 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 154 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0021
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0359
============================================================


============================================================
🔄 Round 155 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 155 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0146
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0025
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0093

📊 Round 155 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0092

============================================================
🔄 Round 157 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 157 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0154
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0026
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0092

============================================================
🔄 Round 158 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 158 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0093
   Val:   Loss=0.0831, RMSE=0.2884, R²=0.0138
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0091

============================================================
🔄 Round 159 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 159 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0039
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0416
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0091

============================================================
🔄 Round 160 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 160 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0160
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0134
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0090

============================================================
🔄 Round 161 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 161 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0165
   Val:   Loss=0.0712, RMSE=0.2668, R²=-0.0098
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2410, R²: 0.0089

============================================================
🔄 Round 163 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 163 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0107
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0037
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2410, R²: 0.0088

📊 Round 163 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2410, R²: 0.0088

============================================================
🔄 Round 165 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 165 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0107
   Val:   Loss=0.0983, RMSE=0.3135, R²=0.0160
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2410, R²: 0.0089

============================================================
🔄 Round 168 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 168 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0152
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0219
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0093

============================================================
🔄 Round 170 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 170 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0083
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0275
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0094

============================================================
🔄 Round 171 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 171 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0152
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0082
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2409, R²: 0.0095

============================================================
🔄 Round 173 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 173 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0139
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0052
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2409, R²: 0.0098

============================================================
🔄 Round 175 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 175 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0114
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0015
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2409, R²: 0.0100

============================================================
🔄 Round 176 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 176 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0064
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0151
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2408, R²: 0.0101

============================================================
🔄 Round 178 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 178 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0109
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0188
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2408, R²: 0.0103

📊 Round 178 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0103

============================================================
🔄 Round 180 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 180 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0154
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0120
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0105

📊 Round 180 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2408, R²: 0.0108

============================================================
🔄 Round 184 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 184 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0152
   Val:   Loss=0.0740, RMSE=0.2719, R²=-0.0035
============================================================


============================================================
🔄 Round 185 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 185 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0079
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0313
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2408, R²: 0.0110

📊 Round 185 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2407, R²: 0.0114

============================================================
🔄 Round 193 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 193 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0141
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0084
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2407, R²: 0.0116

📊 Round 193 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2407, R²: 0.0116

============================================================
🔄 Round 195 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 195 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0121
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0169
============================================================


============================================================
🔄 Round 196 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 196 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0175
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0019
============================================================


============================================================
🔄 Round 198 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 198 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0143
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0101
============================================================


============================================================
🔄 Round 199 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 199 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0110
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0226
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2407, R²: 0.0119

============================================================
🔄 Round 200 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 200 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0129
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0061
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2407, R²: 0.0116

📊 Round 200 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2407, R²: 0.0114

============================================================
🔄 Round 204 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 204 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0086
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0166
============================================================


============================================================
🔄 Round 206 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 206 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0135
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0040
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2407, R²: 0.0113

============================================================
🔄 Round 207 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 207 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0172
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0085
============================================================


============================================================
🔄 Round 208 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 208 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0143
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0095
============================================================


============================================================
🔄 Round 211 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 211 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0147
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0066
============================================================


❌ Client client_25 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
