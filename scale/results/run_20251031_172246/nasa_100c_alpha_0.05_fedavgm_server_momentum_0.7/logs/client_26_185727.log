[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec36fd3f-b78f-4fe1-9e3a-4c08e7593e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f66505f4-1a96-4831-ad4e-96667746533b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b802041-e8b8-438a-9666-8b42c707e2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fced090-c2b9-4646-a228-912e8356eeea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27695973-fcf7-4506-ac36-61a8f9a49e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee00444-3874-45a9-9595-b7088c98a2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c4cfbc2-1cf6-443a-8efa-33b75937b28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672f83b4-1d79-424c-9a58-4adfbec6b7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb74c6ba-5af8-4f9b-9eb0-92225d2b30d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4167c9fe-3535-4690-8817-786e5289e7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080fa2b8-e777-4f07-bdcb-136753a6dda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df44d22c-9e14-44ce-850d-8d2d58404327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cbcb2be-fa54-4cee-bcdd-34d1223ae701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a9cf7d-20fd-49eb-87cc-5e3d66f77d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549f4886-6fbc-458a-960e-e710587f2c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235c8071-21d7-4282-8f93-3fa48892161e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19cc8026-1f56-4b2c-b001-8ab8aa071733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5420f397-6413-437e-a863-50e0cd39c0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14456640-c930-4053-bade-bf1779b5e34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00f4e0b-cbc8-42d8-a9f2-c44eb7674d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db39d94f-1137-4a5a-8e1b-efe2a83912b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e469da-ac53-4828-98ba-0ae37aa8ba97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43bb1deb-4969-4b4e-8544-00a58010830d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b40725d8-0258-439e-b6c3-27e5d94484de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2847afa3-5211-464b-a57c-330fa9a0cc19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9219ce4-0743-4f2c-8865-eb16dd5c3695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0525718-24d8-4a4a-9d49-1b147d8e88a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0fe787e-b8e5-4605-a932-bdf7578689e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a52a6f66-1c81-4a26-82af-452d1dfc1dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a9deb7-4b1b-4af7-a290-e3e5ea7f3f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db5760e9-3746-47c0-856d-d7885fec6e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9286a93d-bf90-4588-87a1-f1ad1f8050ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01047e96-4b67-4fa1-b91f-d72dd7264bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d15d25-4ac7-43b3-9b43-19669b9e8945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f140dd7d-ab61-4c70-bd11-702eb55fe3d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354fb080-237a-4b1a-9430-91952534c611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbe0d209-f1c3-4571-924b-59a23f2042be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80192cf-683c-4b7a-b319-e29fc6a8caff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b2219a-be38-4d67-912c-dc43cd1db0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6b36e9-9ae1-445b-90ef-36b57790ed5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9c02dbe-ef2a-4dc8-96ac-125d5829e4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a0565fb-90f1-4220-8e6a-499cd5e8ed01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message debac7ba-3d58-469b-a5a2-a0f4318bc83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a3ef63d-eb11-4a91-8a68-9099ab8703ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a953b101-5151-495b-bb35-25818ae935be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a9b4b51-6205-4d7d-acb1-8efa01c5a14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72aa2192-846a-4784-b088-3c73cbd7fc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852d52a5-5303-4401-9b48-6896a71bec8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff186700-8274-4ead-a0a9-7fa6f3ad25af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4771947-bb16-4431-b303-1e60e110f47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b4986f-8304-46b6-9a7f-0c070face42b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6351f937-5cc4-4e6e-8c27-22bbac885840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26fa15cb-dc2a-4787-aca5-7ae82ec3c3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd02e51-4814-43fb-a55e-610fbec17176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a685438-558a-41d7-af41-47952f46ee34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ce4798d-b7a0-4067-939a-43ee43f9738a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a436f70-e931-4e26-85ae-c8bb04454bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 242256ae-12e2-43b3-b032-e047d8af0121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a643c45b-b445-4832-9237-3678d55a3d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b52fe6-4864-4080-b69c-878f86861766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2afe7606-8081-4896-afb6-b6a2f72b9b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9df4239e-91a7-4cb7-90b4-2364a11fa8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d8adf9-f960-4f48-adc6-a3aca1a16be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec7da520-f292-4a71-aee3-9bf101cd6c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b82b7b-991c-443a-9e53-b0ceaf770248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd77e9a4-9f9a-4039-b800-28048108770a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8397000a-37ad-411e-9879-6ed8c5c47431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 335e87d6-d4e4-4288-bdf3-a6dc42fa776e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0881631-17a5-462a-9f33-2c8fef313472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92123304-fb2a-492b-b2e9-fa4fbc7b3849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cafb6344-4892-41a8-b39d-01535373ff6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2bbcb31-8056-423f-9465-f7fe9d1e6f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00af724e-d486-44a3-83d9-7206731f74e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8ea1b1-f969-4dfd-be99-dae17ff54cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34313dbd-be79-47a9-81c8-a14ba93eb7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9e65c0-88bb-40db-9aa7-d1d203614ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd5cd62-5e27-4ff2-92c8-023f0e7b65f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6483f9c4-ef4b-480c-ba22-8f45fc279f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 957fe1bb-ab00-4017-868b-c6654b80416a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fa6e428-ef3a-488c-a1b8-161cd0dccdda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 917929e6-09e2-4c04-a3ae-3d9958d2a28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bea41e-2e8f-4f4c-ac66-60690a9cbaf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 049260c6-2521-4588-b31d-66d6f3b7d599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd7deee6-373b-45cb-b28b-ce8bf6f07aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dba2e21-2bf5-48a4-bdd8-595c222f7407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b1232bc-e994-4cc3-b3de-e17b41737fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0dd9ce-f469-4b90-b383-a0b1eef12ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7782d4c2-524f-4a32-9f01-bc981e211edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c0ad69-43eb-4c95-b778-d609c5764558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0ec1649-d034-4b5f-89d8-5fad94462e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 999e4254-255c-452a-bc81-30ad16064abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 483acf0f-4e03-40fa-8b30-b1c3cbbb3cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78feb1b4-8ea8-468f-a852-6a0e1ff3b753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed1c3b1-62b0-49d2-8b83-dd174659ba44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d98b4ba4-1322-4be6-b1f0-3626d12000b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c603a545-9773-4862-9e52-3db26a6240fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f70b9a-7424-4f7e-a78a-e942c8e90357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e219eb17-ea70-4f0e-87a9-93ffac496dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b705653-9716-4cfa-bfb0-336e632f9bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a36b4a9-b331-410a-88d9-e381a751d489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beed2b8c-9065-493f-a095-7973ba7dc1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09369174-cb86-45c9-a829-3dd5e2c3bcfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ce75842-d09c-4d59-94ae-727f7122a48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ef1e05-8e90-4a9b-b3ea-7e6bb872de91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 539e0b14-3f96-4815-b0bd-d199dedfeab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 814e7d89-1ae1-4b05-9e55-7c093c565170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a33285-6c73-40ab-aab2-cf2e63c18573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 290b626f-ffcb-47d8-97cb-1e6404711f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28511f09-c168-47ca-a927-91da40129295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51fbf79b-48ca-49a5-96f1-6431c4e76610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdfe8f8d-1af8-4090-8ce6-5baccbf80ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15df9cc-1354-476c-bf95-1db6c4495ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5334fede-8825-4f85-87b1-57fb28dbab57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 470af674-e39c-484d-ac99-0d00f0b2fc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488041d2-1af1-4eb9-a5cf-cef2fcce50c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21915fcf-f0aa-478c-93f6-2eaf73f945b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34379c8-31a0-41dc-b4fc-fb3bdd396d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1edb1c9-c81a-47ea-83f1-aca69d9e27bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cb2d19e-6b0b-4b0a-97c7-18f1e8ad17eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a089794f-ec1c-4726-a61b-d1692577c3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b277baa-dca9-4c85-87f5-40046c41b7bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d08207d-19d3-416d-8222-526a4f3105f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c9f8655-52ae-4d8a-8d36-398452d5a7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ead56b-536c-4f06-95ef-7452cade1ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8ce5962-8d01-4313-b3e4-aa15c068ca3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e7d4df-bb38-4f01-aeaa-a7b0ca534262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f323e145-f23a-42f5-8efd-4892562a1ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c77bcaee-fc8d-46d9-a28b-ad751951d52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a66e25-b5d2-4861-8e26-0b378cccd74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 588d55d0-e8c9-4844-bce4-60a246c5d997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc220425-9ff3-4906-9616-0d18bcb4f748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2400f3-aec1-4841-a588-750ab3919bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c78651-5aa3-41e3-bee1-254ec46ce53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad0b03b-eac1-41b7-ae20-d8bdffca5531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4a5848-1132-46f6-aca6-96ddec01de24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 061f80f8-6c6b-4df8-bee1-d5a3cf2d3940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6171d61a-3a99-4d65-bbac-f999b70c580c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0d9525a-b22e-4535-ac62-e619abb8ceed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a59a9b-4bbd-4808-9992-ac375b073edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d52d9c-e582-4237-a032-57106e30ecfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c71685-0a00-4197-ab8e-7ca9c86733cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ceb5615-63f9-408f-a35d-140d7c2c67b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e199ad1-28ae-477c-b086-6a3b879645a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f00929bc-3843-4ba0-bb44-63a90a0299eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974e13e9-6dae-418f-b3aa-b2b8bf328368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e41dbe-44c8-4509-b9d9-ff4a19cf6337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d8e519-e6c4-4910-b983-269a5726fc80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6a9866-e6c7-4b6f-a7c5-fdd54a01e6c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 579fad48-6e26-46f4-b177-1063c9b06ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a06ef19-aa5a-4e9b-bac7-0a045c9a0257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message debc5ad7-6ab0-4adb-b4c7-74b868a1c725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71649734-84c9-454c-86e4-b55542378360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9275713-2d91-4804-abc4-52c1085b822d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c7d6d82-66ab-4aa7-b2f5-1ecc14bfded2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ebbfc0-a7a4-4c2f-afd8-7a7b93b1ed6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5761c7c7-5947-45ae-8ca5-3eb8024307e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e18242-7899-4039-8560-5b66bc25c990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fa65517-3d78-4303-b566-975f16f346de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02ab605-a1ea-442c-abfb-0ac3bebcfc59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00cbc99d-de07-4ad2-9dac-22ac6adf6404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd03c56-1676-47a5-bb2f-535a9b7cc5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73aa896-ccff-4133-a6d2-e2c99879c522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e25076e7-d58d-4610-a729-49bac1af131f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33923f7-a7d2-4675-8ff3-04e2eba2afd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff581b2a-9621-40d2-94ed-26f4ecb2b2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a731a9a-efd9-4556-9bf4-e3fa23760199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2774e884-9254-4838-8091-66a3d91bf4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f32724-dcb6-40d4-bba8-ed4650729081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da4cc4f-2b74-4821-a714-be1155d8a7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12161b52-dc3f-49bd-acf5-bb53be7b152a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edaea1ce-9cbc-4780-a444-f0115c60cc95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db14088-c2aa-421c-9e93-6a7b284abfc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122185df-9fa5-48a6-9774-a3fc8afa1636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d93d3c4-dd69-4e2c-92bc-3eecd47ddb19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aeff91a-003f-4b66-8f86-889730358661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c67e5cc8-6915-4a9d-bba9-f1c879bf020f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f0246c-57e1-4908-9aa5-d9ebf2945ef4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_26
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/test_labels.txt

📊 Raw data loaded:
   Train: X=(1231, 24), y=(1231,)
   Test:  X=(308, 24), y=(308,)

⚠️  Limiting training data: 1231 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  299 samples, 5 features
✅ Client client_26 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0995, RMSE: 0.3154, MAE: 0.2716, R²: -0.1571

============================================================
🔄 Round 8 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0893 (↓), lr=0.001000
   • Epoch   2/100: train=0.0794, val=0.0893, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0791, val=0.0892, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0788, val=0.0892, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0784, val=0.0893, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0756, val=0.0890, patience=3/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0672, val=0.0905, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 8 Summary - Client client_26
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0571
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0065
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2629, R²: -0.0601

============================================================
🔄 Round 9 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0870 (↓), lr=0.000500
   • Epoch   2/100: train=0.0795, val=0.0879, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0797, val=0.0873, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0793, val=0.0876, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0792, val=0.0877, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0783, val=0.0881, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 9 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0056
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0043
============================================================


============================================================
🔄 Round 10 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0852 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0812, val=0.0811 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0809, val=0.0803 (↓), lr=0.000125
   • Epoch   4/100: train=0.0808, val=0.0804, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0807, val=0.0805, patience=2/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0803, val=0.0805, patience=8/15, lr=0.000063
   📉 Epoch 17: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 10 Summary - Client client_26
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0191
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0127
============================================================


============================================================
🔄 Round 13 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0822 (↓), lr=0.000031
   • Epoch   2/100: train=0.0806, val=0.0820, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0801, val=0.0820, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0797, val=0.0821, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0795, val=0.0821, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0790, val=0.0825, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 13 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0133
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0057
============================================================


============================================================
🔄 Round 14 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0744 (↓), lr=0.000008
   • Epoch   2/100: train=0.0817, val=0.0744, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0816, val=0.0743, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0816, val=0.0743, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0815, val=0.0743, patience=4/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0813, val=0.0744, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 14 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000004 (1 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0275
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0026
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2592, R²: -0.0193

============================================================
🔄 Round 15 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0787 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0811, val=0.0787, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0811, val=0.0787, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0809, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 15 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0323
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0508
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2594, R²: -0.0191

============================================================
🔄 Round 18 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 18 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0187
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0095
============================================================


============================================================
🔄 Round 21 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 21 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0013
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0839
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2592, R²: -0.0222

📊 Round 21 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2591, R²: -0.0218

============================================================
🔄 Round 23 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 23 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0208
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0259
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2592, R²: -0.0211

📊 Round 23 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2598, R²: -0.0222

============================================================
🔄 Round 25 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 25 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0193
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0287
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2603, R²: -0.0203

============================================================
🔄 Round 29 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 29 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0170
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0271
============================================================


============================================================
🔄 Round 30 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 30 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0078
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0549
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0875, RMSE: 0.2959, MAE: 0.2602, R²: -0.0182

============================================================
🔄 Round 32 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 32 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0169
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0233
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2602, R²: -0.0173

============================================================
🔄 Round 35 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 35 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0222
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0037
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2602, R²: -0.0170

📊 Round 35 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2602, R²: -0.0167

============================================================
🔄 Round 38 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 38 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0153
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0047
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2602, R²: -0.0164

============================================================
🔄 Round 41 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 41 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0131
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0361
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2602, R²: -0.0160

============================================================
🔄 Round 42 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 42 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0214
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0006
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2602, R²: -0.0159

============================================================
🔄 Round 44 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 44 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0179
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0021
============================================================


============================================================
🔄 Round 45 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 45 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0142
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0273
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2601, R²: -0.0155

📊 Round 45 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2601, R²: -0.0154

============================================================
🔄 Round 49 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 49 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0212
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0073
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2601, R²: -0.0153

============================================================
🔄 Round 50 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 50 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0228
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0019
============================================================


============================================================
🔄 Round 51 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 51 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0210
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0098
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2601, R²: -0.0151

📊 Round 51 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2601, R²: -0.0150

📊 Round 51 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2601, R²: -0.0149

📊 Round 51 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2601, R²: -0.0147

============================================================
🔄 Round 57 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 57 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0181
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0208
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2600, R²: -0.0144

============================================================
🔄 Round 60 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 60 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0200
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0155
============================================================


============================================================
🔄 Round 62 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 62 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0136
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0320
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2601, R²: -0.0141

============================================================
🔄 Round 67 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 67 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0222
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0031
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2600, R²: -0.0138

============================================================
🔄 Round 69 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 69 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0132
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0415
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0872, RMSE: 0.2952, MAE: 0.2600, R²: -0.0136

📊 Round 69 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2600, R²: -0.0134

============================================================
🔄 Round 72 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 72 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0193
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0130
============================================================


============================================================
🔄 Round 74 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 74 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0138
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0417
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2600, R²: -0.0131

============================================================
🔄 Round 75 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 75 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0144
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0395
============================================================


============================================================
🔄 Round 76 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 76 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0144
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0349
============================================================


============================================================
🔄 Round 78 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 78 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0188
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0053
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2600, R²: -0.0129

============================================================
🔄 Round 80 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 80 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0193
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0191
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2600, R²: -0.0130

============================================================
🔄 Round 83 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 83 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0218
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0048
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2600, R²: -0.0130

📊 Round 83 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2600, R²: -0.0130

============================================================
🔄 Round 85 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 85 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0220
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0044
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2600, R²: -0.0130

============================================================
🔄 Round 86 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 86 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0188
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0067
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2600, R²: -0.0128

============================================================
🔄 Round 87 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 87 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0296
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0283
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2599, R²: -0.0126

📊 Round 87 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2599, R²: -0.0125

============================================================
🔄 Round 89 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 89 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0132
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0172
============================================================


============================================================
🔄 Round 90 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 90 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0200
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0170
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2599, R²: -0.0122

============================================================
🔄 Round 91 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 91 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0177
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0203
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2599, R²: -0.0121

============================================================
🔄 Round 94 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 94 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0163
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0256
============================================================


============================================================
🔄 Round 95 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 95 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0044
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0765
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2599, R²: -0.0116

============================================================
🔄 Round 96 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 96 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0231
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0139
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2599, R²: -0.0116

📊 Round 96 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2599, R²: -0.0115

============================================================
🔄 Round 99 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 99 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0163
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0273
============================================================


============================================================
🔄 Round 100 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 100 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0205
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0035
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0114

============================================================
🔄 Round 103 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 103 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0232
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0054
============================================================


============================================================
🔄 Round 104 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 104 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0145
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0282
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0113

============================================================
🔄 Round 105 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 105 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0180
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0151
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0113

============================================================
🔄 Round 106 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 106 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0219
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0001
============================================================


============================================================
🔄 Round 107 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 107 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0175
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0231
============================================================


============================================================
🔄 Round 108 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 108 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0262
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0178
============================================================


============================================================
🔄 Round 109 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 109 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0216
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0116
============================================================


============================================================
🔄 Round 110 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 110 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0141
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0437
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0112

============================================================
🔄 Round 115 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 115 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0202
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0127
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0113

============================================================
🔄 Round 119 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 119 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0124
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0439
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0114

============================================================
🔄 Round 123 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 123 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0210
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0032
============================================================


============================================================
🔄 Round 125 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 125 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0214
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0089
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2599, R²: -0.0115

============================================================
🔄 Round 129 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 129 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0214
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0093
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0113

📊 Round 129 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0112

📊 Round 129 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2598, R²: -0.0112

📊 Round 129 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2598, R²: -0.0112

============================================================
🔄 Round 133 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 133 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0106
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0293
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2598, R²: -0.0113

📊 Round 133 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2599, R²: -0.0113

📊 Round 133 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2599, R²: -0.0113

============================================================
🔄 Round 137 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 137 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0223
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0008
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2599, R²: -0.0112

============================================================
🔄 Round 141 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 141 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0213
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0011
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2599, R²: -0.0110

============================================================
🔄 Round 143 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 143 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0169
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0168
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0107

============================================================
🔄 Round 146 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 146 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0233
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0069
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0106

============================================================
🔄 Round 148 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 148 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0190
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0116
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0106

📊 Round 148 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0106

📊 Round 148 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0106

📊 Round 148 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0104

============================================================
🔄 Round 156 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 156 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0171
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0265
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0104

📊 Round 156 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0104

============================================================
🔄 Round 159 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 159 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0205
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0063
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0105

📊 Round 159 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2598, R²: -0.0105

============================================================
🔄 Round 162 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 162 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0174
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0071
============================================================


============================================================
🔄 Round 164 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 164 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0175
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0190
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2598, R²: -0.0103

============================================================
🔄 Round 168 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 168 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0196
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0077
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2598, R²: -0.0101

📊 Round 168 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2598, R²: -0.0099

============================================================
🔄 Round 172 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 172 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0171
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0202
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2598, R²: -0.0098

============================================================
🔄 Round 173 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 173 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0265
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0152
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2598, R²: -0.0097

============================================================
🔄 Round 174 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 174 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0264
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0259
============================================================


============================================================
🔄 Round 175 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 175 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0236
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0211
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2598, R²: -0.0096

📊 Round 175 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2598, R²: -0.0096

📊 Round 175 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2597, R²: -0.0095

============================================================
🔄 Round 178 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 178 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0169
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0290
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2597, R²: -0.0094

📊 Round 178 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2597, R²: -0.0094

============================================================
🔄 Round 181 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 181 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0159
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0242
============================================================


============================================================
🔄 Round 183 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 183 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0185
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0228
============================================================


============================================================
🔄 Round 186 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 186 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0269
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0155
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2597, R²: -0.0090

📊 Round 186 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2597, R²: -0.0089

============================================================
🔄 Round 190 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 190 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0192
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0145
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2597, R²: -0.0088

📊 Round 190 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2597, R²: -0.0087

============================================================
🔄 Round 193 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 193 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0222
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0078
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2597, R²: -0.0087

============================================================
🔄 Round 194 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 194 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0272
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0089
============================================================


============================================================
🔄 Round 197 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 197 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0144
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0309
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2596, R²: -0.0085

============================================================
🔄 Round 198 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 198 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0212
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0154
============================================================


============================================================
🔄 Round 199 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 199 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0194
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0237
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2596, R²: -0.0085

============================================================
🔄 Round 201 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 201 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0222
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0106
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2597, R²: -0.0086

============================================================
🔄 Round 203 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 203 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0175
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0183
============================================================


============================================================
🔄 Round 204 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 204 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0208
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0170
============================================================


============================================================
🔄 Round 207 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 207 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0187
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0230
============================================================


============================================================
🔄 Round 208 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 208 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0184
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0249
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2597, R²: -0.0086

============================================================
🔄 Round 210 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 210 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0163
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0319
============================================================


============================================================
🔄 Round 211 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 211 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0218
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0093
============================================================


❌ Client client_26 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
