[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c47a8733-a5a0-4e31-8033-bc0e66296716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5a331ef-9b87-42ab-9ab4-045b29c0f435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25171130-26cf-4b8b-88f7-457af0b5159b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa7ca5d-840e-4ec4-9499-71899a667bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e427b87d-dcf0-4373-a8b9-552ed2b8a405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d057a9-9276-47f2-b99c-c53da5c662bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403b5a79-2fe8-4087-81bd-8e6b79f5d7cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c20f047-6e84-4da4-b1df-374d62263185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 977e3f3d-ccce-4c6b-9970-8b746fe2539f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5192ab8b-a91d-40e7-89a2-6713b8e2aa58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf7066a-2c5c-4239-81d1-edda4ae51c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ef7db5-e3a7-42ee-b23d-bc75cf745160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d0ff34-ebc9-44f8-9791-77f50cb4c396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd05dbd-ef02-4939-9a0e-156e3e9bac75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01962fa3-e989-4829-8ff0-7ef87e0e3a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db9dc33-2f98-4ae6-a0ed-69321572cd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19cc4a37-8b0a-4d9a-ba2a-b7fff40bd08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a06645b-687d-43e1-9121-8136079e9daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcae645c-5749-45fb-9731-46a275725fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd0f925-5e0b-4950-a326-0d845fa22ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f95a6bb-269c-4de0-9df8-ffb678c44fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddf4e2e-8701-4f64-95d1-2c66ef20295d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c573c550-16b0-4e23-bad7-8b0c5c7ea610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f8f203-d62c-4d8d-adfd-81544a31670f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7757efc-4e8f-4f7f-8646-1744188f3acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8035b2c7-6c9c-46d9-851b-a8b8f8b8f965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e7169ad-f865-4eb9-a202-9c472d17be18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b95f16-c3ed-48d8-b869-ac12e9b72e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc771c72-4df3-4ca2-94b7-f34730cd2a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d8836e-f9e8-4daa-9027-7fd0a0e25bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8282b6af-1f0c-42cf-98f4-d7821ee3331a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae65a018-7dc8-4fba-babe-da79c322fdf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6689e24b-8e93-40b4-9002-deede7d73341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 474c0ab4-4428-43f8-99ee-9cafc7fb2a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 872ce7e9-1fc1-42ec-ab27-a4829ca0b735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da15a31-c1cd-4411-a1af-5d95ba92da10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4109a8f8-9a26-43b5-95df-0f6a22b62088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce4fe3a-0a2b-4906-877c-80e4e2834f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d8e6db-8a9b-42da-aad6-700dbc58425a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5add68d3-5c91-4536-a99c-be244afb681d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1f999e-9a39-49b1-a270-e945d3e84d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92a35091-db21-4b4e-a9ed-f3b7ea18936d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b29790-9f0e-4351-83f6-7812dfb7313f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61d9bbd4-e220-422c-be1f-004aa0a28961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d70d89f-9aa7-4f77-aae3-a282d268fb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5271a54f-b3e8-442f-b6dc-a4dcb1044d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33138787-6e72-4cd4-aaac-67d02f42d66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7254c18-9adb-4fa5-966a-d2e7ca87a362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b520cc69-ef22-458f-900d-f5e7814264f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891da3cc-c04e-420d-8ce3-156cb350198f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6129cae6-1251-4cfb-97fd-50525e1e6e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91df2418-06c0-43fd-9330-cffffe250cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb385c2b-bab6-4d57-9af0-753888b69e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15eac45a-40aa-4147-a348-4387fd1b31c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31863ca0-7be4-4887-8e0d-9068894f1879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8ad6dd-85ca-412d-8986-467a36a4f234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c037e9c9-7cd9-4c97-8a09-ff30b634139e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f71a390-7d3b-4972-b102-98341a107f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4882e45d-e998-493f-ac9b-7f99f572f02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac7d04f-56e4-4aee-97b3-dc98d5aeb95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dee0466-4e6a-4d4b-9b35-d975b1dc2f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c936c71d-834e-43a1-b3f3-f1d2aad4dab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 882e3158-c35d-49bb-92ff-07c04f35900a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 538b49e0-e33d-4d28-b182-04cfcc2eba7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91b2e595-dc46-406c-81fa-1d79da5a3ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9a74ee-f301-401a-9ab9-cd1bc54fdeac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 461ca90e-73a8-464a-a95d-593283694e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cb19f80-930a-410f-9275-c18d6aa37623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eba81118-74e8-40a1-9241-ffbb947ab6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f604bb-5772-4876-b1eb-69cd0b8e62ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b39a145-1ccd-4bf1-a7df-47be6507cfed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc63b1f-29e0-422f-8af1-c9d807e6303b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b3366c9-3b58-46fc-a824-869ee3b81ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad26efe2-659f-436f-b72f-a87b8d98858c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 918492fb-77c9-4659-bc83-bda63a8ca37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60c93569-0746-4e2b-9794-cc95beba62a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85460e09-f283-436e-b944-bcabfa938dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56bee684-f0f9-442e-8f17-fe2fb1278a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7cd4a98-a17b-413d-aab8-fa889d90155d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a310cbee-594f-4e5c-9727-88816a9a6085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be043dc9-4169-4b72-a472-b58a65f877cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42af9544-6ed7-4de9-8a51-ca6379e8d4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 207f176b-66cb-4acc-95db-7a4bb19ec570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dd94aa7-d4c5-497c-9c9d-9f8e5606b29e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3360ffd6-b5b3-4ca4-8fed-e60f2a0684cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 898963b2-7e58-4e8d-aa84-7e0218592c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c61ce3ce-d7b1-4ccc-92c8-e7ee8519e2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25033708-5030-4914-b368-05b015a81008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f38f7e-3e61-4ab0-b5a3-72e8d6486fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcbaa430-1c7d-4aa9-b6f7-3288185047d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 954b3db3-c044-495f-875b-2f965dcf96d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f60e294-5ae1-4617-b825-50abe473597f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad960f0d-a5a9-4d03-91be-a546a7991121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08be758-4397-4e51-8425-28c182552c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e62a90bc-d73a-4b4f-a335-8fc716ae7a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f04e41fa-09ba-4a31-b101-3b1de7f1dc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e53f4b92-2e31-4832-a393-467bd3b4322e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891fff69-986d-4856-96d2-29b3bbfd1bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff3b4609-4c7c-4e2b-a3a0-233b37bd7c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e0e864-62f5-4c09-a66a-2c3e36cd8b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78abe94a-3835-46a6-8e16-b1ea464f73a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f10dc73a-523e-4f06-837e-3ef02303cd10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee1a71a0-a9fe-4506-aa17-f2eeea48ad86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f960a59-7a09-4955-92f0-1d82a9c7f34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b78529b5-7a5e-46b6-b7b5-2dd2d7b55ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d00de9-dbe0-4055-a328-02cb5625c14d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8b7656-f577-48e0-9723-efc9cd1577a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9356541-30ee-45fe-aa01-21f802e9f154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bdb69c1-66d7-4aac-81d7-8f0c2ffcf383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abdd212c-3233-421a-92a0-01ba30927a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29fe6cff-9988-483f-a14c-79fa9b32e5d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b81c3dc9-ed32-4741-a1c9-76cd5e84699e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975f3b70-4cdf-4500-8485-46daa26c479b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867af14c-817c-4fce-ad98-fc1c5744353e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 280e11ed-77f2-4f84-ad6f-efa476bcbd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e49ca5-dfa9-4db2-9457-9755a0f837c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b4cd57-ecdb-4c7a-8d8f-cd024e3a4b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96de5102-667c-4682-b500-1e3df0fd1a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2791ae59-7e6b-4089-818e-5d267e3f55d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0637f84-832a-43b0-a66c-64dd33fc2212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af8e8ef7-9275-4c9a-a0d5-6de93e1a956a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e864dff-87b6-4362-a884-8dd9a409cffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8967e5de-6a43-4a8e-b0b0-f3e7e710f665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 779e4646-eb7f-4fba-9beb-6d8e705a1531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1cb51a3-82ff-47b2-a867-1e68a768d619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bcd41f7-f8bb-4bea-9fe5-bc1d68369425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b88621c-3711-40db-bfb4-5aab5bba93aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb17a2cf-8f1e-4d9a-a634-d7094de4c6b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d51b4d9-5cb4-4833-b391-6c71ed8172f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641e2a09-5bce-4a7a-9562-c2dc8552bea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023149df-ce16-481d-bf59-e7cc09c47c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665429f9-4c33-4bdb-a3fa-337613c925d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e28271c-f7e3-4af3-904f-776ed09d6a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7ae0117-dfe8-4777-bacb-64e66294cf30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582e16bf-3b51-4440-bb21-d0224c20cc06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a1528f-a10a-44a7-a3b8-dcc382013539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7665a65-2872-431b-90da-78e6dc42b0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce8e9026-2b92-4611-bfe3-2dee5bdd1043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77dc4317-92c2-469f-9c52-885d02cbbcfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf5092a-5101-4ab5-8b4a-33160cdde8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caa42ebd-ec36-46c8-8e38-21919a649263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc01173d-1bc0-4d14-b5c7-acb1cf9c5700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0478ab19-7000-4925-9d56-b61923556615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4095a3f3-b3f5-4f4c-bd10-36761573dddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c09296a-6435-4bed-9cf1-34da5f2f823a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01bb8dac-3d0e-41bd-ade8-a5db4e82178e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6896e138-1ce3-4c5f-82ff-69e80fe4a856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e561d971-ffa2-4c3e-94df-475173d2659e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 848753e2-52dc-451e-8c81-d4e59381f1b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e110d7f-2da5-49b2-a42d-c2031b197fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae39d02-6819-4d48-95f6-70b3ec4c4640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ff4ba61-7511-470a-9ca2-2cfa656b0c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca57d685-7e2f-4bd4-a207-70228f22a4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf4c45e-05fc-43c4-85cf-1ec57a7c9239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2046f1b-b69a-4f43-80f1-89f71e0945ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af100704-4535-4074-ba92-15249e1b1db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea157d0-a678-4d25-9a66-4f218226575e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c591ef-9649-4362-bc22-4cf1282475d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0348c66a-baef-4a9b-bb16-44bb835ed48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffead6b-d097-4496-bcbe-416361d58a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0a16c9-9d6f-4a80-8bab-71b01e54038e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a84dd230-ba2f-472f-9714-5ee3cb79221a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2702c0b-1ad6-4d75-af34-f3664521b60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c27f3fab-ac08-4779-b39c-279101132f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 754fe22e-b9e3-40c0-be19-f0c8c0e17be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e417ff7-6596-44b7-8a5c-7982eb5de740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95bd48d3-05ed-4200-b235-b9bc4bd34bce
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_28
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/test_labels.txt

📊 Raw data loaded:
   Train: X=(1617, 24), y=(1617,)
   Test:  X=(405, 24), y=(405,)

⚠️  Limiting training data: 1617 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  396 samples, 5 features
✅ Client client_28 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1240, RMSE: 0.3522, MAE: 0.2848, R²: -0.5357

📊 Round 0 Test Metrics:
   Loss: 0.1176, RMSE: 0.3430, MAE: 0.2879, R²: -0.4566

📊 Round 0 Test Metrics:
   Loss: 0.0906, RMSE: 0.3010, MAE: 0.2579, R²: -0.1220

============================================================
🔄 Round 7 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0839 (↓), lr=0.001000
   • Epoch   2/100: train=0.0856, val=0.0849, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0853, val=0.0856, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0849, val=0.0869, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0843, val=0.0881, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0799, val=0.0956, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 7 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0090
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0184
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2449, R²: -0.0007

============================================================
🔄 Round 10 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0863 (↓), lr=0.000250
   • Epoch   2/100: train=0.0852, val=0.0866, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0848, val=0.0868, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0846, val=0.0871, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0844, val=0.0873, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0838, val=0.0878, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 10 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0005
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0085
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2455, R²: -0.0042

============================================================
🔄 Round 11 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0917 (↓), lr=0.000063
   • Epoch   2/100: train=0.0843, val=0.0918, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0842, val=0.0919, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0841, val=0.0919, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0840, val=0.0920, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0836, val=0.0921, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 11 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0023
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0165
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2496, R²: -0.0407

============================================================
🔄 Round 14 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0766 (↓), lr=0.000016
   • Epoch   2/100: train=0.0891, val=0.0765, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0889, val=0.0765, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0887, val=0.0764, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0885, val=0.0764, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0879, val=0.0764, patience=10/15, lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 14 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000008 (1 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0136
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0031
============================================================


============================================================
🔄 Round 15 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0839 (↓), lr=0.000008
   • Epoch   2/100: train=0.0873, val=0.0838, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0872, val=0.0839, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0872, val=0.0839, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0871, val=0.0839, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0869, val=0.0838, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 15 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0102
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0126
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2450, R²: -0.0070

============================================================
🔄 Round 18 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0921 (↓), lr=0.000002
   • Epoch   2/100: train=0.0856, val=0.0921, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0856, val=0.0921, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0855, val=0.0921, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0855, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 18 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0222
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0032
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2493, R²: -0.0392

📊 Round 18 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2489, R²: -0.0369

============================================================
🔄 Round 20 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 20 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0076
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0314
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2476, R²: -0.0283

📊 Round 20 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2461, R²: -0.0199

📊 Round 20 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2463, R²: -0.0149

📊 Round 20 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2468, R²: -0.0177

============================================================
🔄 Round 26 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 26 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0002
   Val:   Loss=0.0970, RMSE=0.3114, R²=0.0134
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2473, R²: -0.0208

============================================================
🔄 Round 28 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 28 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0072
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0258
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2472, R²: -0.0199

============================================================
🔄 Round 29 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 29 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0066
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0239
============================================================


============================================================
🔄 Round 30 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 30 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0057
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0293
============================================================


============================================================
🔄 Round 31 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 31 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0036
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0077
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2472, R²: -0.0183

============================================================
🔄 Round 32 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 32 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0070
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0186
============================================================


============================================================
🔄 Round 33 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 33 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0094
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0376
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2471, R²: -0.0180

📊 Round 33 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2471, R²: -0.0179

📊 Round 33 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2471, R²: -0.0176

============================================================
🔄 Round 37 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 37 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0002
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0004
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2470, R²: -0.0173

📊 Round 37 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2470, R²: -0.0171

============================================================
🔄 Round 40 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 40 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0015
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0117
============================================================


============================================================
🔄 Round 42 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 42 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0038
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0108
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2469, R²: -0.0166

📊 Round 42 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2469, R²: -0.0165

============================================================
🔄 Round 45 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 45 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0010
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0008
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2469, R²: -0.0163

============================================================
🔄 Round 46 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 46 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0062
   Val:   Loss=0.0959, RMSE=0.3098, R²=-0.0184
============================================================


============================================================
🔄 Round 47 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 47 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0010
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0012
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2469, R²: -0.0160

📊 Round 47 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2469, R²: -0.0157

📊 Round 47 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2468, R²: -0.0155

============================================================
🔄 Round 53 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 53 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0053
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0184
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2468, R²: -0.0150

============================================================
🔄 Round 58 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 58 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0053
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0124
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2468, R²: -0.0149

📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2467, R²: -0.0147

============================================================
🔄 Round 60 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 60 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0021
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0227
============================================================


============================================================
🔄 Round 61 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 61 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0028
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0004
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2468, R²: -0.0148

📊 Round 61 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2468, R²: -0.0150

============================================================
🔄 Round 64 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 64 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0044
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0035
============================================================


============================================================
🔄 Round 65 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 65 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0037
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0042
============================================================


============================================================
🔄 Round 66 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.1025 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.1025, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.1025, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.1025, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.1025, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.1025, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1025)

============================================================
📊 Round 66 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0044
   Val:   Loss=0.1025, RMSE=0.3202, R²=0.0086
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2468, R²: -0.0149

============================================================
🔄 Round 68 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 68 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0018
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0022
============================================================


============================================================
🔄 Round 71 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 71 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0003
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0151
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2467, R²: -0.0141

============================================================
🔄 Round 75 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 75 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0081
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0222
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2466, R²: -0.0136

📊 Round 75 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2466, R²: -0.0136

============================================================
🔄 Round 78 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 78 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0024
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0039
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2466, R²: -0.0136

============================================================
🔄 Round 80 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 80 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0101
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0273
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2467, R²: -0.0138

============================================================
🔄 Round 82 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 82 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0036
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0024
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2467, R²: -0.0141

📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2467, R²: -0.0142

📊 Round 82 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2467, R²: -0.0138

============================================================
🔄 Round 88 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 88 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0047
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0041
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2466, R²: -0.0134

============================================================
🔄 Round 91 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 91 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0083
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0177
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2465, R²: -0.0124

============================================================
🔄 Round 95 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 95 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0055
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0150
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0122

📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0123

📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0123

============================================================
🔄 Round 99 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 99 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0041
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0008
============================================================


============================================================
🔄 Round 103 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 103 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0021
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0007
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0123

============================================================
🔄 Round 104 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 104 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0017
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0118
============================================================


============================================================
🔄 Round 106 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 106 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0044
   Val:   Loss=0.0931, RMSE=0.3052, R²=0.0009
============================================================


============================================================
🔄 Round 107 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 107 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0002
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0174
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0119

📊 Round 107 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0119

📊 Round 107 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0120

============================================================
🔄 Round 112 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 112 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0094
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0202
============================================================


============================================================
🔄 Round 113 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 113 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0045
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0023
============================================================


============================================================
🔄 Round 114 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 114 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0003
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0135
============================================================


============================================================
🔄 Round 115 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 115 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0047
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0328
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0122

📊 Round 115 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2465, R²: -0.0122

============================================================
🔄 Round 119 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 119 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0036
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0008
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2465, R²: -0.0126

📊 Round 119 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2465, R²: -0.0127

============================================================
🔄 Round 121 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 121 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0083
   Val:   Loss=0.0996, RMSE=0.3156, R²=-0.0368
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0129

============================================================
🔄 Round 124 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.1000 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.1000, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.1000, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.1000, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0999, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1000)

============================================================
📊 Round 124 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0068
   Val:   Loss=0.1000, RMSE=0.3162, R²=-0.0369
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0130

============================================================
🔄 Round 126 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 126 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0022
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0262
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0130

📊 Round 126 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0129

📊 Round 126 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0128

============================================================
🔄 Round 133 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 133 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0022
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0202
============================================================


============================================================
🔄 Round 136 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 136 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0031
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0160
============================================================


============================================================
🔄 Round 137 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.1035 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.1035, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.1035, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.1035, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.1035, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.1035, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1035)

============================================================
📊 Round 137 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0023
   Val:   Loss=0.1035, RMSE=0.3217, R²=-0.0146
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0130

📊 Round 137 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0130

============================================================
🔄 Round 142 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 142 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0020
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0207
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0129

📊 Round 142 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0127

============================================================
🔄 Round 146 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 146 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0009
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0062
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2465, R²: -0.0124

📊 Round 146 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2466, R²: -0.0125

============================================================
🔄 Round 150 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 150 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0048
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0091
============================================================


============================================================
🔄 Round 152 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 152 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0014
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0014
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2466, R²: -0.0124

============================================================
🔄 Round 155 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 155 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0017
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0039
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2465, R²: -0.0123

============================================================
🔄 Round 156 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 156 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0029
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0015
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2466, R²: -0.0124

============================================================
🔄 Round 157 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 157 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0033
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0023
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2466, R²: -0.0124

============================================================
🔄 Round 158 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 158 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0044
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0045
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2466, R²: -0.0124

============================================================
🔄 Round 160 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 160 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0007
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0077
============================================================


============================================================
🔄 Round 161 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 161 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0017
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0152
============================================================


============================================================
🔄 Round 162 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 162 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0073
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0247
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2466, R²: -0.0125

============================================================
🔄 Round 163 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 163 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0078
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0301
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2466, R²: -0.0125

============================================================
🔄 Round 164 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 164 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0050
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0107
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2466, R²: -0.0124

📊 Round 164 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2466, R²: -0.0123

============================================================
🔄 Round 169 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 169 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0046
   Val:   Loss=0.0969, RMSE=0.3114, R²=-0.0097
============================================================


============================================================
🔄 Round 170 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 170 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0013
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0147
============================================================


============================================================
🔄 Round 171 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 171 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0004
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0121
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2465, R²: -0.0116

📊 Round 171 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2465, R²: -0.0115

============================================================
🔄 Round 176 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 176 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0061
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0308
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2465, R²: -0.0114

============================================================
🔄 Round 178 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 178 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0039
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0011
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2465, R²: -0.0114

============================================================
🔄 Round 179 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 179 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0046
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0035
============================================================


============================================================
🔄 Round 181 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 181 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0098
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0288
============================================================


============================================================
🔄 Round 182 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 182 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0080
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0166
============================================================


============================================================
🔄 Round 187 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 187 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0039
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0290
============================================================


============================================================
🔄 Round 188 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 188 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0008
   Val:   Loss=0.0951, RMSE=0.3083, R²=0.0174
============================================================


============================================================
🔄 Round 189 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 189 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0060
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0175
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2463, R²: -0.0104

============================================================
🔄 Round 196 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 196 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0021
   Val:   Loss=0.0940, RMSE=0.3067, R²=-0.0240
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2463, R²: -0.0103

============================================================
🔄 Round 198 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 198 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0017
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0119
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2463, R²: -0.0102

============================================================
🔄 Round 199 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 199 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0062
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0060
============================================================


============================================================
🔄 Round 200 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 200 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0010
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0101
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2464, R²: -0.0104

📊 Round 200 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2464, R²: -0.0105

📊 Round 200 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2464, R²: -0.0105

📊 Round 200 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2464, R²: -0.0105

📊 Round 200 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2464, R²: -0.0106

📊 Round 200 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2464, R²: -0.0106

❌ Client client_28 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
