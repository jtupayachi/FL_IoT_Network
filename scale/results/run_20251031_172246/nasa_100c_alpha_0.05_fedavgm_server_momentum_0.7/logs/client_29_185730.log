[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3469987-9a1c-4df8-98a9-ca96fae39be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d9b490b-1556-4c9d-9be5-e4738f9a7f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b2f4a5f-8f57-4418-b8d1-3b897108ff02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4baf1458-cfbe-4e9b-82ed-2a41d586df31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1758c2f9-6360-4224-a4e8-ac1509566f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1296d2-b07b-427f-a7ce-e12e4c9ac01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f03d8ba-1000-486b-a4f5-2fb5914c019a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3a5ef1-d9fe-44b9-9083-9cd2d2e2b4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a986c81-eebe-46df-9d51-1f428f819683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b52deb-8c99-4c92-91f4-b7c8d52f5081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8771cd3-f018-4d12-83df-3783cbd39d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc87ab6e-6ddf-437c-abec-a82d43afb7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2782dd2-4883-4d6f-a386-ac7337fea104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e51b8237-05aa-45c9-8152-b1b96de6a275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd5b09e-d404-41e0-b217-8bacc6f450b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c789bc3-a326-43c9-b3a8-7bd843ac517f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29f0d5dc-8014-48e2-889e-5ebba1a76f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c38ea014-cfdb-464d-af48-a527404afb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a69f881-06af-445a-82bd-772a8543bdc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbe7eb6d-2f5b-4f37-a1cd-d775d9c9581f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c6a683-2ec1-432e-9a1e-f9ba1ec8b2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7263903a-bf72-4d3a-848e-4c237a5bf61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3594fb1c-d68b-473d-add3-e133b3f6572a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8fb437-c26b-4526-9e55-881b5b40e722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3205a4cd-eb6e-47d3-b3cf-def05cf82ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 416b28df-680d-4829-912b-e760f958e833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37e50b6b-8598-4057-b713-f112a5f8e97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e1944d-f4d2-4204-99ed-7600dd528018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c197d105-690e-4db7-ae60-1d609f928596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6719876c-c629-41e8-9cb9-2d1e25a18589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b6599db-c4ae-4e50-81a0-4fd911ad7454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b1fcdd0-b09d-4c40-917f-6d562378a7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5631c59c-fa3a-4fc6-a037-4772ed14be56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f452a77e-9261-4ab7-a04c-90f52bcfc15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6bf6932-5f1a-4c6d-8dca-095a179c2a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf5a455-89d8-49fe-9d47-c0a9d30fb0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda61255-7105-4a8d-8e2a-f840c97fcd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f53daac-eba7-4808-b610-7ab19b4cd012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e9c3a4b-1bdd-43a0-81e4-9a60885c075f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f669219-fb26-49ce-831a-f8bf31a3af49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c05b3405-3027-46c1-b625-6df5d4d3984a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 730bd1de-7ff9-4cb0-ba87-d0ada755d827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c38877d9-dc58-48b1-b133-88bae73635a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e18d142-7556-45f4-ac1f-ed87d4b979a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a069d662-0c91-42f0-84e8-3f735887eb28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f341b5-058f-4bfc-884a-67dbe4e5f0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b43248d-1dcd-4e69-81d4-c690453cd184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b28ddbb-f284-47b7-9d1c-e8952fae38d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a0b86d-6e1f-4d52-a413-05729b6d29a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86460223-083f-4e8c-8b92-9ca7f85f805c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc73310-cc38-4618-b77e-ae6819695f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321979bd-086b-44c7-b5a8-e0aeed910bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a217c1-0a6e-4451-a4d3-aac8c64fccff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c3f6644-f01f-405b-b4f5-6e1424048597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf9b041a-49d3-4100-b901-f6359b0f8b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59a16df2-379f-44f0-bf43-8f0df1bf7b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ee33b9-b95b-4d03-b408-4bbe88d1e8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf77f8e2-bf2c-44da-8e31-729f26d7787d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dac048-f50e-482e-9d10-7eadf9ef3510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cddfb45-c329-4bdf-be4a-5a1a935bde70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11058c09-1e43-4724-9b4e-63b720d412fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e918429e-a9a1-49d0-b66d-8ce22549cfea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93393c49-465c-4c08-9f26-f14606e59c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1428cebc-8692-4104-a1e0-04ebfb88e8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0be38d95-5ec0-4add-a369-79f1ee95a12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e8c6a8-0ea9-417a-8fed-70501cb4c3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e362cf-e921-403c-ad6d-6546b307e4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c46d1e2c-5b21-4eb4-9f65-288d486ba324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1e4d5d4-bd9b-4014-9489-c97d01a16c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4f063c2-5bb9-47b6-a882-f37c86032da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccc894ee-d940-4ac0-8b5a-9f23f17a6c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e2b12c-207c-457a-9ac4-65d0e6b4db56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b4eac2-437a-47a7-82fd-988e328a2254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1b3df1-9f13-409c-a089-b3ef7c7f7766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33842307-8fa4-456c-b653-401c1d13a87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d80827-f86a-45b3-b847-08da47e7ab51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb925d47-a3d1-461b-aac1-f596d39b159a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93626a11-ede7-4e77-83ef-2bb25487058f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87c3a96-601f-4780-ae1d-aa3f730d3bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13670d38-7442-4e29-add0-ff4284019bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 274c6cb5-dee3-45d3-97d5-354e54bc8591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8fa6a7-458a-41d3-bc47-ec7e40f5fa50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e66a376a-cff2-41fe-83af-3ed84093e946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac93861a-66f0-439e-876a-88a231f7ea07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0489939d-093c-4da5-8131-7ac170579b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b15ec4-5ff2-4672-9dfd-78294d652663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beca3bb6-5fd2-462b-9ae4-4f3ad3d24d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b293d125-f461-4ad1-b37f-cacb5d0d61ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11dab48-cef7-4826-931f-4086ddc09afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6d8097-b0b0-4964-92b5-4a309b73d464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9abcea5-3daa-4cc5-bb12-1db3ea463093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba8f019e-f0ac-4ba0-b665-5f00377655fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0c5a418-bc7d-490c-a0c4-5c3b007985e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bdd92a5-c05f-48e1-b283-3807af18d2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 465dc415-2bfc-4e7a-ac41-c8e58248422d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f9766d6-7c00-4e1e-bf0c-144da9e82eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1415f378-2d11-48af-9f1a-1377ba00718d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0718a678-12f9-4bdd-9e76-856c5d1d036a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e49c034-d6bc-478d-bba5-9cb73b67de47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d6122e-1123-418e-a248-c646c779c083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a76a10-4739-4152-8e2b-a4537d6c8669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec73017a-4fd4-43f4-a8b6-1f92b63d782f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 163aa4a0-5077-41fe-8e4e-c1e2f05d0f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bf27722-7899-4096-b2da-d582319cf6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60d6e237-9861-4a2c-8fee-d53780dd6c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df13315b-133f-4510-8bf0-1ad4b17f1148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a49f6bc6-e772-4bae-a1db-2b92aa941b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ef8855-8c1e-4dec-9545-d4ced02bf53d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d80200b-9f04-4ea3-9c70-293cda0e5348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901d1c84-1d77-4b8c-bf03-967df694a8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a52c6e9-4308-44be-89f6-261e36a7a067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822089b5-aee5-49cf-abad-f5251da45172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 293d0bb6-4660-48cb-b87a-08bc9fd1a74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc4b2e19-5b02-4fde-ad9a-670bebf4af22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bfec184-d555-4428-92e8-e27ae19e4a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b9b35a-6eb5-4f79-b751-d4a7dab325a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea84ad1-31fd-4561-9802-2e5a266865fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 341224da-5e57-4ad1-ba8b-7a3567c736f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd4d3f7-9df2-48ac-be9b-68fd95f7c815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81e0d847-7809-4683-b54e-54ca047c7af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e103a54-913d-46b3-9f89-f2ec8de9136b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9750ecea-b83c-447c-8721-5c65de6c714a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb540586-f80b-40a1-9da3-5d747ef29770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69b2c6b-eada-4f8b-a2ab-93f60974d0b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec69192-3e98-4a19-9477-bcfdc4b07e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518884c0-8678-4cea-8798-43c23d8b4923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d57e8d40-d157-4047-a1fa-9b8f67f9b3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf74ac4-a562-4a9b-96a5-47eed028440b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e04f1fa-8911-44eb-a1cf-0d3fc854384c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 348fbd56-c403-4572-b875-cb1a51663e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28a82171-2528-49f2-848b-d38ce269c09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9693977-6efe-4531-9bb1-5af5566fb11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0b01a9-2894-4def-9fd1-16fc47090a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbab09a5-199a-44dc-8fe0-090e7d1f52e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b77e782-636a-486e-9a3a-e667a82cbb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117c40ef-b8fd-40e4-aa44-be91fe642494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def00604-4893-4d94-9807-8aba3dd6dd97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c40378-6eea-464d-8938-476b783678de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03efc170-421a-4bb7-85b1-0d682f81f61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd1ee1a-ab40-4549-a873-4cb3b6e8e55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc567283-2663-4e57-9f46-72d9fcc8889b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 265b66a4-8632-4dbb-be8a-49a72c232937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ddaf682-e8fb-428b-ac40-7abc80b73d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f19db14d-c3b9-462f-a3e4-c92486daedaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46047baf-27da-4c06-9763-db5cef6b3f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7c3643e-0fc7-471e-b41b-302fd4427a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b86f1763-2c70-4b3d-828b-cccd53c6e0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ab60aa-06f7-4536-a582-aea453847b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ba701b-407c-41bb-9812-6bce33e5b321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af79ffac-2e10-447b-9608-e6041a9753a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5138bf8a-1208-401a-a97e-b407c9d92b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21462562-fbd7-49db-9220-8f7a4d0c5cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93afec88-37c9-48a2-8d8f-b93bfedebc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539a9bee-4dad-49b1-80f3-b6266420fc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a85f2b79-b367-4c28-8099-dcc5942c7210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10a724b0-dc6e-4168-8531-f82587d60f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 876f6819-fa09-465b-bb83-d99f20de0e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d461be17-9300-47b1-8280-b4e1b68e32a6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_29
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/test_labels.txt

📊 Raw data loaded:
   Train: X=(2503, 24), y=(2503,)
   Test:  X=(626, 24), y=(626,)

⚠️  Limiting training data: 2503 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  617 samples, 5 features
✅ Client client_29 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2509, R²: -0.0529

📊 Round 0 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2525, R²: -0.0331

============================================================
🔄 Round 9 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0860 (↓), lr=0.001000
   • Epoch   2/100: train=0.0814, val=0.0877, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0807, val=0.0878, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0798, val=0.0885, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0792, val=0.0886, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0740, val=0.0918, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 9 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0167
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0217
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0890, RMSE: 0.2982, MAE: 0.2568, R²: -0.0854

📊 Round 9 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2482, R²: -0.0108

============================================================
🔄 Round 12 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0757 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0848, val=0.0752 (↓), lr=0.000250
   • Epoch   3/100: train=0.0844, val=0.0753, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0750, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0836, val=0.0748, patience=3/15, lr=0.000250
   ✓ Epoch  11/100: train=0.0823, val=0.0741 (↓), lr=0.000250
   • Epoch  21/100: train=0.0804, val=0.0736, patience=2/15, lr=0.000250
   • Epoch  31/100: train=0.0779, val=0.0735, patience=12/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 12 Summary - Client client_29
   Epochs: 34/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0531
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0177
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2487, R²: -0.0097

============================================================
🔄 Round 15 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0866 (↓), lr=0.000250
   • Epoch   2/100: train=0.0818, val=0.0862, patience=1/15, lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   ✓ Epoch   3/100: train=0.0803, val=0.0844 (↓), lr=0.000125
   • Epoch   4/100: train=0.0792, val=0.0845, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0789, val=0.0844, patience=2/15, lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0774, val=0.0842, patience=8/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 15 Summary - Client client_29
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0350
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0223
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2521, R²: -0.0368

📊 Round 15 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2511, R²: -0.0245

============================================================
🔄 Round 17 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0860, val=0.0795 (↓), lr=0.000031
   • Epoch   2/100: train=0.0853, val=0.0791, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0848, val=0.0787 (↓), lr=0.000031
   • Epoch   4/100: train=0.0844, val=0.0784, patience=1/15, lr=0.000031
   ✓ Epoch   5/100: train=0.0840, val=0.0781 (↓), lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0828, val=0.0771, patience=3/15, lr=0.000016
   📉 Epoch 17: LR reduced 0.000016 → 0.000008
   ✓ Epoch  21/100: train=0.0820, val=0.0764 (↓), lr=0.000008
   📉 Epoch 25: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0817, val=0.0761, patience=10/15, lr=0.000004
   📉 Epoch 33: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 17 Summary - Client client_29
   Epochs: 36/100 (early stopped)
   LR: 0.000063 → 0.000002 (5 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0208
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0598
============================================================


============================================================
🔄 Round 20 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0898 (↓), lr=0.000002
   • Epoch   2/100: train=0.0833, val=0.0897, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0833, val=0.0897, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0832, val=0.0896, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0832, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 20 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0105
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0489
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2510, R²: -0.0231

============================================================
🔄 Round 22 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 22 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0079
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0851
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2495, R²: -0.0162

============================================================
🔄 Round 23 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 23 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0096
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0068
============================================================


============================================================
🔄 Round 24 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 24 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0108
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0069
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2501, R²: -0.0154

============================================================
🔄 Round 25 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 25 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0044
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0328
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2503, R²: -0.0161

============================================================
🔄 Round 28 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 28 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0130
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0230
============================================================


============================================================
🔄 Round 29 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 29 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0087
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0012
============================================================


============================================================
🔄 Round 30 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 30 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0074
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0033
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2505, R²: -0.0146

============================================================
🔄 Round 32 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 32 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0030
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0327
============================================================


============================================================
🔄 Round 35 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 35 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0044
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0044
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2505, R²: -0.0137

============================================================
🔄 Round 36 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 36 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0014
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0106
============================================================


============================================================
🔄 Round 38 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 38 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0021
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0103
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2506, R²: -0.0136

📊 Round 38 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2506, R²: -0.0136

📊 Round 38 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2506, R²: -0.0135

📊 Round 38 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2506, R²: -0.0135

============================================================
🔄 Round 44 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 44 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0009
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0066
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2506, R²: -0.0135

============================================================
🔄 Round 46 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 46 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0026
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0411
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2506, R²: -0.0135

============================================================
🔄 Round 47 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 47 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0071
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0065
============================================================


============================================================
🔄 Round 48 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 48 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0031
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0236
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2506, R²: -0.0134

============================================================
🔄 Round 50 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 50 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0057
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0268
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2506, R²: -0.0134

============================================================
🔄 Round 54 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 54 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0071
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0145
============================================================


============================================================
🔄 Round 59 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 59 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0022
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0011
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2505, R²: -0.0132

============================================================
🔄 Round 60 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 60 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0001
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0089
============================================================


============================================================
🔄 Round 62 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 62 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0049
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0123
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2506, R²: -0.0132

============================================================
🔄 Round 65 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 65 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0084
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0278
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2506, R²: -0.0132

============================================================
🔄 Round 68 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 68 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0025
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0028
============================================================


============================================================
🔄 Round 72 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 72 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0033
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0081
============================================================


============================================================
🔄 Round 73 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 73 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0017
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0064
============================================================


============================================================
🔄 Round 75 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 75 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0020
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0013
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2505, R²: -0.0127

============================================================
🔄 Round 79 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 79 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0046
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0260
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2505, R²: -0.0126

📊 Round 79 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2505, R²: -0.0126

📊 Round 79 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2506, R²: -0.0126

============================================================
🔄 Round 84 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 84 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0002
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0058
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2506, R²: -0.0126

📊 Round 84 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2506, R²: -0.0126

============================================================
🔄 Round 86 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 86 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0056
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0242
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2505, R²: -0.0124

============================================================
🔄 Round 87 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 87 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0005
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0159
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2505, R²: -0.0123

============================================================
🔄 Round 88 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 88 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0038
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0127
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2505, R²: -0.0121

============================================================
🔄 Round 90 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 90 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0090
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0116
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2505, R²: -0.0120

📊 Round 90 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2505, R²: -0.0120

============================================================
🔄 Round 93 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 93 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0062
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0063
============================================================


============================================================
🔄 Round 94 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 94 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0026
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0075
============================================================


============================================================
🔄 Round 96 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 96 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0023
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0040
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2505, R²: -0.0120

📊 Round 96 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2505, R²: -0.0120

============================================================
🔄 Round 103 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 103 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0021
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0131
============================================================


============================================================
🔄 Round 104 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 104 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0041
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0226
============================================================


============================================================
🔄 Round 106 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 106 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0009
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0051
============================================================


============================================================
🔄 Round 107 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 107 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0036
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0012
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0118

============================================================
🔄 Round 110 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 110 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0003
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0033
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0116

============================================================
🔄 Round 114 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 114 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0016
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0037
============================================================


============================================================
🔄 Round 117 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 117 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0045
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0474
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0116

============================================================
🔄 Round 119 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 119 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0060
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0271
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0115

📊 Round 119 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0115

📊 Round 119 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0114

============================================================
🔄 Round 124 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 124 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0020
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0050
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0114

============================================================
🔄 Round 128 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 128 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0006
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0096
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0114

============================================================
🔄 Round 129 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 129 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0033
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0063
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0113

📊 Round 129 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0113

📊 Round 129 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0113

============================================================
🔄 Round 132 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 132 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0073
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0423
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2504, R²: -0.0113

============================================================
🔄 Round 134 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 134 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0036
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0194
============================================================


============================================================
🔄 Round 137 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 137 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0039
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0273
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0113

📊 Round 137 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0113

============================================================
🔄 Round 143 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 143 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0001
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0018
============================================================


============================================================
🔄 Round 144 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 144 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0000
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0004
============================================================


============================================================
🔄 Round 146 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 146 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0010
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0027
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0113

============================================================
🔄 Round 149 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 149 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0057
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0262
============================================================


============================================================
🔄 Round 151 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 151 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0001
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0003
============================================================


============================================================
🔄 Round 153 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 153 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0043
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0183
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0113

============================================================
🔄 Round 156 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 156 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0054
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0120
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0113

============================================================
🔄 Round 158 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 158 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0014
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0040
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0114

============================================================
🔄 Round 160 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 160 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0010
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0022
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0114

📊 Round 160 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0114

============================================================
🔄 Round 163 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 163 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0051
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0180
============================================================


============================================================
🔄 Round 166 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 166 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0007
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0032
============================================================


============================================================
🔄 Round 168 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 168 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0040
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0194
============================================================


============================================================
🔄 Round 170 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 170 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0038
   Val:   Loss=0.0741, RMSE=0.2721, R²=-0.0222
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0113

============================================================
🔄 Round 171 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 171 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0012
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0006
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0112

============================================================
🔄 Round 174 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 174 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0050
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0389
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0112

============================================================
🔄 Round 175 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 175 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0070
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0349
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2505, R²: -0.0111

============================================================
🔄 Round 177 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 177 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0035
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0102
============================================================


============================================================
🔄 Round 178 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 178 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0024
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0259
============================================================


============================================================
🔄 Round 179 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 179 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0019
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0127
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2505, R²: -0.0110

============================================================
🔄 Round 180 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 180 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0028
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0067
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2505, R²: -0.0110

============================================================
🔄 Round 183 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 183 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0035
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0131
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2505, R²: -0.0110

============================================================
🔄 Round 185 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 185 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0012
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0103
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2505, R²: -0.0109

============================================================
🔄 Round 188 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 188 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0009
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0003
============================================================


============================================================
🔄 Round 189 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 189 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0024
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0049
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2505, R²: -0.0108

============================================================
🔄 Round 194 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 194 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0031
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0086
============================================================


============================================================
🔄 Round 195 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 195 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0019
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0101
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2504, R²: -0.0107

============================================================
🔄 Round 196 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 196 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0000
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0000
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2504, R²: -0.0107

📊 Round 196 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2504, R²: -0.0106

============================================================
🔄 Round 199 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 199 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0006
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0043
============================================================


============================================================
🔄 Round 200 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 200 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0057
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0078
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2504, R²: -0.0106

📊 Round 200 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2504, R²: -0.0106

📊 Round 200 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2504, R²: -0.0106

============================================================
🔄 Round 209 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 209 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0103
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0456
============================================================


============================================================
🔄 Round 210 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 210 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0023
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0030
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2504, R²: -0.0106

============================================================
🔄 Round 211 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 211 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0040
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0204
============================================================


❌ Client client_29 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
