[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c29aa3af-f337-4d45-9d76-365e30fcdecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d71ec348-a0c6-4b38-8b70-f3e0521991e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e0103a-975e-42f3-8e18-6e685e6d4237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daaffd61-f089-41d9-8d01-736b8ba32def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e1f916a-71be-4d83-bd69-0eb772cd26e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 616b1547-90a5-419c-88a5-62647106cbbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5592770-0701-482a-9d9f-0c0c6235ccaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa9c097-595c-41d2-b809-d43e7a0e2aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96fe1dec-55f6-4c3b-8124-cf370be8c21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53611767-dccf-4013-a5e0-02ba3097e2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 781320e0-2a50-4a9d-a2ed-30191fa7ecb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c08087-6788-4f95-b293-4f02d8f7bae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd3893e-a770-4dbc-9452-92780552c583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3152104d-442e-4ef9-a393-1cd59a4e2c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f35027c-1fe0-4a66-9ce8-5821c96769f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afc65251-ecb8-4dcd-ac49-78496f1ff63b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef3ed7ff-fd49-4eb2-8546-c39c8b1d6ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 344f1610-aba8-45b7-a9fe-5ffb9810824d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10856eff-335c-4d7a-847d-85c4ec32873d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8d4787-5c8f-4a7b-892d-85f213f78e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14536913-e8ff-41a2-b5f5-287fb163e404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe431892-d09e-488d-bf5f-d474113ae113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bfa3320-b6d1-4b2a-9a98-76ef6d0485c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03e6b2ad-c3c4-4d8f-a622-334520f1c579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee01057e-9e80-4c56-a82e-a114bdc4bbf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da20a839-43e5-44b0-9f28-29a9a770030b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ad55c4-0dff-4f93-b580-c44a6a481a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d641703-3fb5-47c4-a229-fc3a49cb6efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94353259-9c74-4752-940c-e07930dfc2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80653823-9cdc-4bf3-a3d1-64d472bb1029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b54ac0-1f5b-4b4c-b4d1-929ed7143c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca87575-7771-4902-99ff-ab835dcf825a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e918090-4593-460c-88db-e0bfc966622e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e20ecee-ad02-4c93-9031-52c0e2f70392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637de890-e5c4-4b1f-b49e-11a4e55e8314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1da15f0b-af6d-46b6-b8aa-312d5f3e3465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c955c57-c9ff-4a72-874c-da82744f4364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca372746-dce6-45dc-b31b-f5f47c5561c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c0085ce-b834-40d5-a799-d3e1fa83b15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbab9afb-9b44-4481-9bc3-0f42e31d9ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a6cb23-aa66-4680-ae4c-dd2fe1070494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf6a24a-ffe9-4b58-bdc9-ca4769aef490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257b49c8-2199-4be9-aeff-72c944368a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe15fc1-00f9-46d3-90c1-379dc2e36442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c782cba9-fd60-4030-a347-eb2581b3efd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b940f92-21c9-4a05-8302-6b12f4fe4328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da6d8e6-d886-47c0-a622-06014fbb6ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 608a537f-0400-46c0-91fa-53b5844e0f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d2897d-8888-4ce2-8211-dcd38c54296c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ff327e-7677-4711-886a-97b227eed225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1382d5a4-60aa-4794-a9cc-d0c6646dff52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e30d51d-370e-427a-bd86-b6d4440c2708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432e0df3-6eb5-4f14-bb37-bca8c40b3417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d37b78f-de5a-4c83-8750-3f1cda297ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eaadde5-37ba-4504-9cdb-e68e8d406410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a68c4ae-08af-40c4-a47c-730eb0979249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d79577-3d24-46f4-a58f-b7ef67ce3caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92d34d9a-cffb-4e5d-9953-d1192d8ba9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab4da888-e970-44dd-ad56-8aa0ad06d9e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f3f0329-4314-48cb-b40b-a25a7b94cb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c5d11a4-9377-4885-9ed4-487bb14c1c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d988da91-b1c2-454c-8a1d-13c8d8ee2899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7dc26cc-2071-416c-b3bc-e6c3f9a35abd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56dac85c-baca-457a-b5b4-2a104a7c8d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 458a6d9c-be53-4533-ac6a-de524a71047e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a4dd3a-f9e2-4acc-8d45-be63e92ee831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce86fb6-2f17-4096-9f6c-2d48a7de2c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa20631c-ab4b-45f3-aa3b-fece21265fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0add32-5d33-4be9-97f6-819b4945ce90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a9aac37-17dc-49cf-b900-61b4fad61405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e65e7f8d-599c-4f6d-b36d-b30eba75f3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d736ac1-efee-4dc8-8d14-99a5704786ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d7982b9-5c11-4b56-a2ce-06a17a68ce23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c4a59a-ab18-442a-a902-65826654d3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43691774-9e50-437e-a909-374e9ebf4d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e0c4b5-95aa-4183-b0bb-ca7a05ca7c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39149e5-cfdd-44c7-8487-f7dbc9249252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 745626c8-0049-4aae-9a98-67ffca11d091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86a7fd16-6a6a-4a9d-b47b-38ada14b5135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2c4c9d-030c-442a-96a0-9ed0aeab8b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ed109f-b427-476e-a6c4-70551e9b28de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5fe7ff-6089-4ab9-8903-01efe1fe8e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae5bb24-a952-42bf-93d8-6b3d9cc248d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3845a2e-dbc9-470f-84c8-8d25ca5c1f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199483d3-a18d-4855-8b6c-f29ac1727d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8975e83-5fa5-4dd2-aa0a-a5f2f6aa441c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18be24e3-989d-49e9-9ff8-71dc197d2c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d0df78-e67a-479d-b308-daadf938fe6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21cbb38-7f4d-4cad-b8a1-5371c238e303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a827804b-cd1a-430e-87e9-c49cda09e78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28aa1175-3e01-4355-a293-5d41658776aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a10fbb2-90ae-44fc-9759-5d5c91f260cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6174bf8e-9e7a-4d42-be90-663e9cd178bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1094575-5315-4368-9cac-aea59f811a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136a089f-5c9f-4801-ae1b-6a1913b5bf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26cf163b-5935-4464-adc1-190b2c28c63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9510e749-1fea-4cc9-9167-6c47badf3194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad404357-ba4a-4482-a528-a144f9e60198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9409d6be-6d7d-4769-b484-5c80e252ac87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 883fa348-fa32-4752-85e9-aeed855ec2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca17770f-d287-47a6-b68b-413c71a20cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebbdc85c-7243-4e30-b41a-eda0fd1cc381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f7ef6b-ece2-4608-a7d4-725b797b64c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ff8459-cb68-4e3a-9dc6-c33c748fb7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a42a2a4-d181-4ad5-8a1c-a9e279ce5fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76da68dd-4a16-4053-ae0e-05abf68b3161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c5a027-23d7-4db3-a306-3e0a0466513d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5076459c-83b9-4170-9401-6d8dce6884a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 343e8af8-9cda-4fbf-b1fc-01ff30b9d593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2811df71-c597-4814-a9b9-c1a1c1e3558c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199ea019-142a-4034-b9a2-c4b189a8efc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e30e2527-1f00-4389-94c5-8fe2eb6da76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a0b112e-1e23-4d43-8e92-597d854b2e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d797170-3e75-459c-a7e8-b75030c3a9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb56989-fb07-45d1-ba8b-c6442db7c61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaa55954-4ff4-4c53-b724-e0cd1193740d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 341b2a5b-0d61-49b0-863c-29b284834444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e791c989-ee3d-4d10-9640-d17bb6055043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38965d61-50f2-4b40-afc5-b9438f74e696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1100309-561d-43f1-a01d-b1b4a84164de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e58faa1-dc7d-4ccf-b0f8-0c848e1589ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c8b8f4-d548-4751-8ffc-0ba8d54fac19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b3fdba8-f3f6-4f4b-aabc-413678e36b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959b539c-1468-4f46-ad08-c8b05a1f904f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5002461d-d46f-4d51-9809-2f6f2aa81b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0601eb6-5f6c-4557-86fd-fab50719e1f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10bc6cb-0285-40cf-8537-da5624930401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 435f067a-40eb-46b3-9c26-8e214c38473b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc7b006-3f43-4b77-87d9-a198424d96da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b86c3259-942e-4320-914f-83a149ad208d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c7ec58-23ed-482d-adb4-e1b366d03964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07a5c4f7-9c1b-4516-8e5a-a9d36cca1f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87a954c9-be48-4d8e-881d-d601e6226fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ec3da56-aa86-4888-971a-936552cfc164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d316232-4a87-42f1-b7cd-cfb4575f9fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb62e449-4396-43e7-ade6-28f21912b5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe186b24-972d-4fa3-be33-a1e201e5b8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc89fc3-108c-4b4d-a77c-d10cef03d126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7071a13a-cca7-4358-ba52-3eafcff2cee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7869a6dd-e66c-4f50-994f-f6e5b1046c75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fff991ef-7177-4fe6-a1ef-dc26cf1c91f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fd4091e-0b84-421b-a99e-60169c6e18b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c20449f8-9b1a-479b-b695-7b9b752ce1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ab2118-89f9-4a1c-aab7-445535e137e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e3273f7-db58-4df3-8378-01428f0f5f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17c15e2-8d35-4b08-9301-524ad8ed299a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980bd936-4d51-4c59-bfea-c28bdcb8201a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed3cbf95-ad87-4927-9c81-290e660c084a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ddccd8-15d1-41f5-b4d5-0528ee38cdf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d99964-2d0d-4983-b624-dc1395687962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e8d3b18-85c3-4664-9a77-c6acd178616a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58b5eb6b-63b2-47ab-bb24-2e33587372bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8982b5ee-0e13-42f6-bd73-ca7245855fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6395ded2-e536-4318-a4a2-9b18fa4f36ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16a0a265-3ef4-4240-83ca-0d2fdfca149e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ad0f56-8a92-4b43-bf22-f832965d57ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f02c91b2-6c30-40eb-845a-1b75b9f83530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581b381c-973d-4457-9aea-1fe9b3c28890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64959a43-ec2f-4b84-b994-0738480945d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5725483e-1e72-44a9-8423-260599fe92a1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_2
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/test_labels.txt

📊 Raw data loaded:
   Train: X=(848, 24), y=(848,)
   Test:  X=(212, 24), y=(212,)

⚠️  Limiting training data: 848 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  203 samples, 5 features
✅ Client client_2 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2274, R²: 0.0004

============================================================
🔄 Round 2 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0968 (↓), lr=0.001000
   • Epoch   2/100: train=0.0849, val=0.0977, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0852, val=0.0974, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0853, val=0.0967, patience=3/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0853, val=0.0961 (↓), lr=0.001000
   • Epoch  11/100: train=0.0843, val=0.0958, patience=1/15, lr=0.001000
   📉 Epoch 16: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0823, val=0.0974, patience=11/15, lr=0.000500
   📉 Epoch 24: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 2 Summary - Client client_2
   Epochs: 25/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0107
   Val:   Loss=0.0956, RMSE=0.3091, R²=0.0009
============================================================


============================================================
🔄 Round 4 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1025, val=0.0987 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0877, val=0.0924 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0862, val=0.0898 (↓), lr=0.000250
   • Epoch   4/100: train=0.0859, val=0.0911, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0859, val=0.0909, patience=2/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0855, val=0.0907, patience=8/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 4 Summary - Client client_2
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0019
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0510
============================================================


============================================================
🔄 Round 5 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0966, val=0.0867 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0923, val=0.0815 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0901, val=0.0792 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0894, val=0.0781 (↓), lr=0.000063
   • Epoch   5/100: train=0.0892, val=0.0777, patience=1/15, lr=0.000063
   • Epoch  11/100: train=0.0890, val=0.0772, patience=5/15, lr=0.000063
   📉 Epoch 18: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0888, val=0.0773, patience=15/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 5 Summary - Client client_2
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0001
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0130
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0951, RMSE: 0.3084, MAE: 0.2549, R²: -0.3365

============================================================
🔄 Round 7 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0952, val=0.0846 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0932, val=0.0837 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0913, val=0.0832 (↓), lr=0.000031
   • Epoch   4/100: train=0.0900, val=0.0829, patience=1/15, lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   • Epoch   5/100: train=0.0890, val=0.0829, patience=2/15, lr=0.000016
   • Epoch  11/100: train=0.0875, val=0.0833, patience=8/15, lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 7 Summary - Client client_2
   Epochs: 18/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0364
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0072
============================================================


============================================================
🔄 Round 10 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0874 (↓), lr=0.000008
   • Epoch   2/100: train=0.0901, val=0.0870, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   ✓ Epoch   3/100: train=0.0897, val=0.0866 (↓), lr=0.000004
   • Epoch   4/100: train=0.0895, val=0.0865, patience=1/15, lr=0.000004
   • Epoch   5/100: train=0.0893, val=0.0863, patience=2/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0886, val=0.0857, patience=4/15, lr=0.000002
   📉 Epoch 19: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0882, val=0.0853, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 10 Summary - Client client_2
   Epochs: 28/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0121
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0256
============================================================


============================================================
🔄 Round 11 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 11 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0021
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0088
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2325, R²: -0.0419

============================================================
🔄 Round 12 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 12 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0189
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0552
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2326, R²: -0.0439

📊 Round 12 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2321, R²: -0.0448

============================================================
🔄 Round 15 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 15 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0195
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0031
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2328, R²: -0.0583

============================================================
🔄 Round 16 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 16 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0247
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0258
============================================================


============================================================
🔄 Round 21 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 21 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=-0.0392
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0048
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0719, RMSE: 0.2681, MAE: 0.2264, R²: -0.0104

============================================================
🔄 Round 26 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 26 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0290
   Val:   Loss=0.1006, RMSE=0.3172, R²=-0.0086
============================================================


============================================================
🔄 Round 27 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 27 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0218
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0265
============================================================


============================================================
🔄 Round 29 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 29 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0145
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0313
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2257, R²: 0.0013

============================================================
🔄 Round 31 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 31 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0174
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0491
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2257, R²: 0.0021

============================================================
🔄 Round 33 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 33 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0107
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0294
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0709, RMSE: 0.2663, MAE: 0.2256, R²: 0.0033

============================================================
🔄 Round 35 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 35 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0212
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0029
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0709, RMSE: 0.2663, MAE: 0.2256, R²: 0.0034

📊 Round 35 Test Metrics:
   Loss: 0.0709, RMSE: 0.2663, MAE: 0.2256, R²: 0.0035

📊 Round 35 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0036

📊 Round 35 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

============================================================
🔄 Round 41 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 41 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0187
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0373
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

============================================================
🔄 Round 43 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 43 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0054
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0997
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

============================================================
🔄 Round 44 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 44 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=-0.0145
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0098
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

📊 Round 44 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

📊 Round 44 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0036

📊 Round 44 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

============================================================
🔄 Round 50 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 50 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0080
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0390
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

📊 Round 50 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

📊 Round 50 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

============================================================
🔄 Round 53 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 53 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0178
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0021
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

============================================================
🔄 Round 54 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 54 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0142
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0095
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0036

============================================================
🔄 Round 57 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 57 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0156
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0002
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0036

============================================================
🔄 Round 58 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 58 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0129
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0134
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0037

📊 Round 58 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0038

============================================================
🔄 Round 63 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 63 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0185
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0076
============================================================


============================================================
🔄 Round 65 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 65 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0158
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0001
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2256, R²: 0.0040

============================================================
🔄 Round 67 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 67 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0163
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0306
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0708, RMSE: 0.2662, MAE: 0.2256, R²: 0.0043

📊 Round 67 Test Metrics:
   Loss: 0.0708, RMSE: 0.2661, MAE: 0.2256, R²: 0.0044

📊 Round 67 Test Metrics:
   Loss: 0.0708, RMSE: 0.2661, MAE: 0.2256, R²: 0.0044

📊 Round 67 Test Metrics:
   Loss: 0.0708, RMSE: 0.2662, MAE: 0.2256, R²: 0.0043

============================================================
🔄 Round 75 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 75 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0093
   Val:   Loss=0.0948, RMSE=0.3078, R²=-0.0374
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0708, RMSE: 0.2661, MAE: 0.2255, R²: 0.0044

============================================================
🔄 Round 77 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 77 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0129
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0101
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0708, RMSE: 0.2661, MAE: 0.2255, R²: 0.0046

============================================================
🔄 Round 79 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 79 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0144
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0005
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0708, RMSE: 0.2661, MAE: 0.2255, R²: 0.0047

============================================================
🔄 Round 80 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 80 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0148
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0128
============================================================


============================================================
🔄 Round 84 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 84 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0082
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0325
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0708, RMSE: 0.2661, MAE: 0.2255, R²: 0.0050

📊 Round 84 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0052

📊 Round 84 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0053

📊 Round 84 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0053

============================================================
🔄 Round 90 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 90 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0093
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0219
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0054

📊 Round 90 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0054

📊 Round 90 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0054

============================================================
🔄 Round 93 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 93 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0101
   Val:   Loss=0.0980, RMSE=0.3130, R²=-0.0493
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0054

📊 Round 93 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0054

============================================================
🔄 Round 97 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 97 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0126
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0086
============================================================


============================================================
🔄 Round 98 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 98 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0096
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0168
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2255, R²: 0.0055

============================================================
🔄 Round 100 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 100 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0085
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0250
============================================================


============================================================
🔄 Round 101 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 101 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0177
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0105
============================================================


============================================================
🔄 Round 102 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 102 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0105
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0214
============================================================


============================================================
🔄 Round 104 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 104 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0105
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0128
============================================================


============================================================
🔄 Round 105 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 105 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0094
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0511
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0707, RMSE: 0.2660, MAE: 0.2255, R²: 0.0057

📊 Round 105 Test Metrics:
   Loss: 0.0707, RMSE: 0.2660, MAE: 0.2255, R²: 0.0057

============================================================
🔄 Round 107 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 107 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0107
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0231
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0707, RMSE: 0.2660, MAE: 0.2255, R²: 0.0058

📊 Round 107 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0059

============================================================
🔄 Round 111 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 111 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0086
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0187
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0059

📊 Round 111 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0060

============================================================
🔄 Round 113 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 113 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0188
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0132
============================================================


============================================================
🔄 Round 115 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 115 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0197
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0045
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0061

============================================================
🔄 Round 118 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 118 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0094
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0169
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0063

============================================================
🔄 Round 119 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 119 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0158
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0081
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0064

📊 Round 119 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0065

============================================================
🔄 Round 123 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 123 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0087
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0205
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2254, R²: 0.0066

📊 Round 123 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0066

============================================================
🔄 Round 126 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 126 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0111
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0113
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0066

============================================================
🔄 Round 127 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 127 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0109
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0324
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0067

============================================================
🔄 Round 131 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 131 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0089
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0402
============================================================


============================================================
🔄 Round 133 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 133 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0119
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0063
============================================================


============================================================
🔄 Round 134 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 134 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0131
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0002
============================================================


============================================================
🔄 Round 136 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 136 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0158
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0121
============================================================


============================================================
🔄 Round 138 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 138 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3011, R²=-0.0152
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0070
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

📊 Round 138 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 141 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 141 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0097
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0231
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

📊 Round 141 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 144 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 144 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0139
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0001
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 147 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 147 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0084
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0245
============================================================


============================================================
🔄 Round 150 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 150 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0148
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0028
============================================================


============================================================
🔄 Round 152 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 152 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0111
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0091
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0067

============================================================
🔄 Round 154 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 154 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0096
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0146
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 155 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 155 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0130
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0069
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 158 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 158 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0062
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0309
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0067

📊 Round 158 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 163 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 163 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0131
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0042
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 166 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 166 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0133
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0034
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 169 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 169 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0140
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0054
============================================================


============================================================
🔄 Round 170 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 170 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0129
   Val:   Loss=0.0831, RMSE=0.2884, R²=-0.0020
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0068

============================================================
🔄 Round 173 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 173 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0104
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0097
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0069

============================================================
🔄 Round 176 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 176 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=-0.0135
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0005
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2254, R²: 0.0070

============================================================
🔄 Round 179 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 179 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0105
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0098
============================================================


============================================================
🔄 Round 180 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 180 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0161
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0055
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2254, R²: 0.0071

📊 Round 180 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2254, R²: 0.0071

============================================================
🔄 Round 186 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 186 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0148
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0066
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2254, R²: 0.0071

📊 Round 186 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2254, R²: 0.0071

📊 Round 186 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2254, R²: 0.0072

============================================================
🔄 Round 191 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 191 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0109
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0062
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2254, R²: 0.0072

📊 Round 191 Test Metrics:
   Loss: 0.0706, RMSE: 0.2658, MAE: 0.2254, R²: 0.0073

============================================================
🔄 Round 198 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 198 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0139
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0021
============================================================


============================================================
🔄 Round 202 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 202 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0085
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0324
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0706, RMSE: 0.2657, MAE: 0.2254, R²: 0.0074

============================================================
🔄 Round 206 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 206 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0100
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0165
============================================================


============================================================
🔄 Round 210 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 210 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0121
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0008
============================================================


❌ Client client_2 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
