[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e616a6-c60b-4df8-a6c5-cf22d7f91320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2622b5a-9a9c-441a-b2f8-14583cbfab0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message accdf4b3-7021-4bba-8259-4d24f5f48ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8619644-cd7b-43d4-8c90-63d775db17fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d7a1c0-1413-4075-b480-be5e6db87aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 043aa9e6-3083-4177-a303-df5c10374a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52d35a51-7c96-4402-8376-84ea9b0b4190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b1861a-4b74-41bb-b072-e1a0a29c502a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2b09a03-f82c-4cc9-b49f-bf078b89f9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bf2e212-44a2-4abb-badb-6fc5e298481a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ffacd9-8c3e-4cc9-b44e-8d488b6c0b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c27f6d1-c8a8-46b1-a2f8-b4c04b530a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9cb16ba-7960-4d9a-8a59-bc732a610452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3df3753-1ff7-481c-9038-c913a0466b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc53cb8b-5439-4882-9131-355e6b931fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e79cbc47-2b3f-4f4a-b023-4f3eea9e7662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0988e021-beee-4451-9970-8c025a813e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a757c1fe-c191-4cbb-a140-625285e49ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6147937d-edee-40bc-b9b4-4079518a1f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c63a6386-3424-42c5-9373-86581953610a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48375e5d-8dec-4e62-abd2-b735ba99a57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f5e09f-50e5-4dd1-99f2-29b11df72411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5306dbf0-87da-4eb4-b25e-0b33ece58155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40ebf0a2-b42b-4d7d-8a40-8333e679d49e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6900509f-be97-4295-891d-e15fe1bed00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62dad9ea-3fa9-4809-bdad-3740b7452549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e38fc93-5c03-450e-8790-4c5633acf54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0154af1d-f4b9-4a10-ac33-ca78562a35c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64f75972-ca27-43b6-8be3-d9b9cf2675d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 504924fd-2039-48da-a05d-483a40c98f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71cb6949-e203-4b85-93ff-959c5c4c834f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f2cc52-0d12-403b-acd2-53802b45545d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e852721-4f57-4b6c-9fd6-09781a52acf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 266f035f-fcea-44ab-8f49-8f59013610e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cfc8074-2438-4ee2-88a4-158f7734a695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd53724f-618c-47a3-b634-d4de79e5c528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4137a4b-dafc-4d6b-bebf-1f7ec42ded23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a199f01-f127-4582-92e7-f948db209e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74447149-659c-4ad8-8f22-df6ce16fe17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974b6870-227c-4a79-b21b-2d9c28859dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be6b036-1a31-4681-9cba-c75da68c3ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb17c90c-ff5e-485f-afd7-4945f062fa56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a10b56a-fd7e-4e8b-9041-3a370a111d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d696468-bb9b-46e0-b7ec-497f2be76299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0a267e-eac2-431f-a25d-63cd13e6760f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46b4c63-f2f7-4431-b6ac-53c68e856c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26efef69-a235-43ce-b971-7d0b2f2db96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0542ad0-7a7c-4a63-9cba-22519a246313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb7a8f3c-5eca-49d8-af2f-f2c2e491af65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f7ee0b8-5496-4603-b8cd-fb21ef005f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c61b5323-00ed-49a2-b013-499650f96d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90cd6289-e7f8-4618-99f1-399a2fd0e317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868100c4-3352-4081-bb13-07fb3aee876c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0f672e-b978-46d7-9ebb-c5c39c97b989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa02b648-8a55-4209-b058-f7462eb556d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3428311-3aae-4bd4-9178-b879aa639e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1d3ee83-53e1-47db-a5d8-485ce015976b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af4f11c-d2a6-42d2-b346-4e95caab63f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46e3c417-6bbc-4d43-916f-da6d0ee69155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeb7caaa-d230-4271-ae7e-5a75075511c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a097dd-7f5e-4d08-a0f0-f3a4e8b9a571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 960b57b9-04d6-44b2-8a24-f0e1f15ed2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237242e3-8987-44e4-bfb4-dc80932b9140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e474870-57c4-433a-9af5-4cf6fe05bb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd5c79f9-3731-4700-b6a1-dfb36fc27ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef032095-bc0d-4a87-b429-774ab6ea855b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85987903-c71e-4f9a-9de3-45c454b6b646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e503188f-0edc-4288-a8d8-986a922ff395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be95490d-165d-4576-9b29-922b958200a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6a136c2-5368-460f-b89b-8c233e434473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa102546-613a-4bdd-8601-7b53ed2141b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c46d86-2491-41be-8f60-3a8dff52cd44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2308ab29-bba0-4e13-9a55-26d4b0b8995c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7865dcf0-6646-4d9e-ba47-da0efd13bd3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6821ac95-7ba3-4ef7-86ed-9f549957e002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a61593b-287a-428d-811f-78839eccc2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebdcd97e-a74d-4cf9-b5fd-cedd7bb3694f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10c1be36-7557-4c03-bd0c-15cd4c4eea9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba96df4-9425-4e6e-82f3-eb37ba8b7650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba5200e9-d096-475c-b815-0be0355b9b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ed2f8f1-7ca3-46ed-bba6-ce8d56a321ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d98bd752-9f3b-4254-a85a-24e76c8b1714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d398139-d3ba-430a-87ca-29b15c54e737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70cb2a1b-6bd0-42a0-bfc7-849e726a9b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ccfe32-5883-4513-b7b3-a9d929b67a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a4a6b39-74a7-4115-81dc-a4d5f831e1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27638061-7c54-4e6b-9880-039140add529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a5fb64a-3016-4d30-84de-a5ccc2addf9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe4ee1e2-c37a-4c11-894a-20e842a01c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cfa3ae2-fb2c-4de1-b71b-670906064c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbc5d07-4aac-49b0-877b-999de391cfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027c87fb-0041-4e9c-9c16-165d5978f8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c13b9e12-5c26-44d0-9ed2-3c24c589fca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 044c64ad-d61c-4aec-96c7-8d606804a37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13945264-d0e4-4acb-8ada-7767efa37146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7131cef4-27de-4c7e-85c1-c241c74ab212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726649c9-874a-4f13-b43e-01b27a3f7189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4d9d916-42da-4db6-9525-3d8cbb218753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5025c932-02cb-4a28-bd0e-2846e42d1625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c1b8b0-9137-4082-adb3-2a7bc4243b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b054ca95-43aa-430c-92cb-22a5443470cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25db4960-61bd-4921-aa3a-2f73033ae89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d72a4341-64f8-4342-824a-5b759beb386d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ce3214-e4da-468f-8b1e-7dfde76b33d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891c6f15-c1bf-43dd-b07c-e92fdf5ecdb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a5645f3-7c48-4f31-9515-a937a0ac7b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31f5191b-8bea-451e-8596-e64e1d6d3947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ac9c2b-bca0-426c-b1e0-4d9b21f56b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beda379b-0493-4e00-a40f-20f85cff00ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11886f7d-f429-43d0-bd83-7d580f438016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4981f3c4-3d9b-4e1c-8ef6-d0d4f50ade24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9db26e7b-3087-41a6-95bc-aa9edb00ba8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c8bb119-c175-42f8-a43b-c7d150cc1ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c2687ba-5096-4152-9e49-510253147188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78987d07-ccee-41b5-be62-25e12b62b1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb9dc45-cdef-4929-a5d1-3d02810b83b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b74cdc-fc3c-413c-a313-5b9405fbc0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5483b40f-7a80-4ada-86e8-d942db116ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23aafcd-91a2-47e0-a832-2a24142ac334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fef5981d-a557-4c60-8da2-40e191327c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fe637ac-bf7f-4d8e-af5a-c928b78fc830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735ca6b9-c084-4c3c-8699-4a85338ac6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 858cfcf1-fdb8-4015-90c4-fdcb39c66418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d7a081c-ad54-4162-a60d-43862ef5f631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dbb96c4-60d5-4aff-8d12-ec9ddfdcf58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6aacc1c-177b-4d26-b5ff-4d2c656b13c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5df5a47-e5e7-4d52-8b11-c03fdd25c0a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e939e8-9071-402c-a02a-d9a9121bd47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d74fed70-c2b8-42d8-854a-58ebe96e15c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0748a93-d9ae-4336-ad51-121ac96d9bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf08d7a5-8cf3-419c-8db1-8aae691cda2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3463725-b0a3-4624-a986-ddeeb1ee636d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8263f12-db84-4268-8019-01ed878bbf50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08cc51fc-19f4-4c10-a18b-7e88d854617d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a947854-cce3-4cb5-ba09-737f1eac4e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a84a22-ac35-461a-9164-6fd8cde7266c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939f9491-bc9e-491f-9e1b-37c2e275e5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 700d3cb3-82d4-4bdf-a5f2-5a59212a6c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a55e24-a313-4e43-81c8-1dd2f214949f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d510f86-dd22-4332-aee2-993dd80825fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 834abe89-e26a-46be-8505-ae837224cd34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c4184fb-95b9-482b-897d-2a6932c3bf46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b0719d7-8ef1-43c0-9e8f-d067bfc51443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0938bd6f-1a4d-4959-b744-cdd8c3c12bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4d5756d-8466-4ad8-926c-f57aaa7a1fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf1456e-4eb8-4187-bb55-bdb12b9bc934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c03b097-402c-4561-9990-4b1c2a3b25d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abe6e87e-7b38-4ac8-bae2-bf99bdea2bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e09ff4-1fe7-4ac8-bdc5-0b3d639424a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fccf58d-0862-4fd9-8d90-823d54297c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d576d0-2a51-409d-b32e-d5b35f871f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c15a166-22b2-48d6-a98d-e1198ec66183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99034c9a-7f5a-4b75-8618-7300a7f745ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fadd080a-fd74-45bc-a754-84c2e5fbb574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d78d9b43-cfb7-4b5e-93f5-deb05a756196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1368c878-9bd3-4ec5-a67e-c69f986c157f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9d04f13-6907-4b5f-a44b-fba4f3cba50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14e61fe-5e1d-4f2f-a0f2-65e4c5e96b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d4ef69-6804-4727-8a06-5dce1bdb304c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eefa0c02-4a2b-4cac-9a06-766d9c56a502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed16b6b4-6931-461f-9e64-677008ec8178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a70ea010-81a5-4595-97fa-fe1267493ab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd0719d-0c1f-4656-8d0d-3d4e1ce92b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92557f8-6dc7-47ad-8636-e09a01153d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7b49b0-3ca8-400b-ba90-7b1e41ef541b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184189c3-41cd-4e80-8c05-f706d009a720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57055169-f276-4d42-b501-4dfb4c590976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8b47d8-79c5-4b45-ad96-1c0619b83052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d40068b-eb72-4dcc-9152-4a878b440504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9ee03e9-dad5-409b-8cec-afe9d648c8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4667d517-2f50-4c3a-85c9-58edcddf1347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b5a16d-e734-40e7-928f-ea1b0b1a2c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ba64b3-6efd-419f-9d82-c8aef7245bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ff4718-4a96-4b71-9285-274d8d36e91e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_31
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/test_labels.txt

📊 Raw data loaded:
   Train: X=(1351, 24), y=(1351,)
   Test:  X=(338, 24), y=(338,)

⚠️  Limiting training data: 1351 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  329 samples, 5 features
✅ Client client_31 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1260, RMSE: 0.3550, MAE: 0.2917, R²: -0.5043

============================================================
🔄 Round 6 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0853 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0832, val=0.0817 (↓), lr=0.001000
   • Epoch   3/100: train=0.0837, val=0.0824, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0830, val=0.0820, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0827, val=0.0819, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0771, val=0.0820, patience=9/15, lr=0.001000
   📉 Epoch 15: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 6 Summary - Client client_31
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0074
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0027
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0926, RMSE: 0.3044, MAE: 0.2589, R²: -0.1056

============================================================
🔄 Round 7 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0834 (↓), lr=0.000500
   • Epoch   2/100: train=0.0835, val=0.0835, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0831, val=0.0836, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0828, val=0.0838, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0827, val=0.0839, patience=4/15, lr=0.000500
   📉 Epoch 6: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0819, val=0.0842, patience=10/15, lr=0.000250
   📉 Epoch 14: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 7 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0090
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0031
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2494, R²: 0.0030

📊 Round 7 Test Metrics:
   Loss: 0.0878, RMSE: 0.2964, MAE: 0.2539, R²: -0.0482

============================================================
🔄 Round 9 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0866 (↓), lr=0.000125
   • Epoch   2/100: train=0.0826, val=0.0866, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0819, val=0.0871, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0818, val=0.0871, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0817, val=0.0870, patience=4/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0814, val=0.0870, patience=10/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 9 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0155
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0094
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2507, R²: -0.0162

============================================================
🔄 Round 10 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0831 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0864, val=0.0817 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0853, val=0.0808 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0845, val=0.0802 (↓), lr=0.000031
   • Epoch   5/100: train=0.0841, val=0.0799, patience=1/15, lr=0.000031
   • Epoch  11/100: train=0.0833, val=0.0794, patience=5/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0829, val=0.0795, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 10 Summary - Client client_31
   Epochs: 21/100 (early stopped)
   LR: 0.000031 → 0.000016 (1 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0181
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0252
============================================================


============================================================
🔄 Round 11 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0879 (↓), lr=0.000016
   • Epoch   2/100: train=0.0817, val=0.0881, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0816, val=0.0882, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0815, val=0.0883, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0814, val=0.0884, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0812, val=0.0887, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 11 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0096
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0064
============================================================


============================================================
🔄 Round 13 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0797 (↓), lr=0.000004
   • Epoch   2/100: train=0.0832, val=0.0797, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0830, val=0.0796, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0829, val=0.0796, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0828, val=0.0796, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0825, val=0.0795, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 13 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0073
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0300
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2455, R²: 0.0239

============================================================
🔄 Round 14 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 14 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0282
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0833
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2439, R²: 0.0435

📊 Round 14 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2433, R²: 0.0465

============================================================
🔄 Round 16 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 16 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0577
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0169
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2450, R²: 0.0167

📊 Round 16 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2427, R²: 0.0402

============================================================
🔄 Round 22 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 22 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0773
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0249
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2423, R²: 0.0436

============================================================
🔄 Round 23 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 23 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0733
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0347
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2446, R²: 0.0276

============================================================
🔄 Round 26 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 26 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0677
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0009
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2454, R²: 0.0217

============================================================
🔄 Round 30 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 30 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0519
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0401
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2459, R²: 0.0188

📊 Round 30 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2459, R²: 0.0186

============================================================
🔄 Round 33 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 33 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0433
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0571
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2460, R²: 0.0185

============================================================
🔄 Round 40 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 40 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0419
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0633
============================================================


============================================================
🔄 Round 41 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 41 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0464
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0478
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2460, R²: 0.0189

============================================================
🔄 Round 43 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 43 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0470
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0452
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2459, R²: 0.0190

============================================================
🔄 Round 46 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 46 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0397
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0658
============================================================


============================================================
🔄 Round 47 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 47 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0461
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0461
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2459, R²: 0.0194

📊 Round 47 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2459, R²: 0.0197

============================================================
🔄 Round 52 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 52 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0439
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0600
============================================================


============================================================
🔄 Round 53 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 53 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0457
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0485
============================================================


============================================================
🔄 Round 55 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 55 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0431
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0481
============================================================


============================================================
🔄 Round 56 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 56 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0460
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0508
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2458, R²: 0.0201

📊 Round 56 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2458, R²: 0.0204

============================================================
🔄 Round 60 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 60 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0448
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0375
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2458, R²: 0.0204

============================================================
🔄 Round 62 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 62 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0455
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0532
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2458, R²: 0.0203

============================================================
🔄 Round 63 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 63 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0425
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0640
============================================================


============================================================
🔄 Round 64 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 64 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0472
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0437
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2458, R²: 0.0203

📊 Round 64 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2458, R²: 0.0203

============================================================
🔄 Round 66 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 66 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0425
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0568
============================================================


============================================================
🔄 Round 67 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 67 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0448
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0508
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2458, R²: 0.0204

============================================================
🔄 Round 69 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 69 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0333
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0909
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2458, R²: 0.0206

============================================================
🔄 Round 71 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 71 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0465
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0470
============================================================


============================================================
🔄 Round 73 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 73 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0464
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0352
============================================================


============================================================
🔄 Round 78 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 78 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0515
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0064
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0212

============================================================
🔄 Round 80 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 80 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0501
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0301
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0211

============================================================
🔄 Round 82 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 82 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0511
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0154
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0209

📊 Round 82 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0208

============================================================
🔄 Round 84 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 84 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0454
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0409
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0208

📊 Round 84 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0210

📊 Round 84 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0211

============================================================
🔄 Round 88 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 88 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0508
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0061
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0212

📊 Round 88 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2458, R²: 0.0214

📊 Round 88 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0215

📊 Round 88 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2457, R²: 0.0216

============================================================
🔄 Round 92 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 92 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0378
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0808
============================================================


============================================================
🔄 Round 93 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 93 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0437
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0255
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2457, R²: 0.0219

============================================================
🔄 Round 96 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 96 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0465
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0446
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2457, R²: 0.0220

📊 Round 96 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2457, R²: 0.0220

============================================================
🔄 Round 102 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 102 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0537
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0116
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2457, R²: 0.0220

📊 Round 102 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2457, R²: 0.0221

============================================================
🔄 Round 105 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 105 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0506
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0251
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2457, R²: 0.0222

============================================================
🔄 Round 108 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 108 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0489
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0319
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2457, R²: 0.0222

============================================================
🔄 Round 109 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 109 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0413
   Val:   Loss=0.0744, RMSE=0.2729, R²=0.0648
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2457, R²: 0.0223

============================================================
🔄 Round 111 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 111 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0302
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0955
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2457, R²: 0.0222

============================================================
🔄 Round 112 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 112 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0419
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0613
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2457, R²: 0.0221

📊 Round 112 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2457, R²: 0.0221

============================================================
🔄 Round 116 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 116 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0502
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0269
============================================================


============================================================
🔄 Round 118 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 118 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0506
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0245
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2457, R²: 0.0220

============================================================
🔄 Round 119 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 119 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0445
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0439
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2457, R²: 0.0219

============================================================
🔄 Round 121 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 121 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0486
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0318
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0217

============================================================
🔄 Round 123 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 123 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0530
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0104
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0217

============================================================
🔄 Round 124 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 124 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0444
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0497
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0217

📊 Round 124 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0218

============================================================
🔄 Round 129 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 129 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0462
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0415
============================================================


============================================================
🔄 Round 131 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 131 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0449
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0453
============================================================


============================================================
🔄 Round 132 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 132 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0447
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0277
============================================================


============================================================
🔄 Round 135 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 135 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0441
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0449
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0217

============================================================
🔄 Round 136 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 136 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0469
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0380
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0217

📊 Round 136 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0216

📊 Round 136 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0216

============================================================
🔄 Round 140 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 140 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0385
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0687
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0217

============================================================
🔄 Round 141 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 141 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0390
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0678
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2458, R²: 0.0217

============================================================
🔄 Round 144 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 144 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0450
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0159
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2458, R²: 0.0220

📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2457, R²: 0.0221

📊 Round 144 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2458, R²: 0.0220

============================================================
🔄 Round 150 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 150 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0435
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0267
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2458, R²: 0.0220

📊 Round 150 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2458, R²: 0.0221

============================================================
🔄 Round 155 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 155 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0490
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0181
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2458, R²: 0.0221

============================================================
🔄 Round 157 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 157 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0465
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0313
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2458, R²: 0.0222

📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2458, R²: 0.0221

📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2458, R²: 0.0220

============================================================
🔄 Round 162 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 162 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0525
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0038
============================================================


============================================================
🔄 Round 164 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 164 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0419
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0210
============================================================


============================================================
🔄 Round 166 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 166 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0341
   Val:   Loss=0.0717, RMSE=0.2679, R²=0.0711
============================================================


============================================================
🔄 Round 167 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 167 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0458
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0373
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2458, R²: 0.0222

📊 Round 167 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2458, R²: 0.0222

============================================================
🔄 Round 170 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 170 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0415
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0530
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2457, R²: 0.0225

============================================================
🔄 Round 173 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 173 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0533
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0025
============================================================


============================================================
🔄 Round 174 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 174 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0495
   Val:   Loss=0.0749, RMSE=0.2738, R²=0.0170
============================================================


============================================================
🔄 Round 175 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 175 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0454
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0403
============================================================


============================================================
🔄 Round 176 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 176 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0439
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0461
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2457, R²: 0.0228

📊 Round 176 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2457, R²: 0.0229

============================================================
🔄 Round 180 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 180 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0394
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0666
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2457, R²: 0.0229

📊 Round 180 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2457, R²: 0.0230

============================================================
🔄 Round 182 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 182 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0365
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0800
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2457, R²: 0.0231

📊 Round 182 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2457, R²: 0.0232

📊 Round 182 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2457, R²: 0.0232

============================================================
🔄 Round 186 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 186 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0484
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0299
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2457, R²: 0.0232

📊 Round 186 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2457, R²: 0.0233

============================================================
🔄 Round 188 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 188 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0404
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0584
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2457, R²: 0.0233

============================================================
🔄 Round 190 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 190 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0470
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0346
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2456, R²: 0.0235

============================================================
🔄 Round 193 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 193 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0368
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0649
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2456, R²: 0.0235

============================================================
🔄 Round 195 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 195 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0459
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0376
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2456, R²: 0.0236

============================================================
🔄 Round 197 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 197 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0453
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0420
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2456, R²: 0.0237

============================================================
🔄 Round 199 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 199 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0427
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0517
============================================================


============================================================
🔄 Round 203 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 203 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0474
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0326
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2456, R²: 0.0235

============================================================
🔄 Round 206 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 206 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0439
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0462
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2456, R²: 0.0235

📊 Round 206 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2456, R²: 0.0235

📊 Round 206 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2457, R²: 0.0235

❌ Client client_31 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
