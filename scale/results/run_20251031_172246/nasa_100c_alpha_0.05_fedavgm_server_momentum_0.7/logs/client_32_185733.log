[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5d5be6-98fc-4222-8e15-362d52cdb675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c434c2a-6352-4a00-b035-af4db368137f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858653a8-fe5f-4324-bf04-b8ca6c0cd94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef0b879b-eefa-4d40-8ff9-ae150bb19b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d308da-b56e-4bee-b43a-efd5f2d1c433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7862a81-f8ae-4e77-9e63-988eac35e453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4389f49a-307c-4f60-b909-b39bf7626447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1107b6d5-731b-4e2c-8218-3325f6396928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7dd3c4e-9802-46d4-bf1c-52a9a856f1b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8bb8fb7-68f3-4ed6-b50f-99322ca75559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6b3781-f969-48a0-b2a8-dbeaba77fbcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6671bfd-8522-4467-8631-8fb6d7d9f18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a436b39-354d-4d7d-acaf-1527e6c3eb74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5703fd-5769-467d-8db6-62fc0f1ffe97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae04a347-24a4-4751-9b44-1697a794080c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f998a44-fc7a-4bdf-97ba-7fe0e68a019e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88005e5-2829-412e-8daa-3cfd755e6a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 172a81f0-a295-4ff1-8e13-e79510090768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2363f7d0-1169-4fb6-a345-c230261cf618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb3e26f4-f2f3-421b-9dca-e08e4cac8332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec7be3c9-d865-46a2-aae3-02b2710cac27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec348258-82b4-46fa-a20e-b3b6258db94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f8e8a0-1fe6-40e6-9383-5de97457bd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c18717b-a739-4206-82ce-1bfa8068b6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 807fda1d-04e1-47e7-9df4-9e381259f6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0cf788-0c0c-4bda-877a-7c4fb0905064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15f40585-765a-4660-92bb-8934afb19239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7858ce-52dc-4332-a5c8-a44a9d24a925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527fe143-8873-43f0-8732-2ef55dfee666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae84a4d-bd37-45b9-a454-a71b58d3f539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b7199b-3472-4311-a0f4-6e2db44e6f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49b9af48-ad09-4735-8e3f-b77f696b209a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de221a68-8805-4402-b542-cadaf7bad6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3763db8f-ce61-42c8-b0a1-5246cef2dfe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbefe4d1-e6d5-4fd9-89c3-b07a1f7c9819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff72872-bfe1-4c11-96c6-2b478e46833d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f628fe49-ddb7-4b5d-86e0-07bdd5b2ff0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f00567-9505-42ee-b648-f54f93cb229f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f136a2bf-795a-431c-a7ec-f8f842e8933f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 255e65bd-a502-4bd9-b946-4cb39c105572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05f4a3f-eeb8-4d80-a38b-f1b6724fe719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4271f7fe-db3f-4de8-a40b-3dc6bb6d8d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e009a113-550c-4afa-952d-885b2a70f07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3f49e05-14ed-44b0-b381-9e12172793c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8440ec1a-cd13-4f67-ae1a-ad86363e3148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9b2d01-9d20-46f7-a3b1-0fd45305693c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5013079-f984-486f-8d35-5ba89878e47a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57060231-bbfd-428e-80f9-8f196ed97c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a7bfa69-3d53-4af6-b4b2-9bc3751826c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ee067c-4923-455a-988c-503678df5df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2739eb84-77a2-4653-98d5-67774ee7833b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5220ac6b-819e-4fc9-8f42-aad3582e599b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c16f5f7e-d284-4bae-902d-d2d7e639d4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 362c8dec-09c6-4462-95d3-9e84db8f636b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 806f3836-7590-4f84-9ac2-df37ac162fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04cd2ccf-e74d-4f8d-bb3f-14d491beb781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab61b7e7-b43d-48e1-b851-578d465f0949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25673761-6826-43d1-b6cc-dfc5d810fa0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2640b776-e282-454b-91b2-e4cc5cb1e381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 530f0bff-98c6-4be3-a62e-259700b2f844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554d923d-48a7-4b78-90ae-ccf006ab8784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c5058ea-6eda-4d37-bc62-f9baa955896d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65035022-92bc-474f-ad05-37b7251db1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ff85c2-17af-40a6-8a52-b7ba566f0dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3abb4fb3-3b81-4464-a472-28d88dcc7bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f9b933-11c7-4d2a-be9f-e67e3aafbb4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eace4916-8df1-4a83-9375-c669253e94e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a199c71c-f341-49fd-a9f6-ee587a92079d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dd278df-77f4-4ed6-8a44-cb9e0ac368fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d8f150-b0f6-4033-a9bf-022fca5be2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e7375a4-30b0-4b7d-9d08-5f6591f56971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb26e3f-e658-4cda-be1c-0de8eb77ce21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4309bc2b-1b5e-4787-89ce-fc56aca00df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a598f22-5243-4589-a90c-58d60a7386c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25415829-5870-4393-82e2-1c3e6cb1f8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 593497bc-fc5f-4476-8f41-6db45ab17803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a0b761-df7c-479a-9c88-31e8417028e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1969134-d915-4b2f-a01a-0bd6c3082044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb658be3-b187-4e67-a79f-afff31ed5467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2769334a-2d47-4e59-b9e9-32e065eca697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 356e92c3-62f0-4aab-afaa-6cbcf3bf3363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2254ab9-be96-4a56-9adf-fd7ef645efab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c453f0b6-e743-4a80-9842-c303185fefb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab28b52-c35a-419b-8d11-50d7fd30c935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c656c33-afbe-482b-a830-49dde8ec1a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e0e08d-6501-4144-86c7-fce7b78c970f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4e5ca2-847a-4508-8e8b-ed24288cdaeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a74f4bd-e0c7-477d-8803-857cb48c44c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4941c260-2da2-4977-bb25-c53e5a744122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57823363-bdf2-4005-85cd-41e8228d5537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e69153-1691-446c-85ef-c4e785ac9968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e357dc-c4cc-47f6-a316-c328f6cc60c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1db0f31-925b-4a13-b279-ca22063b04fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bdcefc5-1e44-4064-8cd7-bdbd227e5b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 773860e5-3d4a-4108-9326-d4f1c44e093e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcf62c9-7607-4e2b-a987-40778e9c9c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4185db2b-2517-442f-be1f-c4043ed6435d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31f79936-c079-41b7-83d7-3c571ba1971d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b831dd74-484d-48da-9a1c-8f3d74bc99e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f60a8e2-2ffe-4638-af47-a8232b413ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca1a846-7385-40cf-9591-e04e53bac3ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14dcf3b-05fb-4733-b7f9-f3501a25a663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ddc76e2-3016-4ea5-93db-6ad161e5f12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40786735-9b06-45dc-8597-0cbd133b6901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5900bc1b-c20f-4dc6-9599-251ddd9918bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 015edfb9-f313-4d4a-9c84-a59de6c9b8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f3467d-120f-4c97-a7e2-133c13f2f588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b23c37-964e-4541-8576-44fa4290df90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd1324b3-7beb-4718-ade5-6c7a0fda82d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09928c91-45f1-4773-ad7d-5bf6dc80bd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b29bde-82f2-4213-bb78-aa25bd90754e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0855439-8e11-4e35-9a93-985ab0333646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dead2097-b6ca-4bcc-8eef-ff2f2d94078d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a8ae3af-1558-4592-9c7b-accf546b827f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ad07bab-63bc-4cb5-bebf-b28c93119d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e225389a-c294-4d00-a847-9982816f4199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e712df29-59a3-43dd-bd36-f43c44929eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e975ed-7869-487f-a224-bedff4d9297c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5096ac4f-a281-4473-a059-553aa48770f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38563d93-32a6-4145-b14c-900759d6e2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87508d9d-7134-4209-b420-597b9c6a6c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f412a3a-5fe6-4b1b-96a3-2a181642050c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aceca38b-6975-4174-9ab8-60e0ba1e0442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bbe4182-aa58-41ee-98d6-1ff7543caa15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7660ac9f-371e-40b3-ac95-40537aae3149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d7a82b-95b2-4eef-9584-8954b0e3253e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3a42e9-ec28-448f-8b77-978b69b26849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40fa33d7-0d14-4b2e-8c44-994e5b7ce72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41e89d5-86ae-478f-956d-5848e7ac579d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 158361eb-f592-4ca7-9030-57ff95a727cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ada1a9-d164-40e9-895a-0d2d3077e27f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166edd7c-90b7-4959-8abd-c487341b2dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0986b08-ec14-42a7-964b-5154b8020562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc85020f-ef77-4079-8465-96f664b61ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d7e853-f2c2-4341-90ab-ed42c960069c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13592a29-b7d4-4868-80ca-3f6b101375ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e868d8c-e44c-49ff-973a-a53f1eab7283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d0bf39-9c7c-4ea1-b3e8-ff885f3e0934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac1c0b6e-0158-4fd3-b6aa-c4b5b0bca69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c508a435-d2ec-4a37-a7f7-8d889d6d5c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d204cf2-eca7-43c3-96c9-6238efa6c877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1770a6f5-cc26-45d9-a515-3c199b3ce238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a179dd0-4c1b-4979-ba4f-df4a8e594aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0507e049-6c65-47e3-b54e-a51c6637d8a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58b5a51-4f9a-4a45-9bf0-dfb78beccfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff75bcd-269f-4307-b3fa-38211158aee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b5771b3-e1be-4016-ad18-cb05ed351702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaec5bc2-cad6-4a62-8d7d-3554d5a78d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad6ebdd-87cc-481c-9c61-b7bec9d6e141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec179c01-9539-4c99-832a-ef409f9f85af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ae68cfe-f8bc-4d4f-82c3-17ff1ac0b018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d477b177-598a-4ab9-b620-8ce1f38effe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6706f5f-d65c-468b-b1e0-b9dcbd48b71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7122cde3-9bc4-47a4-8b56-286e5186c0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf0fc07b-198f-4d7b-b37c-c7963ffd1723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f74eb2b9-6d5b-4a3f-9005-9f37af4c6f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d746558-77a0-471a-a0f1-d1c5c0adbc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f37eaf3-47eb-40bf-9f10-2640c2da8cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30a27d38-acf4-4148-9bbd-30d96af7459d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37fdf7c3-e401-4cfc-97c1-8071ec38f1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f08afa0d-eb81-4342-bab0-65048329e64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1178ead-1b92-48b7-983d-f9fff7653700
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_32
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/test_labels.txt

📊 Raw data loaded:
   Train: X=(620, 24), y=(620,)
   Test:  X=(155, 24), y=(155,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 611 samples, 5 features
   Test:  146 samples, 5 features
✅ Client client_32 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0981 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0839, val=0.0952 (↓), lr=0.001000
   • Epoch   3/100: train=0.0832, val=0.0956, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0828, val=0.0959, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0825, val=0.0964, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0808, val=0.0980, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 6 Summary - Client client_32
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0076
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0180
============================================================


============================================================
🔄 Round 8 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0789 (↓), lr=0.000250
   • Epoch   2/100: train=0.0883, val=0.0790, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0881, val=0.0790, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0879, val=0.0791, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0877, val=0.0791, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0869, val=0.0795, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 8 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0058
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0034
============================================================


============================================================
🔄 Round 9 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.1026 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0857, val=0.0991 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0841, val=0.0970 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0833, val=0.0959 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0829, val=0.0952 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0824, val=0.0945, patience=4/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0822, val=0.0945, patience=14/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 9 Summary - Client client_32
   Epochs: 22/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0014
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0211
============================================================


============================================================
🔄 Round 12 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0862, val=0.0914 (↓), lr=0.000008
   • Epoch   2/100: train=0.0859, val=0.0913, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0858, val=0.0913, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0856, val=0.0912, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0854, val=0.0911, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0848, val=0.0910, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 12 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0303
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0178
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0724, RMSE: 0.2691, MAE: 0.2284, R²: 0.0050

📊 Round 12 Test Metrics:
   Loss: 0.0707, RMSE: 0.2658, MAE: 0.2259, R²: 0.0291

============================================================
🔄 Round 15 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0865, val=0.0924 (↓), lr=0.000002
   • Epoch   2/100: train=0.0865, val=0.0924, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0864, val=0.0924, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0864, val=0.0924, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0864, val=0.0924, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0863, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 15 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0286
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0083
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2253, R²: 0.0263

📊 Round 15 Test Metrics:
   Loss: 0.0709, RMSE: 0.2663, MAE: 0.2255, R²: 0.0255

📊 Round 15 Test Metrics:
   Loss: 0.0703, RMSE: 0.2652, MAE: 0.2254, R²: 0.0337

📊 Round 15 Test Metrics:
   Loss: 0.0710, RMSE: 0.2664, MAE: 0.2267, R²: 0.0250

📊 Round 15 Test Metrics:
   Loss: 0.0715, RMSE: 0.2675, MAE: 0.2276, R²: 0.0170

============================================================
🔄 Round 28 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.1048 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.1048, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.1048, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.1047, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.1047, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.1047, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1048)

============================================================
📊 Round 28 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0142
   Val:   Loss=0.1048, RMSE=0.3237, R²=-0.0191
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0716, RMSE: 0.2677, MAE: 0.2278, R²: 0.0157

📊 Round 28 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2281, R²: 0.0136

============================================================
🔄 Round 32 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 32 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=-0.0084
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0408
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0718, RMSE: 0.2680, MAE: 0.2281, R²: 0.0132

============================================================
🔄 Round 35 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 35 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0087
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0254
============================================================


============================================================
🔄 Round 37 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 37 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0190
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0146
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0718, RMSE: 0.2680, MAE: 0.2282, R²: 0.0132

============================================================
🔄 Round 39 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 39 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0139
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0023
============================================================


============================================================
🔄 Round 40 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 40 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0082
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0390
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0718, RMSE: 0.2680, MAE: 0.2282, R²: 0.0132

============================================================
🔄 Round 43 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 43 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0193
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0029
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0718, RMSE: 0.2680, MAE: 0.2282, R²: 0.0134

============================================================
🔄 Round 45 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 45 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0147
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0043
============================================================


============================================================
🔄 Round 46 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 46 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0082
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0214
============================================================


============================================================
🔄 Round 47 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 47 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0143
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0034
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0718, RMSE: 0.2680, MAE: 0.2282, R²: 0.0135

📊 Round 47 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2282, R²: 0.0136

============================================================
🔄 Round 49 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 49 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0092
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0161
============================================================


============================================================
🔄 Round 50 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 50 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0189
   Val:   Loss=0.0944, RMSE=0.3072, R²=0.0012
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2282, R²: 0.0136

📊 Round 50 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2282, R²: 0.0137

============================================================
🔄 Round 53 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 53 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0111
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0076
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2282, R²: 0.0138

📊 Round 53 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2282, R²: 0.0138

============================================================
🔄 Round 56 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 56 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0153
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0098
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2283, R²: 0.0140

============================================================
🔄 Round 59 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 59 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0076
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0220
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2283, R²: 0.0141

============================================================
🔄 Round 61 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 61 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0073
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0353
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2283, R²: 0.0140

============================================================
🔄 Round 63 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 63 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0129
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0060
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2283, R²: 0.0139

📊 Round 63 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2283, R²: 0.0139

📊 Round 63 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2283, R²: 0.0139

📊 Round 63 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2283, R²: 0.0141

📊 Round 63 Test Metrics:
   Loss: 0.0718, RMSE: 0.2679, MAE: 0.2283, R²: 0.0141

📊 Round 63 Test Metrics:
   Loss: 0.0717, RMSE: 0.2679, MAE: 0.2283, R²: 0.0142

============================================================
🔄 Round 74 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 74 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0158
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0193
============================================================


============================================================
🔄 Round 80 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 80 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0194
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0120
============================================================


============================================================
🔄 Round 82 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 82 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0080
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0182
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0717, RMSE: 0.2679, MAE: 0.2283, R²: 0.0142

============================================================
🔄 Round 83 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 83 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0104
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0440
============================================================


============================================================
🔄 Round 86 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 86 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=-0.0168
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0108
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0143

============================================================
🔄 Round 87 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 87 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0046
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0322
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0144

============================================================
🔄 Round 88 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 88 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0104
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0057
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0145

============================================================
🔄 Round 89 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 89 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0102
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0089
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0146

📊 Round 89 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0147

============================================================
🔄 Round 92 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 92 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0109
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0018
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0147

============================================================
🔄 Round 93 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 93 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0082
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0090
============================================================


============================================================
🔄 Round 95 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 95 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0130
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0110
============================================================


============================================================
🔄 Round 96 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 96 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0161
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0224
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0148

📊 Round 96 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0148

============================================================
🔄 Round 100 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 100 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0115
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0048
============================================================


============================================================
🔄 Round 103 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 103 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0104
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0004
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0717, RMSE: 0.2678, MAE: 0.2283, R²: 0.0150

============================================================
🔄 Round 105 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 105 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0067
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0129
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0152

📊 Round 105 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0152

============================================================
🔄 Round 110 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 110 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0147
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0032
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0153

============================================================
🔄 Round 111 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 111 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0086
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0108
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0153

📊 Round 111 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0154

============================================================
🔄 Round 116 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 116 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0040
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0237
============================================================


============================================================
🔄 Round 118 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 118 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0052
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0478
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0154

============================================================
🔄 Round 120 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.1032 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.1032, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.1032, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.1032, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.1032, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.1032, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1032)

============================================================
📊 Round 120 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0091
   Val:   Loss=0.1032, RMSE=0.3213, R²=-0.0065
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2282, R²: 0.0154

============================================================
🔄 Round 121 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 121 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0056
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0164
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2282, R²: 0.0154

============================================================
🔄 Round 124 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 124 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0035
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0243
============================================================


============================================================
🔄 Round 126 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 126 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0034
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0310
============================================================


============================================================
🔄 Round 128 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 128 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0115
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0044
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2282, R²: 0.0156

============================================================
🔄 Round 135 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 135 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0094
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0000
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2282, R²: 0.0155

============================================================
🔄 Round 136 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 136 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0071
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0303
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2282, R²: 0.0155

📊 Round 136 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2282, R²: 0.0155

============================================================
🔄 Round 139 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 139 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0073
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0282
============================================================


============================================================
🔄 Round 141 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 141 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0142
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0182
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2282, R²: 0.0154

📊 Round 141 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2282, R²: 0.0154

============================================================
🔄 Round 145 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 145 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0047
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0433
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0154

📊 Round 145 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0155

============================================================
🔄 Round 149 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 149 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0038
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0224
============================================================


============================================================
🔄 Round 151 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 151 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0039
   Val:   Loss=0.0994, RMSE=0.3152, R²=-0.0191
============================================================


============================================================
🔄 Round 152 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 152 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0071
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0120
============================================================


============================================================
🔄 Round 154 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 154 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0085
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0218
============================================================


============================================================
🔄 Round 155 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 155 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0043
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0444
============================================================


============================================================
🔄 Round 156 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 156 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0125
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0093
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0151

============================================================
🔄 Round 161 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 161 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0155
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0117
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0150

📊 Round 161 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0151

============================================================
🔄 Round 167 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 167 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0115
   Val:   Loss=0.0961, RMSE=0.3101, R²=-0.0603
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0151

============================================================
🔄 Round 169 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 169 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0046
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0287
============================================================


============================================================
🔄 Round 172 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 172 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0161
   Val:   Loss=0.0876, RMSE=0.2961, R²=-0.0168
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0154

============================================================
🔄 Round 173 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 173 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0029
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0463
============================================================


============================================================
🔄 Round 175 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 175 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0034
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0186
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0717, RMSE: 0.2677, MAE: 0.2283, R²: 0.0156

📊 Round 175 Test Metrics:
   Loss: 0.0716, RMSE: 0.2677, MAE: 0.2283, R²: 0.0156

📊 Round 175 Test Metrics:
   Loss: 0.0716, RMSE: 0.2677, MAE: 0.2283, R²: 0.0157

============================================================
🔄 Round 179 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 179 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0066
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0080
============================================================


============================================================
🔄 Round 180 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 180 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0106
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0393
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2283, R²: 0.0158

============================================================
🔄 Round 182 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 182 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0056
   Val:   Loss=0.0703, RMSE=0.2651, R²=-0.0187
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2283, R²: 0.0160

============================================================
🔄 Round 184 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 184 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0084
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0028
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2283, R²: 0.0161

📊 Round 184 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2283, R²: 0.0161

============================================================
🔄 Round 188 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 188 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0063
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0118
============================================================


============================================================
🔄 Round 189 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 189 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0065
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0040
============================================================


============================================================
🔄 Round 190 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 190 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0021
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0222
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2283, R²: 0.0164

============================================================
🔄 Round 192 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 192 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0025
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0235
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0716, RMSE: 0.2676, MAE: 0.2283, R²: 0.0164

============================================================
🔄 Round 193 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 193 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0058
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0075
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0165

📊 Round 193 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0166

============================================================
🔄 Round 197 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 197 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0011
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0327
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0168

============================================================
🔄 Round 198 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 198 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0062
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0086
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0169

============================================================
🔄 Round 199 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 199 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0105
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0135
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0168

============================================================
🔄 Round 200 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 200 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0029
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0172
============================================================


============================================================
🔄 Round 201 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 201 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0095
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0045
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0166

============================================================
🔄 Round 202 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 202 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0017
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0242
============================================================


============================================================
🔄 Round 203 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 203 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0083
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0069
============================================================


============================================================
🔄 Round 204 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 204 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0045
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0118
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0167

📊 Round 204 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0167

📊 Round 204 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0166

============================================================
🔄 Round 207 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 207 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0123
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0158
============================================================


============================================================
🔄 Round 208 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 208 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0099
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0113
============================================================


============================================================
🔄 Round 209 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 209 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0036
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0139
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0716, RMSE: 0.2675, MAE: 0.2283, R²: 0.0166

============================================================
🔄 Round 211 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 211 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0051
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0108
============================================================


❌ Client client_32 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
