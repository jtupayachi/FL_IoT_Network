[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea345b97-2627-4004-998c-96ff50d18b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2915af-43fb-4a46-83db-5ec9c9755bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f3ed066-5998-40ca-9d51-c04d39ca5088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4132d33a-d39f-467f-bafb-82da6c936ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 144c9736-320d-4ee6-82f3-5695e519075c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24573a6-cc26-4e37-813f-402bd1eb606b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6540d5da-28c9-4748-817f-e8a51d5670a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5946fee-28bd-4e4e-af81-8ffa5d332433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cd7fe6c-dcf4-4453-9467-8af022d88a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9f2f759-2968-4ab0-83ed-6be026ccef82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48901196-50e0-4540-a6da-672444a4e02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e274504-159f-4316-9a36-fa68bb8ac234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dbae6c4-e73e-4401-81eb-3c5269d70505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0703657-7da3-4ef7-85bc-4ec1716f71c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7348246d-7f92-48b3-a171-3b4db96eee0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc379b72-6c00-4759-acdb-eb04d8bf74f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15172ec8-d232-4933-b16d-e5b17bdfb31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e14e24d-f954-491e-bc41-bb173c027ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e49deb-ae66-4826-ace0-0a057ecbc96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3867159-f62c-4460-8a61-65fa34e1ec10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b97074-b471-4155-b609-0a5dedc88fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1844a32f-03af-4d6d-a8f8-9bdc07f31407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e97fa98c-5cc9-43fb-810a-19653ad258ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c399a1dd-c09c-4bfa-b969-47e13c4eb99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fec3c78-c48d-4886-993d-3c755df726ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d37a02e-5d1c-4832-9fa3-238bd890d966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95144943-763f-4c79-b563-030f3764b3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198481c4-4625-46d0-b707-914bcbf2f516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7968f6d-90b5-429c-9c7b-5ae86c01cf56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b51703b-c74e-4422-a65b-ca0b6ded4356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a70b4e4-e542-4008-926a-8fbcfa5032c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2506ec4a-c3bd-4a65-8b0c-be1219cbb39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a9d12b-2284-4032-bc50-c60ebbd05a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d30c7d7-f5f3-4dc8-bc55-a80fee738d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fec0bea-19f7-4800-8e03-febeb312ce6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b12cbd0-0418-45c9-8b29-120c7d101775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5641675-85dd-4215-92aa-14c474a64e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27d92ae-e814-4ca7-b068-fe52f0c5621f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 934bd578-05e8-4459-885b-87b92d826bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0693f6a3-8db8-4138-8721-1f117737eeae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112fdf74-c2c4-44cb-9a84-2c52a257ae07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d958706-a1ed-4e3e-9b5a-1ae40058050e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f82cd8-cee7-45e4-bed6-96a6635726d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e20aa9f-27c7-4aa5-ae0d-2ce37583035b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60dbe3c-3fcd-4efc-a6d1-5587da842262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa3e93a-6920-4d30-9cd0-7f4687ce616e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 844e7154-746f-43dc-8ce4-006421555453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c42b0501-f22f-4301-b9f7-d51725eaef6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab38def9-38d1-4631-bc2e-2373e76d8546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed2670c-9b76-4567-a7f3-d5fdfe562a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f21d9ec2-1064-432d-a673-7c4c7a06bec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cdaf70e-4c95-418e-b543-cd70103e53a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 007726cd-b87c-4665-984c-1fcebcbe14a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 197dfd6c-d13e-4018-826d-be930e802441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 203d8602-fc60-409c-9ad5-0ee8dbb89146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2da18051-5c21-4c44-bc95-6f091f9b9ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f568ba9f-61a6-4007-b1cb-30a140c7f125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6add85e6-db03-4cb2-b641-be6e415a0b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57d9c9ba-9aba-4c2d-9cdd-f4df264441dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b6e419-8ac6-4e0d-9bc3-efacbb9e3b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a14d4475-3127-4ef8-88bb-e7fe10b9d0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9476967d-be8c-4c62-beb9-d555e5cd5055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff91b264-433d-4b29-85e4-91eaa50f8a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e928ba6-7729-4e1a-9764-0a49e57bb351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9451b870-bccd-4741-ac34-6327088601e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82fce5ab-d678-45dd-9266-3d0caee3e46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54472efd-eaf2-4cd0-8959-bde4135998e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb5663d1-7672-4838-a480-7b44ee75ba63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c8161e-a4c5-48c7-b2d5-b76a3135f418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b65847d-1a30-413e-aed8-e8311a285706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135acc1a-0c7c-42f8-b87d-b1615e854563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cfd7e4-ea6f-4989-b3f8-ecbae6eb79ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc92a2a9-2260-48e2-8a4d-34af8bd28fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bbb76aa-978a-4c20-ac17-632daa064481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26617e55-4d2d-4ce5-b3ac-bfb50f4a616a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc1fc66-09ed-4071-bf0c-d5cb24db134b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f21ce0a6-251a-4e01-a943-6b7cf6f03cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962fd4e6-ea60-415e-a7a4-5ae4a3aaf216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59cede5a-ba5f-4a87-aa10-387429bc905d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb07f557-6a34-41af-8046-dd4ae4e738b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1797166d-5f32-421e-8808-9a027480ec4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8238508-73b3-4e1c-b414-c6e26371a107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6d4bb53-0617-4df5-801b-067f164c7120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd4fec87-ddb2-4726-a33f-f632938e1468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f10fc305-b8cf-45a8-a9c3-1e0fa6b4c417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8aab40b-4794-4abc-9a8d-ac8050a4316c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adf28651-e613-488b-9e72-e8cba2bda828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd29ccc0-6b03-423d-98fb-b3f99a61a728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f81ca56-4013-4fe7-968a-f72c8efc2c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad10ade1-8d34-40b5-868f-b3383f26c44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd6326cd-e2b4-498b-bf04-5b599f78418f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b6a8ac8-71ac-46e2-b273-a18fc81efd53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cac8aee-53b6-47e1-8fcd-a090667c75ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0841b804-ac9e-40e9-8a99-9fb678236c6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb889948-707b-4354-adc2-a941e67ea2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e23ea2-fc42-4317-a5d9-31183f01e7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d5715a3-0af0-449f-8580-5b1845f289f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 876a7872-6bae-4ce0-9ae0-bc0f43274ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b07e7a6-de82-48e7-bc43-2406b7753c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f483a9db-d4cf-43d9-9ceb-e830fa89db59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68e02117-1651-4591-bdab-8bc25dcb89d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa60eafb-362a-4de6-9118-fdd1a13db350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67146b94-2300-43de-87db-8550589a3a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93506b0e-e259-4362-8622-56e260cc3e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5eb6968-cfa4-40d8-98d0-5971f3706d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fccf1df6-ed4f-468b-8f35-7193b1ab9d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27705823-fe6c-42b8-93df-b879fbe57feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf4f4ea2-b623-4a4b-abee-ba3b8315b5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80b96a5c-d12d-4c26-8264-bd18478ef07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c250bd54-031a-4114-a5f2-e325bb889590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459e1ff7-9ce1-45c4-90f2-962c4aa9e235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a125b4-5a3c-4594-ac25-45e1e2d150be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8443d7c3-3512-44f0-a967-95e932db8eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d9ae63-03c1-446e-b6ec-1180931ff035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8a499e-b4a3-47e3-8eaa-100ffc1df5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f035235-25a8-41ce-b2d8-83c8e019eb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d6b91c-9a0c-473d-9565-98d47543c9d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bfba58d-c3ab-4da1-a49d-f45a8630b8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb6aaca-c6d9-46db-a674-08c188781dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a7b67a-4c08-4fb2-9904-2a92ebadc81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5daa5cf7-1d8c-4344-a2a5-d455e4dce857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7574a5a4-78bd-44fa-83bf-c4b216fbe873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5297a41-a04a-403c-94fb-93c18b5cd785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0fabfd1-6e63-4725-93e2-962c3d2ef221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e227f1ae-c98e-4535-bb24-cb2add643b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 162c0fe9-845d-44ad-abcd-e2846d56b995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76dcc28a-8a91-4c20-a865-39592c0e9df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adcec13b-ee1a-4fd2-bbaa-d188ce8288db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8361916-7403-408d-a6cd-447963f2fe4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82e7f6cd-0b93-4128-a933-ade2eda7263e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d299fe0-5deb-4175-9f08-4c7422f0ed34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6df10ff2-9534-4bf2-ae68-7ec20dc277b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e85bdd64-7a8d-4f68-a920-213891f433aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c23a7b1-c3e2-4445-80d7-ac8e22d67d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a41ecb6-e976-49bf-95d2-f07ae380a706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 651c543b-c58b-463b-becc-7812fcc88197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b807f579-e3e9-414e-becb-63bba04cd665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07802cdd-a5ac-4617-a40a-47fd41d70784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321797df-d835-4509-abdb-c42c5fac968e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbd38bde-ac0c-42a4-bdbc-b0f552f1b24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bac87c8-fbcd-4345-9997-570642fdb9b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7592a083-9daf-43e3-b9a4-f9477b00f849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c2e2df3-b25d-4d61-b250-e460a2bc7bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e337f77-f074-45c9-b366-606f78ba9731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7292e997-703e-41e8-bd2c-d716f8b4892a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c579e5-6c2c-4175-b466-6967c0cdf5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 195f4d6e-436b-4164-8699-3478d58f4ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d4b6df-0b64-47be-aa49-2f99482e8772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1762937-963d-44e0-aeff-39c44d650177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ca0a6f-9c49-4b3c-b5a4-4ddb829cded2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 250c5f2e-845c-45a1-8692-ba6880d26ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e23423d3-b0dc-4e3e-be30-8c43e25a7101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53aa8abc-311a-4ae5-bd8d-1eca2d91fcc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c1078e-b61b-45a7-94ec-ff3b8d7e367e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 636422ff-adbe-472b-938f-951530626e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9518a091-5e5a-46ad-a72f-3dca383172ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52000203-7796-487e-b5d7-090c5009bbcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0efb0c-107e-4436-bd30-cf41c08a5a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60053e05-16c2-4b2f-82c6-fa716c18f2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ea7064-729c-46e7-a9c1-5980614a0ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfaea88c-0b5d-46ae-948b-ab00eb0ee691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58bfab47-8866-4ecd-ae5f-fd17c93563fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb97476f-f643-4841-9ad5-1640024dee67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a45bca-4a47-4ba1-8f03-54a8bfeadbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 180614e0-53d8-41ac-aec0-12066350a5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619ccbf1-6cde-4152-8994-1431bafa7354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b424aa02-264e-497d-90f2-16234066d448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ff47bc5-8cd5-4c61-9a83-fdb30db9d2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faac2c21-6421-41aa-8dff-1eff8f81ee09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d858467c-c366-4256-a9f7-5b3c3d212cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 881341bc-7388-445c-b446-527daf44896c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_33
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/test_labels.txt

📊 Raw data loaded:
   Train: X=(2282, 24), y=(2282,)
   Test:  X=(571, 24), y=(571,)

⚠️  Limiting training data: 2282 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  562 samples, 5 features
✅ Client client_33 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1340, RMSE: 0.3660, MAE: 0.3009, R²: -0.5559

📊 Round 0 Test Metrics:
   Loss: 0.0959, RMSE: 0.3098, MAE: 0.2644, R²: -0.1144

📊 Round 0 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2562, R²: 0.0044

============================================================
🔄 Round 8 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0855 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0795, val=0.0845 (↓), lr=0.001000
   • Epoch   3/100: train=0.0783, val=0.0849, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0774, val=0.0845, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0761, val=0.0840, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0653, val=0.0811 (↓), lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0535, val=0.0851, patience=10/15, lr=0.000500
   📉 Epoch 26: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 8 Summary - Client client_33
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0631, RMSE=0.2512, R²=0.2215
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0428
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2601, R²: -0.0538

============================================================
🔄 Round 9 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0833 (↓), lr=0.000250
   • Epoch   2/100: train=0.0793, val=0.0832, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0790, val=0.0831, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0788, val=0.0832, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0787, val=0.0832, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0779, val=0.0832, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 9 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0188
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0175
============================================================


============================================================
🔄 Round 11 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0851 (↓), lr=0.000063
   • Epoch   2/100: train=0.0780, val=0.0849, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0779, val=0.0848, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0778, val=0.0847, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0776, val=0.0846, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0771, val=0.0844, patience=5/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0767, val=0.0842, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 11 Summary - Client client_33
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0393
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0176
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2544, R²: 0.0144

============================================================
🔄 Round 12 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0802 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0811, val=0.0795 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0806, val=0.0789 (↓), lr=0.000016
   • Epoch   4/100: train=0.0802, val=0.0785, patience=1/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0799, val=0.0781 (↓), lr=0.000016
   • Epoch  11/100: train=0.0789, val=0.0768, patience=1/15, lr=0.000016
   • Epoch  21/100: train=0.0783, val=0.0760, patience=6/15, lr=0.000016
   • Epoch  31/100: train=0.0779, val=0.0757, patience=6/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 12 Summary - Client client_33
   Epochs: 40/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0543
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0384
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2524, R²: 0.0272

📊 Round 12 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2471, R²: 0.0695

📊 Round 12 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2402, R²: 0.1029

📊 Round 12 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2410, R²: 0.1050

📊 Round 12 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2415, R²: 0.1005

============================================================
🔄 Round 19 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0819 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0717, val=0.0814 (↓), lr=0.000016
   • Epoch   3/100: train=0.0713, val=0.0809, patience=1/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0710, val=0.0805 (↓), lr=0.000016
   • Epoch   5/100: train=0.0707, val=0.0802, patience=1/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0698, val=0.0794, patience=5/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0693, val=0.0790, patience=9/15, lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 19 Summary - Client client_33
   Epochs: 27/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0695, RMSE=0.2637, R²=0.1432
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0636
============================================================


============================================================
🔄 Round 20 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0731 (↓), lr=0.000002
   • Epoch   2/100: train=0.0734, val=0.0730, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0734, val=0.0730, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0733, val=0.0729, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0733, val=0.0729, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0730, val=0.0727, patience=10/15, lr=0.000002
   • Epoch  21/100: train=0.0727, val=0.0724, patience=5/15, lr=0.000002
   • Epoch  31/100: train=0.0724, val=0.0722, patience=15/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 20 Summary - Client client_33
   Epochs: 31/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.1164
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0849
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2364, R²: 0.1218

============================================================
🔄 Round 23 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0662 (↓), lr=0.000002
   • Epoch   2/100: train=0.0734, val=0.0662, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0734, val=0.0661, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0734, val=0.0661, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0734, val=0.0661, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0733, val=0.0659, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 23 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1237
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.1142
============================================================


============================================================
🔄 Round 24 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0698, val=0.0799 (↓), lr=0.000002
   • Epoch   2/100: train=0.0698, val=0.0799, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0698, val=0.0799, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0697, val=0.0798, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0697, val=0.0798, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0696, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 24 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0698, RMSE=0.2643, R²=0.1257
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.1066
============================================================


============================================================
🔄 Round 25 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 25 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0710, RMSE=0.2664, R²=0.1183
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.1221
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2378, R²: 0.1163

📊 Round 25 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2392, R²: 0.1096

============================================================
🔄 Round 29 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 29 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2697, R²=0.1174
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0722
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2403, R²: 0.1046

============================================================
🔄 Round 32 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 32 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.1013
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0901
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2406, R²: 0.1031

============================================================
🔄 Round 36 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 36 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.0996
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.1260
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2410, R²: 0.1016

============================================================
🔄 Round 39 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 39 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.0953
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.1418
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2410, R²: 0.1014

============================================================
🔄 Round 40 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 40 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.1010
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.1196
============================================================


============================================================
🔄 Round 41 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 41 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0966
   Val:   Loss=0.0678, RMSE=0.2605, R²=0.1237
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2410, R²: 0.1015

============================================================
🔄 Round 42 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0708, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0708, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0708, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0708, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0708, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0707, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 42 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2664, R²=0.1040
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.1076
============================================================


============================================================
🔄 Round 45 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 45 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.1086
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0704
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2409, R²: 0.1016

📊 Round 45 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2409, R²: 0.1017

📊 Round 45 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2409, R²: 0.1018

============================================================
🔄 Round 49 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0586 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0586, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0586, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0586, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0586, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0586, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0586)

============================================================
📊 Round 49 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.1039
   Val:   Loss=0.0586, RMSE=0.2420, R²=0.1051
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2409, R²: 0.1018

============================================================
🔄 Round 51 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 51 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2663, R²=0.1108
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0846
============================================================


============================================================
🔄 Round 52 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0716, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 52 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0713, RMSE=0.2671, R²=0.1166
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0573
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1019

📊 Round 52 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1020

📊 Round 52 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2408, R²: 0.1022

============================================================
🔄 Round 58 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 58 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.1017
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.1180
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2407, R²: 0.1024

============================================================
🔄 Round 61 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 61 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.1075
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0895
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2407, R²: 0.1023

📊 Round 61 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2409, R²: 0.1018

============================================================
🔄 Round 64 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 64 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0978
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.1221
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2409, R²: 0.1016

============================================================
🔄 Round 67 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 67 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.1108
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0742
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2409, R²: 0.1018

📊 Round 67 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1019

============================================================
🔄 Round 71 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 71 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.1004
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.1291
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1020

============================================================
🔄 Round 72 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0658 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0658, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0658, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0658, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0658, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0657, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 72 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.1040
   Val:   Loss=0.0658, RMSE=0.2565, R²=0.1134
============================================================


============================================================
🔄 Round 74 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 74 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1100
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0908
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2407, R²: 0.1023

============================================================
🔄 Round 75 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 75 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2688, R²=0.1170
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0521
============================================================


============================================================
🔄 Round 76 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 76 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.1117
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0826
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2408, R²: 0.1021

============================================================
🔄 Round 77 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 77 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2719, R²=0.1084
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0948
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2408, R²: 0.1020

============================================================
🔄 Round 79 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 79 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1054
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0933
============================================================


============================================================
🔄 Round 80 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0702, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0702, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0701, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0701, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0701, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0701, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 80 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0702, RMSE=0.2649, R²=0.1134
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0798
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2409, R²: 0.1017

============================================================
🔄 Round 83 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 83 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.1016
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0910
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2410, R²: 0.1010

📊 Round 83 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2411, R²: 0.1010

============================================================
🔄 Round 86 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 86 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.0994
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.1264
============================================================


============================================================
🔄 Round 87 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 87 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2686, R²=0.1086
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0852
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1018

============================================================
🔄 Round 92 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 92 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1133
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0715
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2407, R²: 0.1024

============================================================
🔄 Round 96 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 96 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.1101
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0843
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2407, R²: 0.1022

============================================================
🔄 Round 97 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0646 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0646, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0646, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0646, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0646, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0646, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0646)

============================================================
📊 Round 97 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0980
   Val:   Loss=0.0646, RMSE=0.2542, R²=0.1412
============================================================


============================================================
🔄 Round 99 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0703, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0703, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0702, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0702, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0702, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0702, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 99 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0702, RMSE=0.2649, R²=0.1082
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0999
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2408, R²: 0.1021

============================================================
🔄 Round 100 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 100 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.1029
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.1193
============================================================


============================================================
🔄 Round 101 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 101 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.1064
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.1054
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1019

============================================================
🔄 Round 102 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 102 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.1066
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0984
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1019

📊 Round 102 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1019

============================================================
🔄 Round 106 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 106 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.1099
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0792
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2407, R²: 0.1021

📊 Round 106 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2407, R²: 0.1022

============================================================
🔄 Round 111 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 111 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1094
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0891
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2407, R²: 0.1021

============================================================
🔄 Round 116 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 116 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.1035
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.1150
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1018

============================================================
🔄 Round 117 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 117 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1099
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0911
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2408, R²: 0.1018

============================================================
🔄 Round 118 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 118 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.1045
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.1077
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2409, R²: 0.1015

============================================================
🔄 Round 120 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 120 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1054
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.1056
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2409, R²: 0.1014

📊 Round 120 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2409, R²: 0.1013

📊 Round 120 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2410, R²: 0.1012

📊 Round 120 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2410, R²: 0.1011

============================================================
🔄 Round 124 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0716, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 124 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2675, R²=0.1108
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0722
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2410, R²: 0.1010

📊 Round 124 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2410, R²: 0.1010

📊 Round 124 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2410, R²: 0.1011

============================================================
🔄 Round 131 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0712, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 131 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2668, R²=0.1046
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.1072
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2410, R²: 0.1011

📊 Round 131 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2411, R²: 0.1008

============================================================
🔄 Round 135 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 135 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1050
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0912
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2412, R²: 0.1004

============================================================
🔄 Round 138 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 138 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0956
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.1257
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2412, R²: 0.1003

============================================================
🔄 Round 139 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 139 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.1038
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.1062
============================================================


============================================================
🔄 Round 140 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 140 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.1053
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.1007
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2412, R²: 0.1000

📊 Round 140 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2412, R²: 0.1000

============================================================
🔄 Round 144 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0709, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 144 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0710, RMSE=0.2665, R²=0.1049
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0977
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0998

============================================================
🔄 Round 156 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 156 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.0960
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.1139
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0996

📊 Round 156 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0996

============================================================
🔄 Round 158 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 158 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.0970
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.1181
============================================================


============================================================
🔄 Round 159 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 159 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2688, R²=0.0976
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.1019
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2414, R²: 0.0994

============================================================
🔄 Round 161 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 161 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1052
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0937
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2414, R²: 0.0993

============================================================
🔄 Round 162 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 162 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1080
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0876
============================================================


============================================================
🔄 Round 163 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 163 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1036
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.1043
============================================================


============================================================
🔄 Round 164 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 164 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1086
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0823
============================================================


============================================================
🔄 Round 166 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 166 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.1027
   Val:   Loss=0.0717, RMSE=0.2679, R²=0.1076
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2415, R²: 0.0990

📊 Round 166 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2414, R²: 0.0993

============================================================
🔄 Round 171 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 171 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.0991
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.1175
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2414, R²: 0.0995

============================================================
🔄 Round 174 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 174 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2686, R²=0.1046
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.1029
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0996

============================================================
🔄 Round 176 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0637 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0637, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0637, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0637, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0637, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0637, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0637)

============================================================
📊 Round 176 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.1019
   Val:   Loss=0.0637, RMSE=0.2525, R²=0.1144
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0997

============================================================
🔄 Round 178 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 178 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.0923
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.1473
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0998

📊 Round 178 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0998

============================================================
🔄 Round 181 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 181 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.1134
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0589
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2412, R²: 0.0999

============================================================
🔄 Round 184 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 184 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.1009
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.1004
============================================================


============================================================
🔄 Round 186 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 186 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.0977
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.1325
============================================================


============================================================
🔄 Round 188 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 188 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0946
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.1435
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2412, R²: 0.1001

📊 Round 188 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2412, R²: 0.1001

============================================================
🔄 Round 190 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 190 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1133
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0653
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2412, R²: 0.1001

============================================================
🔄 Round 191 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 191 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.1185
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0379
============================================================


============================================================
🔄 Round 192 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0712, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 192 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2667, R²=0.1039
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.1067
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2411, R²: 0.1003

============================================================
🔄 Round 194 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 194 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0805
   Val:   Loss=0.0659, RMSE=0.2567, R²=0.1969
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2411, R²: 0.1004

============================================================
🔄 Round 196 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 196 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0906
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.1555
============================================================


============================================================
🔄 Round 198 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 198 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.1108
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0724
============================================================


============================================================
🔄 Round 199 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 199 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.1118
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0677
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2411, R²: 0.1004

📊 Round 199 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2411, R²: 0.1003

============================================================
🔄 Round 201 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 201 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1115
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0783
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2412, R²: 0.1001

============================================================
🔄 Round 202 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 202 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2701, R²=0.1033
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0709
============================================================


============================================================
🔄 Round 205 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 205 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2729, R²=0.1136
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0480
============================================================


============================================================
🔄 Round 206 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 206 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.1033
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.1089
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2412, R²: 0.0999

📊 Round 206 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0998

============================================================
🔄 Round 209 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 209 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.1068
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0948
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2413, R²: 0.0997

❌ Client client_33 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
