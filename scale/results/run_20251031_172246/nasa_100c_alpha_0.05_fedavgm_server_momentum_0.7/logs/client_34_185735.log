[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ae17fdf-8892-4eb8-88e2-3a0e9cbde132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb02e539-f9b8-465b-8ce5-ca1c88842a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d056e47-b986-4bb1-a5fe-25d37cc0a705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c014e4a8-09ef-431a-a66b-45653129382e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb7c7e6f-8a57-4231-bbbd-468861a50bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11930f22-f467-43d2-9687-a24fd213a81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f9376d-08b3-4590-8d29-96c9157ea470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5d14216-49f2-415d-b141-5c20a46dfdbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6f0339c-d5e2-4cca-8427-d0b0c227ad69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71b6020f-380f-4049-9192-0cd0f2c23ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dada5807-86bf-4768-accc-b6b420342ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a154d40a-1a34-4d54-b371-d60b13118b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab37f3cc-1619-40d7-9e9e-c8120f477efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a566f6-b0f7-4ced-9898-de37284294e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 340cde0f-80b5-4843-bc22-1a895349c5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f81ac52-da94-421a-94ac-e870a3fd23eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d94792f3-7713-4573-a78c-1026c80f3609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8da66f-f857-4b10-98cf-312608557098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44948d3-2b29-4f68-8345-1df2195dbb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b9efd3-ccba-47e7-b4c0-046727e2c11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e7752f1-b663-41c9-b310-a4979fabc0a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7abdaf23-1899-43fd-ae4f-55b3331062df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c696311-46b2-41c5-acae-082b5c94e268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abd7b18-4034-452e-a062-e610c893e4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d95f2dd-a0f7-4ab4-85c0-53079801f63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f3e8c26-02a2-4294-8a60-6004c4a405a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6144320-ce93-43ea-97a4-9901767d2371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e27a7ab0-99bb-44b3-b030-208d02b566b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 642057a2-4310-424f-b777-26721899e769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6299ba1a-1146-4036-b391-d22c0bbd74bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be7a2814-30c1-4778-b549-1c186d34d8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37cff2b0-c484-4908-84a5-fac21d8f22d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1593992e-adc5-47cf-8e44-a36a5107e6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042bbb2b-e526-4929-ac9a-3037af63dade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 295dde0a-0ce6-4442-b1ab-6475d686e11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cc71f6b-f35b-43b2-8d5c-40b68010fc00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7765be8-9c34-4def-9812-c3569e7d43c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244eb06d-9131-42be-8319-1924a090b20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c30868-9dd9-4577-bfe7-46af4498ba49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a64915-3983-4772-8e19-1ee553f2177d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e233817b-3669-4a4c-a5fb-c13f76af5029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a378bbf-2204-45eb-a71d-44bc6e4a1479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e202ce-bb8f-4f5c-b5d0-e4d06f671338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e23b3c-447a-43da-b040-f9df489417be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b52bf377-705e-4e6c-8538-a8525e5f8ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ea55414-2adf-4871-8236-0c3d02002ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bf7a86-f5b6-4fd8-b768-712da2562217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8627b2-0b7b-4b90-95eb-74ba100b1469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7592922-af93-492f-8e90-7e69939e2e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98bf3d0-8d0b-47d8-9371-ee8b8ceba1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27e09b0b-777d-448b-adf7-6b209da67500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b44b3109-d07d-4a13-832d-70277e388b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196aefe0-ddc3-4eeb-b508-147377d2e882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cf2b66a-691e-46a1-b817-6314dbad175f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f3584c1-8d7f-4ec5-8135-bf9b37de7379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e01f1146-baf1-4ad7-9163-f02d966dcaf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f7f500-329c-432d-9650-6e269e9c5c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa96bbe-0a76-4b3c-b74a-106f8a854d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2a560f-bbcd-4daf-9966-00509e42190c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6eb72ba-34d9-4f3c-a27a-8aa64777138d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 705e373f-2c70-4eeb-81c5-e980d36b42e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6edb1b-8541-4649-8197-b861a64bf76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e735746-a3a0-4162-b412-555d0192fd9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1dc3d39-02d3-40f5-852d-ddc7078046c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b6776ff-deaa-4ca7-b3e4-8e58fa6d4cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925c8c88-2992-4fa1-8f91-bd7a03a2664a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 108dbc55-f990-4d0a-b62a-a5d949d075b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06e7b06c-de32-410c-be42-08e3cfb0a591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944330b7-b8db-4934-a362-44ffe16867cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0dff8e7-87ac-42e7-ac76-1667486ca1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d8c979-ff4d-496d-a06f-40d1d29e6c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9701d0db-6e9f-4177-aade-588d69b672da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beefb305-fe13-43b3-9154-827a2ce7b34b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d33ef3e5-0414-4de5-9a8b-743363ff462b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11afafb4-b7c2-4339-8641-0f0db6a379e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13982b9-8821-4718-b720-e88b96bddf3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa273842-7d32-4174-8e2f-e3dfe272256a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27aff719-f255-4a4d-b4c1-99bc2c79a935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8404418e-8e3b-4410-9ca9-5b8c2452a362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e5121e2-0d67-4ba2-8994-94fe7a8725e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d168ee6f-d501-4cc4-b1d7-895451219750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce784503-afd2-42a6-b3c3-d86d697b5eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901b8eff-eac1-4e4b-8b74-c3e7e40efc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca41472-7cd4-4fa0-b5ac-087c4d10c332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5fc3e64-1120-4d22-acc4-56f3e10dc90f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8237e7ab-f404-4a3b-b53f-3c03fc161b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc857c45-30bc-4f8d-b27d-fa02fa7a9c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd423459-7f25-45e7-9f97-dc38650a4449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af540b2-eb4d-4b70-be07-b5c041a4fa20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ba5da86-4ed0-48ba-9682-d4277280153f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84392139-4eb9-475d-8eaf-560f7fb5b445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 525d4d84-f437-4305-a16c-1ac21beefea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffda6a2b-5e08-49ec-a9ed-9c1559fb0a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a56fbe-8a5c-45b3-9288-4062080d9153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f276209-3d70-4be0-ae39-024724df4e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ffef7b-b2de-4bc2-9161-fe1545da752b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ea010b-aa90-4335-ba2a-77b5c4e78eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b75e80-b649-4d68-8220-5de7538f16a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9256471-56c9-4a5f-aa5c-6bee36539025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b44279a-40c2-4548-b1c4-cb1c02dce98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea79d65-d735-4cb0-8cef-0006b455dae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd3050de-ba85-4c06-bd0c-3b34c88719da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d6e3c1-64d3-4fbd-b82b-d3991a6300f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21653269-4179-4f15-98bc-a6687d59a4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59fc13d7-4447-46af-9aaf-20ad28e6e09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 798d5bfb-5c31-45c5-bae8-ddbe62457279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 780e345d-4828-40c4-a89b-2c4d62e87a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cba5b35-190e-4d3f-992f-cd1f8a5ffe41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca4242a-df0e-4a74-b94b-584ae2695c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b29d9e-4ef9-4fa3-802f-214ded57cf60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f902cc89-ad69-4d16-9d4d-8e613791a0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbfb7939-f43e-4538-aca2-95f476df0612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e64e40-73f7-48cb-aa93-866e16bf380d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921951f8-4915-4e97-9d67-4a64a91bc1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b3ee195-f509-4c39-91f7-4a54879f3f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a20d5c1d-3137-48a5-8b2d-e776b6f4dbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c5cbba-09b0-43f7-86fe-bb01a80905be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da365da-7b6b-4d1a-bc3f-c8f9fcadb7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9f9b2f4-ec03-473b-aa3a-a0b9965df560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5544ca9c-3042-4d31-ab96-6d6b7d681763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08d4b687-643e-4d71-97be-abc13cf4756f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd60ba5-427a-47fe-bf61-c33164317dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d616dac-d88c-4ec3-ad2c-3e0dd4997d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bc0146-3d4b-4856-85cc-c78c5df1399f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abdcc7c6-439b-4c6b-9b47-0c4670251c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71637e16-d0c2-4062-981e-d0b15845afac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4d285d-35ea-4bd1-924d-a8c51ab5e0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26aa7580-a17b-413b-9fdb-01d290b97fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43b72da2-c750-4e43-9473-83313d114e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7935fd4-f10b-4dad-95a4-a8a9d9904647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d57aed7-991a-4991-9d18-007cb0c4e506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10c3b7f7-8749-4b8a-bd3a-4da60774e7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40ab8de-8aa4-4550-b101-6e1edba6e2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450895ab-1518-4076-8c87-ee0bf4382eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c441e1-0444-4964-8857-05fffb6c4c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585d99e6-18f1-41f0-aff6-94099e3d79e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df9094cc-9acf-4488-9daf-6e0d2eb01b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eb24775-92c3-4d7e-8495-a77ba6ae6128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f2ac437-1786-4b36-acfb-d45a9a6a78b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6202bd2-72a2-4d8e-8c6e-377c30b6b197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db7d5ac1-d52d-4027-ab56-323a5ef6e049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da6862df-fb7d-4fbe-8836-63bb1f2601f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2fa87af-5182-4f51-91e3-f3064eb66397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad9eb15-1fe3-4ed3-8a47-91b649d82521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e607d2a-d511-4db4-be3c-342044fa2625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b1a14f-1068-4c9d-8b68-799073965edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f06d6e-23ad-4ec3-9cb0-06be83c07b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28bcc1bb-ac77-49b0-9b0a-5bcfedfdd39f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7814e4d-78fb-479a-8354-ab7e2cb0726c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c903a0e-e3b1-4b25-b045-1271a431146b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae2fc6f5-0155-45c1-a4b9-db1c1d32dfb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c356a497-b046-4705-bdd2-d3c97bbedcb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acccc1af-0f1c-4eae-93db-6afd8fa51c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e98a985b-4fa1-4e0f-a95a-08d41c450930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19ca1be-2ff8-48e4-ae6e-e1f442ff9eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1534ff4a-a285-4975-9a9f-067dc953eb29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568b7c44-d210-475e-8572-e44092329cea
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_34
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/test_labels.txt

📊 Raw data loaded:
   Train: X=(1148, 24), y=(1148,)
   Test:  X=(287, 24), y=(287,)

⚠️  Limiting training data: 1148 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  278 samples, 5 features
✅ Client client_34 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 11 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.001000
   • Epoch   2/100: train=0.0805, val=0.0778, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0785, val=0.0774, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0771, val=0.0770 (↓), lr=0.001000
   • Epoch   5/100: train=0.0756, val=0.0766, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0670, val=0.0742, patience=2/15, lr=0.001000
   📉 Epoch 16: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0558, val=0.0776, patience=12/15, lr=0.000500
   📉 Epoch 24: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 11 Summary - Client client_34
   Epochs: 24/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0674, RMSE=0.2596, R²=0.1908
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0743
============================================================


============================================================
🔄 Round 12 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0823 (↓), lr=0.000250
   • Epoch   2/100: train=0.0796, val=0.0827, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0792, val=0.0822, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0789, val=0.0821, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0786, val=0.0821, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0772, val=0.0817, patience=3/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   ✓ Epoch  21/100: train=0.0758, val=0.0813 (↓), lr=0.000063
   📉 Epoch 24: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0751, val=0.0812, patience=10/15, lr=0.000031
   📉 Epoch 32: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 12 Summary - Client client_34
   Epochs: 36/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0803
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0256
============================================================


============================================================
🔄 Round 14 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0755 (↓), lr=0.000016
   • Epoch   2/100: train=0.0790, val=0.0752, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0788, val=0.0751, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   ✓ Epoch   4/100: train=0.0786, val=0.0749 (↓), lr=0.000008
   • Epoch   5/100: train=0.0785, val=0.0748, patience=1/15, lr=0.000008
   • Epoch  11/100: train=0.0781, val=0.0746, patience=7/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 14 Summary - Client client_34
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0550
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0654
============================================================


============================================================
🔄 Round 15 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0768, val=0.0781 (↓), lr=0.000002
   • Epoch   2/100: train=0.0767, val=0.0781, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0767, val=0.0781, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0767, val=0.0781, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0767, val=0.0781, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0766, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 15 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0607
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0787
============================================================


============================================================
🔄 Round 16 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 16 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0640
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0727
============================================================


============================================================
🔄 Round 17 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 17 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0659
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0540
============================================================


============================================================
🔄 Round 19 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 19 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0354
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0726
============================================================


============================================================
🔄 Round 20 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 20 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0542
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0152
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2393, R²: 0.0823

📊 Round 20 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0836

📊 Round 20 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2403, R²: 0.0743

📊 Round 20 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2419, R²: 0.0637

📊 Round 20 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2423, R²: 0.0608

============================================================
🔄 Round 30 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 30 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0425
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0319
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2428, R²: 0.0577

📊 Round 30 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0563

============================================================
🔄 Round 33 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 33 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0382
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0328
============================================================


============================================================
🔄 Round 37 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 37 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0400
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0335
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: 0.0552

============================================================
🔄 Round 38 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 38 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0362
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0444
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: 0.0552

============================================================
🔄 Round 39 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 39 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0380
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0432
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: 0.0552

============================================================
🔄 Round 42 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 42 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0459
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0050
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0555

============================================================
🔄 Round 46 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 46 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=0.0431
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0245
============================================================


============================================================
🔄 Round 48 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 48 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0373
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0470
============================================================


============================================================
🔄 Round 50 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 50 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0452
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0166
============================================================


============================================================
🔄 Round 51 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 51 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0401
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0349
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2431, R²: 0.0557

============================================================
🔄 Round 52 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 52 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0430
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0232
============================================================


============================================================
🔄 Round 53 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 53 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0364
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0420
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2431, R²: 0.0559

============================================================
🔄 Round 57 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 57 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0384
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0451
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2431, R²: 0.0560

============================================================
🔄 Round 58 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 58 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0378
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0418
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2431, R²: 0.0561

📊 Round 58 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2431, R²: 0.0561

============================================================
🔄 Round 63 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 63 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0328
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0571
============================================================


============================================================
🔄 Round 66 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 66 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0376
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0393
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2431, R²: 0.0559

📊 Round 66 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2431, R²: 0.0559

📊 Round 66 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2431, R²: 0.0559

📊 Round 66 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2431, R²: 0.0560

============================================================
🔄 Round 70 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 70 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0318
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0705
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2431, R²: 0.0560

============================================================
🔄 Round 73 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 73 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0351
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0460
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0563

============================================================
🔄 Round 75 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 75 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0400
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0396
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0563

============================================================
🔄 Round 77 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 77 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0369
   Val:   Loss=0.0678, RMSE=0.2605, R²=0.0349
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0562

============================================================
🔄 Round 78 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 78 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0351
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0426
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0562

============================================================
🔄 Round 79 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 79 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0441
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0198
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0561

📊 Round 79 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2431, R²: 0.0560

============================================================
🔄 Round 82 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 82 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0402
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0277
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2431, R²: 0.0558

📊 Round 82 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0556

============================================================
🔄 Round 88 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 88 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0355
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0519
============================================================


============================================================
🔄 Round 89 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 89 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0344
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0415
============================================================


============================================================
🔄 Round 90 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 90 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0410
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0312
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2431, R²: 0.0560

============================================================
🔄 Round 91 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 91 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0496
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0045
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0560

============================================================
🔄 Round 92 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 92 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0317
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0738
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0561

============================================================
🔄 Round 93 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 93 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0370
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.0497
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0563

📊 Round 93 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0562

============================================================
🔄 Round 97 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 97 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0398
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0410
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0562

============================================================
🔄 Round 101 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 101 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0426
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0298
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0561

============================================================
🔄 Round 103 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 103 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0436
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0027
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0561

📊 Round 103 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0561

============================================================
🔄 Round 106 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 106 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0421
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0267
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0561

============================================================
🔄 Round 107 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 107 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0406
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.0311
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0561

============================================================
🔄 Round 108 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 108 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0364
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0506
============================================================


============================================================
🔄 Round 109 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 109 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0382
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0386
============================================================


============================================================
🔄 Round 110 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 110 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0466
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0134
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2430, R²: 0.0561

📊 Round 110 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2430, R²: 0.0559

============================================================
🔄 Round 116 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 116 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0394
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0340
============================================================


============================================================
🔄 Round 119 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 119 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0338
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0622
============================================================


============================================================
🔄 Round 120 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 120 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0329
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0377
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0556

============================================================
🔄 Round 121 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 121 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0421
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0306
============================================================


============================================================
🔄 Round 122 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 122 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0426
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0086
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0553

📊 Round 122 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0553

📊 Round 122 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0553

============================================================
🔄 Round 127 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 127 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0354
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0554
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0554

============================================================
🔄 Round 130 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 130 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0383
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0445
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0554

============================================================
🔄 Round 131 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 131 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0408
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0338
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0554

============================================================
🔄 Round 133 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 133 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0355
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0458
============================================================


============================================================
🔄 Round 135 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 135 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0366
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0490
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: 0.0550

📊 Round 135 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0550

============================================================
🔄 Round 139 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 139 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0332
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0612
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0550

============================================================
🔄 Round 140 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 140 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0387
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0371
============================================================


============================================================
🔄 Round 144 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 144 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0428
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0255
============================================================


============================================================
🔄 Round 146 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 146 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0354
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0507
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0551

📊 Round 146 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0551

============================================================
🔄 Round 151 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 151 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0463
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0030
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: 0.0550

============================================================
🔄 Round 152 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 152 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0423
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0281
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2432, R²: 0.0550

📊 Round 152 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0550

📊 Round 152 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0550

📊 Round 152 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0549

📊 Round 152 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0548

============================================================
🔄 Round 163 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 163 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0306
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0682
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0548

============================================================
🔄 Round 164 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 164 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0376
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0461
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0548

============================================================
🔄 Round 165 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 165 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0371
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0483
============================================================


============================================================
🔄 Round 166 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 166 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0405
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0330
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0548

============================================================
🔄 Round 168 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 168 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0422
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0193
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2432, R²: 0.0550

📊 Round 168 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0550

📊 Round 168 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0551

============================================================
🔄 Round 174 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 174 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0454
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0062
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0551

============================================================
🔄 Round 176 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 176 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0398
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0382
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0552

📊 Round 176 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0553

============================================================
🔄 Round 183 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 183 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0316
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0459
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0553

============================================================
🔄 Round 185 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 185 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0457
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0198
============================================================


============================================================
🔄 Round 186 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 186 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0451
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0139
============================================================


============================================================
🔄 Round 188 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 188 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0354
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0565
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0554

📊 Round 188 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2430, R²: 0.0555

📊 Round 188 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2430, R²: 0.0555

============================================================
🔄 Round 197 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 197 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0349
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0586
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2430, R²: 0.0556

============================================================
🔄 Round 200 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 200 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0432
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0232
============================================================


============================================================
🔄 Round 201 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 201 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0445
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0037
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2430, R²: 0.0554

============================================================
🔄 Round 204 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 204 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0411
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0267
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0553

📊 Round 204 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0553

============================================================
🔄 Round 208 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 208 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0398
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0400
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0553

============================================================
🔄 Round 209 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 209 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0288
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0804
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2431, R²: 0.0552

❌ Client client_34 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
