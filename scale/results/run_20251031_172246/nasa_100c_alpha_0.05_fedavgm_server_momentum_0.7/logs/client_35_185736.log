[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6deabbe9-447a-4ebf-bcfc-b9848d9f4f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d3e40e5-2a54-447f-b278-4501aba7f777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025de799-dfe5-4d76-8d55-573839ef43d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d7af66-6428-4bf4-a1ad-ace57d9e909d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9aae60f-2e67-42fd-be93-8e341518bf45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e67f686-0366-46de-833e-971491ac371e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16a1fae-9496-4098-a5a2-d58236099ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1262fb28-1b1d-4b74-8f27-579cace9c070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1e70b31-d70d-4574-a590-f4b89d6a11ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc29733-c4b2-426a-975d-99be665cc628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb257d0d-555e-4b2c-b931-032ad97f80cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80476b63-ac1e-4e86-a4f3-9195761e55e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35588bc-9b5a-4d4e-ae40-15be15411226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6592901-1b88-4b72-b02f-0a96681d4f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2fb5656-76af-4da9-8ccf-d7cd76a77d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca6771da-8d39-462f-adb9-c2d0966603f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eb18a73-7e61-403f-bc6f-fae828cfa97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef9d498-c763-43a7-b29d-e655a4efddfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14b26830-f184-4b0c-8ca5-2635002a8965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 143dddb8-a23c-41a7-9b78-10f352070e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5933479b-01da-42cb-a36d-1f1ef993c3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5fed3f-dd3b-4992-b698-e72782490a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac00e14-ea80-4cd3-9cba-fe6f53e716c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d39641ed-cf3d-405e-97ca-700567827721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eeb9df8-da97-4c69-80f8-fc6dcc8607a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4172fc-0876-48f2-8f57-a7b0f4963666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd9a29b-04ae-4670-be7f-758abcbe7999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97fd0fac-eb6b-4559-963a-ddabafcc7f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f879d489-a2b2-432e-9a3d-23fdab31efef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85887d3b-5c38-42cf-b77b-4e3689c54413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21423d2e-083d-411a-924d-ab84d63ad724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95873dce-b03a-4dc5-8079-0661ba4e50ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 038119ac-d11a-4757-8dd2-958840229d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199c1c18-085b-49b8-af25-f3fa8318da4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79eb7b5c-d491-4018-9de5-e492d485cb79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36fe9b05-ec4e-4422-8219-47e4ab981eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe8f2337-4c13-4219-92ff-7313b8c809f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb43f22-8682-46a3-982e-939239200069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92fa24af-e083-41e3-bbb5-dad8cb9c320b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe314a30-813a-478d-b8d2-0b88d6c3733f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5ae8d8-fdf5-4de1-b095-51c1eaa9d5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d8b4cc-ee18-468d-ab2b-0613242d8816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a95daaf8-4e08-4e26-ae09-ba26f7a02772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7519732-0fd2-4b80-890b-e7501d381ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0b3604-408e-4038-93a7-6f97230d0d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf2aed41-d45c-4189-bc3a-fc2c3c7047f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db66d08-2aa5-433d-b5a7-93569c496cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f0dada-8cd9-4bbb-9208-5b4826caa6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73c86ea-5368-4345-84eb-56518ab9a3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d1805d-9f00-46ad-8ab9-5084c280f797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c61dd24-fe27-408f-8d9a-dc0e8e7f79b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40adcca4-6dc7-496c-8420-06de40d9898c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b43ad5e-898f-41b8-91b2-2d80659742c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f92be42f-297f-456f-b39c-5607d6d19704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d20f50-3c89-4d42-b145-019b57efd4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76abb88e-04db-491d-bdfe-fe5be4ba69fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5225909-f64c-42d3-a466-7b155a1a41a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ead9c71-64a7-4b05-a150-06d9f9ad685a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76acd7d1-ef02-4698-9a69-00fd7d85518b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e89ef496-6c72-40e7-b75a-e4b5e760b379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bf74e01-390c-4fcd-abd2-34742181ce59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c4f3c2-9098-4822-9e58-906dfec1b473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997c1297-8f40-4cac-af71-3f435250dfba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 425aead8-23b9-4627-b296-1909a3e9bfca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e180f73f-5509-4560-ae5a-fbf4c473e7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fd5b631-b3e3-49bd-b337-cc2be86a583f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba21217e-e34c-45a3-950c-b6bd305c80bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3484d04-ce33-4228-a8d6-cb04aba4ecf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef74f71a-9c8c-42e9-a120-634fd20f535b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e20f6ce8-ef6e-4320-a04e-eb54d18fc0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efab826e-47bf-4517-a117-aee475e517b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d10c67-cce0-42c8-a3f7-fddb89ecbdd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b2b71b4-2ec9-4458-9c35-202c32bc9d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25001eb-8e13-4890-bd98-200d491f2170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 151f3ce4-80cc-4547-acbe-80792f8cb368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e104f4ff-d23c-4f02-9963-503db0c2d599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1269251b-3bba-4a48-a4fb-3831b11bac8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ed4d3c-ded2-4a2e-825e-1564d0a5fda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46875f48-7b62-4ad2-9869-9ff73e086eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 073858dd-b7f0-48a6-80eb-04db71bfcdf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66e0f5b0-9484-4d04-9a32-5f62cca3c0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4347cc1a-0165-4280-94eb-26296eca86cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce93ddb2-b0d8-4f2c-aae2-7166fe635eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ce367c-798e-4688-961c-eff129c9bcc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c83f03-12b7-4b67-ac58-619c1db28f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c29ba8-d9fb-47c2-9904-9aa210d37d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6e07db-a8ca-4a58-acb1-e646257ae698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d9fd88-cbff-45c5-b27a-9ab5456d84fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d47654a4-56fb-417c-b8f6-0695e8118df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70bb218b-1416-4ee3-9b52-0663887ff7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c12877-a268-4520-9aeb-6aad314e3279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d91784a-3812-49dc-8d30-b3392821bd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ee9cab-88ee-483f-8a2c-e66e2876e07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43be02f9-994f-4a10-8ae1-980ee577f56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d563f9-fa50-4525-a6d5-8746fdd64fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec362b6b-de3f-4fa5-bcc1-457da2a15354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4f5223-d49d-4ead-b9d9-f626f65743e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a209228-3f31-436b-874c-1cdbc9e9a721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47e8492b-5e68-416f-82cf-bb700358ae1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49abfca2-5a5a-496f-814e-868a9e8d9a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1389f649-a841-4810-a206-e40369af7f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02344c83-1ad0-4023-8247-c03fd2c923c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b68da1-c3d3-4b39-b359-bee62c609b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a805c8-beb6-416a-a867-12a115b92a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9769eb99-fb27-4772-971e-c66fb379b4a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417384a5-5a2d-4f00-9f94-e50eef237592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73352400-c73b-4a19-91a3-6ff1fec2fe02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5aa43a-d7a6-48df-a149-b7b4fe64ae20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c77b2aa6-7255-45bd-82b0-41a730555b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 669330a2-211c-40ae-b7e6-8f1c599af41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b6b6270-3be7-40e1-b5f5-e7489a53c28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a94e87df-75cd-4b5c-9bc4-d51cef99a896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b70aa31-8937-4408-ab47-55009d0c08d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb722de-5984-4991-a840-83fadea462bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57a21b2f-47b1-4d05-9ccd-064aa2d2694c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d773dca-fc29-4ec3-a9aa-f218da821833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21150c43-687c-4d16-8d4b-d7497f9dd276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2037689-c9dc-4034-9f48-596c73f7b1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c39ef43-c850-4f0d-9dea-2de680ba5426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a82e91d2-b561-4482-b598-86b256de6409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message effebd24-9801-406d-b1c3-f651bf0e89f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17eaf114-15ac-4ab9-b8f9-be8d5db6ae44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 600439e2-526f-44ee-b74c-6d9b34c9db4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d18eae-7b1c-4a47-aa0d-427e4ab390f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4f67ca-75e2-4064-85a6-6fcbf8a6a00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42857609-889e-447e-8b6a-1c32157b842a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681a550a-adee-4f30-8995-6f43ad1ba058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4afa8d6d-4d43-43b6-b08e-58c589b83654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f596452e-531b-4dca-b6d2-9f80e3df5a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c91e7db2-3fa2-45b7-949e-bcbd1de39ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b5164a9-8a18-4fb8-b047-3dc13b120042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e657ada0-55b0-4cd3-a481-baf513544619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e00e9b19-9210-425c-81c5-a095664267f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa27e7ae-833f-445e-8bc3-539112980a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d941bb58-74ff-438a-9420-c7795cacbc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0303f99-4bea-4275-98fe-819d0d47c307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c9994e-a400-42dc-9597-981333485f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc625f03-518b-4789-9197-8c6ff34f2f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a32137-0d07-47e4-9f3d-f0c043c32d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d75dc8c-b2ce-4c59-a9e5-7a3a197d535c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb10295-a5db-4e4d-a988-8b3906a63ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d39b9465-0227-4100-bffc-7fcaab749254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f865e5-4ab8-4326-9ba2-1b77c9ead702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495687f4-4ae0-43bd-9b2b-af989f45a300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f2ea5ca-a2d9-4246-aa36-5dc4d3f62da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe5adec-0ff6-4f86-965f-128188a8736a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598bef69-7cb1-438a-8ecd-5cb9f1f3928e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc1009d-b09e-4999-b4b8-334060bb96a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e7bb48-6d3e-4b3e-aac7-6bee540afe03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db87bfcf-af7b-4842-84b2-1f0c24b0a42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4559bc3d-acea-41fb-9b74-0f5c6a2d6dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d034d37-95c6-45fc-9b77-eb6cb3752093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71734096-4950-4c4c-80bf-edfdf9966f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf52987-e59d-46e7-93e0-4541b8487a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5045568-cee5-46a6-9879-6bf2caeb47ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b666fec2-d1ef-4f9f-9c87-23e708955524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad2b09f6-52de-48ca-acc5-f7923e644346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a15d5dc-6b90-468a-90af-8c33f245d1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d81481df-22c5-4d94-964a-c151877f03cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e3018c-f87c-45ca-ba09-aa77caf73649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e03c34b-6767-4ed8-9cce-83621a1e3d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34c22f59-1024-4fe8-a15e-851fdc23e35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a28e2d51-aea9-4da9-9a01-aaa88357ddab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5ac5b5e-235c-4a58-95c5-0622d5d57146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ace568-e368-4f77-b0ff-7ff3c5551d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 897fa74e-2745-490d-9257-1fa1134593cf
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_35
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/test_labels.txt

📊 Raw data loaded:
   Train: X=(1627, 24), y=(1627,)
   Test:  X=(407, 24), y=(407,)

⚠️  Limiting training data: 1627 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  398 samples, 5 features
✅ Client client_35 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2466, R²: -0.0144

============================================================
🔄 Round 10 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0874 (↓), lr=0.001000
   • Epoch   2/100: train=0.0839, val=0.0888, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0836, val=0.0887, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0889, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0822, val=0.0899, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0776, val=0.0952, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 10 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0148
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0130
============================================================


============================================================
🔄 Round 13 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0932 (↓), lr=0.000250
   • Epoch   2/100: train=0.0822, val=0.0932, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0819, val=0.0932, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0816, val=0.0933, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0814, val=0.0934, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0801, val=0.0941, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 13 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0164
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0186
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2438, R²: 0.0194

============================================================
🔄 Round 14 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0889 (↓), lr=0.000063
   • Epoch   2/100: train=0.0829, val=0.0886, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0827, val=0.0884 (↓), lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0824, val=0.0882, patience=2/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0820, val=0.0878, patience=1/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0818, val=0.0877, patience=11/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 14 Summary - Client client_35
   Epochs: 25/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0293
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0263
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2406, R²: 0.0404

============================================================
🔄 Round 16 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0912 (↓), lr=0.000008
   • Epoch   2/100: train=0.0826, val=0.0911, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0825, val=0.0910, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0824, val=0.0910, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0823, val=0.0909, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0820, val=0.0908, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0819, val=0.0907, patience=6/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 16 Summary - Client client_35
   Epochs: 30/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0284
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0060
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2416, R²: 0.0336

============================================================
🔄 Round 18 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 18 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0248
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0144
============================================================


============================================================
🔄 Round 19 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 19 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0173
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0104
============================================================


============================================================
🔄 Round 20 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 20 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0081
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0314
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2441, R²: 0.0149

============================================================
🔄 Round 21 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 21 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0178
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0415
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2427, R²: 0.0263

============================================================
🔄 Round 25 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 25 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0171
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0279
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2438, R²: 0.0176

📊 Round 25 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2444, R²: 0.0139

============================================================
🔄 Round 28 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 28 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0168
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0532
============================================================


============================================================
🔄 Round 29 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 29 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0204
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0013
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2447, R²: 0.0123

📊 Round 29 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2448, R²: 0.0118

============================================================
🔄 Round 31 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 31 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0281
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0027
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2449, R²: 0.0110

============================================================
🔄 Round 35 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 35 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0216
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0123
============================================================


============================================================
🔄 Round 36 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 36 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0194
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0162
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2450, R²: 0.0109

============================================================
🔄 Round 38 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 38 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0283
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0004
============================================================


============================================================
🔄 Round 39 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 39 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0268
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0021
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2449, R²: 0.0112

============================================================
🔄 Round 40 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 40 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0193
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0377
============================================================


============================================================
🔄 Round 41 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 41 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0198
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0278
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2449, R²: 0.0116

============================================================
🔄 Round 44 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 44 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0201
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0325
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2449, R²: 0.0118

============================================================
🔄 Round 48 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 48 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0249
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0113
============================================================


============================================================
🔄 Round 50 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 50 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0176
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0378
============================================================


============================================================
🔄 Round 51 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 51 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0255
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0094
============================================================


============================================================
🔄 Round 53 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 53 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0229
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0215
============================================================


============================================================
🔄 Round 55 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 55 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0307
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0071
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2448, R²: 0.0126

📊 Round 55 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0127

============================================================
🔄 Round 59 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 59 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0172
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0483
============================================================


============================================================
🔄 Round 60 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 60 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0199
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0306
============================================================


============================================================
🔄 Round 61 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 61 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0234
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0210
============================================================


============================================================
🔄 Round 62 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 62 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0198
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0291
============================================================


============================================================
🔄 Round 64 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 64 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0188
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0206
============================================================


============================================================
🔄 Round 66 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 66 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0201
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0308
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0127

============================================================
🔄 Round 68 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 68 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0273
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0027
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0127

============================================================
🔄 Round 70 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 70 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0114
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0636
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0129

============================================================
🔄 Round 71 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 71 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0243
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0155
============================================================


============================================================
🔄 Round 73 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 73 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0204
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0308
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0132

============================================================
🔄 Round 74 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 74 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0248
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0084
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0133

============================================================
🔄 Round 75 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 75 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0272
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0033
============================================================


============================================================
🔄 Round 77 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 77 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0196
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0336
============================================================


============================================================
🔄 Round 79 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 79 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0236
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0191
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0133

============================================================
🔄 Round 80 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 80 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0179
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0281
============================================================


============================================================
🔄 Round 81 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 81 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0234
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0169
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0130

============================================================
🔄 Round 83 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 83 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0246
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0016
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0129

============================================================
🔄 Round 86 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 86 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0221
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0206
============================================================


============================================================
🔄 Round 88 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 88 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0240
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0023
============================================================


============================================================
🔄 Round 89 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 89 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0182
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0401
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0132

📊 Round 89 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0135

============================================================
🔄 Round 93 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 93 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0246
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0126
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0136

============================================================
🔄 Round 94 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 94 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0179
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0418
============================================================


============================================================
🔄 Round 96 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 96 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0215
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0267
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0137

📊 Round 96 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0137

📊 Round 96 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0137

📊 Round 96 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0137

============================================================
🔄 Round 107 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 107 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0210
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0180
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0138

============================================================
🔄 Round 108 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 108 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0292
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0054
============================================================


============================================================
🔄 Round 111 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 111 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0164
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0412
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0138

📊 Round 111 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0137

============================================================
🔄 Round 114 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 114 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0245
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0038
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0136

============================================================
🔄 Round 116 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 116 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0213
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0263
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0136

============================================================
🔄 Round 117 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 117 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0247
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0125
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0135

📊 Round 117 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0133

============================================================
🔄 Round 120 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 120 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0243
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0027
============================================================


============================================================
🔄 Round 122 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 122 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0134
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0540
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0130

============================================================
🔄 Round 125 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 125 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0274
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0030
============================================================


============================================================
🔄 Round 126 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 126 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0266
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0027
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0130

📊 Round 126 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0131

============================================================
🔄 Round 129 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 129 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0255
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0066
============================================================


============================================================
🔄 Round 130 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 130 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0209
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0271
============================================================


============================================================
🔄 Round 132 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 132 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0231
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0041
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0132

============================================================
🔄 Round 133 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 133 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0304
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0199
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0131

============================================================
🔄 Round 134 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 134 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0184
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0354
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0130

============================================================
🔄 Round 135 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 135 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0256
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0072
============================================================


============================================================
🔄 Round 136 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 136 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0178
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0324
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0129

📊 Round 136 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0129

============================================================
🔄 Round 138 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 138 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0217
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0185
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2447, R²: 0.0129

============================================================
🔄 Round 141 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 141 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0207
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0224
============================================================


============================================================
🔄 Round 142 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 142 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0187
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0309
============================================================


============================================================
🔄 Round 144 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 144 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0243
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0217
============================================================


============================================================
🔄 Round 145 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 145 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0158
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0475
============================================================


============================================================
🔄 Round 147 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 147 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0220
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0091
============================================================


============================================================
🔄 Round 149 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 149 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0218
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0135
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0133

============================================================
🔄 Round 151 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 151 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0218
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0211
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0132

📊 Round 151 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0133

📊 Round 151 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0133

📊 Round 151 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0133

============================================================
🔄 Round 156 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 156 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0240
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0009
============================================================


============================================================
🔄 Round 157 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 157 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0192
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0277
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0133

============================================================
🔄 Round 158 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 158 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0227
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0176
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0133

📊 Round 158 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0132

============================================================
🔄 Round 163 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 163 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0163
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0357
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2447, R²: 0.0132

============================================================
🔄 Round 165 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 165 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0185
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0286
============================================================


============================================================
🔄 Round 166 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 166 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0203
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0212
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0133

============================================================
🔄 Round 170 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 170 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0190
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0297
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0135

============================================================
🔄 Round 171 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 171 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0204
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0254
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0136

📊 Round 171 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2446, R²: 0.0136

📊 Round 171 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0138

📊 Round 171 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0138

============================================================
🔄 Round 180 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 180 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0177
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0371
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0139

📊 Round 180 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2446, R²: 0.0139

📊 Round 180 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0140

============================================================
🔄 Round 184 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 184 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0164
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0398
============================================================


============================================================
🔄 Round 185 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 185 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0199
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0160
============================================================


============================================================
🔄 Round 189 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 189 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0248
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0106
============================================================


============================================================
🔄 Round 190 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 190 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0238
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0022
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0142

📊 Round 190 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0142

============================================================
🔄 Round 193 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 193 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0198
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0285
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0143

📊 Round 193 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0144

📊 Round 193 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2445, R²: 0.0145

📊 Round 193 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2445, R²: 0.0144

============================================================
🔄 Round 201 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 201 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0245
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0009
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0142

============================================================
🔄 Round 202 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 202 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0290
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0159
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0142

============================================================
🔄 Round 205 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 205 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0306
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0189
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0141

============================================================
🔄 Round 209 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 209 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0130
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0237
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2445, R²: 0.0141

❌ Client client_35 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
