[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157aaaaf-12b7-47f0-9796-7ab8b7715534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d46e1f-dbe9-4005-8c29-a86c03201b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61730ae-5356-46dd-81d3-d64d2ff383c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de1fdf4-ea64-4a22-89e2-002ac6191ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c5e676-e5c0-4d34-8723-1ddda8bf1a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f07f72-f41d-425e-8049-be7d25255c32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcba953a-38c1-4dec-a1e0-e8fede66b4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bab840d-62b0-416e-976f-cd45ba811e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9eae735-9de6-48dd-92c7-0eb34722d5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d19f77aa-4196-4818-a5be-0119c2dd8622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f544304e-2799-4ddc-9198-c21d2b32aac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5adfa867-3d05-47ac-bcde-0cf0736ecfbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c8bf7a-6a4b-409c-8e6c-786b06c9a380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d81d08-48a9-450c-9c9f-91971cd3e608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2487cd-7db4-40bd-80b8-b2e6c17cc9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3faddb5-509a-471a-87b2-2d9015e3c8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2cb245b-7ade-47d6-a839-c66302c9fb56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e07229-8f36-41b2-bdfb-b81f3ff09e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9294c4c6-8f0a-4fce-881b-d1f0c41c7ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac924be9-7c8a-465c-b1c2-bf1216842b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a25ba63-e529-47d5-bf6c-c92b14f29717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd2bb81-245f-4211-8564-143fcf4dd339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e53ed5-43c6-42aa-9a20-425e40827fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506c3de7-1bc8-4af5-9916-9ecf5b7fe64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e657279-2b26-4b1f-9f90-f635d1e810a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5052b2cb-c0bd-4ade-8121-50e0e9f3a7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb358810-69e8-4d11-bcee-eee78a770cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c285a4-5e31-43a3-ae91-1d1a3c8027cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a5ac8e-c011-4e55-85f2-22aed38b5aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03fbd4cf-a016-4b7a-b1c9-4157410e4b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37ddca67-c679-4a68-ba0d-197df6a5d2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f20a1795-7023-4946-bb58-c265855acfa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d332ecf-d56d-49db-9488-98d4e03d96c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b593a3-24be-4617-af80-237f21eb1017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ed2309-6baf-432b-8041-5bd86d8fe3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec70729f-6633-4798-8e0a-a120962dee2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f4af98-07c4-405d-8019-ec7f31c34409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 868910ab-bf04-47db-9892-a4645765bdc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3776dfc-2b34-4ed8-8a5a-1141cc3533f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b9ed30-97c5-4eb3-9a19-998a7418121d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0140fe16-5cfa-4680-83f0-401547c8be64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac7e8c07-06fa-4682-89ae-760cfbd8a98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c35c1e3d-5cef-4182-9c09-eec5e7151e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cdbc616-e745-48da-9f9e-dfe97f53fd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9032ccb8-b62e-4dea-b94d-b84288ad482a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ae9871-6c78-42e3-9a1e-df54d5b0c88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f5a51a-3e27-412f-b2a6-01f60644e3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05dfa4b6-09d5-4646-9e41-307443428a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dd56f94-3070-4d20-a080-02e4c535a23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd61af5-1b08-4c31-a4ed-4fc3267b5638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0cefe1-ac4d-4fff-ac44-dddf0e334b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c7b3a71-8f8c-4d3a-8b31-88f002719ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d80aec1a-8b7c-4a1f-851e-a499979d98cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20fa172d-4d7c-4ab4-9ff0-0aeae2adecbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e316d7-133e-424b-96c0-020be160638b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f5bbec-ca6e-4ec5-b40c-040a00dc7ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1666e93-9fa8-4da0-96d0-26358f1a5652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51a08a9-d5db-4e85-837a-c28e1dfae821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ea82b2-43dd-461a-a60d-307f1b445bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cac6849-7233-4115-958d-1f7d99ecd8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b958873f-550e-414a-8477-6394c4b9c9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a78ad9a8-69b3-4a37-8b57-82be6c7ffa42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 493d26d9-6439-4836-9522-92f99ee20578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b82567b6-9ecb-47b1-a58b-258325ffc05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa965a3-8e53-457d-88ef-813d758600b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33425369-a83e-415b-b8b5-7f37c16e7dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d3c4197-3594-40aa-b410-950857b149cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b3d68af-64ae-44c5-9652-97153a55bd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50e8e7d-ad2f-470a-a244-b8aec9e8a336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 415c0a64-49e4-489b-91ee-98d2fe615310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5786dd1b-61fb-4abb-855b-f27974326a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e20c208-ffa1-45d3-9ec8-d086f38749b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f85ea2b9-6d02-425b-a708-4f491065020b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a996b5-5d83-4108-a473-e3840c051bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e1543d7-dcc9-4dc5-9f77-039355417ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1eff27-b165-4754-8fd0-eea11d81bf73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6469424-fed1-455c-9778-92ad48447101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72d38f03-8f48-47d0-9b15-1f3fce82a5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b212a0c-7439-4d35-8723-e960e98e79a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc1435b8-963c-446f-a8dc-a115617792fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c907ffa-46c9-41fa-b115-8aeb079841f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db1559f-704f-4b0a-8f64-d31b192395c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7fa24b-4a27-4256-a1a3-f33005ddf46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3700e0ea-c25d-45aa-9093-6e03720162db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8420a974-f8e6-48a8-aedd-212ecd0dc7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0f2851-887f-4edf-89a5-9c373e3dd05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f050382-a565-4b87-b2a2-a30e403d3972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 166d002c-3235-4dbf-8319-fb0e4b3540b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 405013ea-a72f-40a6-93f4-c2291e644dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81e8f491-acc0-4a1c-b1d8-9e0e3405d901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7c59ac-0b5b-4e84-9ba0-2dba08fc9f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64be7e21-d80d-4bdd-9e23-138682b7ae0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01247cb4-19c1-4fff-b2dd-5ec1376038ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc045409-0857-4ad1-afd8-36f9a6e926e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4800a00-ad40-49e2-a7e4-d9e11d952641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f165f4-10c3-46f2-b67e-5d08e7278299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9321b4aa-65fa-4177-99b1-81ce5c92624b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361710a3-b878-4fad-9daa-814551beab73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef45412b-2410-4df1-9aa1-1a8f94f31f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4271df-fbcf-4950-b679-b9d5d4158b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef41647-8348-42b8-9453-820669249e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 723962a0-6cdd-4720-beb1-2ab3a2d7fbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d56f57f8-bd59-4287-ae61-bfc48e1b486f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4105ba-ff64-4932-918e-d6c5565b842f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a662461-a49d-4023-92da-514808209686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e0ce03-7a6d-4797-bad7-892d8d8ead50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7761a264-e753-4247-8d8a-863edec55e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10d1ef8-d100-4501-a20c-678a0794d2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ebd7e0-6ce0-4f5d-a8ec-a143460febbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b3e249-bcca-4a7d-9d2e-c6081c9e3feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f3f4884-b1d4-4b2f-8582-ea41986c73e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d49b0b-4487-4fc4-8597-6fef3851d945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d2175f-177e-4877-91d1-7a9030524bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f439e3f-6c13-4d42-9918-9135f1092eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8892947c-e1c7-45f1-a0e5-5141f84bccfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1924b39-6f18-4e93-aebb-199f1c800796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a64c7cf6-f0c5-41f5-a0db-07568fb1308c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 907be466-9a68-4c9c-ae52-0ac0ea38cc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 695b400e-e309-4ed4-b8da-334f1c4ce43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bdf56c4-2073-49d5-838b-1eefef6a6272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0c35e3-5a78-4950-a40e-0815732ac58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f90721a7-551c-4fc5-ba4f-d3230c3a8b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b47ce8c5-2273-451e-bdd9-9ba7f8684902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6a16cc-f877-4d9a-894c-68bf2a2d234e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a8da5c-692c-41d4-999f-771fbb6fcea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d109eb-f237-4759-a9db-846eecf93f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 546ecb04-f70c-41f1-a12b-aba279a9efde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1a77f7-3419-4f7d-a946-46ae0d8aa898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af7cecc7-505a-42f1-a71d-105f4e4b9b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a68d8a41-bc55-4a55-a3df-14c6c448a0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84188e2e-5627-4bed-8d06-1a0d09a76b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d28b2622-f4bc-4d53-9419-98d4bdb7e9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bc00beb-e4d4-49f4-97d3-33d508e61306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745ecf67-bb68-423b-b923-d108640e374a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc2c7194-348a-49c9-b435-745993c14f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f8bce9-22e6-44b0-a9b9-00ba4892be29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08443076-379d-4f6a-b4a1-267883862525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27581d0f-e3aa-43a2-b58c-660804d5006b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8ab63e-b286-4680-b7ea-f56d13920f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a2b04c-b372-4984-97ac-30f7721413d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 294747a9-79e3-4f70-a9f7-a42731ee2236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f08f98-2569-44f9-aebb-5979fe2d720a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 662719ac-83f4-4869-950f-002e353943a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f5cf780-3edc-4e12-8f00-24bb4c05655b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b253278-b4c1-4216-a976-04b86a60306c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2dfcbde-d29c-4334-b80c-c2b2149bdd80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e96a775-800a-420d-a45d-80c9e8245b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d091c96-40e2-4628-88ae-cd126156c6f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65bf482-e771-4020-84cd-ed5b514d596a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22200c8a-2d71-4904-8977-5ecd832cc7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb3275d-abba-4345-b9c2-c19324618207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 504db5df-9bea-48bb-9feb-38f4bb5126b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4006bd7-3221-4de8-9e03-76522026e800
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_36
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/test_labels.txt

📊 Raw data loaded:
   Train: X=(1354, 24), y=(1354,)
   Test:  X=(339, 24), y=(339,)

⚠️  Limiting training data: 1354 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  330 samples, 5 features
✅ Client client_36 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2529, R²: -0.0540

📊 Round 0 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2456, R²: 0.0161

📊 Round 0 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2436, R²: 0.0347

============================================================
🔄 Round 14 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0793 (↓), lr=0.001000
   • Epoch   2/100: train=0.0747, val=0.0799, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0728, val=0.0802, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0712, val=0.0809, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0698, val=0.0815, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0645, val=0.0821, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 14 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0749, RMSE=0.2738, R²=0.0880
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0255
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2393, R²: 0.0620

============================================================
🔄 Round 16 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0712 (↓), lr=0.000250
   • Epoch   2/100: train=0.0779, val=0.0717, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0770, val=0.0721, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0765, val=0.0720, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0759, val=0.0720, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0739, val=0.0713, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 16 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0615
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0574
============================================================


============================================================
🔄 Round 17 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0730 (↓), lr=0.000125
   • Epoch   2/100: train=0.0774, val=0.0729, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0768, val=0.0727, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0763, val=0.0727, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0760, val=0.0727, patience=4/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0747, val=0.0728, patience=10/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 17 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0573
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0643
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2393, R²: 0.0633

============================================================
🔄 Round 21 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0825 (↓), lr=0.000031
   • Epoch   2/100: train=0.0764, val=0.0824, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0760, val=0.0822, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0757, val=0.0822, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0755, val=0.0821, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0749, val=0.0818, patience=4/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0745, val=0.0816, patience=14/15, lr=0.000008
   📉 Epoch 22: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 21 Summary - Client client_36
   Epochs: 22/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0565
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0796
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2382, R²: 0.0681

📊 Round 21 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2381, R²: 0.0685

📊 Round 21 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2389, R²: 0.0652

============================================================
🔄 Round 24 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0766 (↓), lr=0.000004
   • Epoch   2/100: train=0.0782, val=0.0766, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0781, val=0.0765, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0781, val=0.0765, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0780, val=0.0765, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0779, val=0.0764, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 24 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0398
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0818
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2399, R²: 0.0598

📊 Round 24 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2403, R²: 0.0583

============================================================
🔄 Round 26 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 26 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0362
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0560
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2407, R²: 0.0563

============================================================
🔄 Round 27 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 27 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0360
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0536
============================================================


============================================================
🔄 Round 28 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 28 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0364
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0100
============================================================


============================================================
🔄 Round 29 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 29 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0385
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0312
============================================================


============================================================
🔄 Round 31 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 31 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0369
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0235
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2419, R²: 0.0481

============================================================
🔄 Round 32 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 32 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0417
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0109
============================================================


============================================================
🔄 Round 34 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 34 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0367
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0298
============================================================


============================================================
🔄 Round 35 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 35 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0382
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0222
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2421, R²: 0.0461

============================================================
🔄 Round 38 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 38 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0301
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0502
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2422, R²: 0.0456

📊 Round 38 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2422, R²: 0.0456

============================================================
🔄 Round 40 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 40 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0296
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0538
============================================================


============================================================
🔄 Round 42 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 42 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0424
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0068
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2422, R²: 0.0455

============================================================
🔄 Round 44 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 44 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0280
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0671
============================================================


============================================================
🔄 Round 45 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 45 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0286
   Val:   Loss=0.0674, RMSE=0.2596, R²=0.0655
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2422, R²: 0.0454

📊 Round 45 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2422, R²: 0.0454

📊 Round 45 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2422, R²: 0.0454

============================================================
🔄 Round 48 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 48 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0308
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0011
============================================================


============================================================
🔄 Round 50 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 50 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0349
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0379
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2422, R²: 0.0452

📊 Round 50 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2422, R²: 0.0452

============================================================
🔄 Round 54 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 54 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0347
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0355
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2422, R²: 0.0453

📊 Round 54 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2422, R²: 0.0453

📊 Round 54 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2422, R²: 0.0453

📊 Round 54 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2422, R²: 0.0453

📊 Round 54 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2422, R²: 0.0452

============================================================
🔄 Round 61 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 61 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0377
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0296
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2422, R²: 0.0452

============================================================
🔄 Round 64 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 64 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0361
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0350
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2422, R²: 0.0447

============================================================
🔄 Round 65 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 65 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0384
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0179
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2423, R²: 0.0446

📊 Round 65 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2423, R²: 0.0445

============================================================
🔄 Round 67 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 67 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0380
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0243
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2423, R²: 0.0445

📊 Round 67 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2423, R²: 0.0445

📊 Round 67 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2423, R²: 0.0445

📊 Round 67 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2423, R²: 0.0445

📊 Round 67 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2423, R²: 0.0444

📊 Round 67 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2423, R²: 0.0444

============================================================
🔄 Round 75 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 75 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0306
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0555
============================================================


============================================================
🔄 Round 76 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 76 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0423
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0148
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2424, R²: 0.0437

============================================================
🔄 Round 83 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 83 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0364
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0293
============================================================


============================================================
🔄 Round 85 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 85 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0428
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0046
============================================================


============================================================
🔄 Round 86 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 86 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0440
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0057
============================================================


============================================================
🔄 Round 87 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 87 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0353
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0348
============================================================


============================================================
🔄 Round 88 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 88 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0275
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0710
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2424, R²: 0.0437

📊 Round 88 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0435

============================================================
🔄 Round 99 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 99 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0392
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0226
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0434

============================================================
🔄 Round 100 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 100 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0362
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0198
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0434

============================================================
🔄 Round 101 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 101 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0318
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0431
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0433

📊 Round 101 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0433

============================================================
🔄 Round 104 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 104 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0361
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0072
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0433

📊 Round 104 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0433

📊 Round 104 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0433

============================================================
🔄 Round 110 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 110 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0414
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0009
============================================================


============================================================
🔄 Round 112 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 112 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0293
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0623
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2424, R²: 0.0433

📊 Round 112 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: 0.0432

============================================================
🔄 Round 116 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 116 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0357
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0267
============================================================


============================================================
🔄 Round 117 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 117 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0380
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0278
============================================================


============================================================
🔄 Round 118 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 118 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0453
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0043
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: 0.0431

📊 Round 118 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2425, R²: 0.0430

============================================================
🔄 Round 120 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 120 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0319
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0377
============================================================


============================================================
🔄 Round 122 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 122 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0383
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0281
============================================================


============================================================
🔄 Round 123 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 123 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0405
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0186
============================================================


============================================================
🔄 Round 124 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 124 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0320
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0542
============================================================


============================================================
🔄 Round 127 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 127 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0345
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0306
============================================================


============================================================
🔄 Round 129 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 129 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0282
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0440
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2425, R²: 0.0428

📊 Round 129 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2425, R²: 0.0427

📊 Round 129 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2425, R²: 0.0426

============================================================
🔄 Round 133 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 133 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0415
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0224
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2426, R²: 0.0425

📊 Round 133 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2426, R²: 0.0423

============================================================
🔄 Round 138 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 138 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0342
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0427
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2426, R²: 0.0421

📊 Round 138 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2426, R²: 0.0421

============================================================
🔄 Round 141 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 141 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0311
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0467
============================================================


============================================================
🔄 Round 144 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 144 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0380
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0031
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2426, R²: 0.0419

📊 Round 144 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2426, R²: 0.0419

============================================================
🔄 Round 148 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 148 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0423
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0023
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2426, R²: 0.0418

============================================================
🔄 Round 149 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 149 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0362
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0348
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2426, R²: 0.0417

============================================================
🔄 Round 151 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 151 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0273
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0668
============================================================


============================================================
🔄 Round 153 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 153 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=0.0377
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0213
============================================================


============================================================
🔄 Round 155 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 155 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0324
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0503
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2426, R²: 0.0415

============================================================
🔄 Round 158 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 158 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0328
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0328
============================================================


============================================================
🔄 Round 159 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 159 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0310
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0418
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0413

📊 Round 159 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0413

============================================================
🔄 Round 161 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 161 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0345
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0363
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0410

📊 Round 161 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0410

============================================================
🔄 Round 171 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 171 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0316
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0492
============================================================


============================================================
🔄 Round 172 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 172 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0365
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.0321
============================================================


============================================================
🔄 Round 174 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 174 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0349
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0074
============================================================


============================================================
🔄 Round 176 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 176 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0410
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0117
============================================================


============================================================
🔄 Round 177 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 177 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0463
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0081
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0411

============================================================
🔄 Round 179 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 179 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0339
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0458
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0411

============================================================
🔄 Round 180 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 180 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0270
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0623
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0412

============================================================
🔄 Round 185 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 185 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0381
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0304
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0411

============================================================
🔄 Round 187 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 187 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0341
   Val:   Loss=0.0654, RMSE=0.2557, R²=0.0380
============================================================


============================================================
🔄 Round 189 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 189 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0363
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0369
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0412

============================================================
🔄 Round 191 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 191 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0417
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.0100
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0412

============================================================
🔄 Round 194 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 194 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0334
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0428
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0413

============================================================
🔄 Round 197 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 197 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0355
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0424
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0413

============================================================
🔄 Round 198 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 198 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0387
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0284
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2427, R²: 0.0413

============================================================
🔄 Round 201 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 201 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0386
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0283
============================================================


============================================================
🔄 Round 203 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 203 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0393
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0151
============================================================


============================================================
🔄 Round 205 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 205 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0409
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0140
============================================================


============================================================
🔄 Round 206 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 206 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0399
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0204
============================================================


============================================================
🔄 Round 209 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 209 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0352
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0328
============================================================


❌ Client client_36 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
