[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2359f2b-5b2f-4400-b0e8-cb7ae8520a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ebfd553-1ab4-429d-84fa-d3f14e8c0d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ea9ef0a-8492-4e82-a060-d8b8d68c5254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66eeb3e1-f2d8-4bb7-b659-90b12763f3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1daa0692-7013-4a81-9222-94886cba9c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0fe654a-c95c-454f-baf2-e95fd72d9c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e18a6f2b-4dc4-4a35-a715-348b069e3a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f766699b-d446-457b-b5e4-2e363eed7ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61082eb-b1af-4b03-9fb8-b67199cfbfbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31f4a9b1-5520-43c4-9fc5-9647c4cc4fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d99525-02ff-4ddb-8226-3a8e3520baf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed8dbf93-7454-457a-bd74-e26b14dcf74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3602c304-45fa-43f3-81af-0a9d646281e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca0bb4cc-4bed-4f0b-8f9c-2b984b2e7c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f085796-50e9-4d1c-9cee-3688b4689a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a62e328-ca1e-4533-bd17-b0e5da419187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c245434f-e0d5-4631-aedc-4aa48ce2d904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2e8472-22dd-453c-b059-59586507b1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02880fe3-d156-4fd7-a072-110e3784286e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a4bbc6-ca48-441d-862e-388c55273524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab28fcb-bd31-456f-a546-03e1dd057746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2231104e-b531-4c9b-bdf2-fa0f215e6331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35fddf18-f7ac-40fe-a594-f46ff28794dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b66780cb-756c-4ab9-afa3-964a26135ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e44c7108-3a44-4bbb-90d2-219aa5b75fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21187404-4202-45f6-ba6e-4e6aa2af534c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc52e91d-bb3b-40d3-9a73-f73e20f9e82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83308db5-a3a7-4c84-84dc-d2c4766c8421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194366b1-3509-4196-bd9b-3569c1f9f77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de246a4-fee4-4be6-b88c-97443f422ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b25c13d-d156-4976-af2b-77766696621c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d87eb1a9-5e23-4695-9887-bc1a4401b54c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6bb53b-9aa2-48f7-9706-e61df98eb56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1358701-838f-443b-8660-e91e8cc196c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21450f5f-994d-4358-a54c-31be4e60d8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6925d13-9c10-44e0-b4e9-18e6705e916a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c78f8da-c2ea-4595-b5e9-6f22d3584c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d67d18-e60f-4c57-9c87-930f05f62f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 793ee13a-6260-405e-b3f9-5c87638aedbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f55e714-7045-4808-aa55-a527cd46e99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 864b18db-c2c8-4ae9-9ad9-b244b876ec14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310467e9-fe26-437c-8454-76b4462d4b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d907e103-bbae-45ef-bb72-af47539d0dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf2e7f17-00d3-422b-8739-6a72049b6d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8557d13-c3cc-43ed-b7a7-55716fbe7a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681a3ac7-8837-4b69-8ecd-b9e1819de490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ed3e0a-4420-4539-bc25-e307fd970dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1001b183-7d6c-4729-bd8d-6b09ff2e92d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f2f0e5-fe64-4d3b-a0c7-2c2af11f6888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35eccc21-12b9-4bd6-b10d-14e524825f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee069b8-5932-4e8b-ab7d-420174adb930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a434dc-4485-44ce-a733-efc20532da8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a629a61-b194-4b2f-9311-ee582f72d11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f452bf-6460-46e9-b196-8320db86e573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6abcce5-9545-4272-adb9-19e031ca0060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef783960-766e-482d-a1a6-fa31f2ecd184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10753a91-58d8-4a1d-b28c-20375710d1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94eafdf-4a1c-40b1-82c5-edf69b703a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea6af761-eaf7-4361-8664-e3eead21ae57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b01bf16-5ab2-40f5-a57d-b444a889c8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21de9d5b-fa45-4e28-946f-a13d23b55961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c374ff-beb7-49a8-9142-2d8f475f8d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 132df073-ff73-4d91-9cbc-c819e7f8da2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b30c3f39-5eca-4250-87b0-238ca30a73e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 469d4a12-c9c0-4a0e-a981-fa4f5126b16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58b0996-19aa-457a-8904-97c68adf15ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d5d915-fe92-4f9c-af78-45ff69803687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa083286-b431-4501-8b1a-800a4cdcb7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9a988c6-3e3c-4020-81ec-f9d560eaad51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65d1361a-98e4-4c9e-b3a6-a7c7bbc5d3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad0ec77-6e03-4029-9edc-728013dc5ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2eae4c0-68e5-4388-a51a-ad1c73248d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be53eeb8-1e43-4976-9f7f-b6522243665f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba74e3bf-cd8a-4cdc-9a59-14bfe34f3189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c4bd4ed-b4e6-460c-90c0-c0ddc3c6f880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b5ad36d-75b6-4d37-8fc0-31692679738c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb6b0106-17f8-4971-986e-682a310d4b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ddcb10-0e05-4876-8991-32898f0ba1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd1c7b99-18b7-49be-9cb9-e845bbdc3867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65ade60-990b-4287-98c4-8dc2427f48c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f96933-7601-4e46-8da1-9087d71524e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03b6d0d1-6595-4529-bc9d-6f18e4973344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b8ab1c-ae7e-41e9-b1b0-3e8fcc5e83e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b226c6df-c16c-42a3-a6c8-1fbb8d7b1cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7a3f828-78c6-4023-8bcb-b9da156add0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d452383-febf-46f4-bffc-7fa6e547a940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f72350-015b-4819-838a-dc6ac3a7b1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 618dba5a-3737-4fad-bc37-897e817ac0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c1c622f-eec0-42fa-9287-1cf11bf498d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a11f5233-6837-4be9-99ed-7bf9c3fdbb9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b181863-21a9-4bac-a337-1bd7a58272c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56959553-6185-4e7e-9e4a-dd95632f47f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe83f90-b5bb-4e59-adcc-ca035b43d539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b89580-b11d-4750-a913-aebcefaca706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21f162cf-e592-4b2b-84e2-fde9779c5fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379e2977-4b57-4169-84b2-ce380dde84d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e3f12f-32d1-4619-aaf4-f08bfde857ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f91e11-900c-4a5f-ae94-c674fc3e0254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3f67d71-c5db-45cc-849f-1a9fad63dc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ffa9bb-925b-40e6-b853-d890537fbe1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f650ec87-8e67-49f3-9dc2-d423bc340f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb6e642-c1ff-46b1-b0e2-b65f4c0c8643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f920e4-d77c-4f73-84f3-ae63dbdc25b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b90a09e-3551-453b-9199-32aa97a9805e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cadda7c-4976-4618-8784-ed20d287843d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6967f6-a7be-4757-aec5-c36517011ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0fece0-1a30-443d-aeee-0e54156ea844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e6ede8-b492-4a60-8fec-c1a9dab966cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab65957-12b3-463d-a6d9-292bba7df871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c7fae21-4444-4c9d-bc40-a6290f8e7379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a9f1fb2-3a50-4449-ad31-a4ead0f4f5ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5796a531-fd4c-4db1-adbf-24019176af87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c634b43-5046-497c-86cf-96d827f7935a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002d99d1-612a-4c53-a1b1-a7af9753aa9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda8966a-c647-4d77-81b8-2c44a0220652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0feda2b-90b8-464d-ab5d-51f0e17a6ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c9b36c-a31a-4759-8654-606bba5fa1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1ca167-c467-4c65-b21e-078b27919f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead22264-d4c0-436d-aefe-864b0b631315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dab46e6-f14e-4c03-bedd-f25be8e128bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddccd99f-1ea2-45df-9d72-b88012774e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6a51e3-00ee-4b1c-b784-dd901dca6b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58601d27-080b-41e7-baa4-6879a3a7517d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23481a13-bdae-4690-bf77-f8db655a1972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be3245d-9e58-4f4e-b2d8-0f99cfb79122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e1e06e-6374-49ef-800d-31c167556259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0867752b-f330-4bf3-aa5c-e2a658089754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1858eb18-b868-4ab4-baae-ba73d427530c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 841d9d0d-14ea-4a3c-a14c-d0070b9a01d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da1d9aa7-4377-4f56-9ccb-4505e3f20be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a5d6d4-3c19-4a61-92f9-3c15269a2e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c91ba978-0485-4d2c-9787-f26c3295052f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78b8e355-202b-40c0-8d02-9bc9675add7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7387f000-e084-4d77-b137-00a54998564c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d48210ac-56da-4eaa-97f4-3535ac695800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eed50f88-31cf-4220-b6e9-7027f9c89ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44c561a0-79f0-4084-8adf-48746a022f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f07c187-e576-4d4b-aaa1-12636b0bfa4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0454a3-b7c8-4230-acd0-5a1ddfde06c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b36ec477-0093-4892-85c1-955dacd20158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48020010-5512-4f5c-993d-6c999d8ad823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d914c3c2-049b-4ecd-a159-6dc9e12470d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb551b3-94b6-4049-9f7a-eb371233d543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4acc84-17d2-47e5-bcef-3520a85eb362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8233745a-a7f8-4cb7-a975-509343410ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9156a80d-9624-4b00-9b20-f0fc2884459b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba50dc7-c923-40b9-bd39-0617c2f07b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1060b82d-381c-430b-ac0b-5450602f6945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2792da91-4ff5-42b0-ac84-f65ff171f2f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7765f4ab-3eae-4d21-b49b-a4f40e326a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b493cf0a-bd90-4225-9715-c6cef9dcab66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c477ed93-c364-4f23-8f97-14858599c258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18f96181-13c1-41be-96e2-84095144b11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd31d51-247d-4647-9c0b-012fcfedc068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e700fdf9-332f-4f70-9bb9-7ed623bb5516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db0fd83e-888c-4b9e-8a3c-95a267590865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed58b40-e215-41df-874e-4c80d0a80bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab521f2-34b8-41e1-893e-143be0896ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b209026a-422c-43e4-9f6d-0fd8772fe594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3148a80-716c-443b-a03e-edd68c615a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b3c581-ff6d-4ff5-b391-e6385d662299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121ed7c3-20a0-41bd-97f0-6309ee88d8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a02d411-2cf5-4ba5-be9c-f9ae34ac3371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52492c25-ad9d-468b-b368-8c98b0893f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d458ef94-27ad-4b9c-9393-02f608b8b7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 577320b5-5a96-4b27-8055-c4d82ea8df79
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_37
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/test_labels.txt

📊 Raw data loaded:
   Train: X=(1276, 24), y=(1276,)
   Test:  X=(319, 24), y=(319,)

⚠️  Limiting training data: 1276 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  310 samples, 5 features
✅ Client client_37 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2476, R²: -0.0438

============================================================
🔄 Round 12 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0872 (↓), lr=0.001000
   • Epoch   2/100: train=0.0812, val=0.0872, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0798, val=0.0870, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0793, val=0.0865 (↓), lr=0.001000
   • Epoch   5/100: train=0.0788, val=0.0864, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0731, val=0.0856, patience=2/15, lr=0.001000
   📉 Epoch 15: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0618, val=0.0980, patience=12/15, lr=0.000500
   📉 Epoch 23: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 12 Summary - Client client_37
   Epochs: 24/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1023
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0202
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2458, R²: -0.0342

============================================================
🔄 Round 13 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0832 (↓), lr=0.000250
   • Epoch   2/100: train=0.0808, val=0.0837, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0801, val=0.0837, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0793, val=0.0839, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 13 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0250
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0102
============================================================


============================================================
🔄 Round 14 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0931 (↓), lr=0.000063
   • Epoch   2/100: train=0.0780, val=0.0928, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0779, val=0.0926, patience=2/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0778, val=0.0926 (↓), lr=0.000063
   • Epoch   5/100: train=0.0777, val=0.0925, patience=1/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0773, val=0.0925, patience=7/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 14 Summary - Client client_37
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0337
   Val:   Loss=0.0926, RMSE=0.3042, R²=0.0091
============================================================


============================================================
🔄 Round 17 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0833 (↓), lr=0.000016
   • Epoch   2/100: train=0.0798, val=0.0833, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0798, val=0.0834, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0797, val=0.0834, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 17 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0310
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0363
============================================================


============================================================
🔄 Round 18 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0784 (↓), lr=0.000004
   • Epoch   2/100: train=0.0813, val=0.0784, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0813, val=0.0784, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0812, val=0.0784, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0812, val=0.0784, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0811, val=0.0784, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 18 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0212
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0555
============================================================


============================================================
🔄 Round 19 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000004
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0815, val=0.0790, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0814, val=0.0790, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0812, val=0.0792, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 19 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0175
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0207
============================================================


============================================================
🔄 Round 21 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 21 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0366
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0136
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2380, R²: 0.0347

📊 Round 21 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2375, R²: 0.0383

============================================================
🔄 Round 24 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 24 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0382
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0306
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2387, R²: 0.0294

============================================================
🔄 Round 26 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 26 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0339
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0005
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2395, R²: 0.0231

============================================================
🔄 Round 28 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 28 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0296
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0020
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2405, R²: 0.0165

📊 Round 28 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0155

============================================================
🔄 Round 32 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 32 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0196
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0230
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2408, R²: 0.0144

============================================================
🔄 Round 33 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 33 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0190
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0271
============================================================


============================================================
🔄 Round 34 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 34 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0195
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0290
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2409, R²: 0.0140

============================================================
🔄 Round 37 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 37 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0179
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0235
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2409, R²: 0.0140

📊 Round 37 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2408, R²: 0.0141

📊 Round 37 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2408, R²: 0.0143

============================================================
🔄 Round 42 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 42 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0233
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0123
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2408, R²: 0.0145

============================================================
🔄 Round 43 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 43 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0213
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0177
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2408, R²: 0.0146

============================================================
🔄 Round 45 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 45 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0240
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0030
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0792, RMSE: 0.2813, MAE: 0.2408, R²: 0.0148

============================================================
🔄 Round 47 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 47 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0208
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0109
============================================================


============================================================
🔄 Round 48 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 48 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0194
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0279
============================================================


============================================================
🔄 Round 49 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 49 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0188
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0319
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2407, R²: 0.0150

📊 Round 49 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

📊 Round 49 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0156

📊 Round 49 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0157

📊 Round 49 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0157

============================================================
🔄 Round 63 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 63 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0184
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0326
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

============================================================
🔄 Round 65 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 65 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0226
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0167
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

============================================================
🔄 Round 66 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 66 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0182
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0317
============================================================


============================================================
🔄 Round 69 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 69 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0239
   Val:   Loss=0.0947, RMSE=0.3077, R²=0.0104
============================================================


============================================================
🔄 Round 70 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 70 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0278
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0032
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

============================================================
🔄 Round 74 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 74 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0230
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0137
============================================================


============================================================
🔄 Round 75 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 75 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0218
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0209
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2406, R²: 0.0161

📊 Round 75 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0160

============================================================
🔄 Round 78 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 78 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0262
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0024
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0160

📊 Round 78 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

============================================================
🔄 Round 81 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 81 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0187
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0186
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0157

============================================================
🔄 Round 82 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 82 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0161
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0411
============================================================


============================================================
🔄 Round 83 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 83 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0180
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0339
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

📊 Round 83 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

============================================================
🔄 Round 85 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 85 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0194
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0216
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

============================================================
🔄 Round 86 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 86 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0190
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0209
============================================================


============================================================
🔄 Round 88 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 88 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0247
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0052
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0157

📊 Round 88 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0160

============================================================
🔄 Round 91 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 91 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0197
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0276
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2406, R²: 0.0161

============================================================
🔄 Round 93 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 93 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0185
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0277
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0163

============================================================
🔄 Round 95 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 95 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0180
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0345
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

============================================================
🔄 Round 98 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 98 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0242
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0028
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

📊 Round 98 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0163

============================================================
🔄 Round 102 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 102 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0208
   Val:   Loss=0.0757, RMSE=0.2750, R²=0.0229
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0163

📊 Round 102 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

📊 Round 102 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

============================================================
🔄 Round 108 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 108 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0271
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0034
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0165

============================================================
🔄 Round 110 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 110 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0226
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0097
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

📊 Round 110 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

============================================================
🔄 Round 112 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 112 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0235
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0124
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0162

📊 Round 112 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0162

📊 Round 112 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0162

============================================================
🔄 Round 118 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 118 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0193
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0223
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2406, R²: 0.0160

📊 Round 118 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

============================================================
🔄 Round 121 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 121 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0184
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0294
============================================================


============================================================
🔄 Round 122 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 122 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0218
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0108
============================================================


============================================================
🔄 Round 123 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 123 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0199
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0109
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0157

============================================================
🔄 Round 124 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 124 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0238
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0086
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0156

============================================================
🔄 Round 125 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 125 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0210
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0185
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0156

============================================================
🔄 Round 126 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 126 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0184
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0046
============================================================


============================================================
🔄 Round 127 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 127 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0225
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0005
============================================================


============================================================
🔄 Round 128 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 128 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0152
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0414
============================================================


============================================================
🔄 Round 129 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 129 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0200
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0165
============================================================


============================================================
🔄 Round 134 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 134 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0249
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0133
============================================================


============================================================
🔄 Round 135 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 135 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0210
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0090
============================================================


============================================================
🔄 Round 136 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 136 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0176
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0314
============================================================


============================================================
🔄 Round 137 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 137 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0206
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0192
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

📊 Round 137 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

============================================================
🔄 Round 140 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 140 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0207
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0044
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

============================================================
🔄 Round 141 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 141 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0152
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0401
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0155

📊 Round 141 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0156

📊 Round 141 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0157

============================================================
🔄 Round 146 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 146 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0207
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0115
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

📊 Round 146 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

============================================================
🔄 Round 149 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 149 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0199
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0183
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0158

📊 Round 149 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0158

📊 Round 149 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

============================================================
🔄 Round 155 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 155 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0201
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0205
============================================================


============================================================
🔄 Round 156 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 156 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0184
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0076
============================================================


============================================================
🔄 Round 157 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 157 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0213
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0118
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

📊 Round 157 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

============================================================
🔄 Round 161 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 161 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0211
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0035
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0159

============================================================
🔄 Round 163 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 163 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0210
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0157
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0158

============================================================
🔄 Round 165 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 165 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0179
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0253
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2407, R²: 0.0158

============================================================
🔄 Round 167 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 167 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0202
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0154
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0159

📊 Round 167 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2406, R²: 0.0160

============================================================
🔄 Round 169 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 169 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0126
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0488
============================================================


============================================================
🔄 Round 171 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 171 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0182
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0239
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0162

📊 Round 171 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0162

============================================================
🔄 Round 173 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 173 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0214
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0036
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

📊 Round 173 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

============================================================
🔄 Round 178 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 178 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0173
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0331
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0164

📊 Round 178 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0165

============================================================
🔄 Round 181 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 181 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0180
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0283
============================================================


============================================================
🔄 Round 182 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 182 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0172
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0315
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0166

📊 Round 182 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0166

============================================================
🔄 Round 184 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 184 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0161
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0382
============================================================


============================================================
🔄 Round 186 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 186 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0149
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0004
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0168

📊 Round 186 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0168

============================================================
🔄 Round 196 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 196 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0183
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0173
============================================================


============================================================
🔄 Round 199 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 199 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0250
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0053
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2405, R²: 0.0168

============================================================
🔄 Round 201 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 201 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0187
   Val:   Loss=0.0951, RMSE=0.3083, R²=0.0241
============================================================


============================================================
🔄 Round 202 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 202 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0202
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0179
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0167

============================================================
🔄 Round 204 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 204 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0179
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0288
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2406, R²: 0.0167

============================================================
🔄 Round 205 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 205 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0199
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0217
============================================================


============================================================
🔄 Round 210 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 210 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0187
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0209
============================================================


❌ Client client_37 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
