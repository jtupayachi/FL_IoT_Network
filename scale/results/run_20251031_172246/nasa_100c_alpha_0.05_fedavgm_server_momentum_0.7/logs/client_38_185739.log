[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3903715b-1d00-4eeb-ab49-d003f67700ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0c6aa92-1b60-4d64-ac0f-3f3e9237a11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4476dfc0-ea36-479d-8911-7bb29cb79ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600673d9-7f75-49d3-97c8-2afb1e5841f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da29d26b-f240-4d7d-acaa-f863ca4548ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f9630c-8736-4a92-8ac0-cc4cb78ac40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24ecc155-d049-435f-86b5-c00af11b6e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7695047c-9a5c-4a13-b6aa-1e3b672feb52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a326fc-ca20-40c4-9538-816a7dc45f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ccb22d-3dad-464c-8319-0906f1265edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7eb2f4-6b62-4e5a-b3c5-5b2d3ffd7bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064d73ae-c416-40de-bf3e-c483c63cb9e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c979b1e6-b8c6-4d6f-af9e-7940e6e8dc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd68f01f-3ff8-4578-bf44-3707fe970f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 254dcf2d-8dec-49ed-8a88-71018398be1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33e3092-638c-4dfb-a83c-a77f359204cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97696b2-b383-4252-9eb9-434aa274f400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c1f6ad-1847-436b-ab04-381926efe1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16b734d-bd23-4bcf-82a0-3eb712401518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c748f5-3108-425c-af20-12cf91e34fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb08a697-61ec-47cc-a409-fee2628b40cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a7c8368-0c65-462b-ad7c-40ae11b17152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca82c915-4bd3-490f-b647-062ce855f280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 625fb805-2034-4761-8263-0cc222267527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ddb19b9-5d71-4ee5-b8a8-4891dabf4124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f25fc3e4-20f9-43d2-9fa6-d4b89b01e521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 433c407e-3ec7-41e8-bcca-cd4fcd38ae2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abdb6753-0560-494b-a7ee-9ab891b94043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f0c1c6c-e50a-4cd3-961a-34219eb32af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d73eb5-cd6b-4635-aee2-52240c06aba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c2d2ce4-a1f5-4c0b-8dc6-a8325ab22c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5412bf92-dbb3-44b0-a575-deeff2fe2722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57962df-97b7-473b-924f-9c971c2c8d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efacf80f-725c-402a-a1d1-6c4f5c4c281e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d806bea-aad6-4579-be28-7520e6681597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5883a509-461d-45a7-a5bf-54fff0089b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a558fd8c-c692-4bbd-a312-2c8979fcb820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a27090-aded-452a-be17-9529270871bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0baaf9f3-80f1-4ed6-bbdb-e52cf18ed03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc18940-8350-42dd-8e8e-4327d004e232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db0edd0-2fc7-46ed-b768-b4ce2d4e5c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34d673e2-cab3-4290-a443-a88514eec95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c321c616-8896-41d5-9405-e6c5480c7a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f41ba1e7-3fad-4011-9e7c-a61aaf6b294e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ef0464-4a95-417e-916a-de112a03fd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff85cc79-a49d-4796-bd02-4b94ccc0fe1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adaceb9b-2a1c-4d6e-bf0c-6ecf2e3945c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed3f6f8-0c5c-4a3b-9843-edd0c39ba7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1d15a0-7b3f-4d59-bbda-9c966f517aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82fd39c3-8121-4ab6-aee4-ff4e73e06eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d01be88-b28f-4f97-800b-1710e6c5c449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b805835-342f-4900-b606-5ef4c9201dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea92f34-7e09-4c26-a7b3-5b2f216f7e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180de78e-5878-4e01-8dc3-7262e9b6e2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a24e7521-6a79-4768-881f-42bdf7de0669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1c9675e-597c-49ce-8dcd-fdb2b5890b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a56095-26c6-4948-8ac7-647e4e4ba6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0360067b-8be9-4a25-85c3-d9ca978c8b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be7ee92d-fe4d-40db-90aa-23f677282d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4245352a-bc72-4b2f-b48c-23edb02270ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a757fc-2694-4076-9e25-b91e59953c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9b63952-8b92-4fa3-a167-80095c4b538c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f76cfa70-7faa-4c1c-a79f-a4154cf30ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9798833d-7cb0-47b5-81b5-32c26edae494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b058d754-b628-4f08-aab3-33483d011047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4cd772-6e07-45de-a5b0-6c14aab5d867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680ce7e7-9a0e-411c-be48-d106735a0a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ab7216-719c-4078-86f4-44240e41dae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11efa65-d44b-4894-9ef4-581ed4b0d94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc639d1-1694-4c13-899f-d329cbb2efcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e44251-0252-47d0-a1a4-797ae10d70a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0fb7cc-24d8-444f-9b9e-997fd0a84290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2b0dde-d004-4ffc-adbe-bb96900f6b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38c7ba8-171e-41b4-a03b-11153d159c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b1340d-2c06-43e0-b478-f624be879916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c2b8c88-f991-4ac5-95ba-6ecfd857f93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0106c7b3-b259-4ef4-8ae7-58fe710e51c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3c8b464-59da-46a8-a503-c62a93865ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb97623-c3ec-4152-bd7e-6fc632ba15de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6acc0be-3135-4dc9-a6c7-aaebe3e72029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 607305e4-4d83-45c7-b84c-83488d4bf17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e002241b-d6a9-435e-8e48-3823db517457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce07623-3a13-4451-ac52-6bcc9120e334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5213b0e-8ac2-41c9-a7de-96623eb540c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ea52c1-a25f-47a5-bcd2-02e442b62f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb57a5e0-bc94-4fb2-9455-7518b750e12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b44d31-ab06-4476-bafb-e819720d1652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2f7c10-d4fc-4fc5-a26e-84ba8378d42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f588a2b-45b9-4875-bc1e-6e02215e6f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da8219da-52e5-4c1d-a153-0f698c5fc139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab8ddc6-2f3a-424b-b93e-7fb23d1eee79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e03864-1e1b-45be-af7b-48499d91bf41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d06d049-8426-4f1f-9802-783a598004ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5575cd4d-e641-47e1-9f79-97d01485abe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0380438e-cd70-4607-b1b7-86f083e1891c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3bae4bd-4496-4f25-8cb4-f0a93eff64e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f3b7d5-e000-40b5-ba6a-253983430adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e75465-b6b4-4270-be1d-9558ef65b3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72e2da58-6092-4d84-9dd4-04d6dc9b55f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180a1ae4-4929-44a9-b597-83432f192186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc172b2-3256-4906-9580-900baa8eb504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acfef908-9dc0-450e-b443-058a697d28d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 213360d6-0e99-4a56-80c2-9f78e54df7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4837ba3-e94e-4074-baca-cd1028e90f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49624627-fbc1-454a-96d9-0543b6bae9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df10919d-ca13-464a-bbd2-5f8da74fa53f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b1b6873-f0dc-492a-aef7-34534b9c2f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b920b057-cb73-41ee-83d9-71f30685203e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf5955d-76cc-4603-941f-994cdc28c4e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc891c2c-a271-4610-8894-489b818bfb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f06ee6c4-7cb5-4e25-8072-4196eed1f12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a7d9de-b571-413e-a1da-cf4a1a340588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7279cc-1376-49b1-8df2-db06c9dd48d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df6bfb31-d392-4267-8303-5d8129436e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62fc17a-8cdb-4657-ac6a-d2b8263b65ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b90a8a03-f28e-4f7e-a86e-3c0f44b530a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb1746d0-e066-4e33-b537-b7e1254ea78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ca1a5f0-63b1-41fe-a5ef-14d340ad215b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48df0bc-10ba-4665-8c30-12088967449d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf187d5-cd40-4441-8757-a342de3cfc37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e479e1d-0ddb-49bf-9d21-293f3ffc4113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65147749-3c2e-4084-8574-0d520957a4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f19c4954-ba20-4592-a9af-ca3a74c74cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89237679-933b-478e-937a-226a67580ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9692ff-10f6-4c07-b35a-94de1e166759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 288ca605-6fa6-45a1-b4ed-e7ee8d938b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd413f8c-fdbd-4d1d-b8bd-852871fef4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb4e409e-eaed-4d3e-bd60-37094f56b8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 246d4121-aecb-456b-9a6f-cfed50748859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14b015d-fd14-4443-a707-3e6676857ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bed0a64-3c7c-42ac-bae4-94f57d7b70c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6854bcce-6530-4e19-b227-c7cc80dc17cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9066a57d-856f-4ecc-bb83-2a3ccd884d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa071c4c-4eba-4d23-91d8-2eb811fb4e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e854ea9-4a09-401a-baf1-d5f081c8a68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d92435f6-bebb-4a70-85af-607a2539e510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c213e9-c5a3-4a81-94ef-097cc1fd9f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d24a3d1-742a-46d8-b95a-07337170361d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418795db-5bf6-464c-a47f-90dfb80800b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c162eb-64eb-4d74-9be2-d1360c77c4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75cc8288-24ae-4625-b224-0f69b49d4d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1545a0bb-d0f5-4ac0-8477-2bb2b9b80b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75240fad-9bd6-4f88-a547-963a872ff9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6956067e-05b9-4c70-a812-f07afa7da432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75039bbe-4e71-44a1-803e-d1433fabca11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12b3d86b-d866-41c4-bb9b-3a85529f3eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 819af356-0a2e-4825-b536-58fefa8d90ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 731f41bc-1ea5-435d-9071-e119f736d6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9909019a-0b4e-4861-97cf-e879e4cd5bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a85363-f418-4f25-a3e5-f1169c58a84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45bb859-8058-4c6e-aecd-1db64cc0f26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa3409b-6b71-4c0c-a4be-8247e1d4e945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6f67280-38cd-4695-9359-1b218342da79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7e141b4-f1b7-4bf7-bb4f-8824a8c71eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8341b197-542e-446c-a6c7-e6485a6e66f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e97aa02-fd3b-495d-bebd-941b45c9eabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f331e4c4-2579-4c71-833d-2ec31a24b05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba33ad60-1eac-45e0-ab6b-91957359d1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa9afbad-c296-451f-9a7c-8db2c12aacfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0768da2e-98c2-47bf-8609-85ed339c990d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa7eacc9-626b-4943-9062-bfcb2d3c6478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc123d15-9251-442b-ac92-f9b7a7bda803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b373d07d-b491-4c69-a82a-db6fe4d3da21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 057ebd81-2154-4ceb-b303-0b302f35b950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a226111d-5147-4abb-9595-8c33747ae404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bd8a39f-ed39-439c-839a-3922e7cb5054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c2f9cf-f494-49a2-ba23-24c09f9eabe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94e032cc-8fd8-49b3-a74a-e94bb122e1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e96ecff-e025-45c5-be8d-59cd4f153038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f63e7d-39b2-42ad-96ab-c80d49501739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf24a98-3e2d-4466-9d71-40d94ab2d294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8f297ad-88ff-4c60-8a56-5da23a40b464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68405ee7-a515-4c62-b450-34f3a6fb9e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd8db31-3459-4035-938d-fba77e6c1ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89fc2a47-56eb-465c-8cfc-4c2ff949debd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67582667-d617-40a6-973f-001c763df112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680c548c-90d8-45ba-a8bd-1382dbc39095
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_38
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/test_labels.txt

📊 Raw data loaded:
   Train: X=(847, 24), y=(847,)
   Test:  X=(212, 24), y=(212,)

⚠️  Limiting training data: 847 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  203 samples, 5 features
✅ Client client_38 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 11 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0848 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0832, val=0.0820 (↓), lr=0.001000
   • Epoch   3/100: train=0.0807, val=0.0817, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0801, val=0.0810 (↓), lr=0.001000
   • Epoch   5/100: train=0.0790, val=0.0809, patience=1/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0701, val=0.0840, patience=7/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 11 Summary - Client client_38
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0350
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0542
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2575, R²: -0.0072

📊 Round 11 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2569, R²: -0.0092

============================================================
🔄 Round 13 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0880 (↓), lr=0.000250
   • Epoch   2/100: train=0.0802, val=0.0896, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0793, val=0.0889, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0786, val=0.0889, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0781, val=0.0890, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0763, val=0.0892, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 13 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0067
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0241
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2569, R²: -0.0056

📊 Round 13 Test Metrics:
   Loss: 0.0892, RMSE: 0.2987, MAE: 0.2586, R²: -0.0197

============================================================
🔄 Round 15 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0806 (↓), lr=0.000063
   • Epoch   2/100: train=0.0821, val=0.0803, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0816, val=0.0800 (↓), lr=0.000063
   • Epoch   4/100: train=0.0812, val=0.0797, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0808, val=0.0795, patience=2/15, lr=0.000063
   • Epoch  11/100: train=0.0793, val=0.0787, patience=1/15, lr=0.000063
   ✓ Epoch  21/100: train=0.0776, val=0.0778 (↓), lr=0.000063
   • Epoch  31/100: train=0.0763, val=0.0770, patience=3/15, lr=0.000063
   • Epoch  41/100: train=0.0750, val=0.0763, patience=6/15, lr=0.000063
   • Epoch  51/100: train=0.0737, val=0.0758, patience=7/15, lr=0.000063
   • Epoch  61/100: train=0.0723, val=0.0755, patience=6/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 15 Summary - Client client_38
   Epochs: 70/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1209
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0624
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2592, R²: -0.0296

📊 Round 15 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2568, R²: -0.0114

============================================================
🔄 Round 17 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0734 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0821, val=0.0728 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0817, val=0.0723 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0813, val=0.0718 (↓), lr=0.000063
   • Epoch   5/100: train=0.0809, val=0.0713, patience=1/15, lr=0.000063
   • Epoch  11/100: train=0.0790, val=0.0691, patience=1/15, lr=0.000063
   • Epoch  21/100: train=0.0772, val=0.0668, patience=2/15, lr=0.000063
   • Epoch  31/100: train=0.0759, val=0.0656, patience=3/15, lr=0.000063
   ✓ Epoch  41/100: train=0.0748, val=0.0648 (↓), lr=0.000063
   • Epoch  51/100: train=0.0737, val=0.0640, patience=3/15, lr=0.000063
   • Epoch  61/100: train=0.0725, val=0.0632, patience=6/15, lr=0.000063
   • Epoch  71/100: train=0.0712, val=0.0625, patience=1/15, lr=0.000063
   • Epoch  81/100: train=0.0698, val=0.0624, patience=11/15, lr=0.000063
   📉 Epoch 83: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0626)

============================================================
📊 Round 17 Summary - Client client_38
   Epochs: 85/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0714, RMSE=0.2673, R²=0.1527
   Val:   Loss=0.0626, RMSE=0.2501, R²=0.1602
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2545, R²: 0.0061

============================================================
🔄 Round 19 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0760 (↓), lr=0.000031
   • Epoch   2/100: train=0.0809, val=0.0760, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0802, val=0.0762, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0796, val=0.0763, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0792, val=0.0765, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0779, val=0.0767, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 19 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0269
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0042
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2531, R²: 0.0163

📊 Round 19 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2526, R²: 0.0204

📊 Round 19 Test Metrics:
   Loss: 0.0855, RMSE: 0.2925, MAE: 0.2517, R²: 0.0222

============================================================
🔄 Round 24 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0837 (↓), lr=0.000008
   • Epoch   2/100: train=0.0770, val=0.0836, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0769, val=0.0836, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0768, val=0.0835, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0767, val=0.0835, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0763, val=0.0833, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 24 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0460
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0554
============================================================


============================================================
🔄 Round 26 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0861 (↓), lr=0.000002
   • Epoch   2/100: train=0.0762, val=0.0861, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0762, val=0.0861, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0762, val=0.0861, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0761, val=0.0861, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0760, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 26 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0490
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0493
============================================================


============================================================
🔄 Round 27 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 27 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0398
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0730
============================================================


============================================================
🔄 Round 28 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 28 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0569
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0417
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2520, R²: 0.0317

============================================================
🔄 Round 30 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 30 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0555
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0489
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2521, R²: 0.0325

============================================================
🔄 Round 32 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 32 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0589
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0345
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2521, R²: 0.0326

📊 Round 32 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0322

============================================================
🔄 Round 39 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 39 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0580
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0370
============================================================


============================================================
🔄 Round 41 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 41 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0533
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0550
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0321

📊 Round 41 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0320

📊 Round 41 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0320

============================================================
🔄 Round 44 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 44 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0610
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0243
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0320

📊 Round 44 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0320

📊 Round 44 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0320

============================================================
🔄 Round 48 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 48 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0608
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0256
============================================================


============================================================
🔄 Round 49 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 49 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0537
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0569
============================================================


============================================================
🔄 Round 51 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 51 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0557
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0483
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0320

============================================================
🔄 Round 52 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 52 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0560
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0423
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0320

============================================================
🔄 Round 54 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 54 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0545
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0464
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0320

============================================================
🔄 Round 55 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 55 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0577
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0347
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0321

📊 Round 55 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0321

📊 Round 55 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2524, R²: 0.0321

============================================================
🔄 Round 60 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 60 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0509
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0693
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2525, R²: 0.0318

📊 Round 60 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2525, R²: 0.0317

📊 Round 60 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2525, R²: 0.0316

============================================================
🔄 Round 68 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 68 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0506
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0674
============================================================


============================================================
🔄 Round 71 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 71 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0586
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0356
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2526, R²: 0.0313

📊 Round 71 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2526, R²: 0.0313

📊 Round 71 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2526, R²: 0.0311

📊 Round 71 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2527, R²: 0.0308

📊 Round 71 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: 0.0306

============================================================
🔄 Round 83 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 83 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0680
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0081
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2529, R²: 0.0303

📊 Round 83 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2529, R²: 0.0303

============================================================
🔄 Round 86 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 86 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0496
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0593
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2528, R²: 0.0304

============================================================
🔄 Round 87 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 87 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0563
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0423
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2528, R²: 0.0305

============================================================
🔄 Round 88 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 88 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0601
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0206
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: 0.0305

============================================================
🔄 Round 89 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 89 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0551
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0321
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: 0.0306

📊 Round 89 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2527, R²: 0.0307

============================================================
🔄 Round 92 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 92 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0517
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0589
============================================================


============================================================
🔄 Round 93 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 93 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0428
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0946
============================================================


============================================================
🔄 Round 94 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 94 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0581
   Val:   Loss=0.0686, RMSE=0.2620, R²=0.0333
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2527, R²: 0.0307

============================================================
🔄 Round 95 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 95 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0604
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0272
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2527, R²: 0.0308

📊 Round 95 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2527, R²: 0.0306

============================================================
🔄 Round 98 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 98 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0504
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0595
============================================================


============================================================
🔄 Round 99 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 99 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0552
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0452
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2528, R²: 0.0304

============================================================
🔄 Round 103 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 103 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0383
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0889
============================================================


============================================================
🔄 Round 104 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 104 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0510
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0617
============================================================


============================================================
🔄 Round 105 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 105 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0520
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0574
============================================================


============================================================
🔄 Round 110 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 110 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0461
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0766
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: 0.0306

============================================================
🔄 Round 111 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 111 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0456
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0790
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2528, R²: 0.0305

============================================================
🔄 Round 114 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 114 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0522
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0469
============================================================


============================================================
🔄 Round 115 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 115 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0603
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0272
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2528, R²: 0.0303

============================================================
🔄 Round 117 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 117 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0527
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0467
============================================================


============================================================
🔄 Round 120 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 120 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0599
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0206
============================================================


============================================================
🔄 Round 121 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 121 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0525
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0460
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2529, R²: 0.0302

📊 Round 121 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2529, R²: 0.0301

============================================================
🔄 Round 123 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 123 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0560
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0271
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2530, R²: 0.0300

============================================================
🔄 Round 124 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 124 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0515
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0567
============================================================


============================================================
🔄 Round 125 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 125 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0447
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0780
============================================================


============================================================
🔄 Round 126 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 126 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0528
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0489
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2530, R²: 0.0299

============================================================
🔄 Round 129 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 129 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0334
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.1265
============================================================


============================================================
🔄 Round 131 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 131 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0561
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0353
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2530, R²: 0.0299

============================================================
🔄 Round 132 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 132 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0486
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0602
============================================================


============================================================
🔄 Round 133 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 133 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0439
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0819
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2530, R²: 0.0297

============================================================
🔄 Round 134 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 134 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0548
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0205
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2530, R²: 0.0296

============================================================
🔄 Round 135 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 135 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0548
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0427
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2531, R²: 0.0296

============================================================
🔄 Round 136 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 136 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0602
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0205
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2531, R²: 0.0293

📊 Round 136 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2531, R²: 0.0292

============================================================
🔄 Round 142 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 142 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0541
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0407
============================================================


============================================================
🔄 Round 143 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 143 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0431
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0852
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0290

============================================================
🔄 Round 147 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 147 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0573
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0315
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0290

📊 Round 147 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0289

📊 Round 147 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0288

📊 Round 147 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0287

============================================================
🔄 Round 153 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 153 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0491
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0602
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0285

📊 Round 153 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0284

📊 Round 153 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0283

📊 Round 153 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0282

============================================================
🔄 Round 160 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 160 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0409
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0847
============================================================


============================================================
🔄 Round 161 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 161 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0547
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0096
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0282

============================================================
🔄 Round 164 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 164 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0496
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0490
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2534, R²: 0.0280

============================================================
🔄 Round 165 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 165 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0498
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0531
============================================================


============================================================
🔄 Round 166 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 166 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0608
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0011
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2534, R²: 0.0280

============================================================
🔄 Round 168 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 168 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0547
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0378
============================================================


============================================================
🔄 Round 169 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 169 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0538
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0222
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2534, R²: 0.0280

============================================================
🔄 Round 170 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 170 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0581
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0108
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0281

============================================================
🔄 Round 172 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 172 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0498
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0419
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0282

📊 Round 172 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0282

============================================================
🔄 Round 175 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 175 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0560
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0295
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0283

📊 Round 175 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0283

============================================================
🔄 Round 177 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 177 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0446
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.0811
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0284

📊 Round 177 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: 0.0284

📊 Round 177 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2533, R²: 0.0285

============================================================
🔄 Round 182 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 182 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0563
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0311
============================================================


============================================================
🔄 Round 183 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 183 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0448
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0803
============================================================


============================================================
🔄 Round 184 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 184 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0472
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0645
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0286

============================================================
🔄 Round 185 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 185 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0568
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0215
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0286

============================================================
🔄 Round 188 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 188 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0498
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0614
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0287

============================================================
🔄 Round 191 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 191 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0515
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0506
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0288

============================================================
🔄 Round 193 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 193 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0551
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0363
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0289

============================================================
🔄 Round 195 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 195 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0479
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0692
============================================================


============================================================
🔄 Round 196 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 196 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0427
   Val:   Loss=0.0670, RMSE=0.2588, R²=0.0955
============================================================


============================================================
🔄 Round 198 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 198 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0501
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0531
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0849, RMSE: 0.2915, MAE: 0.2531, R²: 0.0292

============================================================
🔄 Round 199 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 199 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0559
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0390
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0288

============================================================
🔄 Round 202 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 202 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0546
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0346
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0288

============================================================
🔄 Round 204 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 204 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0496
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0461
============================================================


============================================================
🔄 Round 206 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 206 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0474
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0720
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0288

📊 Round 206 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0287

📊 Round 206 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0287

============================================================
🔄 Round 209 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 209 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0571
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0313
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: 0.0287

📊 Round 209 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2533, R²: 0.0287

❌ Client client_38 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
