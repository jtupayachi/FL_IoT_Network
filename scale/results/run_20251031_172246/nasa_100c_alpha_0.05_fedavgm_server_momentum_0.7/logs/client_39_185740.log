[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bf916b-a0ba-44bf-beef-3ad596489aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41cb3bee-469a-4151-8155-e08dc2551d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6659c18-062f-426b-8a88-4b894d225ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821fd3b7-6ea4-4926-963c-d4f5836edb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 837bfa95-fc24-4904-a693-b6fd7a052e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b101e62-3626-4753-9373-37d496643061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff6b0db5-a88e-49ce-8e6e-39841f26f4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5abcc309-a77e-4d27-9da2-109904c07ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 313840a4-95e8-4be5-ac41-35bd0d923812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f83f05ed-1748-47c5-b543-db5e06901e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a88915b8-30f5-47ea-88a4-788e9e167ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b4d92a3-733b-4b65-9490-66e4b059a390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e33d15f4-d475-44f8-9c1a-1e1218f1d4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed6dab26-b634-4530-b1bf-c7644c41cb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b221f33-0770-49f5-a518-b39623907ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a5c1cc8-aec9-49a7-a466-be9618ab47bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 051951ab-a503-4fb4-8247-48f4c180d50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59557451-456c-407b-ad77-357b89860b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0583f4ee-fab9-4027-8399-fb08eb4b823b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33124070-5c5a-4b26-8d12-e8f9fa27a2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47bfde38-2e1b-4f84-9d8b-70b67fdaff18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb25e04-87db-4d05-bce3-c4296ff5bc81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c841c7-371f-4436-95ee-aa7fc3995108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0413085-3eaf-4419-93ed-d03d937c882b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78070d28-bd45-4a23-9ce9-762947f03e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf98afb-3d65-46eb-99c1-72a19ff782f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004ae36b-2e7c-4c0b-b8f2-04921f6ec4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 187ce312-0150-458f-8276-aac4252ae45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4c8aee-6877-46b6-90cd-abdd9164d223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53f8d68a-24c4-4992-a544-8e625fb6f033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 681aedfd-caa3-401b-8504-f87d670ab706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be65132-3ee1-4161-bf55-2ef56f1b3cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d139974a-c6e0-4f8f-9160-2743a5ed432a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6936f0-8fcb-4c81-82e2-6aeea6e1a36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc4b3f69-b78e-4d1f-a3a6-2f4160492f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba39fdb0-8c03-4b69-9615-4e90bb2d5a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6f42f2-509f-4155-861f-8a18f0260fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a06d2e08-5915-42f9-b851-e53670a42002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f492bdfe-c844-455f-94cd-303bdb916396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7dd945a-9884-40a9-8710-f0f91039eece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e7cdde-aaa7-45ac-b2ac-23df24f1f1f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4bfa21-5ae8-49f7-af1f-bdf7c832c9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76007fd2-4ac9-4e3f-b786-b8e31b34390d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a884d74c-5ea7-4278-ab7e-f023798ceb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a15bbb1e-de59-4bbd-b032-5566795503c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ecabfb6-2953-4f27-b419-690472d240e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd819d6f-8578-41ff-931f-940ac9a66907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89540a64-bcdb-4eb5-bfed-7669dfb02448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab27be72-efee-4fe4-a4c8-1f6104cbc84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72bb827a-d823-4f23-981a-6462bb478752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 768bf731-49e8-4463-9c7b-41623f0074c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efff956c-6657-4825-b4eb-2211e28ff326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62c1c7da-e295-44d2-ac05-c1a81f123c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac6a4a9-ef98-43f9-89a8-e9e997588e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858197d2-1374-491f-b926-f942f7faf568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afa9a519-73a0-4adf-87a1-f1d2ee88f926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b49c2123-ca8b-49bb-8ef2-02da440d1dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c558722-84a8-480f-930e-57ae627255e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aae8d4bf-c114-41b4-a4d4-04709b95d3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e3d818-a1d7-4d62-a7e0-7cdc3dd879d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb94899-5457-4a6c-aa48-6415aa63f645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca7e7b99-a189-4b9a-8091-ed85b024eb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55584f8e-9ab8-460e-98a9-93d36df92c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16d5d764-ad1f-4d1c-a427-1060404f1e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ddde11-2cab-4ea0-9bbf-97d490f5c570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996dda0c-95a1-4114-82f3-f721f8cbb9e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e50183-ed29-4703-bb39-f30f9b13d364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c925550-d8ef-47bd-8bdb-20a9113b6f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5114c92-5e39-49b4-91a8-b7ffe5fc7961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2992fdca-52d8-4c3d-89e8-bc0204e61441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05bfd70c-63b8-4ec6-85ee-9976d89f8d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ffa269-b514-4843-9950-dd10270d05f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c528564-bbbd-44eb-b531-00b645159c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7452a22-8535-431a-aa70-6297b15de905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d5ca1b2-d211-452d-9fa9-a2407b3f677f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9aeb06-0c7f-444b-9fe5-dd1f36e6b422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b052594-23f3-4309-a481-b102a57b1cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b845d4-342c-4802-af9a-c595f71c778b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f898abc-a8f1-41ee-89f4-19eff0acbd50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5b97dc-7f81-4279-9d75-c7f51bafb3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e494cf-fecf-4230-ba44-21d2ddd4c7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eceb3be1-71b0-40a8-b5ff-f67dec8bda27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7eb98c-38c9-4bec-8f03-e5da35833a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6bdb027-d154-439e-b54b-e1cce15d20db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a080fd7c-b2cc-461a-8ea1-c2d30ae8d7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170ef3eb-fcd1-4d25-bcbb-28e4d8b81e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01c5cfc-3fc3-4005-ba5e-735c4ca8d579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67376ef6-61e2-49ac-aee7-dd8b243fa4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6196326e-b49d-45fa-aade-330454d1b89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79c1493-f3ed-47d9-bcd3-a18611b79985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cea14686-098c-4c96-a063-0c987248eac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f93a6b8-fcf2-42e4-a2a4-43c27185ef13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee04c3d5-6fec-43c8-bb2b-0166ee87ee52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e43ebcb-429d-47f6-9f65-828e141dad6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d98d02e8-f0f7-4eb7-b0e0-1cbb666518ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6847382c-c565-4bc9-bcec-727cde3da5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25c64f12-b917-450c-ac73-9baa1af0e70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9b9b8f-efd9-4406-91ac-0e8639e292ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a4c565-46a6-4197-a9d6-2923ef70f1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce82f9ec-6745-40f0-9c98-2af803419076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ad201e-ec59-427a-b98b-31c252eeb082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b5c511-eea6-4162-89c9-7ff32a14c817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085f3d24-5ad8-4485-aeb8-b7f572824edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239b3c46-2831-4f05-a54f-f7aa2310e1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd9dbb3-d1bb-4d9e-807c-828b1adb8adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86755b11-052a-4fd4-97ed-e131103e1fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdf75ea5-1ca5-4179-b413-b143a9181ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0aba7d1-7dfb-41ea-a5ea-56514c251fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d79f38de-efbf-403a-8c15-1273fc4da923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27ceafd8-bfb6-487d-8baa-8af0ccc7b65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14da5f9d-d914-4ec7-845f-a73b78ccb287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec33bba-6c87-4b19-b16d-709a4e5b5626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0db3872-903b-4b1f-b0c4-2484915b7492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ec19da-6c38-4ec5-aea3-0c94d9ef027b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a963f68c-e6e1-46fc-8417-dfdde56e8bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3f3e5c-7023-4880-a15d-abf11de8f88e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f05c9fcb-80f7-424d-8dfb-8765e7334929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 493cfd2a-a514-4e50-85be-7417f9418e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d834caaa-9db7-4cd8-ab7a-fea4707155df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c1842a-f278-4495-923c-fc1da9c51582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc619028-cb7f-4768-84d4-27e2f9710211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2da070b-1ff4-4ee7-b46a-0c2bab1c2630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94529270-d2f1-4438-8ad6-7cedf0dff404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b92f3514-0887-4dbc-a1a8-936d54497b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f5a5cc-c549-4a94-8ea2-86dc3b9c6363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5bdc6b-59ae-4604-b341-0ad323939bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa4ae05-6c39-4242-9fdf-56fe0f852657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d085ec7-c600-4a4b-b5d7-f924573ba0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf751362-b896-4366-8787-ec058c906e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c58870ba-5786-4fdc-a2b8-d9193e15ebbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df5a8bf-a79a-4ebb-890f-ae568ee6abe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf213e68-e765-43c3-b28b-e31a1e280ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215e83dc-db9d-46cc-a454-911311ec4ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f7a1f25-8d60-4451-a29c-ad854631050d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e0d52a-3770-419b-af31-c35121c91530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d370309-631c-474a-ad5c-7b0c48bb095b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e04a6d8-b5be-4e65-893a-d24b48d03eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa94f71-f9fc-4470-ad8e-874afb414cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08f91bb7-7635-4419-9ecb-04eba4c25edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb6c8d7-d77a-4204-ad98-9acbaed41a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55979c4f-c7ad-4c0b-9092-ed65ba7e773a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3454063-940d-4fe1-ad76-3d5fb4bfb47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e094e337-4097-4e0c-a49a-6f822f4f6e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72697037-770a-4c65-b32c-9fbbccafb2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98cca3d9-7eed-4645-ae57-a6396d2df9a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df631bfc-4a4a-41ab-999c-2abf06a6815a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17532421-c206-4657-af1a-164e18029a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0029374-c2e9-4461-9222-fbb458cea955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfca9354-a9dc-4141-b4b1-b057f3c282c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d60bbe3-f207-4488-a354-1331d77d2bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2faa4353-5ff1-4dee-94cf-82094a5e8f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f2c48d9-57da-4498-a0cf-6d8ef939bc1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9b4078-5a06-4308-a276-910a5a35f234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4228531a-4e9b-44f7-96d1-f96f1705524e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b317b3a9-3deb-48df-88c4-48b2cb723296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cda574f-fead-4ab5-8767-ee9c0feea740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e7a423-f1f8-4675-bc8e-565703e76eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b265839-8024-473e-a751-5382988b2e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5651c7bc-9461-415a-afde-927339e623d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f6d7d2-be95-4093-813c-88aa3b9b4561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32905a9b-1219-43ab-944a-df11a65e7a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message addd7f85-88b1-462a-9211-49295e44f1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf69919f-3a65-4265-b286-9b89e6b1a727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49031e6a-d11d-4402-9575-3c8f77638b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f065b88-02d6-4dff-bfd8-b1123216efde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01831e83-1982-453a-ad6b-6baeeb9d748e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd8187b-0707-4c16-aef2-f663f1f5d23a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_39
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/test_labels.txt

📊 Raw data loaded:
   Train: X=(1819, 24), y=(1819,)
   Test:  X=(455, 24), y=(455,)

⚠️  Limiting training data: 1819 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  446 samples, 5 features
✅ Client client_39 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0248

📊 Round 0 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2456, R²: -0.0213

============================================================
🔄 Round 13 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0783 (↓), lr=0.001000
   • Epoch   2/100: train=0.0853, val=0.0797, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0844, val=0.0800, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0836, val=0.0807, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0829, val=0.0800, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0782, val=0.0815, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 13 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0390
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0489
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2406, R²: 0.0156

📊 Round 13 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2372, R²: 0.0352

📊 Round 13 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2356, R²: 0.0400

============================================================
🔄 Round 19 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0849 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0832, val=0.0843 (↓), lr=0.000250
   • Epoch   3/100: train=0.0825, val=0.0844, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0818, val=0.0844, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0812, val=0.0845, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0784, val=0.0838, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 19 Summary - Client client_39
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0595
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0579
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2389, R²: 0.0224

📊 Round 19 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2355, R²: 0.0478

📊 Round 19 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2352, R²: 0.0499

============================================================
🔄 Round 24 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0722 (↓), lr=0.000063
   • Epoch   2/100: train=0.0865, val=0.0722, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0861, val=0.0721, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0858, val=0.0721, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0855, val=0.0721, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0842, val=0.0720, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 24 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0517
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0483
============================================================


============================================================
🔄 Round 25 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0852 (↓), lr=0.000031
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0832, val=0.0847 (↓), lr=0.000031
   • Epoch   4/100: train=0.0829, val=0.0846, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0827, val=0.0846, patience=2/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0819, val=0.0845, patience=8/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 25 Summary - Client client_39
   Epochs: 18/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0510
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0500
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2371, R²: 0.0354

📊 Round 25 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2377, R²: 0.0313

============================================================
🔄 Round 32 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0786 (↓), lr=0.000008
   • Epoch   2/100: train=0.0874, val=0.0786, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0873, val=0.0786, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0873, val=0.0786, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0872, val=0.0786, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0871, val=0.0785, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 32 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0221
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0524
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0308

============================================================
🔄 Round 34 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0918 (↓), lr=0.000002
   • Epoch   2/100: train=0.0839, val=0.0918, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0839, val=0.0918, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0839, val=0.0918, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0839, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 34 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0268
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0292
============================================================


============================================================
🔄 Round 35 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 35 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0266
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0320
============================================================


============================================================
🔄 Round 37 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 37 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0306
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0090
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2379, R²: 0.0297

============================================================
🔄 Round 38 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 38 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0310
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0110
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2379, R²: 0.0297

📊 Round 38 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2379, R²: 0.0299

============================================================
🔄 Round 41 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 41 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0288
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0097
============================================================


============================================================
🔄 Round 42 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 42 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0309
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0142
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2379, R²: 0.0301

============================================================
🔄 Round 43 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 43 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0289
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0206
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2379, R²: 0.0302

============================================================
🔄 Round 46 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 46 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0273
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0301
============================================================


============================================================
🔄 Round 47 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 47 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0285
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0180
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0306

============================================================
🔄 Round 48 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 48 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0218
   Val:   Loss=0.0950, RMSE=0.3081, R²=0.0488
============================================================


============================================================
🔄 Round 52 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 52 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0250
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0387
============================================================


============================================================
🔄 Round 53 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 53 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0314
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0122
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2378, R²: 0.0311

============================================================
🔄 Round 55 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 55 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0298
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0208
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2377, R²: 0.0312

============================================================
🔄 Round 57 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 57 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0268
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0201
============================================================


============================================================
🔄 Round 58 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 58 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0277
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0292
============================================================


============================================================
🔄 Round 59 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 59 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0318
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0124
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2377, R²: 0.0316

📊 Round 59 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2377, R²: 0.0316

📊 Round 59 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2377, R²: 0.0314

============================================================
🔄 Round 62 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 62 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0257
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0296
============================================================


============================================================
🔄 Round 64 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 64 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0329
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0081
============================================================


============================================================
🔄 Round 65 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 65 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0298
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0192
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0308

============================================================
🔄 Round 66 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 66 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0290
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0125
============================================================


============================================================
🔄 Round 67 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 67 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0230
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0395
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0306

============================================================
🔄 Round 69 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 69 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0251
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0321
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0308

============================================================
🔄 Round 70 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 70 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0341
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0159
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0309

============================================================
🔄 Round 73 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.1016 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.1016, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.1016, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.1016, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.1017, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.1017, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1016)

============================================================
📊 Round 73 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0383
   Val:   Loss=0.1016, RMSE=0.3188, R²=-0.0127
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2377, R²: 0.0312

============================================================
🔄 Round 74 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 74 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0247
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0435
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2377, R²: 0.0313

============================================================
🔄 Round 77 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 77 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0277
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0145
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2378, R²: 0.0311

============================================================
🔄 Round 78 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 78 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0249
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0426
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2378, R²: 0.0310

============================================================
🔄 Round 80 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 80 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0286
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0238
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0304

============================================================
🔄 Round 82 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 82 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0243
   Val:   Loss=0.0980, RMSE=0.3131, R²=0.0247
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0768, RMSE: 0.2770, MAE: 0.2379, R²: 0.0303

📊 Round 82 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2379, R²: 0.0300

============================================================
🔄 Round 85 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 85 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0304
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0186
============================================================


============================================================
🔄 Round 86 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 86 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0278
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0295
============================================================


============================================================
🔄 Round 87 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 87 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0209
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0555
============================================================


============================================================
🔄 Round 88 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 88 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0257
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0372
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2379, R²: 0.0304

============================================================
🔄 Round 89 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 89 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0315
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0143
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0306

📊 Round 89 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0307

============================================================
🔄 Round 92 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.1061 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.1061, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.1061, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.1061, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.1061, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.1061, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1061)

============================================================
📊 Round 92 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0303
   Val:   Loss=0.1061, RMSE=0.3258, R²=0.0168
============================================================


============================================================
🔄 Round 94 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 94 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0330
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0017
============================================================


============================================================
🔄 Round 95 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 95 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0256
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0323
============================================================


============================================================
🔄 Round 98 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 98 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=0.0279
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0308
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2378, R²: 0.0311

============================================================
🔄 Round 102 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 102 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0257
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0376
============================================================


============================================================
🔄 Round 103 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 103 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0268
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0338
============================================================


============================================================
🔄 Round 104 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 104 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0260
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0372
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0308

============================================================
🔄 Round 105 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 105 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0284
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0291
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0309

📊 Round 105 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2378, R²: 0.0310

============================================================
🔄 Round 107 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 107 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0347
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0047
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2378, R²: 0.0310

============================================================
🔄 Round 109 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 109 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0299
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0200
============================================================


============================================================
🔄 Round 111 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 111 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0283
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0197
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2378, R²: 0.0310

============================================================
🔄 Round 112 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 112 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0331
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0100
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2378, R²: 0.0306

============================================================
🔄 Round 118 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 118 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0270
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0336
============================================================


============================================================
🔄 Round 120 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 120 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0313
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0072
============================================================


============================================================
🔄 Round 121 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 121 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0290
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0224
============================================================


============================================================
🔄 Round 122 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 122 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0216
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0432
============================================================


============================================================
🔄 Round 123 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 123 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0295
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0227
============================================================


============================================================
🔄 Round 125 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 125 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0257
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0372
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2380, R²: 0.0294

============================================================
🔄 Round 127 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 127 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0310
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0084
============================================================


============================================================
🔄 Round 130 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 130 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0249
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0406
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2380, R²: 0.0296

📊 Round 130 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2380, R²: 0.0296

============================================================
🔄 Round 134 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 134 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0324
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0073
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0287

============================================================
🔄 Round 139 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 139 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0236
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0106
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0285

📊 Round 139 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0285

============================================================
🔄 Round 143 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 143 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0348
   Val:   Loss=0.0980, RMSE=0.3130, R²=0.0036
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0286

============================================================
🔄 Round 144 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 144 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0272
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0304
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0287

============================================================
🔄 Round 146 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 146 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0294
   Val:   Loss=0.0948, RMSE=0.3078, R²=0.0212
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0288

============================================================
🔄 Round 149 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 149 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0287
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0229
============================================================


============================================================
🔄 Round 150 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 150 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0264
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0313
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0285

============================================================
🔄 Round 152 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 152 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0256
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0370
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0285

============================================================
🔄 Round 153 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 153 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0270
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0305
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0285

============================================================
🔄 Round 154 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 154 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0259
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0309
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0285

============================================================
🔄 Round 156 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 156 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0346
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0014
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0284

📊 Round 156 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0284

📊 Round 156 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0283

============================================================
🔄 Round 162 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 162 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0262
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0322
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2382, R²: 0.0280

📊 Round 162 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2382, R²: 0.0279

============================================================
🔄 Round 165 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 165 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0309
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0139
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0769, RMSE: 0.2774, MAE: 0.2382, R²: 0.0281

============================================================
🔄 Round 171 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 171 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0261
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0226
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0285

============================================================
🔄 Round 173 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 173 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0287
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0202
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0286

📊 Round 173 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0287

📊 Round 173 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0287

============================================================
🔄 Round 176 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 176 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0268
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0303
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0287

============================================================
🔄 Round 177 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 177 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0287
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0247
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0288

============================================================
🔄 Round 179 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 179 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0229
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0426
============================================================


============================================================
🔄 Round 183 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 183 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0307
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0065
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2380, R²: 0.0291

============================================================
🔄 Round 184 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 184 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0284
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0271
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2380, R²: 0.0292

============================================================
🔄 Round 185 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 185 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0267
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0343
============================================================


============================================================
🔄 Round 189 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 189 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0295
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0052
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2380, R²: 0.0293

============================================================
🔄 Round 190 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 190 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0300
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0194
============================================================


============================================================
🔄 Round 191 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 191 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0202
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0551
============================================================


============================================================
🔄 Round 192 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 192 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0251
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0321
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2380, R²: 0.0296

📊 Round 192 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2380, R²: 0.0296

📊 Round 192 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2380, R²: 0.0292

📊 Round 192 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2380, R²: 0.0292

============================================================
🔄 Round 205 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 205 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0271
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0325
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2380, R²: 0.0292

📊 Round 205 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2381, R²: 0.0291

📊 Round 205 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2381, R²: 0.0290

📊 Round 205 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2381, R²: 0.0290

============================================================
🔄 Round 209 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 209 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0306
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0176
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0769, RMSE: 0.2773, MAE: 0.2381, R²: 0.0288

============================================================
🔄 Round 211 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 211 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0274
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0235
============================================================


❌ Client client_39 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
