[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9ec99b-d8d2-404a-81aa-8bf4f34152bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2337f612-8f8b-4ea3-a492-1d16325ee4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59ec73df-6fac-44d4-9f6b-96bd30bc2824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2fc82fb-a85e-4e70-8df7-bdb2351f8e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9043bb29-f07a-4a99-b6e5-933ac6c824ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50678a68-c2ae-4158-be03-c294c59b284a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57d3f223-fe05-4038-874a-dfaa52cfeed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29f245bd-9941-42e3-92be-a756a691319d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a1443a-4ffe-4288-8388-16efbf1767f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56556ece-d22b-44fd-a2a8-678db3076a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8bffce-1de8-4529-89fa-ff8ad42f91ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ec18c2-c42d-43a7-947c-ba77a22c54fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f64aab9-9486-403d-b660-33629a1aef1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f69a94b2-c5e9-4368-a225-5f8392306dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f229591-a400-46ee-a895-89f558bc519e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c59327-7cc1-40b3-ab69-622e5ef58d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f70f9469-4fb6-4108-8096-d3171dce1ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5590d7b4-821f-4298-b0d6-1d8f8144a202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948c7374-9eef-4fcc-a569-699297d5d840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a753513d-0d2a-477e-a14e-02fcce8c0d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 454afb84-8b28-419c-8644-0e001c38eccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47ff2376-dd84-4f40-aff9-513917582def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 897f61f1-bc70-4764-a64e-3d0bf3edf99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a7bba73-012a-47cf-bded-2d686c253a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75cf12e7-7ae0-460e-a334-f2e5a0315141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72801354-28cf-4554-a057-9343f248cfc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c79074-f735-4ca6-93ee-3062a421c2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5684246-d647-4887-8861-21590c4d5676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d8b7a66-bc50-49d6-a665-1ed1c0769231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5b46cb-af6b-43bf-8123-a3e5e8a6731c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9807815-5f82-44c2-b3a4-61185dd521ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b5cac09-ea73-446b-87e4-076e2ee7f96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66f85677-156f-430b-acab-45404d39c1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9fcf570-6018-4665-8bdc-d2c5170a6fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7fe64c-1498-4d0f-8851-35e6cda564cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a1d88f-8092-463c-ab6c-15cf1caf8606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8e40f4-f160-4047-acba-666ceb5ec70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdc2fc00-3799-4c53-9b3d-a765e250d6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 709189fd-5833-4744-b913-406971d3b00c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ac63df-fbb5-4591-981e-8f94a44c026d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc96f791-5621-4418-a282-dbb1654f96b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122b0ab1-b04f-4dcb-a122-c552b282b2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f9ae78-1616-4a1d-b095-2500d9bcb3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0649e0e0-e233-4c39-abcf-2513312f9c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1caf718b-a140-49c5-9a85-936f87174b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45f34e3c-a993-44a6-8af9-eca5616a8026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48873d26-e8bb-455c-a907-eb6aa610c579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5085d59b-4eed-4c79-a99b-a6a3e7429a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb89874-773b-44c5-8f4a-99ca3c274ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f04d27-f63f-49e7-b792-02917ecbaa14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f0e8add-8e72-403e-af32-71a4aa65eed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b04d6e-dc65-48c8-902b-fd9c567deb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be902b63-4e48-4570-be48-3d9b0dbfc702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a9001cf-f619-4c89-a869-b01f4574be8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f5c0f3-e2a9-4904-8ebe-67b4ab2d7e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb2e75dc-a920-45a8-b2f2-4dec22cf3e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f41632-b100-43e4-8123-96e3f5adbfec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de073541-2d09-442c-a14e-6d57c080ff99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 635f741d-7a1e-4101-94ee-0856cbd22c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5a054b-203c-451f-9ade-1784d1d238de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42f4c07-ed5c-43ef-bcfd-5750a15afe56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79602f40-4cbd-4ad9-94e4-715b9f6ad041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e4002de-7be5-4ab4-97c5-5c96f18a1f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43972d57-0981-472a-8839-123055b38eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c823ec4d-529f-4acf-bd76-e4f671354140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc234fe8-cd47-4fa1-8b70-8f2997994623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bdca196-bd38-462a-96d0-5f48ee7bebf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cfb8f10-8774-408c-9370-0aeb7e339805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc72eed-4e42-4afc-a4de-81bc359e24f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 438f7eb6-6111-44ef-9bfe-80611ef50832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19373930-56ee-4ce9-be9b-638a372d1bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1609e788-0af5-4ea9-8f91-8bb1ed54de03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f209c05-5001-4966-8af7-fbc19234626c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6921301-0c98-483a-b407-89ae56de4cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcbacf4-4ab8-4264-b590-9259f60e5a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded2753e-8282-46b4-9830-b71115af0efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c02df0-9fd8-48fd-9a09-94b8e3ea361d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f96bcf5f-8518-4166-a9a0-33728de944f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c153714-0e0b-496f-84a0-89df9c52c3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b5b8421-ae08-43c6-a23e-c2772e2f8f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 852b3b77-1582-472a-98c8-d973f2fb7d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a266cd14-eb9b-44b3-b187-f7b4fed5016e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6a5f494-2b53-408d-bfee-cb08ec38d384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d44a57-80cf-4b92-998f-4d0f7cb6eec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04adfab9-d8ff-40ad-a4c9-38dc309b3294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd27aecb-6eb5-44c8-b8db-f1e0bfe3a633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b5e9cc-1d66-4b78-92ed-5878aca4e804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7781b5-77de-4277-af79-09daed3ac641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bf99154-8b29-4628-8589-d3bec7b6f6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a7bdd0-1730-4777-96a6-76743491e8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37255e33-4fef-4f51-9acc-e40bb73b7a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42741fa-adcf-4975-9fa6-875feb000fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b658d0f1-aa52-4519-8e8f-0e37b35c3530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12f0dd11-1362-4ced-b645-48bef371717d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e31bb06-d1b8-4a51-b00e-199f709dcacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ee05d3-94ec-405b-958f-499450f1bc4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317532ec-d401-475b-9838-e6c8481e8bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468cddbf-5034-4beb-8f9d-64f33569ee04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4137c75-6be4-4f9d-8c66-c88dc7c5472f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed6b9200-0c03-403a-a3b4-6da99e595c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c782ec09-37ce-4421-bfc5-311fc43b7d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc2a592-5d2d-4f94-8dde-4de31ae54050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4f17a0b-cf54-4594-a14b-f7c339e65c7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb87eef2-3063-47c6-a619-36356df3543a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8408d71-f414-4300-b640-4d0b94fdb7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 023b0543-1466-42d1-9eb1-0284f8228cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bf3aea2-a727-4b3f-8371-cb9556cde9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc0c233b-070b-4387-aa7b-0a66193fb652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244ef84e-0ba6-41a3-a742-66d05fcffa09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 529ef9f7-595d-4ad5-a94f-2f6611db4376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcc8744d-d255-4dae-8d41-75a4091b132f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1315d2f6-279a-439a-8c3a-b280822f60f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf22de17-3594-458a-9969-01757a90e3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee8dd3c8-3008-4bb1-9c3d-1ca932440603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b922971-c424-414f-ae1c-114fbd672d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb7615e-b272-45e2-9377-734741750c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 327233c4-1eb2-425c-9b29-08ee0fe18562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63556006-216d-43c3-a9d9-c864e32c5b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df2dfd5d-4046-4a1d-903a-a1bc6cd15337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8a6316-64e3-405a-ac61-ff2fb287081e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3e832d-3a23-43f5-af92-6bd1f887baa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e20772-f2b5-43f1-9a4c-84b21be4c5b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0c6bf11-29cc-46b2-8bb5-788d30233292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7d7073c-e164-4058-b64f-421f77f5a535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80305048-d364-4bac-b1e5-7ef6ff9f8467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e032076-0253-4bf5-83e7-8419cab876ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 748d43f3-e4a4-4c41-87db-cb433eeaed02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6489cc-8862-437b-8f55-4dc9017ff554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380ecc36-e65d-4362-a8d1-5af7d5a540be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4152599c-1f0c-4c64-8a42-f312c4bd6625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a886ddf6-61ae-4396-bc89-1994b6934b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0668f37b-05cc-42f8-bb4d-9b9813332aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050f9bd8-d856-40ce-aa5a-90038117fa7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 270d095b-0130-43ea-84f0-d8714d98d9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc1f04a-d038-4417-9140-a77f76965b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff10b05d-163b-49b5-9b3d-90aa6a1b3d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9788b242-2428-4705-9831-45efb2d691ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68928367-b1f4-4014-bad9-cb0805eda5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096caa7f-8072-4a84-9142-f74c33eae1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b04069f-88de-42a3-9231-dabbea3305db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a34f2433-99b1-4698-bda1-740cd11a1ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb4eaa7-befc-43f2-9fb1-f18421b354ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad77ecb-2d4e-4753-b9d5-76c03063d952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a2649c-d568-40c6-8865-248fbc098d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2bcfc19-401e-4b2b-a0b7-4eedbfa86380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4ea336-6f78-4628-9d43-fe0457abf905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a704979c-332f-4a88-a06c-569df9cb4f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dd37338-d6d1-4e8f-8c19-287e5e33c378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f0784b-1f98-4a4e-8af1-04f0fc44ddb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf91c60-2589-4d47-86a1-5c2bfd2dd217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ac2c3e-e1ee-426f-9722-9a5a2d3f8820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1f3486-2488-4ae5-ba39-0ecdfadf40eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d5a0e4-a8ef-4d23-a8f4-32b601f840da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4242cd-986a-404e-a9b8-986212e8a9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be753704-a551-4658-9d5c-71db544c9319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b31d81b-900d-4a83-8e62-7d88bf3006d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f769cd5f-6ccb-453b-a732-d72200bbbff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceabce0f-3817-4444-9407-efcf56d606d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95336a0a-5290-46d0-a070-bf9193f2e2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 641219b7-920d-41de-8a8e-b373aabcb61b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d796c0f1-fcac-4e1d-a367-135423ae99cf
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_3
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_3/test_labels.txt

📊 Raw data loaded:
   Train: X=(1521, 24), y=(1521,)
   Test:  X=(381, 24), y=(381,)

⚠️  Limiting training data: 1521 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  372 samples, 5 features
✅ Client client_3 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2451, val=0.0818 (↓), lr=0.001000
   • Epoch   2/100: train=0.0925, val=0.0839, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0883, val=0.0824, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0864, val=0.0829, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0822, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0846, val=0.0823, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 1 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0109
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0048
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.3475, RMSE: 0.5895, MAE: 0.5174, R²: -3.3493

📊 Round 1 Test Metrics:
   Loss: 0.1332, RMSE: 0.3650, MAE: 0.2990, R²: -0.6670

============================================================
🔄 Round 4 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1032, val=0.0817 (↓), lr=0.000250
   • Epoch   2/100: train=0.0854, val=0.0819, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0843, val=0.0825, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0843, val=0.0823, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0841, val=0.0824, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0837, val=0.0826, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 4 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0003
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0182
============================================================


============================================================
🔄 Round 7 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0842 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0869, val=0.0820 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0855, val=0.0810 (↓), lr=0.000063
   • Epoch   4/100: train=0.0848, val=0.0805, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0846, val=0.0802 (↓), lr=0.000063
   • Epoch  11/100: train=0.0842, val=0.0800, patience=6/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 7 Summary - Client client_3
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0103
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0104
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2422, R²: -0.0072

============================================================
🔄 Round 10 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0859 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0848, val=0.0848 (↓), lr=0.000063
   • Epoch   3/100: train=0.0836, val=0.0846, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0829, val=0.0846, patience=3/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0825, val=0.0843, patience=9/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0821, val=0.0842, patience=8/15, lr=0.000016
   📉 Epoch 22: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 10 Summary - Client client_3
   Epochs: 28/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0176
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0354
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2386, R²: 0.0166

============================================================
🔄 Round 11 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0792 (↓), lr=0.000008
   • Epoch   2/100: train=0.0854, val=0.0792, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0854, val=0.0791, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0853, val=0.0791, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0853, val=0.0791, patience=4/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0851, val=0.0791, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 11 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000004 (1 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0004
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0271
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2373, R²: 0.0234

📊 Round 11 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2319, R²: 0.0715

📊 Round 11 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2323, R²: 0.0682

============================================================
🔄 Round 19 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0741 (↓), lr=0.000004
   • Epoch   2/100: train=0.0808, val=0.0740, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0808, val=0.0740, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0807, val=0.0740, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0807, val=0.0739, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0805, val=0.0737, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 19 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0539
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0622
============================================================


============================================================
🔄 Round 20 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0821 (↓), lr=0.000004
   • Epoch   2/100: train=0.0783, val=0.0821, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0783, val=0.0821, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0783, val=0.0820, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0783, val=0.0820, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0782, val=0.0819, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 20 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0688
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0365
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2317, R²: 0.0730

============================================================
🔄 Round 21 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 21 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0664
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0684
============================================================


============================================================
🔄 Round 22 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 22 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0743
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0062
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2320, R²: 0.0689

📊 Round 22 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2326, R²: 0.0662

📊 Round 22 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2333, R²: 0.0624

📊 Round 22 Test Metrics:
   Loss: 0.0749, RMSE: 0.2738, MAE: 0.2333, R²: 0.0620

============================================================
🔄 Round 32 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 32 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0569
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0488
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0750, RMSE: 0.2739, MAE: 0.2335, R²: 0.0612

============================================================
🔄 Round 34 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 34 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0476
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0766
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0750, RMSE: 0.2739, MAE: 0.2335, R²: 0.0609

📊 Round 34 Test Metrics:
   Loss: 0.0750, RMSE: 0.2739, MAE: 0.2335, R²: 0.0607

============================================================
🔄 Round 38 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 38 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0504
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.0611
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0750, RMSE: 0.2739, MAE: 0.2335, R²: 0.0607

============================================================
🔄 Round 39 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 39 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0485
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0707
============================================================


============================================================
🔄 Round 40 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 40 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0588
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0340
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0606

============================================================
🔄 Round 41 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 41 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0452
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0902
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0606

============================================================
🔄 Round 44 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 44 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0502
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0673
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0606

============================================================
🔄 Round 45 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 45 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0439
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0812
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0605

============================================================
🔄 Round 46 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 46 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0392
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.1083
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0605

📊 Round 46 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0605

============================================================
🔄 Round 48 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 48 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0512
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0648
============================================================


============================================================
🔄 Round 50 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 50 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0508
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0649
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0605

============================================================
🔄 Round 51 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 51 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0545
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0529
============================================================


============================================================
🔄 Round 52 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 52 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0576
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0414
============================================================


============================================================
🔄 Round 53 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 53 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0425
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0989
============================================================


============================================================
🔄 Round 54 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 54 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0497
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0691
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0605

📊 Round 54 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0605

============================================================
🔄 Round 56 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 56 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0554
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0476
============================================================


============================================================
🔄 Round 57 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 57 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0556
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0471
============================================================


============================================================
🔄 Round 60 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 60 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0542
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0448
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0604

============================================================
🔄 Round 61 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 61 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0460
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0763
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0604

============================================================
🔄 Round 63 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 63 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0531
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0582
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0604

📊 Round 63 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0604

📊 Round 63 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0603

============================================================
🔄 Round 68 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 68 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0573
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0416
============================================================


============================================================
🔄 Round 69 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 69 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0523
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0605
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0603

============================================================
🔄 Round 72 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 72 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0520
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0608
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0602

============================================================
🔄 Round 75 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 75 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0527
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0598
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0602

============================================================
🔄 Round 77 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 77 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0486
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0746
============================================================


============================================================
🔄 Round 81 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 81 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0605
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0271
============================================================


============================================================
🔄 Round 82 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 82 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0605
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0144
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0602

📊 Round 82 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0602

============================================================
🔄 Round 86 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 86 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0554
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0466
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0602

📊 Round 86 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0602

============================================================
🔄 Round 90 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 90 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0535
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0557
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0602

📊 Round 90 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0602

📊 Round 90 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0602

============================================================
🔄 Round 95 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 95 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0580
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0303
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0601

📊 Round 95 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

📊 Round 95 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

============================================================
🔄 Round 100 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 100 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0551
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0495
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

============================================================
🔄 Round 103 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 103 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0441
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0938
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

============================================================
🔄 Round 104 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 104 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0501
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0524
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

============================================================
🔄 Round 105 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 105 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0550
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0411
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

📊 Round 105 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0601

============================================================
🔄 Round 110 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 110 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0560
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0457
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0602

📊 Round 110 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0602

============================================================
🔄 Round 113 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 113 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0591
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0350
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0602

📊 Round 113 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2335, R²: 0.0602

============================================================
🔄 Round 115 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 115 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0512
   Val:   Loss=0.0686, RMSE=0.2618, R²=0.0648
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0602

📊 Round 115 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0603

============================================================
🔄 Round 120 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 120 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0399
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0976
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0603

📊 Round 120 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0604

============================================================
🔄 Round 123 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 123 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0445
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0896
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0604

📊 Round 123 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0604

============================================================
🔄 Round 131 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 131 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0603
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0303
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0604

📊 Round 131 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0603

============================================================
🔄 Round 133 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 133 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0569
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0413
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0604

📊 Round 133 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0604

📊 Round 133 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0604

============================================================
🔄 Round 137 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 137 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0581
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0325
============================================================


============================================================
🔄 Round 140 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 140 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0603
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0120
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

============================================================
🔄 Round 145 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 145 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0497
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0701
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

📊 Round 145 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0601

============================================================
🔄 Round 152 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 152 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0444
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0895
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0600

============================================================
🔄 Round 156 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 156 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0520
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0481
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0600

📊 Round 156 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0600

============================================================
🔄 Round 160 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 160 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0414
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0881
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2337, R²: 0.0600

📊 Round 160 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2337, R²: 0.0599

📊 Round 160 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2337, R²: 0.0599

============================================================
🔄 Round 170 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 170 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0568
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0382
============================================================


============================================================
🔄 Round 171 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 171 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0531
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0475
============================================================


============================================================
🔄 Round 172 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 172 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0427
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0969
============================================================


============================================================
🔄 Round 177 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 177 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0660
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0245
============================================================


============================================================
🔄 Round 178 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 178 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0567
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0365
============================================================


============================================================
🔄 Round 179 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 179 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0544
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0382
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0599

📊 Round 179 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0599

============================================================
🔄 Round 184 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 184 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0552
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0196
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0599

📊 Round 184 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0599

============================================================
🔄 Round 188 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 188 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0546
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0492
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0599

============================================================
🔄 Round 189 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 189 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0549
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0496
============================================================


============================================================
🔄 Round 191 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 191 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0511
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0625
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0599

============================================================
🔄 Round 192 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 192 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0474
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0649
============================================================


============================================================
🔄 Round 193 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 193 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0520
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0559
============================================================


============================================================
🔄 Round 194 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 194 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0518
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0362
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0600

============================================================
🔄 Round 195 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 195 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0614
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0061
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0600

============================================================
🔄 Round 197 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 197 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0576
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0387
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0600

============================================================
🔄 Round 201 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 201 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0497
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0643
============================================================


============================================================
🔄 Round 203 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 203 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0642
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0087
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2336, R²: 0.0600

============================================================
🔄 Round 207 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 207 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0532
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0571
============================================================


============================================================
🔄 Round 208 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 208 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0456
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0849
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0600

📊 Round 208 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0600

============================================================
🔄 Round 210 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 210 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0552
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0495
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0751, RMSE: 0.2741, MAE: 0.2336, R²: 0.0600

❌ Client client_3 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
