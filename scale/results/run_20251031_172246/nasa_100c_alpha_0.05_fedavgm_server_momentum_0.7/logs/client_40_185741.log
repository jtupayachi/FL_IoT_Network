[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68268d3a-7ef0-46ea-9ee7-1971ea70ba64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d3233c8-ccc7-472a-b597-12bad4a36be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb054a7a-1a34-47f7-9326-f63458a4313e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafb5aca-057b-48eb-8fbe-9a8bbe1b1b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb2981e-8240-43c4-8df4-ba6a8242f859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59eb5d6-ec45-43df-9a0c-e84c42b899e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc0579b-b60c-43d5-8c17-26fcc720a625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2c79d6c-e285-415e-9b54-33a6d42eb882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc944975-2f9f-45a6-b1ab-23b21c4e5d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22934a2d-4dbd-4702-af08-df302330c5f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec1c8da-37de-4daf-bf92-c8d44ae43633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b5176e5-a8f9-43c1-bbb7-119dbafab6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c659a1b3-5d1a-4faf-aa88-34cf1e6efffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ab7db3-47e0-4aa6-a65a-8b515282824e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1acc742-63f0-482d-b160-c1e5ef26a0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d335c38c-eb53-438e-bfae-901be98843f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb7300d-ba62-49d8-860c-845794299e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd1ebc1-d2b0-4188-b701-95e7352a6ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f4b149-1154-4031-ae2b-6a511228c707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95050696-1804-45bb-a803-ae5258542fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07538bf3-1b56-4123-b937-984d12b89228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed869bbc-3bb7-4f55-8ef2-c463de5a0088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3212f5b4-805f-4ecf-b3f5-04ebea928b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d0d09b0-6c8e-462c-b9cb-33602d9ef0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd4d8bbc-801d-4afd-babd-e407a6365b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f36064-db7f-482c-8d57-3e167b4a97c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08d8e41-d4f3-491b-8f77-629a11ca1d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334fafb2-d047-40ad-a2a4-f4d2c1022784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d6d9a72-3d83-4ba6-af62-f15f26cc582d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8292058f-27d7-4c95-9334-a17a61977126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d7b444-58fd-4cec-8cec-0eb185000f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd482795-5778-48e2-8d94-87d5a91c7fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d893c938-53f1-4e37-bd3a-ab4644992abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0824d4b-e461-4c40-a5d7-865cb24f3c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 942296c4-9b0f-447e-aed3-17f9b243d122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb3c7655-427a-469b-a8dc-cdc2a6e3bcec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7027891-8cdb-4edc-b51d-9a4140009a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d59aa562-8b29-4b5f-ab44-84c683496beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c2fe1c-6ee5-4053-a973-78bb76904893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 148a8aeb-b20b-4ed6-bb18-2de4167d1ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28b1020-166a-4497-9291-83cbcf52580b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df55387f-ffcc-4ef5-b665-45ab46d0c316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c825e2-d41d-4d8a-8b7c-20df51051cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dce3a25-a5b3-4ec1-b81e-42c4a86051f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b1509d-6be4-4818-a812-2e5aefb6bab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a56f0ef-6d82-400e-877d-20b91a6eed37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de504367-8460-4cde-845b-747734e257c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb58721d-9322-4413-a005-7a9ec5730323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f75ca46a-c097-44ef-97fb-0b1d71346a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6ce9cb-f481-483e-9d99-02fef758e6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6a4d2c-dd6d-4bd9-b611-9efd40233383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 403df104-58a8-4c35-855f-89a503d017b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c0b6df-14c6-47d3-bae7-8aa1496c5a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6e5edb-d32d-4335-8cdf-ffa0cd66aa16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238f9b10-3568-421b-b702-f53eaf2bf249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23bd33ed-6161-42c1-9b80-b48a6d144eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7c9c498-4c12-4dbf-80ff-428f2bc66f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6e764d6-5526-400d-9513-320ce740a2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944826e2-8d6d-49a4-9a1d-0fb8f81c3de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3398374-e207-43b3-8f7d-0bece978c8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59040c1f-9a8d-4712-bad8-0311816104bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc6946d-c385-4e1b-bb99-3080aca90237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751abef4-9b1a-436b-bbc4-b73dbdd98aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32dc4396-977d-4686-a214-37a4dd7ed382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a3a359-6903-4d33-af81-1f2ec707d24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a078a30-694c-4dbe-b0b0-9cb2b07a5e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2668e3e-79d8-4fd5-a111-82cc06a45a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba88997b-3922-42c6-a054-2f63d4def65c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 235af44b-3d0d-4a7a-a9f4-fc06664a3921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f289de-dab9-4313-920c-f33c280c3d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68657ef-ce8c-4abb-b0da-a6ba63af9a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c659284-a42e-464b-bc18-c1e4cfcc3ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 177becfa-1e06-44e6-ac7e-dca9d8e1b79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d46e0c7-5eea-4fdc-8898-10bca42c0e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c16733-8121-4aef-be11-6c92ca16dbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dafb1d5d-1ad4-4c2a-9bc6-56317aefc8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b374898-9976-44c4-ab69-06082c17b649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4b332e-1398-4a2b-b975-03065de9f77a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f043096c-041a-40c1-8966-a8848852903e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3851a450-d3d7-4f22-afdd-bc79fba8b95f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0933962-2c58-4a9a-85cf-4dbbfc193cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9003f33d-4e42-4368-ba24-25d00af8557b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e6e9bf2-347d-4646-a1b2-b3ad251992fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aeb2d0a-0a54-4c23-b13f-7da77483498b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2387925a-2e7d-4306-8892-0d92f6e1a167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db433860-f032-412a-ac58-84a66f823e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f55982d-9876-4ca1-a470-da761eda1d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba0b168-6240-4928-ad03-c20676ae57a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e8ad68-d6f5-49bc-a07b-a229fadfbc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 903af7ad-4ff1-419a-9656-61e373274b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 607dcf40-cbc2-49af-a564-e516384626e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab5a54a-b9f4-4086-a78e-2150b108ff0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233d6219-8cf3-43b6-8c82-eab768a6e02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06e74b0e-7720-4d89-afd5-7122b19e24a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eebd3648-875d-40c9-b3b5-69787135b535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec7b0adc-7fa9-4645-88e3-66560d8f6129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b506c666-819a-4d3a-94f3-0bcf5f05290a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06be55ae-7e5e-4d92-b131-979f4a7a9316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f166fb3-0d7b-410f-a8a3-01edb3445737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26dc2c95-5e48-4078-9446-279673d1ff4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc28ad81-495b-4b29-9da3-88f23dadfef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e300d65a-3fce-4eba-8533-dda771af536a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebbbc1a5-bc79-4f36-8213-b1b1ed45828e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f33336-43e1-49aa-9c41-8e1a6700a081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b94bc02c-0f6a-4054-8753-b3ebd26418c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947d4624-e3fb-449d-9538-358c33dd6b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b415faa9-5159-474e-8adc-b5287e56b553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f1ae5c7-533e-4104-bbe9-736c0c22d799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1309d3d0-bfba-4bf6-8ab6-55d4e67efee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e38440fe-abb3-45d0-b3d1-6dc085b33f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f4ea4e-b61f-426f-bca7-afc78c7e7edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e04586-5f8f-446e-aadf-1d0daf98d3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58aa7ada-2228-4d24-85d5-ca9f8029d4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925ea307-3288-4b83-89c6-8372c3b181d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3305345f-2812-41d8-9845-8601dd9cd89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22cf4c3a-7199-495f-a994-d85f6d18ad5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd412cc-d2b3-4d09-be0c-8ceab9140e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec5ef3a0-c8b7-433c-b1e8-0fca98eec137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf15450-6394-4b5c-a6d0-f05decbf8d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb54a948-f1d0-4e33-bee5-390061ed876b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040f1d85-dcd1-46c5-8bef-1d532c2ae143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5098460-d29c-4938-be21-b300d5778b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75958f50-97b7-4371-a39c-11774910188c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b36e51-ce01-4e4f-ae81-79cd79c6ee23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2408e54-e4d4-4a7f-8175-3f05cee02816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927f8e9f-0ebc-422e-9f58-126e1987163b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8272cd17-6b1e-44a0-9a19-61bcdbe90e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57057bc1-d4e7-49c2-a7f9-6d8f62b852b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1bc78ee-d57a-4eab-8dd4-333c8bbb5df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac22de7-51c1-4bcd-a42b-b1486df7f5c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa7457d-bedf-4580-8cf7-5bd2d472c738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f954ca30-373a-4aae-b7cf-299bbfc8829b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1fde274-b473-489a-9fd5-1e19feeacd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c87769bb-1fde-4042-8949-2da1eaf4f628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df1d6eb-9784-43af-82b7-d9e10c5d5c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44aa6842-a4b2-4837-83cf-11569dacd8ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e97e08b-9e13-4795-a512-20840e15a1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf54e96e-cbae-4de9-9429-c40ad7e8f79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5322ac79-a244-46a9-a1cb-133132b24493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f998881-0d26-436b-953f-8aac240c4dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372288f1-ec27-4d85-8869-912b54614e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f18e0af-d02b-42f4-8061-1cf477d8f151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb6bf27-e66e-4554-a420-5e173722fdac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e42a1c-ffdf-4f01-9cda-2c4cf22c8a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f904836-de14-4bcb-a6c9-669a64ac13ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b76b13-102b-4570-abda-4bcfc9b2b346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7eccb3-51a6-49c0-a3a5-8d4048549c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce2ea74d-ed6b-47ba-b853-43d546c68958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f5881b-5655-4a1c-b957-632555750a35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c866b8c-ef47-432e-94d9-fbeef9228b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4483d45e-f14a-4d4a-a5d5-18d80d632e6c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_40
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/test_labels.txt

📊 Raw data loaded:
   Train: X=(1839, 24), y=(1839,)
   Test:  X=(460, 24), y=(460,)

⚠️  Limiting training data: 1839 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  451 samples, 5 features
✅ Client client_40 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 11 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.001000
   • Epoch   2/100: train=0.0788, val=0.0816, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0777, val=0.0817, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0766, val=0.0821, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0757, val=0.0817, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0702, val=0.0840, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 11 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0302
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0088
============================================================


============================================================
🔄 Round 12 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0841 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0794, val=0.0823 (↓), lr=0.000250
   • Epoch   3/100: train=0.0792, val=0.0826, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0788, val=0.0825, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0785, val=0.0823, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0774, val=0.0818, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0766, val=0.0815, patience=9/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 12 Summary - Client client_40
   Epochs: 27/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0481
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0192
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2584, R²: 0.0088

============================================================
🔄 Round 13 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0914 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0783, val=0.0890 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0774, val=0.0880 (↓), lr=0.000063
   • Epoch   4/100: train=0.0771, val=0.0876, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0769, val=0.0874 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0764, val=0.0874, patience=6/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 13 Summary - Client client_40
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0379
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0281
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2561, R²: 0.0309

============================================================
🔄 Round 16 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0772 (↓), lr=0.000016
   • Epoch   2/100: train=0.0782, val=0.0772, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0782, val=0.0772, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0781, val=0.0772, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0780, val=0.0772, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0775, val=0.0771, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 16 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0483
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0310
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2545, R²: 0.0427

============================================================
🔄 Round 18 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0825 (↓), lr=0.000016
   • Epoch   2/100: train=0.0781, val=0.0821, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0777, val=0.0818 (↓), lr=0.000016
   • Epoch   4/100: train=0.0774, val=0.0816, patience=1/15, lr=0.000016
   • Epoch   5/100: train=0.0772, val=0.0815, patience=2/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0767, val=0.0812, patience=4/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0764, val=0.0810, patience=14/15, lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 18 Summary - Client client_40
   Epochs: 22/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0535
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0398
============================================================


============================================================
🔄 Round 19 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0817 (↓), lr=0.000002
   • Epoch   2/100: train=0.0797, val=0.0816, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0796, val=0.0815, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0795, val=0.0814, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0795, val=0.0814, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0792, val=0.0811, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0789, val=0.0808, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 19 Summary - Client client_40
   Epochs: 23/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0354
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0009
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2548, R²: 0.0395

============================================================
🔄 Round 21 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 21 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0481
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0114
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2543, R²: 0.0417

============================================================
🔄 Round 22 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 22 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0477
   Val:   Loss=0.0661, RMSE=0.2571, R²=0.0380
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2542, R²: 0.0429

📊 Round 22 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2553, R²: 0.0382

📊 Round 22 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2554, R²: 0.0379

📊 Round 22 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2554, R²: 0.0377

📊 Round 22 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2556, R²: 0.0370

============================================================
🔄 Round 40 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 40 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0300
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0361
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: 0.0369

============================================================
🔄 Round 41 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 41 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0354
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0154
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: 0.0370

============================================================
🔄 Round 45 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 45 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0329
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0283
============================================================


============================================================
🔄 Round 46 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 46 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0319
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0312
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: 0.0370

📊 Round 46 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: 0.0370

============================================================
🔄 Round 49 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 49 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0297
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0438
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: 0.0370

📊 Round 49 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: 0.0370

📊 Round 49 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: 0.0370

============================================================
🔄 Round 56 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 56 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0396
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0481
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: 0.0371

============================================================
🔄 Round 57 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 57 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0326
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0349
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2555, R²: 0.0371

============================================================
🔄 Round 59 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 59 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0349
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0217
============================================================


============================================================
🔄 Round 60 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 60 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0334
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0317
============================================================


============================================================
🔄 Round 61 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0616 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0616, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0616, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0615, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0615, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0615, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0616)

============================================================
📊 Round 61 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0354
   Val:   Loss=0.0616, RMSE=0.2481, R²=0.0222
============================================================


============================================================
🔄 Round 62 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 62 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0346
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0269
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2555, R²: 0.0369

============================================================
🔄 Round 65 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 65 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0262
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0611
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: 0.0367

============================================================
🔄 Round 68 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 68 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0323
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0241
============================================================


============================================================
🔄 Round 70 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 70 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0329
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0325
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: 0.0368

============================================================
🔄 Round 71 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 71 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0273
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0533
============================================================


============================================================
🔄 Round 72 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 72 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0404
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0016
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: 0.0368

============================================================
🔄 Round 73 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 73 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0394
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0159
============================================================


============================================================
🔄 Round 74 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 74 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0216
   Val:   Loss=0.0849, RMSE=0.2915, R²=0.0730
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2555, R²: 0.0368

============================================================
🔄 Round 75 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 75 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0347
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0279
============================================================


============================================================
🔄 Round 77 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 77 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0342
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0295
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: 0.0367

📊 Round 77 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2556, R²: 0.0367

📊 Round 77 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0365

============================================================
🔄 Round 85 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 85 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0402
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0110
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0364

============================================================
🔄 Round 87 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 87 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0391
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0064
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0365

============================================================
🔄 Round 89 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 89 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0282
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0370
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0365

============================================================
🔄 Round 90 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 90 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0345
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0188
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0365

============================================================
🔄 Round 91 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 91 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0339
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0200
============================================================


============================================================
🔄 Round 92 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 92 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0302
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0318
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0366

============================================================
🔄 Round 94 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 94 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0338
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0320
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0366

============================================================
🔄 Round 96 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 96 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0237
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0737
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0365

============================================================
🔄 Round 98 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 98 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0330
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0306
============================================================


============================================================
🔄 Round 99 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 99 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=0.0347
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0290
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0365

📊 Round 99 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0364

📊 Round 99 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0364

============================================================
🔄 Round 105 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 105 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0322
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0389
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0364

============================================================
🔄 Round 106 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 106 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0332
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0255
============================================================


============================================================
🔄 Round 108 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 108 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0370
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0188
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0365

📊 Round 108 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0365

📊 Round 108 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0364

📊 Round 108 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0364

============================================================
🔄 Round 117 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 117 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0377
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0135
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0364

============================================================
🔄 Round 118 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 118 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0358
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0236
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0364

============================================================
🔄 Round 119 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 119 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0310
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0405
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0363

============================================================
🔄 Round 121 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 121 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0272
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0544
============================================================


============================================================
🔄 Round 123 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 123 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0370
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0123
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0362

============================================================
🔄 Round 125 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 125 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0325
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0314
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0362

📊 Round 125 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0362

📊 Round 125 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0362

============================================================
🔄 Round 128 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 128 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0250
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0245
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2556, R²: 0.0362

============================================================
🔄 Round 135 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 135 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0300
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0370
============================================================


============================================================
🔄 Round 136 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 136 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0343
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0012
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2557, R²: 0.0360

============================================================
🔄 Round 137 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 137 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0341
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0247
============================================================


============================================================
🔄 Round 138 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 138 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0311
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0356
============================================================


============================================================
🔄 Round 139 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 139 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0356
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0178
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0358

============================================================
🔄 Round 141 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 141 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0353
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0153
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0358

============================================================
🔄 Round 143 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 143 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0259
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0066
============================================================


============================================================
🔄 Round 145 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 145 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0310
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0375
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0358

📊 Round 145 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0358

============================================================
🔄 Round 149 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 149 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0314
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0350
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0356

📊 Round 149 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0356

📊 Round 149 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0356

============================================================
🔄 Round 154 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 154 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0410
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0231
============================================================


============================================================
🔄 Round 156 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 156 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0297
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.0359
============================================================


============================================================
🔄 Round 158 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 158 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0272
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0533
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0354

============================================================
🔄 Round 160 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 160 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0284
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0471
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0354

============================================================
🔄 Round 163 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 163 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0363
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0142
============================================================


============================================================
🔄 Round 165 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 165 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0314
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0314
============================================================


============================================================
🔄 Round 167 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 167 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0350
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0174
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2558, R²: 0.0353

============================================================
🔄 Round 170 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 170 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0333
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0231
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2558, R²: 0.0353

📊 Round 170 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0354

📊 Round 170 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0354

📊 Round 170 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0354

============================================================
🔄 Round 177 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 177 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0329
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0278
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0354

============================================================
🔄 Round 182 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 182 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0382
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0008
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0355

📊 Round 182 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0355

📊 Round 182 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0355

📊 Round 182 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0356

============================================================
🔄 Round 196 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 196 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0410
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0014
============================================================


============================================================
🔄 Round 198 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 198 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0371
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0113
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0357

============================================================
🔄 Round 199 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 199 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0403
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0040
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0356

📊 Round 199 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0355

============================================================
🔄 Round 201 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 201 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0337
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0246
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2557, R²: 0.0355

============================================================
🔄 Round 205 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 205 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0331
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0191
============================================================


============================================================
🔄 Round 206 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 206 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0339
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0277
============================================================


============================================================
🔄 Round 208 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 208 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0307
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0354
============================================================


============================================================
🔄 Round 210 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 210 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0331
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0297
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2558, R²: 0.0353

============================================================
🔄 Round 211 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 211 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0240
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0644
============================================================


❌ Client client_40 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
