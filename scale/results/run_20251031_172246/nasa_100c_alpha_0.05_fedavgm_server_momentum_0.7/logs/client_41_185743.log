[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40e5f909-b34e-49f7-9811-7e308dc4a445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77434556-1019-4661-a91c-f85a65b754a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ced448-c2d4-40c8-b78e-0a4c9fff85d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a7af47d-f3e5-4acb-b720-c7b93a5ef266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c427ef34-a38b-4b80-9a12-ff331577f3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df61d5d-6cfc-4c71-a97f-7940f2a9ff94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc6df82-9d36-4048-a967-d15744f926c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d09d43d-ec47-418d-a5c2-a76441e72718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a69ecf9-efbf-4b22-a952-80157456fc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63651017-3404-4356-b798-1afea18d1bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b0d3e19-3d14-460c-ae88-c5a922f800dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16152d5f-eef6-4c26-9161-73e1c42b1744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a861df85-0117-4fb9-9b31-0993f56eaa3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885883a1-4891-427f-aa4e-85c437a38a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f9772b-3f20-4b7f-ac3f-972e03c8e809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c200b148-3428-429c-bb53-9c08b71de5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5cb5b3f-d60b-4620-98c6-5980e76601c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc842ea5-d61f-491d-aa9e-4f046a512bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e7325a9-db9b-4bfd-a8a7-4112e548b249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d537d6ad-2619-4064-982f-7bd399d19ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d2aa8dc-28d2-469b-a507-52bf806148e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b404032d-fa67-4f03-9b44-f9623489cddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8df40085-dbf7-4a9d-a575-b369912a5fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d378e99c-2cb8-49e4-a221-3fa7c02a5e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8332beb-9ee5-4296-8e26-c5db62f28517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f60321b-9277-4efa-b6ef-b954ece22b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e63471eb-b177-42ed-8d6c-faa8e71e747b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4676a7e-2670-4cde-80c8-c5a0365f2810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c91b32b5-0856-4f37-860c-be87e302d286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4ed5cb-98a0-47cb-b65e-94459a4be52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e0ed40-c208-4b64-8abb-d5077ad8adb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c447994-7f8d-4aaa-bbc0-36b33c1054bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c3e30aa-ee5a-44cd-a5b4-399653fafdb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4770da80-82d0-4c0b-9d71-2d1916b393fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a0c759-25b0-4af4-b1bb-33fba2301657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45ac8f5-3549-4229-9e70-6617acc7c245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67cc56de-3037-4488-bc59-2f6d6e9156cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 508ecfd6-d6ae-4cae-a475-aa0d5fdeeea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 576743da-b451-48fa-961b-956f22d34d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7daf1b95-39a7-4dbf-894a-9e7351a504ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3762fb6-1e17-4c6b-a3d4-da11ae9ee1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33e0f61-c18c-4911-ab97-f81857a1c4b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab8b50cd-842a-4224-adec-7ce5ad867d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced88c9d-58d5-403d-9f7c-83662b583e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b611f99-5fa2-4483-af38-00930405b982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eddcac13-e22b-43f1-b57e-89c373171a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dca7acf-0c9a-42a5-a094-af4aab149a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354db567-0468-42f9-9821-4c3678a01ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775c9836-b36e-482a-8222-6e2bf3c5b253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d63038-76c5-499b-b363-a78da000b416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dffa552-6770-410a-966c-4cb886b14db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2757982-d134-42fb-a2fb-26650d60cd5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abf858b7-bdf3-4789-9dc4-f073e70a1e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a0559af-719e-49f2-85b6-383eddd0f364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de18757b-81c4-4e9c-ae2f-089ecd0b1032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885512fc-59c8-4034-bc2e-acab6b1b5a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7280545c-eb29-4488-a182-46a5b0beb8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7154217-565a-41b5-af5a-fe7c3219f1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432e5dd9-ba0e-4a87-8c16-ab968f7744bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af62f0fa-3c61-43c5-bb29-2da5e3549e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cae4346-bf93-4c73-8659-6705c84008ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1f780e7-64aa-429a-b9ca-d1b09257dc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eee766d-3923-43e5-93ec-ace3a86de2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02f4bdb-62d5-493e-92b9-a8bd56dbf89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c52ccdb1-a9e4-421b-b14e-8976d5e3107a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65713dea-10c3-4d0c-8173-5604f19d9115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c19a68dc-56ed-4805-a034-3736c376ae57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19d24512-685b-49b3-a0e0-3133a9864169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 430605c5-98f8-4111-898e-355045345ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a29648-3b52-416d-af75-0522def55705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 133b9fec-0eae-4e3a-b906-2e5ef4a82c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890093eb-be17-48bd-9329-9aaa196755b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055ac22b-1ff3-4b88-be26-f446d95ca43d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 650b9b29-5a5a-45d5-8db9-3844f33b16e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fe3b776-4bd7-4aed-970c-bbb2dd6f5b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f9ee1b6-4319-4eb0-bc14-c7a881f2a059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d0883f9-fff9-417b-afeb-d79e56300bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f69e036e-6ffa-4817-ae72-8504c8292d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc7fcae-88a4-4668-aacc-eddc2f591e3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f50a85-7955-4275-a823-e10a3613c0fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9c77070-b2a6-40cd-9c7a-83e5e14c0e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244d3bce-28cc-4866-b82e-12c3958d7de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bff5d01c-5112-497f-b943-7eb68ced4e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c82738a-99f3-4936-8ca3-82e535b845dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 884987c8-280c-4e12-be06-3dd01c6d6a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe5729a-c552-46d9-8410-f06b292c6ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ae3545-ceb9-46b8-980a-59f057cb02d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88f0e9c-6d58-4c15-8888-abe02e4a9a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50a8f68c-000b-4832-bdfc-b6726cc823e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f721446d-3d18-43e6-bd9e-68fe50159ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d6c2a8e-7119-477c-9772-cb101811e737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab13cb93-8763-43db-8100-7067dd224178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf8f34d-73a1-46f2-95e4-7b206c6c0911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07625aa4-7b6b-4101-b99c-39ff68e88d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9034ba91-5673-4b31-9c3c-e0c8105d1fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e6dc0c-3f79-4c5d-95c2-a6942c73bd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1fc090c-6ac3-459e-adbb-12ff8d505c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2adb4ca-1953-46fe-a0b7-4c71763f5351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccfa1189-75c5-4d6f-abb2-21d6a0dabb81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab2f94b4-5f16-4322-b42f-fd53fd03c09f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c89fab07-0d33-4f2c-9bbe-9ba5da8e0679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7687dcbb-fb7b-41f2-a6dd-487aa7680e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c872706a-82f9-42b0-8cc1-18119238b535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 363d6dbf-a714-4d6a-bb63-35327e7c5ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5effb81-fe19-406e-a8f7-c7c33891c2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1764738e-5659-42cc-9f26-0ee7fe2a0ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74086ebd-fc7f-4317-964e-38c761615c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db8c1545-9606-4e8c-b3d9-760cf463a8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50b98c71-3b05-4257-8491-3ea21da38d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d827421-35b2-4e6a-abaa-a5ce024c6396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f364a75-b5c1-445a-96ff-e2f4b077b69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb314eee-f05d-478b-ab6a-19abe0fbadc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9368de89-d980-4879-be29-95c00f9acb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72810498-a516-468a-9c0c-74dad46f922d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcbbf83d-88c2-43f3-9b27-821f1a251037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b44bfa-6252-48b6-8131-091aab0ed769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68435e7-b157-4e24-a80d-5fd9c21dcec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23c27c7-4500-4e88-8534-97eaa078925c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a881a05-24e6-4301-8b13-4bcc545bf6a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffce202d-b8be-49f7-b468-9e59bcccd650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea048b81-c4b6-4f6e-9f5d-5a4e0f6484e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33721848-5432-4885-987a-afe33a63704c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2243ac9b-1c29-4504-9b85-2537c87389bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1b0a5b6-5053-4e3a-8adf-fb107d53a57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493b9905-708f-4e59-beee-20caf7c501e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0be211a-18b5-475c-910d-7145c5885083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e014b7-db66-4fec-8654-acffa9936e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 220ad9a4-b917-4296-b5e5-45edf3bdc1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efce9d7-e2e5-4095-a2dd-a7cebb0b7fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebd17d9-30e1-4cfe-ab29-2cb00c1df0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5209edc-76d1-4d8e-9b18-572d41d7b0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ebe6e9-80df-407d-abb3-637a5ffd7e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65687d05-df21-4e60-be3c-e4a15f0fd2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1394b28-b1be-4cf7-8b2f-1d4ea3c1923f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891d0003-e360-4f5c-aeda-5f39568fe28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8967da45-abe3-47f7-96de-76cfd2e352e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92195cb8-2d82-4d0b-ac28-0906d272431a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa23971-8043-42b2-8182-fa0a13ca87a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d74845-168b-4d41-b7b9-2eace41b118b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f3ee377-4552-433e-a876-c11c4ad25db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55260736-48cd-4675-9f14-2b6084167c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b8969bf-8a61-4138-9506-60adc53fd6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b874bf02-20bf-45a3-bd22-08f49d115adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ac0dc6-d390-412b-b039-dccefd0610b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c95d02-6bd3-4548-888b-41785606aca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1187ee-c2f2-4585-b412-0eaf74a34386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a490266d-e3ac-4e0d-9a33-e939b1b7d0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d20c228-4dcc-4ba6-881b-89107a167e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eefcb0de-3fb2-4a56-b6c9-377ebb55082c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9b009f6-0562-4722-ab88-944acf4c0f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 846772db-37eb-41b2-aee3-c0cb8ff46fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c94a4a1-e466-45ea-87e0-72ef89ba368e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d496f0-fefc-4f20-b3c0-17a1213fbd61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 748815f1-53a3-4376-a543-a2c6d30d9db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58bd6fa3-e07c-4758-84c1-a120dd7be857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5540cf1d-a186-4cb0-87d3-3b9a2c88d983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbada76-d3f9-4c59-80e9-c8f50871ea74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f29a7e5-7d83-4f8f-9824-fb101412efed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db7927f2-e74b-4d61-ada7-78377e5d1676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80fe9893-8ceb-41f6-a0fc-1e4dac7586a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 761047eb-f412-42ce-ba28-e06e12bb3cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa79438-97f5-4ec7-bc39-2c6704c11979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31b5df88-dcf0-4a98-96ff-fbb2249d5682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068f4379-f66f-454c-8ac5-577791003a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e7c19c7-028e-4684-8248-b5e11be62a93
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_41
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/test_labels.txt

📊 Raw data loaded:
   Train: X=(527, 24), y=(527,)
   Test:  X=(132, 24), y=(132,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 518 samples, 5 features
   Test:  123 samples, 5 features
✅ Client client_41 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 12 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0908 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0814, val=0.0895 (↓), lr=0.001000
   • Epoch   3/100: train=0.0804, val=0.0894, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0796, val=0.0893, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0789, val=0.0893, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0724, val=0.0886, patience=2/15, lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0604, val=0.0959, patience=12/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 12 Summary - Client client_41
   Epochs: 24/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1076
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0308
============================================================


============================================================
🔄 Round 13 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0665 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0898, val=0.0657 (↓), lr=0.000500
   • Epoch   3/100: train=0.0891, val=0.0658, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0885, val=0.0660, patience=2/15, lr=0.000500
   • Epoch   5/100: train=0.0880, val=0.0660, patience=3/15, lr=0.000500
   📉 Epoch 8: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0858, val=0.0662, patience=9/15, lr=0.000250
   📉 Epoch 16: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0657)

============================================================
📊 Round 13 Summary - Client client_41
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0059
   Val:   Loss=0.0657, RMSE=0.2564, R²=-0.0037
============================================================


============================================================
🔄 Round 20 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0756 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0897, val=0.0749 (↓), lr=0.000125
   • Epoch   3/100: train=0.0889, val=0.0747, patience=1/15, lr=0.000125
   • Epoch   4/100: train=0.0885, val=0.0745, patience=2/15, lr=0.000125
   ✓ Epoch   5/100: train=0.0881, val=0.0744 (↓), lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0870, val=0.0741, patience=6/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 20 Summary - Client client_41
   Epochs: 20/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0088
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0340
============================================================


============================================================
🔄 Round 21 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0888 (↓), lr=0.000031
   • Epoch   2/100: train=0.0874, val=0.0884, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   ✓ Epoch   3/100: train=0.0868, val=0.0882 (↓), lr=0.000016
   • Epoch   4/100: train=0.0865, val=0.0881, patience=1/15, lr=0.000016
   • Epoch   5/100: train=0.0863, val=0.0880, patience=2/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0856, val=0.0879, patience=8/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 21 Summary - Client client_41
   Epochs: 18/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0258
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0657
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2354, R²: 0.0025

============================================================
🔄 Round 26 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0849, val=0.0979 (↓), lr=0.000004
   • Epoch   2/100: train=0.0848, val=0.0978, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0847, val=0.0978, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0846, val=0.0977, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0845, val=0.0977, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0841, val=0.0975, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 26 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0327
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0933
============================================================


============================================================
🔄 Round 27 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0854, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 27 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0376
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0318
============================================================


============================================================
🔄 Round 28 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 28 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0327
   Val:   Loss=0.0954, RMSE=0.3088, R²=-0.1115
============================================================


============================================================
🔄 Round 30 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 30 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0321
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0290
============================================================


============================================================
🔄 Round 31 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 31 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0211
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0615
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2368, R²: -0.0033

📊 Round 31 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2368, R²: -0.0032

============================================================
🔄 Round 33 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 33 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0197
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0402
============================================================


============================================================
🔄 Round 34 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 34 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0230
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0168
============================================================


============================================================
🔄 Round 36 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.1026 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.1026, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.1026, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.1026, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.1026, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.1026, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1026)

============================================================
📊 Round 36 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0220
   Val:   Loss=0.1026, RMSE=0.3204, R²=-0.0180
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2368, R²: -0.0028

============================================================
🔄 Round 37 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 37 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0210
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0259
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2367, R²: -0.0025

============================================================
🔄 Round 44 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 44 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0218
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0141
============================================================


============================================================
🔄 Round 45 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 45 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0241
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0302
============================================================


============================================================
🔄 Round 47 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 47 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0243
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0086
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2367, R²: -0.0019

📊 Round 47 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2367, R²: -0.0018

📊 Round 47 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2367, R²: -0.0018

📊 Round 47 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2367, R²: -0.0017

📊 Round 47 Test Metrics:
   Loss: 0.0779, RMSE: 0.2792, MAE: 0.2367, R²: -0.0017

📊 Round 47 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2367, R²: -0.0015

============================================================
🔄 Round 57 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 57 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0180
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0289
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2367, R²: -0.0014

📊 Round 57 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2366, R²: -0.0014

============================================================
🔄 Round 59 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 59 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0176
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0696
============================================================


============================================================
🔄 Round 60 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 60 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0270
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0174
============================================================


============================================================
🔄 Round 61 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 61 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0162
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0412
============================================================


============================================================
🔄 Round 62 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 62 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0190
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0256
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2366, R²: -0.0013

============================================================
🔄 Round 64 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 64 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0167
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0326
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2366, R²: -0.0012

============================================================
🔄 Round 65 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 65 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0187
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0267
============================================================


============================================================
🔄 Round 66 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 66 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0179
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0354
============================================================


============================================================
🔄 Round 67 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 67 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0281
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0213
============================================================


============================================================
🔄 Round 68 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 68 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0264
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0096
============================================================


============================================================
🔄 Round 70 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 70 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0188
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0333
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2366, R²: -0.0010

============================================================
🔄 Round 73 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 73 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0163
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0379
============================================================


============================================================
🔄 Round 77 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 77 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0281
   Val:   Loss=0.0953, RMSE=0.3088, R²=0.0073
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2366, R²: -0.0007

============================================================
🔄 Round 79 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 79 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0196
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0261
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2366, R²: -0.0007

📊 Round 79 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2366, R²: -0.0007

============================================================
🔄 Round 81 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 81 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0190
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0212
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2366, R²: -0.0007

============================================================
🔄 Round 82 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 82 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0128
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0570
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2366, R²: -0.0007

============================================================
🔄 Round 85 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 85 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0227
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0419
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2366, R²: -0.0006

============================================================
🔄 Round 87 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 87 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0119
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0509
============================================================


============================================================
🔄 Round 88 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 88 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0231
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0789
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2366, R²: -0.0006

============================================================
🔄 Round 89 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 89 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0146
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0493
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0005

============================================================
🔄 Round 91 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 91 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0159
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0512
============================================================


============================================================
🔄 Round 92 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 92 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0229
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0076
============================================================


============================================================
🔄 Round 93 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 93 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0198
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0173
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0003

============================================================
🔄 Round 96 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 96 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0226
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0078
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0002

📊 Round 96 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0001

============================================================
🔄 Round 98 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 98 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=-0.0200
   Val:   Loss=0.0684, RMSE=0.2615, R²=-0.0153
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: -0.0001

📊 Round 98 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: -0.0001

📊 Round 98 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: -0.0000

============================================================
🔄 Round 104 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 104 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0211
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0131
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0000

📊 Round 104 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0000

📊 Round 104 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0000

📊 Round 104 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0000

============================================================
🔄 Round 110 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 110 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0153
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0354
============================================================


============================================================
🔄 Round 111 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 111 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0132
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0556
============================================================


============================================================
🔄 Round 114 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 114 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0157
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0319
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: -0.0000

============================================================
🔄 Round 116 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 116 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0111
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0616
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: -0.0000

📊 Round 116 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0001

============================================================
🔄 Round 120 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 120 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0134
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0532
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0003

============================================================
🔄 Round 122 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 122 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0155
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0359
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0003

📊 Round 122 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0003

📊 Round 122 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0003

📊 Round 122 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0003

📊 Round 122 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0003

📊 Round 122 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0003

============================================================
🔄 Round 128 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 128 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0232
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0028
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0002

============================================================
🔄 Round 130 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 130 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0191
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0285
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0002

============================================================
🔄 Round 131 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 131 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0166
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0348
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0001

============================================================
🔄 Round 132 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 132 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0248
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0191
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0002

============================================================
🔄 Round 135 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 135 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0140
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0401
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0002

============================================================
🔄 Round 136 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 136 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0259
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0100
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0002

============================================================
🔄 Round 138 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 138 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0144
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0440
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2366, R²: -0.0001

============================================================
🔄 Round 139 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 139 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0163
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0291
============================================================


============================================================
🔄 Round 140 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 140 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0181
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0226
============================================================


============================================================
🔄 Round 142 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 142 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0162
   Val:   Loss=0.0683, RMSE=0.2614, R²=-0.0392
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0002

📊 Round 142 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0002

📊 Round 142 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0003

============================================================
🔄 Round 150 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 150 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0179
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0229
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0003

📊 Round 150 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0003

============================================================
🔄 Round 153 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 153 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0176
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0303
============================================================


============================================================
🔄 Round 155 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 155 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0205
   Val:   Loss=0.0694, RMSE=0.2635, R²=-0.0247
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0004

============================================================
🔄 Round 157 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 157 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0220
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0147
============================================================


============================================================
🔄 Round 159 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 159 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2933, R²=-0.0189
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0211
============================================================


============================================================
🔄 Round 160 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 160 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0144
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0409
============================================================


============================================================
🔄 Round 161 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 161 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0135
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0407
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0005

============================================================
🔄 Round 165 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 165 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0192
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0211
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2366, R²: 0.0006

============================================================
🔄 Round 166 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 166 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0141
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0802
============================================================


============================================================
🔄 Round 167 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 167 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0161
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0414
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2366, R²: 0.0006

📊 Round 167 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2366, R²: 0.0006

============================================================
🔄 Round 170 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 170 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0245
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0012
============================================================


============================================================
🔄 Round 172 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 172 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0300
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0254
============================================================


============================================================
🔄 Round 173 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 173 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0170
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0352
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0008

📊 Round 173 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0008

============================================================
🔄 Round 177 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 177 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0173
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0464
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0008

============================================================
🔄 Round 180 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 180 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0231
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0005
============================================================


============================================================
🔄 Round 182 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 182 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0186
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0876
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0008

============================================================
🔄 Round 187 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 187 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=-0.0198
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0157
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

📊 Round 187 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

============================================================
🔄 Round 190 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 190 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0146
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0340
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

============================================================
🔄 Round 193 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 193 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0221
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0063
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

============================================================
🔄 Round 194 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 194 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0258
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0151
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

============================================================
🔄 Round 195 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 195 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0157
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0352
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

📊 Round 195 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

📊 Round 195 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

============================================================
🔄 Round 198 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 198 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0189
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0226
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0010

============================================================
🔄 Round 199 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 199 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0171
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0334
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

============================================================
🔄 Round 200 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 200 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0198
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0151
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0009

============================================================
🔄 Round 202 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 202 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0186
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0183
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0008

📊 Round 202 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0008

============================================================
🔄 Round 204 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 204 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0243
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0045
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0008

============================================================
🔄 Round 205 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 205 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0196
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0152
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2366, R²: 0.0008

❌ Client client_41 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
