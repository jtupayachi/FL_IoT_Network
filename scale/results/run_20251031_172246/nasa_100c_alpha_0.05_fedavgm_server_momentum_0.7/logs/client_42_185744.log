[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cefe186-5100-46b4-b00c-b747519baa99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0c9ef5-2b60-4c6b-bdb3-61c28c1e74d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a6f66c7-a74e-4f41-83e4-eacaecc688fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77dd0b51-d3fa-4b93-b0ef-50dca57c8379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe99a26-cd53-4c71-8329-d8c3f573a69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53b4291-c661-496b-9d49-22b2d4a00af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf64980-2c3c-4f22-bd08-2350ffbd233b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2adfa1-61c9-472e-850a-7482e4080171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35956689-30be-4636-8c29-395802d135c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2619cab2-1533-4270-99a3-b12664720a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5fe27e4-668f-4ba3-be74-e38f54d594be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4209aff-dc32-43bb-9ec0-285736b8e97d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5858315f-a4a4-426b-af00-be2f39d53c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7431b3-0fc7-473e-ae34-11ac0bb4b287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 116af5d4-8a02-450e-8b0f-acc5acfc538f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8faf0027-b533-4dea-baa5-09016d3c94f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34534f46-ab05-48f3-9c46-ab2001d25490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b29b220-378b-40d4-99f9-c5141fea5841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b72ffc3c-968c-42e9-8994-b07850455aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e6741a-2e77-4b79-a027-c32c19f65ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc0267e-e0aa-4e1f-885d-a76f421bbad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4379842-0e0e-408a-9fb0-63120d43fe0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bd83835-8aa1-4c50-b408-63fe60ebd0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9228f291-ceff-4d60-b41b-22274e4a7284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 434ff3f0-8df6-42c5-b67c-5ac2fbdea6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c49a80b-1719-4687-a678-617e7de4aa29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d49efd-7a42-4873-9355-67611171131e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2475a651-0551-4f3d-bcfe-342bbf3f3509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1b6937-1a76-44b7-902c-a957d353fd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76fcd9d2-2921-4ab6-bdb6-a8704e1b98ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22e0587-dae0-4fc5-887e-b8ddc4d5cd8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b136e3-6709-4b0e-9c80-c2ca2cb85670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a623ca3f-1397-4416-a5b2-0581ac97b91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a475978-0888-4d8e-8361-080b6c54e456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd74cb9-9ebb-438a-84af-a5633ce36fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d72be68-f4bb-4db6-8b75-6e3b13380d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be99ff59-8208-4c9a-b955-314dc6a9c6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d7128f-c680-4fdf-937b-ac6b8d021d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c2bf63-fbc2-46b9-9968-0ba7387fc807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d837bc3-36dc-4ab4-97e2-8b8a02353274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa604ef-fb06-4360-9a0a-329d5f99628a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e01d378-d511-42ec-8964-3f1e16f29988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a55890-54b4-4833-a246-d15db4a38195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac20ac7-1da1-4664-9241-23cda4eb528c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f37531-f819-4ffb-9abc-84344c39a63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 463b9c5b-643f-4cbd-b517-6f4e76285705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a684a5-c772-4b66-b7c1-b11bf7ae6be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460ff64f-13a0-4af4-9c88-20260c6409d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3080448e-67d4-4328-90f9-15d1367fedc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe3bfc77-2ae1-4367-9d2d-380348e4643c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a0e4946-a9c5-4f1e-9974-dd211a1ff151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e10c37-9a96-49f1-b82e-556fe56d0349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdac892f-7270-4519-95db-b831173637a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c2c155a-61a1-435a-b1ae-35779e9174f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2b355b-b84a-4530-a563-83b0c2c02b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4618b62f-4a56-450f-86ac-27a48eeadbf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a805443-5c54-42ca-b449-eae395734176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37274dff-8821-405d-920d-79d290c381e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4904959-215e-4c8e-9d29-e703148a2b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 356a59b8-8a4b-4f82-afe0-80503b970784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a27dd11-fda5-46b9-b9ed-fa42c9d87f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5977d06b-53bd-443d-98ce-84ce9ee3b991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc686e18-0824-4c59-a338-94343b78d9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e87391-0389-47f1-8f12-e8be03b63f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c3b9af-f631-40ba-bbc2-e1ec2a0641a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b179e87-3079-419d-8205-0b75e1990465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f2b734-12dc-4b2e-8b03-07e93424e0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 525c85ff-bb99-4b9b-8f49-a2dae3fdb97d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19de7ad-796b-4599-91ce-8fb5a25f9f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e310bd-9fbd-4dce-8712-dad201d4fee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135a5172-a5ed-4c42-a59b-39afd647feb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64054bbb-b922-479e-a921-4e5dfc55393c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ac0962-6801-499d-a43b-f48c770bb58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc5fdf49-b4a2-4726-b6bb-c7de264ab97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16abee65-57c8-4298-9251-e6d32037e0f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62b6017-a2cc-4c4a-9815-d84d7c45646f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbdb5220-87c4-4e93-93f0-5d2bed7e42b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b45ec7-d5cf-49da-873a-ce19c8fdb110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 790b46a1-f464-4ce9-b515-b5fa0c1f923a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2814450-49e8-4b45-a613-2431bb70054c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7002cf01-aad0-4b19-a93a-ffb1ba3a2b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 094e4209-872d-4b97-b73a-6eaf090933c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98f2aec1-24e7-4787-9394-25b3be15778a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27191e58-7e43-4ad6-9b77-fcb0fdccac22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8eeb8c-bb2d-4d0b-b82c-863ee5b8aabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eea09221-5fb5-4d5f-9281-851a77a2dadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30784529-85e9-4aeb-b90e-f7f4e88860e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9147dbe5-e749-462e-b226-3d6e9b985b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46b98713-e9cc-48f4-bcf9-7b814dd35e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4c499b5-745e-425d-b096-5c4a9b787959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7f34fd7-0609-4cd2-8f02-3ebcb4138160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc07887-3562-4468-a6ab-595c04224e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2390d5c7-836e-4c94-a059-59b9de917b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1181181e-5349-46c2-b17e-c9bcd897cdba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac44f8c-69c6-4843-8468-728fdc9797c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0103f463-df90-4bc8-91fc-51b8937e97b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12ae330-4893-4b5a-8437-c6e030c0b181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c439a4c-6321-4720-af11-30ba8ed0597e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63440c7-fa19-452a-9960-6cfaf1b197ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6d8551-7a97-4683-bf12-1dbf4557b0bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117d2712-d636-4bd7-8438-81f2884ed24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e292fd69-f7c9-4ce9-be37-de9ef91bd175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c391fc4-15a8-4c48-8b5b-d8c9c0f73dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dec6e9b-6954-40c5-a8d4-e6c19e896dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41df5338-2113-40fa-85d3-bb6a2b0cbf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ca2afa-8650-4da3-a8e6-989e1727e320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46680568-2d24-4d13-aee1-596db56d5db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46d23c3-18cd-4c41-8f72-995b418b9984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a66fcc-f6f1-4f61-9e3a-a96500db4a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7864684-b2cf-40e5-84e1-9f9e9ee29970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1468d9c6-8406-4385-9eb4-e9ee4c6b9f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1bf508f-7ef9-4eb7-a76d-6203d7516084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7673f40a-76a4-426e-b028-9580202e93b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18908874-cdf7-4f30-ab97-e5964eec9a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ea14c5-0e30-4ce9-81f7-d594763cee12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2a972b-1657-4f22-8f65-c76682d0180f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af532e42-1b5d-481a-b5a9-a5479221160b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c433d12-ad5c-4806-abc8-61d237ee8b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c514e3-cbef-4d3b-890a-f6b7cb9c49fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ba1682-8193-48ee-9899-a69883b78ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0b014f-2d72-466c-afff-70b8a9842cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a23fbd91-eb7f-4f69-a20c-68eff0fdd6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b3e4c7-94eb-44e9-83b6-0d85232d47fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7df04ee4-f386-40df-9d46-295ae55e254f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e1aaf2c-2541-4764-9a3d-6cfcbc30231f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67c3e42d-08c5-440e-8751-a1f6c2c4ead5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d14504a-7f91-47d8-8670-911b66079421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b12e96-3283-4b84-af62-5fb45c3a7f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01432e87-84e8-4e6a-b79f-067632418216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a82525-1939-42b5-8774-f41ee26b559a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17be2959-39cb-4806-85ae-0ca3831f49c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46acdae7-0349-4e4a-931a-ef0f49477f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c6adcc-a8d8-4fb2-b9c2-efcaf97ed80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0786ce-3898-44ac-afbd-b4ca796abb9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 115cc001-de87-4077-917a-2520d84ff56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd186a7c-114a-4290-9b53-99425a026cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19e95400-e5c0-45f5-91b6-b72ce0a6a325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 856c0ecb-a98f-416e-8376-b1ac5d95e999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436fad6a-ef3a-4a07-aa47-cbbec39e4ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1fe6345-2a8c-4eb2-b401-f6d728e4de16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 444c44b2-312d-4708-a4a4-c505d67f38df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b932362-4f60-4448-8b09-c0077926e1cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99a161bc-822a-401c-9b74-695d6a414af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1814bf8b-5009-4401-b16a-747e011dfae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f058693f-41e8-4047-9525-a772583e9e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03e9503-6d67-4124-8730-8568416958d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28fa70ec-cc69-407a-a87f-3b9bffdfd64b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4be82b7-e9cf-4cf9-a089-b8d35d470c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8a6dfb-1066-47ed-a2cd-cba02ea1a472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e575766e-b6d7-4508-aba4-8b9b7370a803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053cf9fe-8146-423b-92df-ee58174165df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8bb2269-8515-4f46-a757-89e0afddfafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 242cc992-590a-4b09-a236-f1b9d2a80d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e3f650-da3c-4941-abcb-5c495bb8e322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a97cb1e5-9ad9-4a85-b7ff-08e807eac2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21322381-a7b3-4792-9274-3cf77836a4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ffb5213-4735-4841-961a-3d0446b53475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cef11f5-e40a-4098-9e37-69bc1bb1cd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0739d800-2da2-4c09-a218-896c91b2743c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0cecfb6-645e-4112-9303-19fede0d9bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 113b0bd9-6d76-4f00-8d61-6dcf785db443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5326575-0cf4-4011-8915-3ad6bef660ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e03b0aab-c787-4597-8a07-195d13768826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3abe980e-60b8-478a-91c1-7ca82c60488e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac165ff-d5ed-42ef-ab45-d745ea7211a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e390cf69-2e49-4822-9f2f-0d542818fb45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e246ab6-6810-4511-a52c-8d8ae1a6b11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df9ce62a-993c-43d0-a36c-50085b34eeb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1503e3-c8d2-4e8f-9413-c63ab820d61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcab101d-4013-4e13-bffa-0f643541c2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8082d68-e88c-4962-9654-0a3464a88921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b18d1ca4-52f1-4994-bb42-db4d7285a908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c31e08b8-a65e-4abd-bdb2-747535061fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ee7eca8-6296-49c3-8feb-eb9a9c46327d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_42
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/test_labels.txt

📊 Raw data loaded:
   Train: X=(1319, 24), y=(1319,)
   Test:  X=(330, 24), y=(330,)

⚠️  Limiting training data: 1319 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  321 samples, 5 features
✅ Client client_42 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 11 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0874 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0777, val=0.0838 (↓), lr=0.001000
   • Epoch   3/100: train=0.0759, val=0.0853, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0749, val=0.0848, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0741, val=0.0837, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0676, val=0.0794 (↓), lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0537, val=0.0862, patience=9/15, lr=0.000500
   📉 Epoch 26: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 11 Summary - Client client_42
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0637, RMSE=0.2523, R²=0.2058
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0783
============================================================


============================================================
🔄 Round 12 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0753 (↓), lr=0.000250
   • Epoch   2/100: train=0.0795, val=0.0751, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0791, val=0.0749, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0787, val=0.0748 (↓), lr=0.000250
   • Epoch   5/100: train=0.0784, val=0.0747, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0771, val=0.0741, patience=1/15, lr=0.000250
   • Epoch  21/100: train=0.0747, val=0.0726, patience=3/15, lr=0.000250
   • Epoch  31/100: train=0.0717, val=0.0719, patience=8/15, lr=0.000250
   📉 Epoch 37: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 12 Summary - Client client_42
   Epochs: 38/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.1107
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0901
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2501, R²: 0.0247

============================================================
🔄 Round 15 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0786 (↓), lr=0.000125
   • Epoch   2/100: train=0.0714, val=0.0787, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0709, val=0.0787, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0704, val=0.0787, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0700, val=0.0787, patience=4/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0688, val=0.0787, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 15 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0718, RMSE=0.2679, R²=0.1227
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0516
============================================================


============================================================
🔄 Round 16 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0739 (↓), lr=0.000031
   • Epoch   2/100: train=0.0719, val=0.0742, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0715, val=0.0744, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0712, val=0.0746, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0709, val=0.0748, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0701, val=0.0751, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 16 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0724, RMSE=0.2690, R²=0.1264
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0566
============================================================


============================================================
🔄 Round 18 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0642 (↓), lr=0.000008
   • Epoch   2/100: train=0.0748, val=0.0641, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0746, val=0.0641, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0745, val=0.0640, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0743, val=0.0640, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0736, val=0.0638, patience=10/15, lr=0.000008
   • Epoch  21/100: train=0.0726, val=0.0634, patience=7/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0636)

============================================================
📊 Round 18 Summary - Client client_42
   Epochs: 29/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1354
   Val:   Loss=0.0636, RMSE=0.2523, R²=0.1084
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0770, RMSE: 0.2775, MAE: 0.2406, R²: 0.0926

📊 Round 18 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2386, R²: 0.1031

📊 Round 18 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2334, R²: 0.1265

============================================================
🔄 Round 23 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0610 (↓), lr=0.000008
   • Epoch   2/100: train=0.0734, val=0.0609, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0733, val=0.0609, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0732, val=0.0609, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0731, val=0.0608, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0725, val=0.0606, patience=10/15, lr=0.000008
   • Epoch  21/100: train=0.0719, val=0.0603, patience=7/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0605)

============================================================
📊 Round 23 Summary - Client client_42
   Epochs: 29/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.1469
   Val:   Loss=0.0605, RMSE=0.2459, R²=0.1470
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2335, R²: 0.1255

============================================================
🔄 Round 24 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0692, val=0.0789 (↓), lr=0.000008
   • Epoch   2/100: train=0.0691, val=0.0788, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0690, val=0.0788, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0690, val=0.0788, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0689, val=0.0788, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0686, val=0.0787, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 24 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0692, RMSE=0.2631, R²=0.1345
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.1303
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2347, R²: 0.1202

📊 Round 24 Test Metrics:
   Loss: 0.0752, RMSE: 0.2742, MAE: 0.2360, R²: 0.1141

📊 Round 24 Test Metrics:
   Loss: 0.0755, RMSE: 0.2747, MAE: 0.2366, R²: 0.1108

📊 Round 24 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2370, R²: 0.1090

📊 Round 24 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2375, R²: 0.1068

============================================================
🔄 Round 31 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0742 (↓), lr=0.000002
   • Epoch   2/100: train=0.0722, val=0.0742, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0722, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 31 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1103
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.1359
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2378, R²: 0.1051

============================================================
🔄 Round 34 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 34 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.1152
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.1044
============================================================


============================================================
🔄 Round 35 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 35 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0981
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.1516
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2380, R²: 0.1043

============================================================
🔄 Round 36 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0704, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0704, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0704, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0704, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0703, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0703, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 36 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0704, RMSE=0.2652, R²=0.1160
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.1016
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2380, R²: 0.1039

============================================================
🔄 Round 38 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0606 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0606, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0605, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0605, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0605, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0604, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0606)

============================================================
📊 Round 38 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0982
   Val:   Loss=0.0606, RMSE=0.2461, R²=0.1779
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2381, R²: 0.1038

============================================================
🔄 Round 39 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 39 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1213
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0718
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2380, R²: 0.1038

============================================================
🔄 Round 42 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 42 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.1211
   Val:   Loss=0.0677, RMSE=0.2603, R²=0.0727
============================================================


============================================================
🔄 Round 43 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 43 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.1003
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.1544
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2380, R²: 0.1038

============================================================
🔄 Round 47 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 47 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0968
   Val:   Loss=0.0675, RMSE=0.2599, R²=0.1770
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2380, R²: 0.1039

📊 Round 47 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2380, R²: 0.1040

============================================================
🔄 Round 49 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 49 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.1091
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.1234
============================================================


============================================================
🔄 Round 50 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0631 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0631, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0630, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0630, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0630, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0629, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0631)

============================================================
📊 Round 50 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.1080
   Val:   Loss=0.0631, RMSE=0.2511, R²=0.1162
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2380, R²: 0.1039

============================================================
🔄 Round 51 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 51 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2688, R²=0.1179
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0908
============================================================


============================================================
🔄 Round 52 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 52 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2675, R²=0.1144
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.1075
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2380, R²: 0.1039

============================================================
🔄 Round 55 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0612 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0612, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0612, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0612, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0612, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0612, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0612)

============================================================
📊 Round 55 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.1055
   Val:   Loss=0.0612, RMSE=0.2475, R²=0.1248
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2379, R²: 0.1041

============================================================
🔄 Round 57 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 57 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2682, R²=0.1154
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.1047
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2379, R²: 0.1042

============================================================
🔄 Round 58 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 58 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2712, R²=0.1167
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0855
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2379, R²: 0.1042

============================================================
🔄 Round 59 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0627 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0627, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0627, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0627, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0627, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0626, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0627)

============================================================
📊 Round 59 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0922
   Val:   Loss=0.0627, RMSE=0.2504, R²=0.1851
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2379, R²: 0.1043

📊 Round 59 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2379, R²: 0.1042

============================================================
🔄 Round 63 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 63 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1224
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0648
============================================================


============================================================
🔄 Round 64 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 64 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.1118
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.1184
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.1033

============================================================
🔄 Round 65 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 65 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.1170
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0942
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2382, R²: 0.1031

📊 Round 65 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2382, R²: 0.1029

============================================================
🔄 Round 67 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0618 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0617, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0617, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0617, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0617, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0616, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0618)

============================================================
📊 Round 67 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.1088
   Val:   Loss=0.0618, RMSE=0.2485, R²=0.1304
============================================================


============================================================
🔄 Round 68 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0699, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0698, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0698, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0698, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0698, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0697, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 68 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0699, RMSE=0.2644, R²=0.1157
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.1008
============================================================


============================================================
🔄 Round 70 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0627 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0627, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0626, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0626, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0626, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0626, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0627)

============================================================
📊 Round 70 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.1176
   Val:   Loss=0.0627, RMSE=0.2503, R²=0.0866
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.1032

============================================================
🔄 Round 72 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 72 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.1101
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.1198
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.1034

============================================================
🔄 Round 73 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 73 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.0954
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.1595
============================================================


============================================================
🔄 Round 75 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 75 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1176
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0979
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.1032

============================================================
🔄 Round 78 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 78 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2686, R²=0.1167
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0941
============================================================


============================================================
🔄 Round 79 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 79 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2699, R²=0.1167
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0958
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.1027

============================================================
🔄 Round 83 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 83 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2675, R²=0.1117
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.1075
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2384, R²: 0.1019

============================================================
🔄 Round 84 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 84 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1077
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.1268
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2384, R²: 0.1018

============================================================
🔄 Round 85 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 85 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1202
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0779
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2384, R²: 0.1018

============================================================
🔄 Round 86 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0706, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0706, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0706, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0706, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0706, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0705, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 86 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2662, R²=0.1110
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.1131
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.1020

============================================================
🔄 Round 87 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0699, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0699, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0699, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0699, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0699, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0698, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 87 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0699, RMSE=0.2643, R²=0.1164
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0974
============================================================


============================================================
🔄 Round 89 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 89 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1176
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0945
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2382, R²: 0.1028

📊 Round 89 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.1030

============================================================
🔄 Round 95 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0714, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 95 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1151
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.1082
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.1031

📊 Round 95 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2381, R²: 0.1029

============================================================
🔄 Round 97 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0648 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0648, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0648)

============================================================
📊 Round 97 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.1080
   Val:   Loss=0.0648, RMSE=0.2545, R²=0.1308
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.1027

📊 Round 97 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.1025

============================================================
🔄 Round 101 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 101 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.1228
   Val:   Loss=0.0704, RMSE=0.2652, R²=0.0705
============================================================


============================================================
🔄 Round 102 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 102 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1124
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.1160
============================================================


============================================================
🔄 Round 103 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 103 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2662, R²=0.1141
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.1060
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.1024

📊 Round 103 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.1025

============================================================
🔄 Round 107 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 107 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1231
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0700
============================================================


============================================================
🔄 Round 108 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 108 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1160
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0976
============================================================


============================================================
🔄 Round 110 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 110 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1175
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0953
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.1027

============================================================
🔄 Round 112 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 112 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2686, R²=0.1175
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0972
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.1027

============================================================
🔄 Round 113 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 113 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1235
   Val:   Loss=0.0698, RMSE=0.2643, R²=0.0631
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2382, R²: 0.1025

📊 Round 113 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.1022

============================================================
🔄 Round 117 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 117 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0991
   Val:   Loss=0.0668, RMSE=0.2584, R²=0.1682
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2383, R²: 0.1022

============================================================
🔄 Round 118 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0652, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0652, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0652, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 118 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.1017
   Val:   Loss=0.0652, RMSE=0.2554, R²=0.1470
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2383, R²: 0.1018

============================================================
🔄 Round 121 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 121 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1150
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.1041
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2384, R²: 0.1017

📊 Round 121 Test Metrics:
   Loss: 0.0763, RMSE: 0.2761, MAE: 0.2384, R²: 0.1015

============================================================
🔄 Round 124 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 124 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1090
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.1231
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2385, R²: 0.1013

============================================================
🔄 Round 126 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 126 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.1075
   Val:   Loss=0.0674, RMSE=0.2596, R²=0.1308
============================================================


============================================================
🔄 Round 128 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 128 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.1168
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0869
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2385, R²: 0.1013

📊 Round 128 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2385, R²: 0.1014

============================================================
🔄 Round 130 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0606 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0606, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0606, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0606, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0606, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0605, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0606)

============================================================
📊 Round 130 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.1155
   Val:   Loss=0.0606, RMSE=0.2462, R²=0.0951
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2384, R²: 0.1014

📊 Round 130 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2385, R²: 0.1010

📊 Round 130 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2386, R²: 0.1008

📊 Round 130 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2387, R²: 0.1002

📊 Round 130 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2387, R²: 0.1001

============================================================
🔄 Round 142 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 142 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.1051
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0935
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2387, R²: 0.1000

============================================================
🔄 Round 143 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 143 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1084
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.1198
============================================================


============================================================
🔄 Round 145 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 145 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1051
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.1307
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2387, R²: 0.1001

📊 Round 145 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2387, R²: 0.1002

📊 Round 145 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2387, R²: 0.1002

============================================================
🔄 Round 148 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 148 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.1047
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.1317
============================================================


============================================================
🔄 Round 149 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 149 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2694, R²=0.1215
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0690
============================================================


============================================================
🔄 Round 154 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 154 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.1019
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.1468
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2388, R²: 0.0994

============================================================
🔄 Round 155 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0626 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0626, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0626, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0626, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0626, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0626, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0626)

============================================================
📊 Round 155 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.1107
   Val:   Loss=0.0626, RMSE=0.2502, R²=0.0918
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2389, R²: 0.0993

============================================================
🔄 Round 157 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 157 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2677, R²=0.1128
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.1007
============================================================


============================================================
🔄 Round 161 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 161 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1158
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0796
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2389, R²: 0.0989

📊 Round 161 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2390, R²: 0.0987

============================================================
🔄 Round 163 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 163 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.1112
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.1051
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2390, R²: 0.0986

============================================================
🔄 Round 167 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 167 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2703, R²=0.1083
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.1027
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2390, R²: 0.0986

📊 Round 167 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2390, R²: 0.0987

📊 Round 167 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2389, R²: 0.0990

============================================================
🔄 Round 173 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0627 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0627, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0627, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0627, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0627, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0626, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0627)

============================================================
📊 Round 173 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.1086
   Val:   Loss=0.0627, RMSE=0.2504, R²=0.0950
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2389, R²: 0.0991

📊 Round 173 Test Metrics:
   Loss: 0.0765, RMSE: 0.2765, MAE: 0.2389, R²: 0.0992

============================================================
🔄 Round 176 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 176 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1164
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.0844
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2388, R²: 0.0993

============================================================
🔄 Round 179 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 179 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.1070
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.1271
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2388, R²: 0.0995

============================================================
🔄 Round 183 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 183 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2703, R²=0.1130
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0545
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2387, R²: 0.0997

============================================================
🔄 Round 188 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 188 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1138
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0981
============================================================


============================================================
🔄 Round 189 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 189 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1070
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.1253
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2387, R²: 0.0998

============================================================
🔄 Round 190 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 190 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1118
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.1095
============================================================


============================================================
🔄 Round 193 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 193 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.1151
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0931
============================================================


============================================================
🔄 Round 194 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 194 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1164
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0610
============================================================


============================================================
🔄 Round 195 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 195 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1042
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.1194
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2386, R²: 0.1001

============================================================
🔄 Round 196 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 196 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1108
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0875
============================================================


============================================================
🔄 Round 197 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 197 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.1134
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.1054
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2386, R²: 0.1003

============================================================
🔄 Round 199 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 199 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1092
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.1222
============================================================


============================================================
🔄 Round 200 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 200 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1130
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.1069
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2387, R²: 0.1000

📊 Round 200 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2387, R²: 0.0998

============================================================
🔄 Round 202 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 202 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.1204
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0605
============================================================


============================================================
🔄 Round 203 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 203 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.1168
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0462
============================================================


============================================================
🔄 Round 204 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 204 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2678, R²=0.1103
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.1022
============================================================


============================================================
🔄 Round 205 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 205 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1218
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0636
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2387, R²: 0.0998

============================================================
🔄 Round 206 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 206 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.1059
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.1334
============================================================


============================================================
🔄 Round 207 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 207 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2688, R²=0.1166
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0866
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2388, R²: 0.0995

📊 Round 207 Test Metrics:
   Loss: 0.0764, RMSE: 0.2765, MAE: 0.2388, R²: 0.0993

❌ Client client_42 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
