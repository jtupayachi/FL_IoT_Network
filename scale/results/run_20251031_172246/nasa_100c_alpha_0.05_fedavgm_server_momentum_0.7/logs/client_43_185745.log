[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 624e89c3-716f-4673-9c62-4171d2457208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f99a2ac-302c-4a78-b0ea-dd32b4823a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd41f33-3f55-46ab-b5cb-5cdbb28c1a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6597123-f7e8-4bee-aff8-18fec5d8c9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e5a4ed3-691c-4315-967a-e45a0d0d5741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0609303-9a12-4d47-8b69-739e1cbe1ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c8e868-6860-401c-8c29-303360cb00c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2749b77e-9f72-45db-b1b8-39c34c63e0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35107ab6-818e-45f4-9a39-bd306a98bae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b26386b-81a1-4086-ad9c-0d06df8047af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9218b89-ec9d-4cdd-b95e-08e6ee4692e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ac01fe-bf5d-49e1-a55c-bafff24c9367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d3be0f2-5881-4054-82e1-25550a5f8d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efebb728-578d-46e5-8873-3a32638483b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6791e2-4fcc-486f-ac09-ba885affdb6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce63aec-7bce-4345-b816-b77e4a9f21cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9ffb90-7294-45df-9dae-c90383752912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffeaa4ab-de78-48ed-9d98-2a62e9aaa6f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f9aeab-0cd4-490b-802d-1f06685e7a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de7be041-1f37-4d76-96ff-d05282e85e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d24f17bf-2b10-4512-91e8-3b7b7dc1b0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09bdf613-46c5-4652-9f81-8faebaa0ea5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d53c0f8-9259-49ac-a5e5-2cd276674c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c079ab7-96d9-4548-91f2-aff6a3181b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be0f219-ac99-4b9e-a674-3169e939f9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a861d542-91b1-4fbb-a0ec-9119d9634960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7380e47e-ef2a-4cb5-aae9-1e325caf3e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21386b6-3f6f-4bf3-8fe1-1172306b23a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b211a9-4938-48c1-a8d9-fb710a513fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1617b53-f11c-4553-bac3-37c4bbd4bb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2a08c16-0281-4803-b2d7-88d04a656969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48335f8-ff86-4069-9efd-fda210d52fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 910479fd-3af9-41de-a4ee-07506a076776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b73c5c1-b187-496c-806b-1ea97c4ad5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c656e660-8d17-4f5a-85d1-e211bcf630eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b4a8a6-f866-424c-ae4d-66222f0d9c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8088183e-63fc-4d0d-bf49-8f043e31c5d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b22db7e7-c6c8-4aa3-b09c-f14f936df9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20aa6b82-b07c-450d-bc66-98685cee13e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a646ea1-d8ca-443c-b7f6-767abc94bbc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2478ebc3-fa29-410f-925b-9d303ddef96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d52dfe9-f256-432d-b0db-7b4a47a71842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4720ae-db16-4443-a70c-a82545d74f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ca6bf6-0480-49c9-b6f9-0499853bd9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e407fa5-dd0f-4201-80b1-2a49d37d4c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3a29a5f-4263-4cbd-a930-05d4ae8d4316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eb18128-0407-476c-ba29-a9a310fcc077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 160c1300-0d56-4bad-9499-1bfe7ba46bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad4f5cd4-fd59-48c4-80ca-bc598dc4bec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97fe45ec-cc94-455a-9b61-0c39bedeb590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b0f05a-bde6-4f0f-a196-f49a4596c93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3d1462-0813-4ffd-a456-2597553b5914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feda774c-1b1b-4573-aee7-34338a5a2289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc4d2d29-135c-4092-a876-ffd1134cfd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e64ef0-ce24-46fc-a841-0c9e857e1f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6619f98-d0ac-4ac2-a08b-9760b8422d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9313fe4c-14f8-4a05-b2d6-28f471c140b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2a9b51-a3c4-4e3a-8f7b-ac941eb294f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594d6043-af60-4aa6-97dd-3bb746b2379c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699a6614-d8d6-481f-b64b-8d30c8c8aba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54623cbf-b4ab-4ced-b41f-3b7d0adb03e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5107e117-a83b-4daf-8445-14f7954c5323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8a89d1-9ffa-43dd-b07f-963586976bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2acb870d-9800-435d-a3f4-e5726f9a89e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6527c749-f2b6-4ebf-b532-260e629a864c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e0cdf23-c364-4130-a882-3af52942e6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f863a8fe-d5ce-455b-a4f7-937d69628751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b9497a-20b8-48df-8556-875c663cff88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d694ebe8-af6b-4140-8bd2-ef5c012173aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d090273-6fb3-4a93-8a91-e6381206cfc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cc1b5a-e54a-40e6-ba77-8f0a34616b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e8fd30-9fe4-456e-a5ae-44b1f1165bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6519d226-6721-46c0-9c36-54e0e8f5d9e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd2167e-647e-45c3-85e1-b1f778c843e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07dce44-e1c7-45f7-b885-6455b3ab69ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb230446-27de-4b69-b245-b2e02849925f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 692e2163-c125-4f22-b140-88e0f95885be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d0bf5ae-f8e9-4441-853e-6cf21d71944f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41330dfd-a648-4c24-b348-fa12a05a9b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 262c8301-cae6-47fc-97ed-385af555fde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec4b2fe0-b92f-40c8-b397-6107a1a74707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c230826-618a-45b0-b141-413067a05e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e637e992-48a7-41cc-bcad-8b83c487cf1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1072264a-3f48-4d91-9fde-6b9a7e6444ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a221b16f-e8b9-49cb-8771-68b0a22d1364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fd14c1e-3285-4944-909e-de7a9821574d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 901a6dcc-4252-4dbd-a96e-38a216ddfc7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9dfd329-7c5b-4506-aa94-bc7ec0be9e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c47c08b9-fffc-487a-bebe-d9b0d117fc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 876df068-909e-4c3b-96ce-415816e92eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d77077-aad7-46b6-ac6c-5d57f3fec533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f236ef6-d54a-4687-8a5e-a2010cada11d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af91ac6-37f1-4507-90bf-7fde8ff65b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d3564fb-cf26-4a7c-aaee-52484e4b309b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52dd48de-fc45-4b0c-83e9-7b13ee1a5bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 356b94aa-361f-4dde-b50c-58e2de086bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b1b36f0-24a6-435c-a438-b843e886ac93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a76827c9-b6fb-4e8f-b8d4-e74845fde7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a78f3bcd-28ec-4777-b8bf-f358be9708c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b449ef-922b-4a94-aea3-37d19d61d839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0302438-ed86-4137-bea3-f4e1496ad146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e79cd40-7fa4-488e-b797-64f4b490a67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 910cd2fb-f42b-4d77-b247-77318bc5127d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a79eacb-5f52-437e-8018-2a5d3fb1954e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f5540e0-e47b-484a-93cf-29949139f47b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1076af8-b38f-4654-b90f-9b78d2b38b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a80401-8f9a-4769-9299-2bb2dea0d594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95156be8-11d5-4bd8-a3aa-0f2338b81f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3a19ce-8aa1-45dc-aff7-d663ac77bc49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea9aacb4-867a-4b73-8638-9d22168a1f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444dff1a-c33e-46e9-94e1-42b3afb157d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1699986d-9282-4db5-b7dd-fb0b3ca0a57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84175a53-b5b5-468b-8ba3-c79b6764b918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7c1742-5256-4999-9fb4-ad6bd2c7336c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5004ca0a-ab1a-4523-9eba-b020eda2e225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 219d7836-75ce-4898-936e-93985718f2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59479da4-bb0b-4eff-986e-bd8820aaf47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30165c3-711a-48cb-94d4-0a1b8103859b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a97112-9394-4115-b1b6-01b7b20082bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c65f9355-f8dc-4e52-be75-50748fc78334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a9ac953-4116-43c1-abcb-07c739d74e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24457694-46c1-4727-b0d6-0b90ee5e4b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 894c3a9e-c112-4b51-9719-fa56340d9dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a51217c-188f-4355-9340-bd6087741786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 701339c1-9bb0-4249-938c-fa070f2a874d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8d8ba58-fbd2-4781-b597-70785a05287e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d770b5e-49b4-4ea9-bcf6-3cb69cdf86b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea5f976-bdce-42b1-a98a-783610917983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f013a3bb-a1ce-4fe4-b8c0-192c02aba662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f774b4c-dd8e-420b-b695-3cf78946647d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030f6a4f-3236-4ba8-a49a-249efe79ec3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a84c13-2bb2-41f2-84a9-24c976a68547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1005ce83-17d3-46f7-a0df-a8666bece1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2052aa35-fb88-4d52-95b9-d4b332e9c3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c56259bf-e6cd-4888-bcd6-a88b4edf70c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bace945-10d9-4327-af0e-753fb71ccaa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d2cd0c-e2aa-4693-99a6-299288ce563c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d76a455-a673-4406-a041-9ecbe31ec0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02051c23-2846-4408-94be-fee3b62b770c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51901b84-ec0b-4561-9ebb-75ee81af32d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f08b08-025b-4b41-8880-7f12c6fbed8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e536134-5930-4d09-92b5-c7aefb1ad8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb553251-bfc9-4593-a5fa-8b095f5eb5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f91c72-845d-4632-9864-f7149cf94eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c582e0d-7c19-454a-b376-25e16a8956f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b13fba1d-5a55-43a3-8c43-67eec6fa67e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a4166e-9087-4ea8-9bc5-2f9971858d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce06d626-7c72-450d-b935-a44b984ee4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8815d028-e4bf-4684-a11d-5862ee58d270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8580587c-9856-44d6-aab1-70954124c234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b929f617-45c8-495e-bdc9-b5c1969c15de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe695a97-72f7-430e-a322-3ecf4955a5dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 673986ac-f92e-44ca-8c49-b86afea42b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d0a0e8-fc9b-4539-a2fa-4a78e27b84fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e09832-7fe6-45e7-8042-e3bd7b36da58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb07c03a-b4b1-4577-8c5f-b28041c42d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da89b6bb-b454-4450-b061-f5e22b1b12a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a950683b-dfc8-41c8-8ed6-df78e22db2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03aa344c-d631-43c5-8be9-0798dc1720bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5fdc90-4c8a-4864-8af2-fbe428e0aecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 721fd027-8a49-492c-bff9-3390377ea18b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615a7de6-f549-491c-9a31-974684e51983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847c0aee-baee-4613-8021-26a209cf3ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20e2cddc-a017-43c9-be53-97a4c0e4fc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a4e0e5-98e9-470d-84af-4c21b232502f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2ba11e-8ee8-402c-8786-74b658eaa5b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bb67898-56ae-4e31-9ec4-c8d4287e65a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8076301e-054a-484a-b1f7-a47dcd86d149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d018d901-0771-4d00-acc5-98921b05eed0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0bff47-034d-4264-beb9-01d71595b409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56eefbe1-79f5-42e3-828d-9406cd5df33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 569ea6ad-a7d1-4a00-bf10-2df1fe9cb550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f01a744c-b5da-4d16-9844-6405fb8386ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c5030d-bc29-4853-aaf4-8257bfa98e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a0b795-e41e-4498-9958-bc6760f60e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b767c0b-c32e-4c6b-bd34-e1f379da8019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29d5f384-80a8-4b6b-bb20-244191968b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce4367f5-3cbc-46e5-a068-102b0d619833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d68c66c-df7d-433b-add2-dcae2933ab76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c9f3ed-24ee-44dc-ab65-b6253a48205f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f686f2b5-e366-4899-a49b-602feb796ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f653582-87ef-4a68-a22f-9dd112d083f5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_43
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/test_labels.txt

📊 Raw data loaded:
   Train: X=(877, 24), y=(877,)
   Test:  X=(220, 24), y=(220,)

⚠️  Limiting training data: 877 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  211 samples, 5 features
✅ Client client_43 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 11 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0829 (↓), lr=0.001000
   • Epoch   2/100: train=0.0815, val=0.0829, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0810, val=0.0829, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0804, val=0.0830, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0797, val=0.0833, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0712, val=0.0956, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 11 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0055
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0052
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0878, RMSE: 0.2962, MAE: 0.2508, R²: -0.0268

📊 Round 11 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2517, R²: -0.0336

============================================================
🔄 Round 13 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0818 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0823, val=0.0812 (↓), lr=0.000500
   • Epoch   3/100: train=0.0821, val=0.0812, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0818, val=0.0812, patience=2/15, lr=0.000500
   • Epoch   5/100: train=0.0816, val=0.0811, patience=3/15, lr=0.000500
   • Epoch  11/100: train=0.0801, val=0.0812, patience=9/15, lr=0.000500
   📉 Epoch 13: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 13 Summary - Client client_43
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0102
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0324
============================================================


============================================================
🔄 Round 14 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0713 (↓), lr=0.000250
   • Epoch   2/100: train=0.0846, val=0.0715, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0841, val=0.0718, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0837, val=0.0721, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0834, val=0.0722, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0823, val=0.0727, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 14 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0035
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0150
============================================================


============================================================
🔄 Round 15 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0871 (↓), lr=0.000063
   • Epoch   2/100: train=0.0814, val=0.0869, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0812, val=0.0867, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0811, val=0.0866, patience=3/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0810, val=0.0865 (↓), lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0805, val=0.0863, patience=6/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 15 Summary - Client client_43
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0099
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0150
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2498, R²: 0.0054

============================================================
🔄 Round 18 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0823 (↓), lr=0.000016
   • Epoch   2/100: train=0.0832, val=0.0823, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0831, val=0.0822, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0830, val=0.0822, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0829, val=0.0822, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0826, val=0.0821, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 18 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0093
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0004
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2525, R²: -0.0160

============================================================
🔄 Round 22 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0840 (↓), lr=0.000004
   • Epoch   2/100: train=0.0824, val=0.0839, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0823, val=0.0839, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0823, val=0.0839, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0823, val=0.0839, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0822, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 22 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0104
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0218
============================================================


============================================================
🔄 Round 24 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 24 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0009
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0065
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2523, R²: -0.0073

📊 Round 24 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2528, R²: -0.0105

📊 Round 24 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2529, R²: -0.0109

============================================================
🔄 Round 28 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 28 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0029
   Val:   Loss=0.0700, RMSE=0.2645, R²=-0.0129
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2529, R²: -0.0111

📊 Round 28 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2529, R²: -0.0113

============================================================
🔄 Round 31 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 31 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0016
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0280
============================================================


============================================================
🔄 Round 33 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 33 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0137
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0211
============================================================


============================================================
🔄 Round 34 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 34 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0029
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0072
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2529, R²: -0.0112

📊 Round 34 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2529, R²: -0.0112

📊 Round 34 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2529, R²: -0.0111

📊 Round 34 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2529, R²: -0.0110

📊 Round 34 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2529, R²: -0.0107

============================================================
🔄 Round 40 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 40 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0008
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0297
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2529, R²: -0.0106

============================================================
🔄 Round 41 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 41 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0122
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0309
============================================================


============================================================
🔄 Round 42 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 42 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0000
   Val:   Loss=0.0707, RMSE=0.2660, R²=-0.0223
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2529, R²: -0.0102

📊 Round 42 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2528, R²: -0.0099

============================================================
🔄 Round 49 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 49 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0001
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0150
============================================================


============================================================
🔄 Round 51 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 51 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0105
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0042
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2528, R²: -0.0093

============================================================
🔄 Round 53 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 53 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0039
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0011
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2528, R²: -0.0091

📊 Round 53 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2528, R²: -0.0090

📊 Round 53 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2528, R²: -0.0089

📊 Round 53 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2528, R²: -0.0088

============================================================
🔄 Round 58 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 58 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0015
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0265
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2527, R²: -0.0087

============================================================
🔄 Round 59 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 59 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0004
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0138
============================================================


============================================================
🔄 Round 60 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 60 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0021
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0241
============================================================


============================================================
🔄 Round 61 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 61 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0066
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0106
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2527, R²: -0.0086

============================================================
🔄 Round 63 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 63 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0050
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0072
============================================================


============================================================
🔄 Round 64 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 64 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0115
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0319
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2527, R²: -0.0086

📊 Round 64 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2527, R²: -0.0086

📊 Round 64 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2527, R²: -0.0084

============================================================
🔄 Round 71 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 71 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0045
   Val:   Loss=0.0749, RMSE=0.2738, R²=0.0057
============================================================


============================================================
🔄 Round 72 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 72 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0022
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0248
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2527, R²: -0.0077

============================================================
🔄 Round 73 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 73 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0044
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0008
============================================================


============================================================
🔄 Round 74 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 74 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0032
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0034
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2527, R²: -0.0074

============================================================
🔄 Round 76 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 76 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0045
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0314
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2527, R²: -0.0074

============================================================
🔄 Round 79 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 79 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0018
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0030
============================================================


============================================================
🔄 Round 80 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 80 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0013
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0045
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2527, R²: -0.0073

============================================================
🔄 Round 81 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 81 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0049
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0102
============================================================


============================================================
🔄 Round 82 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 82 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0036
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0069
============================================================


============================================================
🔄 Round 83 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 83 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0026
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0203
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2527, R²: -0.0074

============================================================
🔄 Round 84 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 84 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0023
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0078
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2527, R²: -0.0074

============================================================
🔄 Round 85 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 85 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0042
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0074
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2527, R²: -0.0073

============================================================
🔄 Round 86 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 86 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0017
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0026
============================================================


============================================================
🔄 Round 87 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 87 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0028
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0021
============================================================


============================================================
🔄 Round 89 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 89 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0017
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0145
============================================================


============================================================
🔄 Round 90 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 90 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0043
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0096
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0860, RMSE: 0.2933, MAE: 0.2526, R²: -0.0064

============================================================
🔄 Round 91 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 91 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0080
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0187
============================================================


============================================================
🔄 Round 93 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 93 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0019
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0023
============================================================


============================================================
🔄 Round 94 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 94 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0028
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0235
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2525, R²: -0.0057

📊 Round 94 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2525, R²: -0.0057

============================================================
🔄 Round 97 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 97 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0014
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0117
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2525, R²: -0.0057

📊 Round 97 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2525, R²: -0.0056

============================================================
🔄 Round 100 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 100 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0038
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0076
============================================================


============================================================
🔄 Round 102 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 102 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0055
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0076
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2525, R²: -0.0055

============================================================
🔄 Round 103 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 103 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0005
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0168
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2525, R²: -0.0054

📊 Round 103 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2525, R²: -0.0052

============================================================
🔄 Round 107 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 107 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0027
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0237
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2524, R²: -0.0051

============================================================
🔄 Round 108 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 108 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0022
   Val:   Loss=0.0915, RMSE=0.3024, R²=0.0040
============================================================


============================================================
🔄 Round 109 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 109 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0055
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0172
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2524, R²: -0.0049

============================================================
🔄 Round 111 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 111 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0022
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0296
============================================================


============================================================
🔄 Round 112 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 112 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0027
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0149
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2524, R²: -0.0049

📊 Round 112 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2524, R²: -0.0050

============================================================
🔄 Round 116 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 116 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0054
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0166
============================================================


============================================================
🔄 Round 117 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 117 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0042
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0135
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2524, R²: -0.0050

============================================================
🔄 Round 118 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 118 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0054
   Val:   Loss=0.0871, RMSE=0.2950, R²=0.0092
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2524, R²: -0.0050

============================================================
🔄 Round 120 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 120 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0039
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0229
============================================================


============================================================
🔄 Round 122 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 122 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0059
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0309
============================================================


============================================================
🔄 Round 123 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 123 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0025
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0127
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2524, R²: -0.0050

============================================================
🔄 Round 127 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 127 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0007
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0006
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0859, RMSE: 0.2931, MAE: 0.2524, R²: -0.0049

============================================================
🔄 Round 128 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 128 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0015
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0023
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0048

============================================================
🔄 Round 130 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 130 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0018
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0443
============================================================


============================================================
🔄 Round 131 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 131 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0017
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0093
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0047

============================================================
🔄 Round 135 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 135 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0010
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0086
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0047

📊 Round 135 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0047

📊 Round 135 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0048

============================================================
🔄 Round 138 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 138 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0041
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0197
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0047

📊 Round 138 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0047

============================================================
🔄 Round 140 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 140 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0029
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0163
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0047

============================================================
🔄 Round 141 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 141 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0020
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0020
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0859, RMSE: 0.2930, MAE: 0.2524, R²: -0.0046

============================================================
🔄 Round 142 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 142 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0037
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0187
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2524, R²: -0.0045

============================================================
🔄 Round 144 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 144 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0051
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0245
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0858, RMSE: 0.2930, MAE: 0.2524, R²: -0.0044

============================================================
🔄 Round 145 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 145 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0010
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0079
============================================================


============================================================
🔄 Round 147 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 147 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0031
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0066
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0042

============================================================
🔄 Round 149 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 149 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0036
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0325
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0041

============================================================
🔄 Round 152 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 152 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0047
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0022
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0040

📊 Round 152 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0039

============================================================
🔄 Round 155 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 155 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0018
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0060
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0039

============================================================
🔄 Round 158 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 158 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0003
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0008
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0038

============================================================
🔄 Round 160 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 160 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0031
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0230
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0038

============================================================
🔄 Round 162 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 162 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0013
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0062
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0038

📊 Round 162 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0037

📊 Round 162 Test Metrics:
   Loss: 0.0858, RMSE: 0.2929, MAE: 0.2523, R²: -0.0036

============================================================
🔄 Round 168 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 168 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0003
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0011
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0858, RMSE: 0.2928, MAE: 0.2523, R²: -0.0035

📊 Round 168 Test Metrics:
   Loss: 0.0858, RMSE: 0.2928, MAE: 0.2523, R²: -0.0034

📊 Round 168 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2523, R²: -0.0034

============================================================
🔄 Round 171 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 171 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0037
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0377
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2523, R²: -0.0033

📊 Round 171 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2523, R²: -0.0032

============================================================
🔄 Round 173 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 173 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0038
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0149
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2523, R²: -0.0031

📊 Round 173 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2523, R²: -0.0031

============================================================
🔄 Round 177 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 177 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0050
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0389
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0857, RMSE: 0.2928, MAE: 0.2522, R²: -0.0029

============================================================
🔄 Round 179 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 179 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0033
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0225
============================================================


============================================================
🔄 Round 182 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 182 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0020
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0092
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2522, R²: -0.0027

============================================================
🔄 Round 183 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 183 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0028
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0141
============================================================


============================================================
🔄 Round 184 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 184 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0053
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0223
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2522, R²: -0.0025

============================================================
🔄 Round 186 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 186 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0032
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0089
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2522, R²: -0.0024

============================================================
🔄 Round 188 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 188 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0055
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0215
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0857, RMSE: 0.2927, MAE: 0.2522, R²: -0.0023

📊 Round 188 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2522, R²: -0.0022

📊 Round 188 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2521, R²: -0.0021

📊 Round 188 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2521, R²: -0.0020

============================================================
🔄 Round 195 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 195 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0018
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0020
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2521, R²: -0.0020

============================================================
🔄 Round 196 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 196 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0040
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0174
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2521, R²: -0.0018

============================================================
🔄 Round 200 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 200 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0053
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0223
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2521, R²: -0.0019

============================================================
🔄 Round 203 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 203 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0006
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0059
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2521, R²: -0.0019

============================================================
🔄 Round 208 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 208 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0058
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0190
============================================================


============================================================
🔄 Round 209 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 209 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0021
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0072
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2521, R²: -0.0018

❌ Client client_43 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
