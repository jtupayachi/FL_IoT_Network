[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e8510c-d690-40f0-ba14-985253d5ceb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae4ee58-c7a4-44cc-b226-2b29fefb7a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e7f8c4-50a0-4f92-9dba-64aedc5a3478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c1707d-5d29-42b1-b2f9-088a03c4e0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00a75e9c-3217-40dd-8220-485b8e059801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0638e0b5-903a-403f-81b2-6523955f9585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa59935c-962c-40e6-a91f-03925fe0cb19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a91a81e-e271-4a35-8165-c9a93f3a807e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd1ed120-a136-4de9-bf55-7e01411100eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c74bc9b-229e-4985-8d30-019fbf3c395d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e5e864-2764-402f-b655-5ef156f0751e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 573915f6-64b2-4f62-b96b-e1fde775b278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8edbf1ee-68de-4996-a8b1-1482dd6438f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 310a9e43-8cca-4e8a-b58c-99110af9f425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81502b96-35f1-467b-8fbb-ab13cf2a6ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b53cc8ce-e790-48b9-9082-abbeb02de955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff22994c-f12e-492e-afe9-a4bca3b3a861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c5cd5e8-1297-4c0b-9551-8a663b13dd96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec0fe68-d2ae-466b-95c8-8c4b5a345cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b93a3ce-e7ba-4159-a10e-90764f998eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25487675-12a8-4031-afe0-30de1c6f9cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6897177c-e914-4b63-baa0-a58fce240648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message effbd239-0c55-4dbf-b244-dd6e144bc44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7ba3b8-022d-4816-b834-7cf0050d2cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4578859-d707-46a8-ae84-3904e309fd67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c680f210-7cba-4601-9892-84176fa99db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f38a74-ae7d-4b28-982a-6c0f3932979e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d454f64-1ea4-41b3-bb24-ab65a4068b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0327c67-ccad-4405-89ff-93f06c7e6fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524e041e-b53b-42e2-9a46-a1245e29c481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 185a2b00-f9b7-431e-b1e8-fed915bcb5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b879f3-89e1-4a45-91b3-a85def25f206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 339c7d96-bfbc-4087-8011-618c558cc080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c11ce05-874a-45ce-adc1-e48ebc59021e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9627e6a8-ac3d-45c9-80c0-7ae967e20bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa88ecf0-f87b-4bcb-a229-7b8c72a1b1a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa56b397-43ad-49d3-be35-1debd0622c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a86bcdd-7858-47a3-9487-516709524527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae3c161-9a71-4ec2-a276-af434bdb8acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1450b2c6-e07b-4e50-905d-25cb9b5a9cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78827f3c-a86e-4ed7-a08f-b4b59fadec57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ad31b18-dbb0-4011-a014-15393ecec109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 627b8621-7764-4f36-9773-e4074067db84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e948847e-03cb-4ab8-9e5c-b10ddb654824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae74f61e-47ea-4637-a0cc-1548ea997f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62ea4291-77f0-4487-94d4-cb49944fd02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da582b7d-d6fa-4269-8c61-a1982f01012a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba24e669-e7d4-4d2c-ae98-3e0dfa588ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222ed651-8dcf-42ca-b5fa-6bc5150fd805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32217b4a-7bbf-4735-b3fd-3861ffd6c760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9312756-1306-41d5-a0b6-35eca9d94950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b360e2-e846-4e9d-a693-55e812fef2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d7096a-d62a-46fa-a5e1-78b907d30542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ec095f1-9c27-4765-9bf5-01b1f97e8b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc223d61-05fc-4754-9408-f483b587bb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c89e9fe-21d9-4342-b044-e3d706e8476f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 719bbdb3-63f2-4adb-8bf2-ffb5d63c2c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c727455d-cc90-428f-896a-62c1056d0393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f120fae5-57f3-4785-94e2-26577679ad07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a29522ad-49f1-46fc-b656-b4d06e842907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cbda9cd-3c02-4ead-8e1c-0d3f8a74b839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0aa6f81-6f05-4640-bc2a-232a966fbc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01c3abf-7853-4fdd-9ada-cd68fe2cf7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6269d822-bab6-487c-a2f6-9f5129018df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a295a680-bf6f-4add-90f7-089deb37d8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e53c34da-1794-4173-9b4b-a69ad146a072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f660221-7163-49f1-885b-92d05df63eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cdb4bf-f042-4576-bbec-b07c1c95f1f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6a3460-00de-42f4-9329-d0e2ee977f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbde6295-3d44-4d5d-b605-3a7344801415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e5368f-b954-453b-8479-3777911788e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b403592-4c21-4b42-a478-57ec9913a764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce0e7aff-dc3a-491b-ae44-e809f0ef8156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5554d11d-6b33-4acc-b0ba-9bb0a4144bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 682c865c-64d1-43ca-953a-9c92f5a0173b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f2922cf-4b1f-47a5-bc9d-ed2760c0a54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0b27eb1-a86c-4c12-8439-d84112ed03fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff773da3-93a9-45ee-bc97-5249e59108b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a87679fe-1037-4d32-a5d5-9c63f0525c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db9598c-5974-437f-af47-efe8dcb108a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daacfdcf-92cb-48e2-a7e1-421d5b3927cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc9fa39-fd83-4b59-9bd2-6a0cd6608a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fbe8300-0f30-425e-a50c-1a98e7dde2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bf1218d-f8cd-4fed-a05c-2389e5f6d2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91fc20e7-6033-4216-92f1-7131e5bc14b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d9e5b7a-b5a5-4352-9bdd-68bd0b36c29a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38634f32-09f1-4bee-ad5f-083fa3bf6185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e378d2c3-14b0-4033-9c10-a395276d0771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc64bfd7-be30-4a0b-bd54-b6b870ad4294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c09d2c1-78d9-412b-b00e-057686021299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e90ae3b-359c-4c35-b71a-7a27f50a2243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b489d1-a15d-49d1-b11f-73e410576af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86fac9b8-120f-43b8-b3d8-d316b48f6296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c32a4af-dddb-4285-86fe-852960f40936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e539905f-0bcf-41e3-8690-1fcb6bd98924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19210b4a-3f4f-4523-8e1a-7124cda42090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59a5cb8-4fdc-4d0b-b8a8-c0c31b3a8ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a61211f-3851-44db-a731-5dcbb6ab1180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5ecc4c9-6f65-4f4d-bdde-cb7e2791e8d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e065e8-b85d-4d5b-9c4c-5be463d7182c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0027ce1f-0e52-43d5-ab0d-a50dd869f179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a00420a-960c-4981-a312-694cd88aa95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f4b7c3-008b-435b-aa7b-4033332570cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b24645-cd49-410d-bee8-88a64ae58c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3263cace-2927-42a4-a030-db08c8e14a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a326da6-0398-4950-96a8-6a9e5a315587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d8fe76c-4eaf-4b83-8b5e-62ab6f358a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86fdf2fe-40c3-465b-9613-c846e0bcb679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d0d5787-c04a-4522-9b40-760bc27a9dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 463ddb46-d626-437b-9166-7fd40b757803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d74e990-9adb-4f8b-adaa-32c132f7d513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf884b35-9152-4c02-8df7-9a0095943a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc71375-4686-461e-833b-984aad308667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a89a7d25-3334-42a7-9e7d-064b8500d20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0af004-9493-4760-8318-c3e7b2ef11d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feed3c84-1184-4fb1-b2b7-14ed5647198d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d08d3e-3676-4367-9c93-997929a8aec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c17fb7-14a5-46b1-b0d7-6a09bb886d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51a4fe1-0a30-4ee7-8ff7-017eafa66e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5aa755d-84de-440b-a99c-36d60f91c1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc5c018-644c-41bd-86d3-11b69a3f0297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca9e0a67-aafa-4d21-8d27-bd829d940362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc13786a-f8dc-4033-b634-d6aae06e7816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a5141e4-3a25-4e89-8cea-f2a45dfe0cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5af9a986-b707-4b29-97fe-87b024778407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64edf664-673c-4625-b842-ef82f1985348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8d63712-a6a6-4295-8113-974c2d8f33e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54035b4c-224e-4203-bf5d-6090c199cb92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fc53f7-e28b-4817-baa7-43368d073ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07710ce0-e2de-4035-aaf2-b3701fc30964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5189ca7c-37ed-4a71-9f65-1f7e165d881e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bcbb4af-9e3c-43b7-85f9-fdca22a9ab46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc9adf1-f760-48c0-ae82-7c388e6481b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10c7f7f-cdc6-4935-adf1-a180fbce610d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9786fc3a-46e5-4a88-8ec3-7d2b785b2bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0899684b-2a10-4eab-b47b-09bad83bb578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ad030f6-ab9f-4d37-858e-3948cc324be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfaa8bb-6d0e-425d-a601-d3109a5208ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e46a1a9-cbe4-4d19-938e-35e5e5ebcff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e54e4e62-dedf-46c9-a866-b09006fcda40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586df986-ef0a-439d-ad6c-3916824d64e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f6eabb-299a-4440-89d3-72e151538747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f29694-f944-43ff-ae6b-ee0a92d7b303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b98c89a-29d5-4cf6-89d3-9597a7fb5c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2640b689-b5a8-4652-96c1-e3e1c42cd642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f87c23-3596-49bf-b265-66150aa9273a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb6117e6-5ef8-415e-8633-a9d33e62142b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd318139-7168-4522-96a0-15c13d121788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cee9b168-3b17-4737-9135-5081c0ef5fd2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_44
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/test_labels.txt

📊 Raw data loaded:
   Train: X=(1072, 24), y=(1072,)
   Test:  X=(268, 24), y=(268,)

⚠️  Limiting training data: 1072 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  259 samples, 5 features
✅ Client client_44 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0882, RMSE: 0.2970, MAE: 0.2557, R²: -0.0427

============================================================
🔄 Round 12 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0795 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0768, val=0.0787 (↓), lr=0.001000
   • Epoch   3/100: train=0.0749, val=0.0783, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0730, val=0.0778 (↓), lr=0.001000
   • Epoch   5/100: train=0.0711, val=0.0781, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0622, val=0.0786, patience=3/15, lr=0.001000
   📉 Epoch 14: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0522, val=0.0883, patience=13/15, lr=0.000500
   📉 Epoch 22: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 12 Summary - Client client_44
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0640, RMSE=0.2531, R²=0.2168
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0710
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2438, R²: 0.0116

📊 Round 12 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2423, R²: 0.0269

📊 Round 12 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2416, R²: 0.0343

============================================================
🔄 Round 18 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0765 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0734, val=0.0757 (↓), lr=0.000250
   • Epoch   3/100: train=0.0724, val=0.0753, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0714, val=0.0751 (↓), lr=0.000250
   • Epoch   5/100: train=0.0704, val=0.0751, patience=1/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0670, val=0.0761, patience=7/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 18 Summary - Client client_44
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0707, RMSE=0.2660, R²=0.1202
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.1593
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2419, R²: 0.0344

============================================================
🔄 Round 20 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0784 (↓), lr=0.000063
   • Epoch   2/100: train=0.0737, val=0.0780, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0734, val=0.0778 (↓), lr=0.000063
   • Epoch   4/100: train=0.0732, val=0.0776, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0729, val=0.0773, patience=2/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0720, val=0.0764, patience=1/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0710, val=0.0753, patience=2/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0707, val=0.0750, patience=12/15, lr=0.000008
   • Epoch  41/100: train=0.0705, val=0.0747, patience=7/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 20 Summary - Client client_44
   Epochs: 49/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0705, RMSE=0.2655, R²=0.1292
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.1390
============================================================


============================================================
🔄 Round 22 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0708 (↓), lr=0.000008
   • Epoch   2/100: train=0.0750, val=0.0707, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0750, val=0.0707, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0749, val=0.0707, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0749, val=0.0707, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0745, val=0.0707, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 22 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.1011
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.0872
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2392, R²: 0.0548

📊 Round 22 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2392, R²: 0.0612

============================================================
🔄 Round 30 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0777 (↓), lr=0.000008
   • Epoch   2/100: train=0.0748, val=0.0777, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0747, val=0.0777, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0747, val=0.0777, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0746, val=0.0776, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0744, val=0.0776, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 30 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0848
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0811
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2396, R²: 0.0596

📊 Round 30 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2397, R²: 0.0590

============================================================
🔄 Round 35 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0708 (↓), lr=0.000002
   • Epoch   2/100: train=0.0767, val=0.0708, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0767, val=0.0708, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0766, val=0.0708, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0766, val=0.0708, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0766, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 35 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0793
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0785
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2398, R²: 0.0589

============================================================
🔄 Round 36 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 36 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0719
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.1034
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2399, R²: 0.0587

============================================================
🔄 Round 39 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 39 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0765
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0983
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2399, R²: 0.0587

============================================================
🔄 Round 40 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 40 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0887
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0256
============================================================


============================================================
🔄 Round 41 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 41 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0827
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0717
============================================================


============================================================
🔄 Round 46 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 46 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0814
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0788
============================================================


============================================================
🔄 Round 50 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 50 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0794
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0867
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2398, R²: 0.0590

============================================================
🔄 Round 51 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 51 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2712, R²=0.0841
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0557
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2398, R²: 0.0590

============================================================
🔄 Round 52 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 52 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0756
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0919
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2398, R²: 0.0591

============================================================
🔄 Round 53 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 53 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0845
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0671
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0591

============================================================
🔄 Round 54 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 54 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.0926
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0276
============================================================


============================================================
🔄 Round 56 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 56 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0785
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0864
============================================================


============================================================
🔄 Round 59 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 59 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2741, R²=0.0865
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0405
============================================================


============================================================
🔄 Round 60 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 60 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.0803
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0810
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2397, R²: 0.0594

📊 Round 60 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0593

============================================================
🔄 Round 63 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 63 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2703, R²=0.0900
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0437
============================================================


============================================================
🔄 Round 64 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 64 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0816
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0762
============================================================


============================================================
🔄 Round 66 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 66 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0874
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0493
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0591

============================================================
🔄 Round 67 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 67 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0794
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0780
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0591

============================================================
🔄 Round 69 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 69 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0894
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0456
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0592

📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0592

============================================================
🔄 Round 72 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 72 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0886
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0469
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0593

============================================================
🔄 Round 73 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 73 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0766
   Val:   Loss=0.0708, RMSE=0.2662, R²=0.0993
============================================================


============================================================
🔄 Round 78 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 78 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0853
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0625
============================================================


============================================================
🔄 Round 79 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 79 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0869
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0424
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2399, R²: 0.0591

============================================================
🔄 Round 83 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 83 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0821
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0604
============================================================


============================================================
🔄 Round 85 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 85 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0772
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0880
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0593

📊 Round 85 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0593

📊 Round 85 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0594

📊 Round 85 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0595

============================================================
🔄 Round 92 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 92 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0812
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0780
============================================================


============================================================
🔄 Round 94 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 94 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0757
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.1001
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2397, R²: 0.0596

============================================================
🔄 Round 97 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 97 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0792
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0853
============================================================


============================================================
🔄 Round 98 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 98 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0688
   Val:   Loss=0.0688, RMSE=0.2624, R²=0.1270
============================================================


============================================================
🔄 Round 100 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 100 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0784
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0857
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0595

📊 Round 100 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0595

============================================================
🔄 Round 105 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 105 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0804
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0799
============================================================


============================================================
🔄 Round 107 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 107 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0877
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0474
============================================================


============================================================
🔄 Round 108 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 108 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.0834
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0662
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0596

============================================================
🔄 Round 111 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 111 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0848
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0493
============================================================


============================================================
🔄 Round 112 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 112 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0833
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0643
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0596

📊 Round 112 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0596

============================================================
🔄 Round 114 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 114 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0845
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0526
============================================================


============================================================
🔄 Round 115 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 115 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0831
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0703
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0595

📊 Round 115 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0595

============================================================
🔄 Round 117 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 117 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0862
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0496
============================================================


============================================================
🔄 Round 118 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 118 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0746
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.1068
============================================================


============================================================
🔄 Round 120 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 120 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0726
   Val:   Loss=0.0701, RMSE=0.2649, R²=0.0971
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2398, R²: 0.0594

📊 Round 120 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0594

📊 Round 120 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0593

============================================================
🔄 Round 126 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 126 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0760
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0980
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0594

============================================================
🔄 Round 129 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 129 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0728
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0947
============================================================


============================================================
🔄 Round 131 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 131 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0829
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0684
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0594

============================================================
🔄 Round 132 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 132 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0799
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0711
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0594

============================================================
🔄 Round 133 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 133 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0783
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0891
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0593

============================================================
🔄 Round 135 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 135 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0862
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0560
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0592

============================================================
🔄 Round 136 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 136 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0804
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0782
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0592

📊 Round 136 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0590

============================================================
🔄 Round 140 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 140 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0933
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0263
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0590

📊 Round 140 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0590

📊 Round 140 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0591

============================================================
🔄 Round 146 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 146 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0891
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0445
============================================================


============================================================
🔄 Round 148 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 148 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0787
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0864
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0591

============================================================
🔄 Round 151 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 151 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0844
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0526
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0590

============================================================
🔄 Round 153 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 153 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0727
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.1076
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0590

📊 Round 153 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0590

============================================================
🔄 Round 158 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 158 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0934
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0166
============================================================


============================================================
🔄 Round 159 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 159 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0915
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0321
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2401, R²: 0.0589

📊 Round 159 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2401, R²: 0.0589

📊 Round 159 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2401, R²: 0.0589

📊 Round 159 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2401, R²: 0.0588

============================================================
🔄 Round 163 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 163 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0866
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0449
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2401, R²: 0.0587

============================================================
🔄 Round 165 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 165 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0769
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0890
============================================================


============================================================
🔄 Round 167 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 167 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0789
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0792
============================================================


============================================================
🔄 Round 169 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 169 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0778
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0849
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2401, R²: 0.0589

📊 Round 169 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2401, R²: 0.0589

📊 Round 169 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0590

📊 Round 169 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2400, R²: 0.0591

============================================================
🔄 Round 177 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 177 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0804
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0743
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2400, R²: 0.0591

============================================================
🔄 Round 178 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 178 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0871
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0489
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2400, R²: 0.0592

📊 Round 178 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2400, R²: 0.0593

============================================================
🔄 Round 184 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 184 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.0921
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0314
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2400, R²: 0.0593

📊 Round 184 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2400, R²: 0.0593

📊 Round 184 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0594

============================================================
🔄 Round 191 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 191 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0917
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0308
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0594

============================================================
🔄 Round 193 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 193 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0887
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0421
============================================================


============================================================
🔄 Round 197 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 197 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0829
   Val:   Loss=0.0671, RMSE=0.2591, R²=0.0680
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0596

============================================================
🔄 Round 198 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 198 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0644
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.1317
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2399, R²: 0.0596

📊 Round 198 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2400, R²: 0.0593

============================================================
🔄 Round 204 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 204 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0812
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0758
============================================================


============================================================
🔄 Round 205 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 205 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0752
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0974
============================================================


============================================================
🔄 Round 206 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 206 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0756
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0942
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2400, R²: 0.0593

============================================================
🔄 Round 207 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 207 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0796
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0754
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2400, R²: 0.0592

============================================================
🔄 Round 211 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0656 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0656, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0656, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0656, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0655, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0656)

============================================================
📊 Round 211 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0803
   Val:   Loss=0.0656, RMSE=0.2561, R²=0.0712
============================================================


❌ Client client_44 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
