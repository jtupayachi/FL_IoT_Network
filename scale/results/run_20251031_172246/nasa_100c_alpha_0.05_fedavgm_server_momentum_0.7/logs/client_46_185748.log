[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 729af34b-2d9c-4b05-b022-3e25e98eeb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d2195a-1668-4e9e-bde3-82e337a88460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af816a70-edeb-4093-8de9-b0f1fd392de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a01f0fd-426f-4da8-b472-57587686876c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91b63ae2-5790-4899-8b1b-c3b6a6ad22e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c2914c-d63c-4afe-91f4-b79ebc5c6819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419d18e9-1a11-4825-b500-b644814f33e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2d8453-5b67-473d-a0c6-f775762c12d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81331a91-a96c-4202-8ee1-55a0b7449217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 555a71d3-54a6-4a6e-a776-a54725144d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00358ef3-9d6c-427c-82bd-cd048308f3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee3889f-e9c6-4567-b177-365830c6bb49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 907ff02c-1e77-4840-b80f-1154891cc066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987879c1-e734-45a6-a064-28c224df0b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aed9cc6-9b66-4546-b86c-a5e06808b81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 780389d2-2a5c-43c7-94a6-9a2f3d868dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac1d5c7-79d1-4912-8e5b-64b7c1d2750b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236fccb0-9346-44c8-b1fa-508277e3124b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 877ce6da-83aa-41a1-a334-9bb0ebc0e38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f91326-40e7-4341-bbc2-2e9162e29488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d254a31-9251-4b91-a920-f48a1152fea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f87f85-8498-4993-97d0-3a9c9b1accae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b9833f-ff12-4ef5-a4f4-cc9c54928a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd446a6-3f52-4476-a6fc-7986bc61c519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4515a601-2d53-41ac-b1dd-dbe8c6fe21be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e672b9-df18-4ade-a735-eb2624dbd867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab86d63-2dad-4857-aa99-66c924967ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fefa90da-e124-4521-ba57-ab8071078e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d0f6b0f-cd7f-41f1-a2d8-9c7c4cd991aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 860e1338-5fe9-4675-9bb6-ff4a134cbec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc993f7-2582-4a79-8ab4-62339065e6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c830fe-c5e1-4443-a452-e77eeeeb365a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70bef2ef-2e29-4e18-a8a4-e0ab3c17f23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c0b924-40e8-4124-96b7-d7b26e5293e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e70444-0976-41c3-843b-c165e1ac01cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f75f1c3-851c-4321-8730-9d36954365ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34064991-801f-4fb2-ba5e-c7150ea084fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac29ff7e-0eb4-42e0-af87-55073649bc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27c2f55-86dd-489f-9911-e7c79e526146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8b80913-864d-4b40-8500-c736ae8e6d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d55eb1d-18ec-4b33-9a8c-4edd0cf17568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98ec55bf-23d5-41d7-93c1-e9ad24936476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 560129b9-5483-4568-a83a-ff48c076e660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee034089-b723-4da9-9b16-ebff7d76f1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc6f311-c293-4724-9340-9430b52d8ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf7d62f-b880-47c1-89e7-44f61c1eceea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3517e1-787a-4e4e-a871-acef8db9ccbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d63a930-9e6f-4621-b83d-c471e12906ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ffa219-4dc8-4ae6-b4d9-57f085ed70d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a5d3094-2e26-4f9b-a2e5-8eef3b7bf154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f857008c-95b4-4fe5-b1d3-fc023ead979b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0ed0aed-5787-4dd4-aaae-b9135710196f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a098b35-38a2-48c1-b07d-03d80b341fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56b82c6c-0080-4e52-8039-023d96effdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4174fb9f-c185-4df7-af45-d82e1cfd1a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a64acf-d64b-44cf-b335-789b9e402373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0580a75-6f3d-4015-9aaf-20fddd6d60d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b28f3bbc-3099-4625-ba52-f10617ff7b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a52e08-0eeb-4a0e-8d04-321482c63494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bca767d6-55f5-48af-8b27-079d9275adc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65fcc700-d8e2-4f7a-a582-20c033401f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ce6591-bbc2-4e9a-9478-ea6b52134ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71788b7a-970a-4d97-9fcb-d4c9dc3291e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0cf0fc4-bb9a-4397-9a45-54c7082c7647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58769fcd-3dae-4f2c-a558-8f53bb82e4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476c31ae-556d-46b2-ab07-8d08ab6da14d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6afc0cef-f0c3-4043-ae51-31d7d228d913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08577910-329e-4ae4-abd2-b7729d670e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90d6f1a-b654-439e-9021-60b208bf5a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 670cef98-0fd0-4279-b16f-d77ccbf89266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4b13d6-f847-41a6-98d7-794d1f48862d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3865d71e-7c7b-4af0-8a87-a6c2088b6ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df196445-7ac9-4cf0-ba8e-1fabd1716a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a929fc33-f8cf-434a-bae1-203c42c79d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056fe932-2558-4cba-815e-53fc30e3fdb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 013fbbcc-2b1a-4390-9238-712500f59058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e47e533-6671-43f8-8b5e-2978e8b433b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d39a887a-7338-4114-96e7-b3e8c3ac350a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f7a7c1-bd51-4a26-acf2-b3663113fd38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9f73d51-3d93-44bc-8128-a3329dd9c0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4485cb8b-ff48-43e6-80d8-c137e08f4b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4df11995-47a3-405d-935a-348cbe7c4fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 969b1932-bf4f-4ca0-afb7-7b4cf4733bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb9abae-0d53-4364-8215-5004e2137d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab99280-711a-4f39-8ee7-caae508eefcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c4542b-6687-4063-b7e2-af541491536f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e68ab52b-761d-4a7b-94bb-19621cacb88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b749ea-872c-4830-b346-8a7a2572dce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be45d854-88f5-4545-86fa-cd3910a98824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 250a8c0f-7da0-4a59-92a3-748863621308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eebebd7e-8d7b-4abb-afbe-a90109624373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e119da1-271a-4fc4-b5e5-1f055e69e590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8849634f-a4f3-4469-8489-27e52609f5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1a6fa0-5a76-4af8-acfb-9140c23558b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfcf547-32a0-418f-b7b1-715026c7ef53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba03e2f-4635-446c-8389-002e82df1d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b871649-b22e-45b9-8dc2-3d542bc84da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257a36b5-bcd5-4d56-a09b-6d7d1668900e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e247251-7a13-4a3b-a6ad-461ab56b7a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5513cc8-b665-4bb9-840d-58df0396de4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55759f02-d7b4-4236-9809-c6f35544f512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cf96b4d-cb96-4ecd-b522-7a8aead77ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00378f6d-8635-41ec-9a45-4f78024d4f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80ea857-1d13-4fd3-a966-80a07824476f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42fb50fb-c863-412a-9adf-3c64326ec673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d945dc6c-61ea-484a-bb2b-018a44983961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d05a3c-0037-4039-94b0-a56a665d70d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ddfa2f-f7ad-4b59-841a-a71a73ca8807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 984f887a-7d08-455a-ae9e-a1df2b775248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c11dca4-5ce5-4038-aff3-42ae0efa8d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c893d44-0fe4-4abd-bc95-4160bca30be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4d1140f-ac2d-482f-bcbd-a0dea4815699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35e8247-813f-4392-8187-54851f686c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97a6812-2d0d-4539-8f9e-b104f428706b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4599f0b9-d369-46e8-a908-a4be7e0615a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb0206e-8dc1-4868-8d9d-8f9f877443cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a323290-7c47-406a-af0d-6a32d602473a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7d18fa-fc32-4b8e-85d1-ecd1145a8c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f9ec3c9-893e-4982-9a81-a653ca947262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f21a65f-1693-42fc-856d-5b611925db12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a1d35d6-22e4-485f-8a36-7ca20c081885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 328de387-502b-4f5a-a4af-a70a2ae613c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cb0b5ae-b14a-422f-92c5-f1dfa1273e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904c4d96-b47f-44ce-9ef2-ff5fad5c1083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 895404b7-78ff-41d0-acee-77345ef823e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0592a9b1-7288-469c-b963-66ca69a0de0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce7de36-84b1-49e7-b6e8-21b23d3ec92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 116ea248-2aaf-49ac-a44b-311592d251dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c0152ff-db12-44d3-beae-4abf1e0a90ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f75a17f3-f204-48b0-8bd5-8a9bac8f751e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e033543c-ae73-4427-a351-8a28e5670808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203e819b-be1a-49ba-812d-4be16686f876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56fab41c-c1f8-4f33-8fcb-18888caaa212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff325c6e-bcec-485b-b630-9488b43208f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8539d44a-15ac-405a-b32c-c119cdd83655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d78515-57f0-47b6-99f9-795b4141b840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d8ba916-4626-428b-a01e-54cd72174cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eed207f-6250-4655-a4ec-cb59d2314d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b8b96a-3689-4474-9a3c-ee8cb159a4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd94616-c605-4641-81df-3b7150c2ad05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9961e032-1599-4225-8980-7bc511170846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f11315b4-1c94-42ba-ad91-0c3a678637a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f20ac7cd-28a8-441c-87d2-9685451f92f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24639058-7433-4ece-bedc-246de85f926a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f07e51-4703-4d12-a1bf-22a4526eac7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23c2d161-3092-4aad-a1a3-572f537482d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ce0a4e0-18da-4931-8b23-01723e4e3107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aec2e281-32df-4adf-bb0d-28f66d3c18a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b4158d-2f43-4f88-9404-9cf6626c9710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72cf3a3d-b029-4052-b088-3d7dcda04fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a811a993-12ed-485b-9def-15c9c3c9b843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a9c4a61-b6fe-42a5-88fc-ed320d3439ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87111f25-6f0d-4b7a-94aa-b1b12571298c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25ee085c-2360-4b11-800c-2a17ae48b85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e3d0c1-4b3c-4b62-b7db-aed2f2512468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4708b3c-a288-4b92-9f03-fe4b0a3c8398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdce7a99-6f94-4b45-be6b-3d03d4dde0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2483f2f8-a649-4830-8929-2603cd465223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fff98e6-12fe-4bc6-a068-6358280d5b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b90cba-7ee6-4d1c-8f77-bd50681e5e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e723317-6a1b-49bd-b83f-f57b59eeac12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915ae914-4b29-4b61-a5fd-78b36a502aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbd8ab80-ed29-4245-8b0e-5332e65fc2ed
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_46
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_46/test_labels.txt

📊 Raw data loaded:
   Train: X=(1336, 24), y=(1336,)
   Test:  X=(335, 24), y=(335,)

⚠️  Limiting training data: 1336 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  326 samples, 5 features
✅ Client client_46 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2554, R²: -0.0261

============================================================
🔄 Round 12 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0997 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0750, val=0.0969 (↓), lr=0.001000
   • Epoch   3/100: train=0.0740, val=0.0975, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0737, val=0.0977, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0733, val=0.0978, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0689, val=0.1028, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 12 Summary - Client client_46
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.0189
   Val:   Loss=0.0969, RMSE=0.3113, R²=-0.0029
============================================================


============================================================
🔄 Round 14 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0820 (↓), lr=0.000250
   • Epoch   2/100: train=0.0787, val=0.0816, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0783, val=0.0814 (↓), lr=0.000250
   • Epoch   4/100: train=0.0779, val=0.0812, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0776, val=0.0812, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0768, val=0.0812, patience=8/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 14 Summary - Client client_46
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0252
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0117
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2435, R²: 0.0405

📊 Round 14 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2416, R²: 0.0443

============================================================
🔄 Round 17 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0783 (↓), lr=0.000125
   • Epoch   2/100: train=0.0784, val=0.0782, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0781, val=0.0782, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0779, val=0.0782, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0777, val=0.0783, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0770, val=0.0787, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 17 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2804, R²=0.0219
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0082
============================================================


============================================================
🔄 Round 19 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0808 (↓), lr=0.000031
   • Epoch   2/100: train=0.0778, val=0.0808, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0776, val=0.0808, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0775, val=0.0808, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0775, val=0.0808, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0772, val=0.0809, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 19 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0224
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0173
============================================================


============================================================
🔄 Round 20 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0819 (↓), lr=0.000008
   • Epoch   2/100: train=0.0776, val=0.0819, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0775, val=0.0819, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0775, val=0.0820, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0774, val=0.0820, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0773, val=0.0821, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 20 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0096
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0633
============================================================


============================================================
🔄 Round 22 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0717 (↓), lr=0.000002
   • Epoch   2/100: train=0.0808, val=0.0716, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0808, val=0.0715, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0807, val=0.0715, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0807, val=0.0714, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0805, val=0.0712, patience=10/15, lr=0.000002
   • Epoch  21/100: train=0.0803, val=0.0709, patience=9/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 22 Summary - Client client_46
   Epochs: 27/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0171
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0223
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2415, R²: 0.0549

📊 Round 22 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2412, R²: 0.0579

============================================================
🔄 Round 24 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0728 (↓), lr=0.000002
   • Epoch   2/100: train=0.0803, val=0.0728, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0802, val=0.0728, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0802, val=0.0727, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0801, val=0.0727, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0800, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 24 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0129
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0408
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2415, R²: 0.0597

📊 Round 24 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2422, R²: 0.0583

📊 Round 24 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2431, R²: 0.0555

============================================================
🔄 Round 27 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 27 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0306
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0297
============================================================


============================================================
🔄 Round 29 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 29 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0184
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0202
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2448, R²: 0.0492

============================================================
🔄 Round 30 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 30 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0252
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0443
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2451, R²: 0.0482

📊 Round 30 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2454, R²: 0.0469

📊 Round 30 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: 0.0464

============================================================
🔄 Round 35 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 35 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0241
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0388
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2457, R²: 0.0457

============================================================
🔄 Round 36 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 36 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0278
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0261
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2457, R²: 0.0455

📊 Round 36 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2457, R²: 0.0455

📊 Round 36 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2457, R²: 0.0456

📊 Round 36 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2457, R²: 0.0458

============================================================
🔄 Round 42 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 42 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0390
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0289
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2457, R²: 0.0460

============================================================
🔄 Round 44 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 44 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0254
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0374
============================================================


============================================================
🔄 Round 47 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 47 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0275
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0266
============================================================


============================================================
🔄 Round 49 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 49 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0297
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0157
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0466

📊 Round 49 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0466

📊 Round 49 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0470

📊 Round 49 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0472

📊 Round 49 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2454, R²: 0.0474

============================================================
🔄 Round 61 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 61 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0320
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0009
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0475

============================================================
🔄 Round 63 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 63 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0194
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0588
============================================================


============================================================
🔄 Round 64 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 64 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0240
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0373
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0467

============================================================
🔄 Round 66 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 66 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0271
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0313
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0467

📊 Round 66 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2456, R²: 0.0469

============================================================
🔄 Round 69 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 69 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0335
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0007
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0475

============================================================
🔄 Round 74 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 74 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0292
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0037
============================================================


============================================================
🔄 Round 75 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 75 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0270
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0313
============================================================


============================================================
🔄 Round 76 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 76 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0317
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0054
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0477

============================================================
🔄 Round 77 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 77 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0378
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0084
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0476

============================================================
🔄 Round 80 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 80 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0258
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0328
============================================================


============================================================
🔄 Round 81 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 81 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0321
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0091
============================================================


============================================================
🔄 Round 82 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 82 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0236
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0431
============================================================


============================================================
🔄 Round 84 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 84 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0304
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0149
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2456, R²: 0.0470

============================================================
🔄 Round 90 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 90 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0260
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0081
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0473

============================================================
🔄 Round 91 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 91 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0183
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0436
============================================================


============================================================
🔄 Round 92 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 92 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0291
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0245
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0477

============================================================
🔄 Round 94 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 94 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0188
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0584
============================================================


============================================================
🔄 Round 95 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 95 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0207
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0582
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2453, R²: 0.0481

============================================================
🔄 Round 97 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 97 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0300
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0065
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0479

📊 Round 97 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0479

📊 Round 97 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0478

📊 Round 97 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0477

============================================================
🔄 Round 102 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 102 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0221
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0393
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0477

============================================================
🔄 Round 108 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 108 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0238
   Val:   Loss=0.0669, RMSE=0.2586, R²=0.0445
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0480

📊 Round 108 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0479

============================================================
🔄 Round 111 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 111 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0315
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0114
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0477

============================================================
🔄 Round 113 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 113 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0238
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0450
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0475

============================================================
🔄 Round 114 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 114 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0331
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0069
============================================================


============================================================
🔄 Round 115 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 115 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0340
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0161
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0473

============================================================
🔄 Round 117 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 117 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0248
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0384
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2456, R²: 0.0470

📊 Round 117 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2457, R²: 0.0466

============================================================
🔄 Round 122 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 122 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0250
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0324
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0460

📊 Round 122 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0459

📊 Round 122 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0458

============================================================
🔄 Round 128 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 128 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0293
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0189
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0459

============================================================
🔄 Round 131 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 131 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0367
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0088
============================================================


============================================================
🔄 Round 132 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 132 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0233
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0153
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0459

📊 Round 132 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0457

============================================================
🔄 Round 136 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 136 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0289
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0128
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2459, R²: 0.0453

============================================================
🔄 Round 137 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 137 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0156
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0715
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2459, R²: 0.0452

============================================================
🔄 Round 138 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 138 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0311
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0119
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2460, R²: 0.0451

============================================================
🔄 Round 139 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 139 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0277
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0189
============================================================


============================================================
🔄 Round 141 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 141 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0261
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0335
============================================================


============================================================
🔄 Round 143 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 143 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0312
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0086
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2459, R²: 0.0453

📊 Round 143 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2459, R²: 0.0455

============================================================
🔄 Round 148 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 148 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0328
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0084
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2460, R²: 0.0450

============================================================
🔄 Round 153 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 153 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0241
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0385
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2460, R²: 0.0451

============================================================
🔄 Round 157 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 157 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0245
   Val:   Loss=0.0744, RMSE=0.2729, R²=0.0307
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2460, R²: 0.0449

============================================================
🔄 Round 158 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 158 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0188
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0435
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2461, R²: 0.0447

📊 Round 158 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2461, R²: 0.0446

📊 Round 158 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2461, R²: 0.0446

============================================================
🔄 Round 164 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 164 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0194
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0506
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0443

============================================================
🔄 Round 165 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 165 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0169
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0554
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2462, R²: 0.0443

📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2461, R²: 0.0444

📊 Round 165 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2461, R²: 0.0445

============================================================
🔄 Round 169 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 169 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0169
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0371
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2461, R²: 0.0448

============================================================
🔄 Round 171 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 171 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0269
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0261
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2460, R²: 0.0449

📊 Round 171 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2460, R²: 0.0452

📊 Round 171 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2460, R²: 0.0453

============================================================
🔄 Round 175 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 175 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0249
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0366
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2460, R²: 0.0453

📊 Round 175 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2459, R²: 0.0455

============================================================
🔄 Round 181 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 181 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0147
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0601
============================================================


============================================================
🔄 Round 182 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 182 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0281
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0150
============================================================


============================================================
🔄 Round 184 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 184 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0248
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0315
============================================================


============================================================
🔄 Round 185 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 185 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0355
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0175
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0459

============================================================
🔄 Round 186 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 186 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0358
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0116
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0461

📊 Round 186 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0461

============================================================
🔄 Round 191 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 191 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0338
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0027
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2458, R²: 0.0462

============================================================
🔄 Round 193 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 193 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0343
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0063
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2458, R²: 0.0463

📊 Round 193 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2457, R²: 0.0464

📊 Round 193 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2457, R²: 0.0464

📊 Round 193 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2457, R²: 0.0465

============================================================
🔄 Round 199 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 199 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0298
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0031
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2457, R²: 0.0465

============================================================
🔄 Round 200 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 200 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0201
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0351
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2458, R²: 0.0462

============================================================
🔄 Round 201 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 201 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0158
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0281
============================================================


============================================================
🔄 Round 203 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 203 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0385
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0212
============================================================


============================================================
🔄 Round 204 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 204 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0277
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0151
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2458, R²: 0.0459

============================================================
🔄 Round 205 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 205 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0170
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0428
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2459, R²: 0.0458

============================================================
🔄 Round 207 - Client client_46
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 207 Summary - Client client_46
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0298
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0146
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2459, R²: 0.0457

📊 Round 207 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2459, R²: 0.0457

📊 Round 207 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2459, R²: 0.0455

❌ Client client_46 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
