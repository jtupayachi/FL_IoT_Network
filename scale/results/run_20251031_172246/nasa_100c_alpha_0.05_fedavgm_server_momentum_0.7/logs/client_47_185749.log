[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f60fbc27-ad44-4638-b674-d8d01799d71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cd7b16-a43e-4ef2-98e9-35a65ef1b910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc898b1c-5dbd-4285-b330-052403872ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04ea1e7-b435-412c-acb8-c4004f8f6bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9bce7ce-fedb-46b6-9877-464f5e031588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa456bb4-ada6-43bf-b677-316d310808df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab96c47-c480-4e90-9e37-ac69eb17090a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae75519a-c1d9-4333-9f68-c041339bb26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708c6284-7fe2-45ec-ae07-26742acaadab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6c6d16-c07a-48d5-8fdc-7820afb7e745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7f23708-57d9-45eb-a2bc-bec9923e5739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72961475-0162-4023-a71a-316bec369f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ef03d5f-08a6-4a31-8e2e-8365d9ce578d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21ef8e86-1558-4cd4-8a68-6a26befb39b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcd93d3-9805-4ada-8100-d8982de8bd2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a7bd72a-eab2-4b2b-a662-e577f4983aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba7fd21-27c8-41ab-92e4-3e93e1492a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a604ceb3-de38-40d7-bd1f-d5b4a6a72e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84dbee22-75ad-4dfd-b238-c7c94bc2216f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a5bab39-d448-4bf1-ae33-88802846a86a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87961e92-b4e7-4b8c-9108-8c25cd80c24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d006d21-6903-4bae-9954-8b15b8ba64f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fecb34d2-75f9-43c2-b795-df0efcc25be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59fad2d3-6a3a-4b88-ab29-25c794467d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77b69e4-8487-462d-b51f-23401995f1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 275fb4fe-dd94-4a13-950c-340a0d55d216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3fbec44-673a-49b2-8c0a-3db15265dd89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca419518-bad9-4caf-84c8-ab76d2a4c98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3411e388-335d-4f26-b1d1-374b8e2dbe3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446205f5-d3fb-4a12-96a8-316569d0db66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54c41dc1-1470-4b54-bf6e-97dfa44921c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0fe1de-0738-469d-b343-611cd8fd8b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea2c35e6-393a-417c-83c4-0f899f20a57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c54562-ce35-400a-ac3b-22124382bf38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1926e4a6-b7fe-43ac-b6a9-70d390e0c2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5094f50-0a6c-42fe-a403-d66128cc6ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e77cb81e-5dcb-4564-9cb9-7c2392e216ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90eff9cf-a40e-40d6-a1bb-8b5593941747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c6898c-5233-48ad-8ebb-4c9b0d2731bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93000aad-08da-43ee-bef0-7102ca66bcb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 441623af-7443-4be3-86ba-6f47f07b6bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c521c04-3626-40a0-a4cb-77c08103adcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae11ff4f-1d62-45c1-94d2-68231c235c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c334cbb9-ad8e-494f-b211-92fbba063ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc7595f-9dff-4c20-85a6-013816d2a5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1388326-69b8-4246-8d3e-00a5481c018c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33c0f54-9245-4965-a1dd-1790e154be70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236cae3d-80a4-4480-9a48-72a7c6c9a9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2240c072-ce3d-4883-8041-10029efb1c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cdd542c-1d31-4182-9e6b-23bc744723e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 247fc988-d1d9-4cf0-b3e7-eea9d81570d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b4b61e9-1105-4f4e-8ba1-6aa8ed8f4277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95941ba0-a46a-4282-b09b-4e11aed6ba61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c593cf-6620-4729-b70e-6b72b7d5273a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59064419-04a0-47fd-acac-0792bab886ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd3f27cc-cc8f-492e-948d-578e865bb80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f0a1dc0-c822-42c3-a61e-7e21c06258d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59ab7601-31f8-4d01-a273-d83b989e4015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a1534d-ddeb-4cd3-8682-b8c4f5cc6926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 544619b1-62f5-4bfc-9ca2-a58302311d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0435cc6f-e84d-4bc0-9bf3-c4a0a9803e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326762f0-0d3f-4433-b607-5934ab619334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d30ffec2-6e2d-44d3-af58-e2c021cd6fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd73f9c4-84db-4a8a-81ea-8e9013036414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db60dc5-0a3a-4b3d-8dcd-ca27ab3c7041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a8c119-b1c3-4451-be75-368d008de8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a99275f9-62e6-49bd-b941-2e15940104f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f63da659-02b9-49a3-b4df-39638cf54623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d917ad7-ae00-4d7c-b5d6-ce8c01513d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae608d3-a98f-4a88-a91e-210543ba0de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d0f8d3-d669-4e31-8df2-adebcb79be9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 396015d7-713a-4772-b93b-e3ce0b268e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1863ed5-3e24-4a0c-80eb-7541ca1740e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5723530d-a13c-4ef1-834b-f636e0ed933b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c9b0707-1a2c-4401-98b4-577bec1c354c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf5cd3ec-3a3d-4a55-9d20-cad94511c2a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64fd2a48-1af7-4c04-b72b-20c8eeaed877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f86bc319-865a-459f-ab2d-195ddfbc7383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c12c7ac-00de-4ddd-b77b-92b50fda473e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 960a78c6-e93e-4daf-8bdd-2817b64a981a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5e92557-2e9e-4eb6-bde3-442214373e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f13aa8c-5c54-4e41-b5c5-e27c94d2e3b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d33a0974-979a-43fe-9577-272c1c928079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6ec900-810d-4ba3-bfe7-022a5da22fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b464369-a458-46a0-8537-c1a887283435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fabdc02-baaf-4295-9946-4c5bf83a5dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240de46f-c9c8-46e0-8577-5eec7c5e8669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528d153c-09fc-4b16-bc5f-e2af1b4c3244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29af5874-0071-4b8d-8b15-1d4a9fd57e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2fa5166-2933-4c00-8286-954f84766858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874f5f0c-8f93-425c-b7f9-ca666287153d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816c1149-a7f9-42b3-864b-0bcda380580e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c0f0c8-92ec-4d05-91cc-333717dbbe00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bb76df6-1b16-4858-9a57-2c7ae8dd241a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d20cdb-7f96-47f6-a6fe-78ab306b504a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7664d7-788c-459d-b971-f19198107bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19a2ab5d-bc7e-46e5-ba04-352ba992d505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbe9e8e4-af77-49fb-a169-aeff064ceccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd52cbfe-e0c3-4ab1-bcaa-d56ccda9296c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ba8143-20b4-4d7c-92ec-55cab583b46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04917b08-0078-469d-b105-73e87e3c4fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cab9db3-fe1e-4771-8398-2fe94a52feb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612f6db6-bd72-4cc6-b28f-36f2ba4b7599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45157c14-c4ff-4c3a-a38f-593804f243b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b85a2378-6ade-4ba6-ab31-d05570253d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff50662-c005-4787-bb0f-fd348ea8f812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 466b27d3-1bb6-4f5d-a5e5-850279451043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10e07bca-d190-47aa-82fd-5419e1d371a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ae21c9-a3d0-427a-87a2-67b9aae1c1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484f634c-7f53-40a2-a287-3d436bc4f1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4164eb93-61f5-4807-9f35-3632452a107c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e83dd1b4-5433-4d5b-b546-fd8a3b97b660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 056d5025-6110-4c13-8e5e-6b6501cd3921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 659b195a-bd6f-4dd5-9a28-e4b4a67dc304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 525080cc-2c0a-4e06-811a-a7c086911e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1cd1179-8eab-43b5-943a-e1868da66495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a0aadd-2b24-47c3-9069-457f2f1c3199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ef25c5a-db32-4eff-9b89-f23b6e0b7a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43fc1be1-f366-4e53-8d5c-77b87448d201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfde5dfb-da4a-4034-b0e2-176a99f22309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd1df15-bc45-4eeb-bc8f-4e7513c51e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 711716b7-a017-4b1a-8c29-add8585d3dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a774118f-fc8e-4dff-a661-847c33cbfba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 261f3d60-6fef-4408-8e04-e4bebfda124a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7535169a-a634-4dd9-b4d8-8436f121893e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bbe3372-d14e-4011-92f2-415c6a019357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adbf2b3b-928a-4ccc-9a09-9cb5ce678918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f333de0e-8df0-49e9-92b1-3ea2799e8cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2511cafd-cd7d-4b8e-b0e8-76703d40308a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b19726-fabf-40a9-9da9-cecd00f4baa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee1008d-1602-4d3f-9d80-77be2bac6211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f222cdc6-01bf-428c-9228-c96470738fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4460b145-b736-44e6-8716-4b864e4916e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26747da8-7f22-4c73-9619-d449383bfcbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0fa94e-24c8-4512-aaef-3a7d7f1966e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f0b803-0113-4014-92ed-6116a54e3464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9aa72c9-fff7-465d-bbc5-7ed4458952e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ebbd509-e2fa-4a47-9ac0-e2dfb58280c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08b5d77-dfa7-4e2f-9565-2fedfd671bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bab6164-2082-4f0d-94e0-ad95c8a707ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2edb71c6-9186-424c-8b41-bf52945edd1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f445f4e-476a-4c18-8a91-b252f5480831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f810a890-d4e4-4516-a9d6-494cebc13ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a8f2c04-fc2f-4d60-9df7-efff7595e7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6723bed-1c93-406b-b6a3-3c0c770d09b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f84f5d8-6767-45ef-a2a6-928aad18fe0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d60398-4465-4038-9dae-2e7d01866155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 899ca0ee-bd1b-40f2-bf9c-92be488fc0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b08587b7-1d7e-4e80-955e-41e243db1c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed8931b1-442d-4194-946b-449c76ee2c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c2d947f-925e-4905-b3d6-7ecef1117224
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_47
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/test_labels.txt

📊 Raw data loaded:
   Train: X=(1674, 24), y=(1674,)
   Test:  X=(419, 24), y=(419,)

⚠️  Limiting training data: 1674 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  410 samples, 5 features
✅ Client client_47 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 12 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0763 (↓), lr=0.001000
   • Epoch   2/100: train=0.0781, val=0.0761, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0769, val=0.0757 (↓), lr=0.001000
   • Epoch   4/100: train=0.0759, val=0.0753, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0750, val=0.0752, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0661, val=0.0772, patience=5/15, lr=0.001000
   📉 Epoch 14: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0541, val=0.0850, patience=15/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 12 Summary - Client client_47
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0722, RMSE=0.2686, R²=0.1068
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0409
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2411, R²: 0.0312

============================================================
🔄 Round 16 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0698 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0744, val=0.0686 (↓), lr=0.000500
   • Epoch   3/100: train=0.0731, val=0.0683, patience=1/15, lr=0.000500
   ✓ Epoch   4/100: train=0.0722, val=0.0681 (↓), lr=0.000500
   • Epoch   5/100: train=0.0713, val=0.0679, patience=1/15, lr=0.000500
   • Epoch  11/100: train=0.0670, val=0.0687, patience=7/15, lr=0.000500
   📉 Epoch 13: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 16 Summary - Client client_47
   Epochs: 19/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0713, RMSE=0.2671, R²=0.1283
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.0840
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2405, R²: 0.0445

📊 Round 16 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2417, R²: 0.0404

📊 Round 16 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2409, R²: 0.0467

📊 Round 16 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2394, R²: 0.0559

📊 Round 16 Test Metrics:
   Loss: 0.0773, RMSE: 0.2779, MAE: 0.2376, R²: 0.0650

============================================================
🔄 Round 22 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0731 (↓), lr=0.000250
   📉 Epoch 2: LR reduced 0.000250 → 0.000125
   ✓ Epoch   2/100: train=0.0717, val=0.0725 (↓), lr=0.000125
   • Epoch   3/100: train=0.0703, val=0.0721, patience=1/15, lr=0.000125
   ✓ Epoch   4/100: train=0.0696, val=0.0717 (↓), lr=0.000125
   • Epoch   5/100: train=0.0691, val=0.0715, patience=1/15, lr=0.000125
   📉 Epoch 10: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0668, val=0.0721, patience=7/15, lr=0.000063
   📉 Epoch 18: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 22 Summary - Client client_47
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0694, RMSE=0.2635, R²=0.1236
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.1517
============================================================


============================================================
🔄 Round 23 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0724 (↓), lr=0.000031
   • Epoch   2/100: train=0.0732, val=0.0726, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0727, val=0.0727, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0723, val=0.0727, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0720, val=0.0726, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0710, val=0.0719, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0703, val=0.0714, patience=9/15, lr=0.000008
   📉 Epoch 23: LR reduced 0.000008 → 0.000004
   📉 Epoch 31: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0700, val=0.0712, patience=9/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 23 Summary - Client client_47
   Epochs: 37/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0704, RMSE=0.2653, R²=0.1212
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.1067
============================================================


============================================================
🔄 Round 24 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0761 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0730, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 24 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.0756
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.1088
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0772, RMSE: 0.2779, MAE: 0.2378, R²: 0.0655

============================================================
🔄 Round 29 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 29 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0685
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0198
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2404, R²: 0.0511

============================================================
🔄 Round 30 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 30 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0638
   Val:   Loss=0.0688, RMSE=0.2622, R²=0.0326
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2405, R²: 0.0502

📊 Round 30 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2406, R²: 0.0496

============================================================
🔄 Round 32 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0604 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0604, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0604, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0604, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0603, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0602, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0604)

============================================================
📊 Round 32 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0565
   Val:   Loss=0.0604, RMSE=0.2458, R²=0.0543
============================================================


============================================================
🔄 Round 34 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 34 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0617
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0248
============================================================


============================================================
🔄 Round 35 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 35 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0517
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0686
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2409, R²: 0.0477

📊 Round 35 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2409, R²: 0.0474

============================================================
🔄 Round 38 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 38 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0562
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0496
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2409, R²: 0.0473

📊 Round 38 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2409, R²: 0.0473

📊 Round 38 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2409, R²: 0.0476

============================================================
🔄 Round 47 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 47 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0539
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.0647
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2409, R²: 0.0476

============================================================
🔄 Round 49 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 49 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0595
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0378
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2409, R²: 0.0476

============================================================
🔄 Round 50 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 50 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2749, R²=0.0675
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0029
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2409, R²: 0.0477

📊 Round 50 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2408, R²: 0.0479

============================================================
🔄 Round 57 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 57 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0614
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0365
============================================================


============================================================
🔄 Round 58 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 58 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0586
   Val:   Loss=0.0680, RMSE=0.2609, R²=0.0512
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2408, R²: 0.0482

📊 Round 58 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2408, R²: 0.0483

📊 Round 58 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2408, R²: 0.0483

📊 Round 58 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2409, R²: 0.0476

📊 Round 58 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2409, R²: 0.0473

============================================================
🔄 Round 64 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 64 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0505
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0795
============================================================


============================================================
🔄 Round 65 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 65 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0439
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.1060
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2410, R²: 0.0468

📊 Round 65 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2410, R²: 0.0465

============================================================
🔄 Round 67 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 67 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0561
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0327
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2409, R²: 0.0470

============================================================
🔄 Round 72 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 72 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0703
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0003
============================================================


============================================================
🔄 Round 74 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 74 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0668
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0205
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2408, R²: 0.0475

============================================================
🔄 Round 76 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 76 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0641
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0288
============================================================


============================================================
🔄 Round 77 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 77 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0629
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0118
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2409, R²: 0.0472

============================================================
🔄 Round 80 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 80 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0652
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0202
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2410, R²: 0.0465

============================================================
🔄 Round 81 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 81 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0754
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0281
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2411, R²: 0.0458

============================================================
🔄 Round 84 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 84 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0541
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0569
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2411, R²: 0.0454

============================================================
🔄 Round 86 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 86 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0622
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0315
============================================================


============================================================
🔄 Round 87 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 87 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0470
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0849
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2410, R²: 0.0462

============================================================
🔄 Round 89 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 89 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0599
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0367
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2410, R²: 0.0464

📊 Round 89 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2409, R²: 0.0468

============================================================
🔄 Round 92 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 92 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0396
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.1263
============================================================


============================================================
🔄 Round 93 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 93 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0563
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0660
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2409, R²: 0.0471

============================================================
🔄 Round 97 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 97 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0576
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0621
============================================================


============================================================
🔄 Round 99 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0638 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0637, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0637, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0637, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0637, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0636, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0638)

============================================================
📊 Round 99 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0565
   Val:   Loss=0.0638, RMSE=0.2525, R²=0.0664
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2409, R²: 0.0467

============================================================
🔄 Round 100 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 100 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0462
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.1016
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2409, R²: 0.0465

📊 Round 100 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2410, R²: 0.0464

📊 Round 100 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2410, R²: 0.0464

============================================================
🔄 Round 105 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 105 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0519
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0682
============================================================


============================================================
🔄 Round 106 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 106 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0530
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0717
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2409, R²: 0.0466

📊 Round 106 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2409, R²: 0.0468

📊 Round 106 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2409, R²: 0.0468

============================================================
🔄 Round 112 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 112 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.0384
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.1148
============================================================


============================================================
🔄 Round 114 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 114 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0633
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0358
============================================================


============================================================
🔄 Round 116 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0617 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0617, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0616, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0616, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0616, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0616, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0617)

============================================================
📊 Round 116 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0625
   Val:   Loss=0.0617, RMSE=0.2483, R²=0.0329
============================================================


============================================================
🔄 Round 117 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 117 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0651
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0299
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2410, R²: 0.0462

📊 Round 117 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2411, R²: 0.0455

============================================================
🔄 Round 122 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 122 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.0576
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0558
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2411, R²: 0.0453

============================================================
🔄 Round 123 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 123 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0556
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0328
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2412, R²: 0.0451

📊 Round 123 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2412, R²: 0.0450

============================================================
🔄 Round 130 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 130 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0567
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0499
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2411, R²: 0.0452

============================================================
🔄 Round 132 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 132 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.0517
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0400
============================================================


============================================================
🔄 Round 133 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 133 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0607
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0423
============================================================


============================================================
🔄 Round 134 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 134 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0534
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0650
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2413, R²: 0.0442

============================================================
🔄 Round 139 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 139 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0535
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0584
============================================================


============================================================
🔄 Round 140 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 140 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0648
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0182
============================================================


============================================================
🔄 Round 141 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 141 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0554
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0562
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2414, R²: 0.0435

📊 Round 141 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2414, R²: 0.0435

============================================================
🔄 Round 146 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 146 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0494
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0779
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2413, R²: 0.0437

============================================================
🔄 Round 148 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 148 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0393
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.1142
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0432

============================================================
🔄 Round 150 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 150 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0448
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0941
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0430

📊 Round 150 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0429

📊 Round 150 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2415, R²: 0.0426

============================================================
🔄 Round 159 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 159 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0587
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0421
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2415, R²: 0.0422

📊 Round 159 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2416, R²: 0.0419

============================================================
🔄 Round 164 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 164 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0532
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0521
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2416, R²: 0.0418

📊 Round 164 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2416, R²: 0.0418

============================================================
🔄 Round 168 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 168 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0531
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0548
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2415, R²: 0.0422

============================================================
🔄 Round 172 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 172 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0517
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0684
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2415, R²: 0.0423

📊 Round 172 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2415, R²: 0.0425

============================================================
🔄 Round 174 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 174 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0611
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0333
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2415, R²: 0.0426

============================================================
🔄 Round 176 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 176 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0585
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0474
============================================================


============================================================
🔄 Round 177 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 177 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0490
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0873
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0427

📊 Round 177 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0429

============================================================
🔄 Round 180 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 180 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0515
   Val:   Loss=0.0652, RMSE=0.2554, R²=0.0314
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0430

============================================================
🔄 Round 183 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 183 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0613
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0303
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2414, R²: 0.0432

============================================================
🔄 Round 187 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 187 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0502
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0878
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2414, R²: 0.0433

============================================================
🔄 Round 189 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 189 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0468
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.1007
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2413, R²: 0.0435

============================================================
🔄 Round 192 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 192 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0584
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0535
============================================================


============================================================
🔄 Round 195 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 195 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0668
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0191
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2413, R²: 0.0439

============================================================
🔄 Round 196 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 196 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0597
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0481
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2413, R²: 0.0440

============================================================
🔄 Round 197 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 197 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0584
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0566
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2413, R²: 0.0440

📊 Round 197 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2413, R²: 0.0438

============================================================
🔄 Round 202 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 202 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0529
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0760
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2413, R²: 0.0435

📊 Round 202 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2413, R²: 0.0435

============================================================
🔄 Round 205 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 205 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0618
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0346
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2413, R²: 0.0436

📊 Round 205 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0432

📊 Round 205 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0432

============================================================
🔄 Round 209 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0652, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0652, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0652, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 209 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0574
   Val:   Loss=0.0653, RMSE=0.2555, R²=0.0558
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2414, R²: 0.0431

❌ Client client_47 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
