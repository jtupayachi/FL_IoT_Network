[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7413d35a-dd63-4a84-a4fd-40f8c52a206f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 702bb81b-a8e5-42a4-a308-4ac579b5819b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e99567ee-a50f-46fc-b084-93ba0419fbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 738082ef-9c46-466d-aa32-c1fdcb57542a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 051b2adb-4c64-47f4-819c-2b51b63fff18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9907d5c-e6e7-43ef-b378-3c667605b683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde06c8e-86fb-4a62-ae01-0be1d8d6fbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b707a05-ae7d-4bd7-9e08-9334929b164f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb71cee5-4102-4006-87d6-620f2a5179c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba2294e-4445-4969-bee6-84c3585ff2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827d3101-d06e-4605-9882-5493c6795663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ea8371-81ea-43e0-a218-f132dfa86f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5b07811-b834-4c8b-9205-1c6833da7ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05443b42-7902-4389-8d9d-15432ca3ed27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96800ea7-69df-41a0-ba9a-6207f9b3d0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e7c1f6-ec2f-4487-b858-a1083f6f785e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6115b64d-9bd8-4412-a06c-9978dfd585e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9641d8f-b325-45ac-9922-56f95c546f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1996953d-171b-44fd-b17f-09e589e76ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b635a3bd-0183-454e-852a-aacfe41ac9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6db26dfa-9a33-417c-88ae-5b1b3cfe6b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 020e3007-11b2-4079-b029-04b5b6460c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71b9a9e1-91bd-4bcf-8a5f-844613e702cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973944f9-676c-4d32-b3ba-2c4d188d11ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83be94df-0f9b-4f17-b1b9-42625e3cfc3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b94aa0-7f26-4c54-9f33-d0794af3aa3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b5ef12-efc6-4242-8924-2627afe4b61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03380b8-b5fb-4651-9f08-8f0d620350ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4cb4e99-dd99-4ed5-84ac-86e0d5a85a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aa21c96-e304-4a10-8c96-905c7cb3cd59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 441f2ad1-86f9-46bd-a902-1759f142f1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d3a02e2-18ab-499c-92d8-bc081871bcfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a55eb3f-dc15-4f40-bb43-fd0e34a06fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9977d803-a94e-4d21-a3c1-16e1244901bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fe36f0-0b29-4be0-a422-02dd52717128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6024a245-e3d4-415c-91a7-668d8e3b63cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33b1dd20-b423-43df-82bc-02f55c04e1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8860b1-c969-4797-8fb5-8bb61fd43376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d907344-2447-49b2-a613-97a44f2e1337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a705d7b-3565-4d32-9c1a-35dc52ebdf28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa04bee1-1a65-46a0-a8b8-3617838be948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c734ccd6-c68f-42e9-afa4-efdc5c19707e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3704e1e-5616-4284-88ab-4898c73ae61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224f44b5-6aaa-4ce9-bfab-26814bfe7cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d234a52c-d663-4eb0-aaa7-edc141b7964f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4c728b-ff39-4128-a820-d2a5d17560a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86396bbe-e278-43eb-bb17-ff222647cdfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17cc9cdc-9e37-4cd1-8ff7-07ab22239cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e2512c-c1ee-464f-8bf0-6cfe707de88f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5be1078-d03f-4948-8b4d-3f768baf11a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cfe0198-0c7b-4a42-9ff2-57a7d22ff54a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af11e0b6-41ea-40fa-9533-a9c94465b0d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f45d3e-8c8d-4570-857b-59d968cd2e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d563895-1c34-4f25-ab7b-564d9ff031ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223103bf-ae80-4716-9df0-d756facb74e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f7ebdf9-b1c3-46f6-ab8e-fe1bdc186cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2d22f6-6710-4395-844d-801dcd58b93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01e1d24d-06e3-4e87-b6ab-20d2c94c5faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 184b0570-48c7-418a-b083-a13df3d02cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4560a340-d052-46f4-ab67-f38e1cf940bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ac26c8-3d00-4dde-ac85-cc24acf28f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5f39b5-58ba-4239-9701-1133f8460b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a62417-2320-4ae7-8178-6f2c2e153d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec9b3c83-c0e3-4136-8650-5049b5633213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69be8d2-1a42-4d48-9e10-06d434b9ee16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1a19e0-f43f-459f-bbe5-65a4bfe22d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446a5de1-bcc6-49ad-b2ac-c419d6e3f35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fb4bfbe-5727-4193-9ee1-1eb1d0ae1f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06edfbc6-088a-4a07-86c8-ecde93767e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2f9f5b7-bd87-4f64-81f2-eb3fc0da36ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2b236d-4965-45ba-a517-89a3ade6951a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a53e3db-6d98-413d-86e7-2ed3b16294a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3db7602e-f473-406a-91d6-936946221189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e35eda5-bb4c-4c58-95a8-342009a94eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96aa59cd-c0d1-4a4d-a5db-9702b53b1f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b478e3d-ad6d-490c-a3f6-b94760b0efc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3065236-2620-45e0-8744-2f5390e7adbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 002b7773-c007-4151-98cc-bc09317c7403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d05562d8-f3c2-49a8-96e4-f42304683e79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a36707-631c-4b1e-bfcf-6fa3d9c7e14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72b67c24-b33b-40b8-a06d-dfba71af3f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fdaca37-6d8e-40de-8b5b-5d202e539a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a895962-d6b2-4050-969a-4093c6db718c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3f4ad0-d71c-47cf-b5ee-7f7585ee046c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07b05e14-c722-428d-b0ab-adf0743ae217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c7a27b-e26d-4845-96ad-069bbfe8a8d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eab7d7e-f429-4cca-bca0-d317bfd4fd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc73d73-950e-4a31-9c56-2c1e3cda4cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1450f9a-f30a-431b-abc0-a09dbeeebdcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b64cfdc-767c-4169-839b-303d19dbbdb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672c478c-ea45-4b66-a963-4850569dab43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5cc88a0-f3a6-4950-bee8-45b678fed753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 407c8559-dfef-4b81-a125-f6a332636a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b034885-5e90-46c0-a1ab-b4b784f1bea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6cb88e-d678-4470-9299-e37c5df93aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a91c81-bb95-4c65-8033-b2addf30b48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4dbc697-2aca-48c2-8d24-7865dc29d184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23779bbd-9eb4-427a-bca8-6ce07100423a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5070977-20a2-42ee-af86-7fcc6292d557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26fd9e63-4561-4a31-92d1-4d7767b2f336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f497272-6d65-4d53-b729-544c736ef7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff8b1a3-d1e8-46e5-9e77-ae16df2bab85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692a0f2b-fb5e-4f97-acf9-0def09112268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227a74ca-64c8-4300-945e-0f2c4b0dc169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d2d6c8f-cf72-4355-9d57-8f66cb0d08d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4cdcfa8-1c26-40a1-9844-53a42aa7c570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e66acf-d2f4-4d97-aa47-bee208bebc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79df153a-5774-49a3-a3da-82156a69d44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc25e7e-0ed8-430a-b1c2-a698be8792af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef3ca5ac-0fbf-4ed7-b38c-7d105007d7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b807010-124c-459a-9e69-7a95109e1ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efa828ee-edf8-47c2-a7a6-5a52b49c98dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 983cc2e4-08fc-4437-9682-bc859caa2cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959353ad-437c-4b6f-9ee7-a021fcdd5690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75bed91d-f013-41d6-980e-62a29985ac20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322f6281-754e-41e2-af6d-a0ab4e4200d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f23eb5-4e93-4d11-8dae-bd880bb347ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d17425d-8b4b-4629-9840-191c9e138d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c442a6-8ef1-4863-a19c-5ba19d5aa659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc1e4637-09df-4369-b58f-b4e5da8168d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca1cd729-8282-4933-9fc4-9f6932c38066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f164c1cc-a39b-4552-adc5-3038152d0ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b603c17b-f5cb-4ac0-89da-32780a7b851c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6292d5cf-7625-4162-8c36-f1a988999a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15fa9a21-b9bd-4306-bbea-8566af6822a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 175e9ba3-aa81-4ed2-892e-5f85eb685d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33cc350-c3e4-498c-b53c-2663584475aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51086476-6e53-4a55-95fb-3bfaa1413252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2392fe-4b03-46cd-a83a-7452a5cdbc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033a3912-57f7-4f1c-a94e-0a98a15f41d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6910087-4377-46eb-b05f-063bde02b982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7b252b-1e24-4053-8f37-f25a0b026a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a9d1644-24e4-4fc3-9d6d-e1faf2ffc8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a744c7-0659-4c06-9104-da2d6d653cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8728f238-0b6c-4d58-9579-c7493217b235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0e4d055-98db-4798-b2a7-c2ffaabed564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2251e276-94df-4c0d-b99c-a3d39f9ac03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0863f0d4-e8e3-46e5-b59c-a27a0c204693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f689344-61c2-4972-a104-8b6b1e03fb33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3e8d636-a941-4f9b-b603-d87f1420fc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15f22e5f-8316-467f-92a8-9303296e624e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0d15b0-66c3-4fb5-995f-5776ed25ad88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f68cd6-138a-4042-99e0-213124128825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e16e9a6-879f-42f1-9f90-c58548c3c689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a3644d-84aa-494c-a19d-48204b4c0cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821dfb57-3575-41d5-a10d-90fbfa4152dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1796358-e991-4870-b28e-bd1b6d949eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff13aa4-509c-43e5-86a9-9f922ce78054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbcea9a2-64d2-466f-bd96-b8ef68bbcba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77abd5ca-ce78-47d2-981c-bb0954e177ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e1003df-4802-485d-8132-ea5fe9d48046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b52c4a79-4557-40c3-bab0-52098a4a2219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4183d54f-31e9-4ad6-8592-289765375954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 702de977-f0b5-4755-bdec-77569f9078e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc3c9436-5c1f-4950-b523-0d21426ab100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ac792d-abfb-4bee-a91b-71835123a047
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_49
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/test_labels.txt

📊 Raw data loaded:
   Train: X=(2404, 24), y=(2404,)
   Test:  X=(601, 24), y=(601,)

⚠️  Limiting training data: 2404 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  592 samples, 5 features
✅ Client client_49 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 11 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0937 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0849, val=0.0914 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0839, val=0.0905 (↓), lr=0.001000
   • Epoch   4/100: train=0.0831, val=0.0902, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0829, val=0.0894 (↓), lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0779, val=0.0941, patience=6/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 11 Summary - Client client_49
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0272
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0258
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0833, RMSE: 0.2887, MAE: 0.2470, R²: -0.0527

============================================================
🔄 Round 13 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0967 (↓), lr=0.000250
   • Epoch   2/100: train=0.0846, val=0.0962, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0842, val=0.0963, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0962, patience=3/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0836, val=0.0961 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0827, val=0.0963, patience=6/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 13 Summary - Client client_49
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0040
   Val:   Loss=0.0961, RMSE=0.3101, R²=-0.0524
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2451, R²: -0.0345

============================================================
🔄 Round 14 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0808 (↓), lr=0.000063
   • Epoch   2/100: train=0.0902, val=0.0805, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0898, val=0.0804, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0893, val=0.0803, patience=3/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0891, val=0.0802 (↓), lr=0.000063
   • Epoch  11/100: train=0.0881, val=0.0800, patience=6/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 14 Summary - Client client_49
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0345
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0015
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2453, R²: -0.0467

📊 Round 14 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2449, R²: -0.0366

📊 Round 14 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2452, R²: -0.0334

📊 Round 14 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2465, R²: -0.0490

📊 Round 14 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2461, R²: -0.0460

============================================================
🔄 Round 26 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0831 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0903, val=0.0813 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0895, val=0.0802 (↓), lr=0.000063
   • Epoch   4/100: train=0.0889, val=0.0798, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0887, val=0.0796 (↓), lr=0.000063
   • Epoch  11/100: train=0.0876, val=0.0788, patience=3/15, lr=0.000063
   • Epoch  21/100: train=0.0865, val=0.0781, patience=7/15, lr=0.000063
   • Epoch  31/100: train=0.0856, val=0.0780, patience=5/15, lr=0.000063
   • Epoch  41/100: train=0.0849, val=0.0780, patience=15/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 26 Summary - Client client_49
   Epochs: 41/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0053
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0141
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2453, R²: -0.0314

============================================================
🔄 Round 27 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0950 (↓), lr=0.000063
   📉 Epoch 2: LR reduced 0.000063 → 0.000031
   ✓ Epoch   2/100: train=0.0875, val=0.0937 (↓), lr=0.000031
   • Epoch   3/100: train=0.0866, val=0.0933, patience=1/15, lr=0.000031
   ✓ Epoch   4/100: train=0.0863, val=0.0932 (↓), lr=0.000031
   • Epoch   5/100: train=0.0861, val=0.0931, patience=1/15, lr=0.000031
   📉 Epoch 10: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0853, val=0.0929, patience=7/15, lr=0.000016
   📉 Epoch 18: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 27 Summary - Client client_49
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0247
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0514
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2451, R²: -0.0279

📊 Round 27 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2449, R²: -0.0258

============================================================
🔄 Round 29 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.1022 (↓), lr=0.000008
   • Epoch   2/100: train=0.0853, val=0.1019, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0851, val=0.1017, patience=2/15, lr=0.000008
   ✓ Epoch   4/100: train=0.0850, val=0.1015 (↓), lr=0.000008
   • Epoch   5/100: train=0.0849, val=0.1013, patience=1/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0845, val=0.1006, patience=4/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0842, val=0.1001, patience=7/15, lr=0.000002
   📉 Epoch 23: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1003)

============================================================
📊 Round 29 Summary - Client client_49
   Epochs: 29/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0283
   Val:   Loss=0.1003, RMSE=0.3167, R²=-0.0607
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2446, R²: -0.0226

============================================================
🔄 Round 31 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 31 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0415
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.0592
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2445, R²: -0.0216

============================================================
🔄 Round 32 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 32 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0410
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0507
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2444, R²: -0.0208

============================================================
🔄 Round 33 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 33 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0479
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.0815
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2443, R²: -0.0197

============================================================
🔄 Round 36 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 36 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0318
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0657
============================================================


============================================================
🔄 Round 37 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 37 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0429
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0205
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2443, R²: -0.0188

📊 Round 37 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0185

============================================================
🔄 Round 41 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 41 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0335
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0573
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0184

============================================================
🔄 Round 43 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 43 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0353
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0786
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0184

📊 Round 43 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0183

📊 Round 43 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0183

📊 Round 43 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0183

============================================================
🔄 Round 48 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 48 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0355
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0454
============================================================


============================================================
🔄 Round 51 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 51 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0383
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0352
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0181

📊 Round 51 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0181

============================================================
🔄 Round 54 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 54 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0402
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0263
============================================================


============================================================
🔄 Round 55 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 55 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0375
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0435
============================================================


============================================================
🔄 Round 56 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 56 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0375
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0355
============================================================


============================================================
🔄 Round 57 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 57 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0426
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0150
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0181

============================================================
🔄 Round 58 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 58 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0390
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0296
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2442, R²: -0.0181

============================================================
🔄 Round 63 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 63 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0353
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0476
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2441, R²: -0.0175

============================================================
🔄 Round 66 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 66 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=-0.0398
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0207
============================================================


============================================================
🔄 Round 67 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 67 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0328
   Val:   Loss=0.0980, RMSE=0.3131, R²=-0.0502
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2441, R²: -0.0172

============================================================
🔄 Round 71 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 71 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0371
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0325
============================================================


============================================================
🔄 Round 74 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 74 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0345
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0449
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2440, R²: -0.0173

📊 Round 74 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2440, R²: -0.0171

============================================================
🔄 Round 77 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 77 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3019, R²=-0.0394
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0212
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2440, R²: -0.0169

============================================================
🔄 Round 79 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 79 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=-0.0357
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0471
============================================================


============================================================
🔄 Round 80 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 80 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0361
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0353
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2440, R²: -0.0166

📊 Round 80 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2440, R²: -0.0165

📊 Round 80 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2440, R²: -0.0163

📊 Round 80 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0162

📊 Round 80 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0162

📊 Round 80 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0162

📊 Round 80 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0163

============================================================
🔄 Round 88 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 88 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0394
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0188
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2439, R²: -0.0163

============================================================
🔄 Round 90 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 90 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0397
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0204
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2439, R²: -0.0164

============================================================
🔄 Round 93 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 93 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0338
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0548
============================================================


============================================================
🔄 Round 94 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 94 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0275
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0706
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2439, R²: -0.0164

============================================================
🔄 Round 97 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 97 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0403
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0234
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0162

📊 Round 97 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0161

============================================================
🔄 Round 100 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 100 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0313
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0517
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0160

📊 Round 100 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0160

============================================================
🔄 Round 102 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 102 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0260
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.1068
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0160

============================================================
🔄 Round 104 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 104 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0416
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0113
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0159

============================================================
🔄 Round 105 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 105 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0303
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0599
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0159

📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0159

📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0159

📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0159

📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0159

📊 Round 105 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0159

============================================================
🔄 Round 114 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 114 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0377
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0256
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2439, R²: -0.0157

============================================================
🔄 Round 117 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 117 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0386
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0206
============================================================


============================================================
🔄 Round 119 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 119 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0296
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0548
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2438, R²: -0.0156

============================================================
🔄 Round 120 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 120 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0414
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0138
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2438, R²: -0.0155

============================================================
🔄 Round 122 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 122 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0311
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0480
============================================================


============================================================
🔄 Round 123 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0917, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 123 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=-0.0351
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0338
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2438, R²: -0.0152

============================================================
🔄 Round 127 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 127 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0336
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0371
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2438, R²: -0.0152

============================================================
🔄 Round 129 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 129 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0339
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0365
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2438, R²: -0.0152

============================================================
🔄 Round 130 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 130 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0284
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0566
============================================================


============================================================
🔄 Round 135 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 135 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0288
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0545
============================================================


============================================================
🔄 Round 136 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 136 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0313
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0799
============================================================


============================================================
🔄 Round 137 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 137 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0319
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0426
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2438, R²: -0.0148

============================================================
🔄 Round 138 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 138 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0327
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0362
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2438, R²: -0.0146

============================================================
🔄 Round 140 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.1034 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.1034, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.1034, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.1034, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.1034, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.1033, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1034)

============================================================
📊 Round 140 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0280
   Val:   Loss=0.1034, RMSE=0.3215, R²=-0.0505
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2437, R²: -0.0146

============================================================
🔄 Round 141 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 141 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0333
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0332
============================================================


============================================================
🔄 Round 142 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 142 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0319
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0424
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2437, R²: -0.0145

============================================================
🔄 Round 146 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 146 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0330
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0342
============================================================


============================================================
🔄 Round 147 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 147 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0303
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0569
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2437, R²: -0.0144

📊 Round 147 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2437, R²: -0.0143

============================================================
🔄 Round 152 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 152 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0398
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0254
============================================================


============================================================
🔄 Round 154 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.1004, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1005)

============================================================
📊 Round 154 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0255
   Val:   Loss=0.1005, RMSE=0.3170, R²=-0.0581
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2437, R²: -0.0140

============================================================
🔄 Round 155 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 155 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0298
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0614
============================================================


============================================================
🔄 Round 157 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 157 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0363
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0285
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2437, R²: -0.0139

============================================================
🔄 Round 159 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 159 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0372
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0143
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2437, R²: -0.0138

📊 Round 159 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0137

📊 Round 159 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0136

============================================================
🔄 Round 166 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 166 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0380
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0278
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0136

📊 Round 166 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0136

============================================================
🔄 Round 172 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 172 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0321
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0418
============================================================


============================================================
🔄 Round 176 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 176 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0326
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0374
============================================================


============================================================
🔄 Round 177 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 177 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0384
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0138
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0136

============================================================
🔄 Round 181 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 181 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0327
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0333
============================================================


============================================================
🔄 Round 182 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.1009 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.1009, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.1009, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.1009, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.1009, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.1008, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1009)

============================================================
📊 Round 182 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0180
   Val:   Loss=0.1009, RMSE=0.3177, R²=-0.0840
============================================================


============================================================
🔄 Round 184 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 184 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0274
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0741
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0136

============================================================
🔄 Round 186 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 186 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0344
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0274
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0136

============================================================
🔄 Round 191 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 191 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0329
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0333
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0135

📊 Round 191 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2436, R²: -0.0136

📊 Round 191 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2436, R²: -0.0135

============================================================
🔄 Round 197 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 197 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0314
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0376
============================================================


============================================================
🔄 Round 198 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 198 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0330
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0462
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2436, R²: -0.0135

============================================================
🔄 Round 201 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 201 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0318
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0426
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2436, R²: -0.0134

============================================================
🔄 Round 202 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 202 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0379
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0128
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2436, R²: -0.0134

📊 Round 202 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2436, R²: -0.0134

============================================================
🔄 Round 205 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 205 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0297
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0623
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2436, R²: -0.0133

❌ Client client_49 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
