[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46995784-0e21-427f-9d19-0c7d5b18f9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234682d0-5f48-4a68-9267-0cc06f8e1cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f94d801-088d-4e2a-b6be-a4f58d4b656f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf4f4c41-0f90-4497-98f6-e05dd2a7d8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdce13c0-5665-4b10-af12-5ece6fb16844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c82b87-cd1c-40f5-900b-61fb12873d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9304e52c-4896-4787-8ca8-93898f7b1701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 187221ca-01c2-4c54-8695-bc5e4a7b78f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56393f0c-5e49-45fa-8729-efb73b1f4e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f79c8bf5-6266-4481-b272-b2d892c6935d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2dc9ab8-0a2b-477c-b76a-2bca5c1f33d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61a9662-cd5a-457c-944e-8199a6626d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ac80de-0faa-4238-9915-2cfb5d6b4b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 848d1281-220b-420f-8327-469dac5f8e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa03f556-d282-40b6-9fdc-c7c5ce692424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02000db8-2ee5-47d5-a195-732d60d0e8cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f57ed497-3ece-44bd-abb5-95625e1f0324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcd208ab-73c0-499d-a092-785ed08b8cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7fb10ec-039b-4d39-a437-f53d3b988dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7027de87-deca-4185-b3c0-daca7f191a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a2e8ac3-cc11-4bbb-a3e2-946c4973a257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bd9e564-773f-49eb-9e55-fe6047da7621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a9eaf4d-225d-4a6b-a0d9-a709cebde294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cda81c8-2b4b-4a17-8f57-776bbd57fe97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 035f8bdc-206e-4f16-ae28-ceb855e7ed70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc19138-a55d-4bd8-ab77-eb7bd5f3efc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 752c476a-beee-4a64-9f8a-fd20aed78426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a85e166-6929-40bd-892b-5da92979fc66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9633991-ef33-4d86-8f1d-39b03cae2770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8113071c-14fc-41c0-92bb-076932b4745b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44adee11-1dc8-4c9f-af26-dd122308b1d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5cea8d6-22ee-458c-bee2-8715d94e146a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a25b89d4-4c12-40db-87e3-df25bb863581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9129229d-32ce-4faf-b3e2-d841bc06d4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de60738f-2236-48ea-82a6-74aab7f17c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d32cbeb-3ab7-4252-923b-b8ad776c3c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7752a9-29c3-4546-9637-3d038c288f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5bc8295-cc8c-4ccb-b441-18a6f01c3cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1205ae15-097f-46a9-865b-445fd2269da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe70ae4-dc67-47de-82d9-3e23d22896f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c3e747d-654d-4b09-bd10-d79caa487d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c48cec-db37-4819-9c3c-1760f2d5f67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ff2ff2-d1f1-4a35-a9a0-63eb70463a45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6468dd-1676-47a0-b877-5c42976c8298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825b9fa9-711c-483c-986e-d6f1bd95d34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe12378-ec22-455d-b545-699b8e794ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46db45b7-f5b5-4bc2-8cd7-6f45f4c0bd0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 448f1818-46ec-4ac7-bede-d24288f76f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62b368de-6eda-4b07-8b6c-19b35a679dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d38a6f-f824-4f19-91e7-c7b60d6ae3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bc479d5-aee3-42d3-ac78-e4091030377c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abba4673-fec7-4a62-b26b-d51af7d7c728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe348ca7-7fe5-4231-adbc-10515fa44aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a9c07c-a000-49fb-b3ef-7bcfe1de8e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d7e6842-c166-4445-889c-842aa804674d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a1eaca-f791-427d-af69-2e63e2205566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0d2541-dd5d-46cc-b0c1-0cf867e0aafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca7f30b2-dfab-4c7a-89e9-a8150f550050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe142c57-8e6d-4650-9a2f-c0e04bee8a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b6f786-c418-4aaf-8d68-fdc09ad16651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a28f01-7f64-4d70-99b3-a6d73ffed449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecab84d4-bb02-413b-af6d-22c031746e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10a07e02-5836-4b69-873b-8f272d4fdea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c89e3ca-807e-4067-8db2-29032acebb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bee01511-c542-4600-82af-edeefe1f3a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424db08d-ce4b-43c2-97af-3318492eadf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0b6b336-2034-453c-b7d9-e5008ede91bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d120408-ed60-40e1-91fc-26ee87ea8e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1459344-c48a-4ded-9a13-96313cb289ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc32df6-502e-4be5-9279-1df0e8b6c4df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9b59aba-a305-4a65-86ca-65ec61255bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 292c54d5-cc72-4690-adfb-73c075ec3c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd7b682-68f8-46dd-a2f4-ee2b1d3d6001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6413f121-c072-44ac-9bec-7c8540717124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91a24a8a-4f18-40cc-8919-80066c23448e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde48dbf-6a11-4b36-9f64-325c60233faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 128c4c43-601c-43af-a378-1a3ed57c7aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 159cae0a-2eeb-44e4-ae3f-de79deabde12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c22cff-7b0e-458f-bfdd-f5d4d76ad554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d8dc06-d426-4eb0-8363-9c53f9b552f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2455dec-2bf9-41c4-87e9-4ceb762a08f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b32d0ef-8a28-47d2-bd8e-37be3d4e3142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca5d5f37-ac36-4a73-921a-cbb8426ee3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4211c119-aaf2-411c-8557-05717c66a3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2c11f8-8af0-4f98-902d-58c846d9a258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29ad411c-9f66-44fc-adbf-1477fd6d1917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904f042a-de41-497b-ae3a-bc71445678c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e3e304a-ed04-454d-80fe-c3663e30ce5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca4613cf-663f-4156-b816-129c570f2ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aaa8059-b1e3-4e87-87c1-085e25d96dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1bee171-0c6c-42e3-8396-d648e5e7b4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2e146f-6770-4a1a-ae63-0ed580811f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b91bc75-e8be-4d01-a964-851821abab05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c34b1f74-e69b-4065-9636-7a47aa5b9832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d94b426-a98a-4302-80c1-298bac74c007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c830b72d-0e16-4736-8b46-4145da33c03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7c014e3-f2fd-4cce-8970-751a2ca6913d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def1b1b0-fa6e-43a9-8bec-805816bd057a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d6721ce-eba7-45e1-bbcf-95a639e8a1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1785c96c-08fd-42c6-b1e2-ad4483cb1b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea571c5-426a-4c0d-86cd-4ba741781d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ede15be-b68e-4239-9cc5-39cc42d1d043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b17f7bc-0f89-4784-9b1a-f10e062efe0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 638fb69f-9294-45c8-80da-ddff29564f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff9d875-3587-49ea-8eef-81cda8e4b1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf3f5a6-d5a0-456d-b0ad-108464655f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead7b064-6fcb-42ac-baa9-20ce9cd8290c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421f7202-ecc6-4381-a791-fe863ebf9fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 762756a1-bdf0-4bf1-a1cc-ec44114ecf93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ae477b-ed42-4155-9082-0cd024834cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60fbf373-a818-43fd-a827-84a9b585e9b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e458933c-d38f-4aa3-acfb-36709a494a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf9b80b0-2ae8-4bb4-8f3f-30f7e338bfdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49162518-cee6-41c3-ac30-461a35ff37c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 737391e5-d2cd-4200-bc60-ff2625aa03df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a111bb-be37-4ef4-8901-57c184fc94d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c81651c-1b72-44e6-99e3-0c1f424052ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e639160e-40e0-4776-a8fa-02bc2d3c276f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79534e3c-2144-405b-956c-1911b6bed7a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987ac8c9-fd5f-4138-a104-3af2e50abc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1253521-4a1f-4ed8-9708-90f321577a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da7a5fe-bdfc-4dec-a97b-d118d9709d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e07745-db8e-4478-bc86-b09c6f226637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c738169-ac8b-41a4-b943-70e335e24ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d725664-d9fe-4c22-95b1-254dabfbc96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988a8267-c427-4d09-9b32-c8878be626e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fa721e9-c75f-41fe-ba66-b6ffd366ee1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b15c903-f3dd-46f4-98fe-9e9abe3d6439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5dd166-14da-42f8-ba66-7b2fdc22aecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c201821-e7b5-41b4-83d6-838157004105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57a27c76-262a-4ec9-9c84-af3a971eed73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec0dde39-4c49-4315-b0f0-2abac6469b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521410c5-0bd0-4e9d-973c-fa7f19b92c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df270537-3b99-4bcc-85cd-3f8eca29c481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd5dcde-f920-40ba-9d0c-b0ddd0e9fc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60de695-9ff3-4226-9893-aef80bc2b3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e33d284-fca5-4749-9b4e-f96e7cb9b88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6410b21a-c57b-475c-b490-f7ebb05ba64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71568097-c665-4fef-a890-e66e9b9185d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67dd7935-93a2-485f-a425-3e454ad66e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1896813a-8899-413d-b0d3-b65269616e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 110405de-0215-4ad4-8715-b0d31e8313ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ac9a38-eb7e-4132-91d6-1b4d4d804006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4479dd-e076-4a8b-bc62-44a4e320186e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d614a8e-58c5-4527-8ddd-8ca6ad9d9f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13b3bae-d2ed-4895-a79a-dbea76046320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea31c0f-ee25-4674-8b84-6905152b6de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 070f8eb5-f221-41f5-a62c-ddfbb99b7187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00b842ea-913c-46d6-a891-b9dff9aa5e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce69e85-6c80-4640-8a5e-912ba15c155b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f882b9-ab83-4ee6-b36c-b97f5ca8f7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd2ff7c6-a6c9-47b9-8310-67422f44ac17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09d1793d-8997-4599-ad4d-562d67ee65aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f40027-7ee5-4776-a90b-b4252985030c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783d9c77-bedb-4dda-8cb4-2d2ec0df73e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f12fa9-a572-46ad-8488-e2ad4af64ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e437881-cd70-44b9-827c-885ae03f9e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fb0cd88-54bf-46c7-94e0-fcb80a66e480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf7dad2-cf3b-4bc2-ba6d-3c20d7d6828d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c04d23-a94a-4f5d-aafa-97efdbd9e9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3e6f8b-ac6f-4139-b860-b39bf2e5c10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5158bdc9-f6ad-4555-b8bb-360ecd0bc1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be7e3d2-afdf-4484-addf-357d1f5ca041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714fe898-38c7-472a-b5e4-db69aadeb1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7462676b-a6fe-4c7c-9b21-4169f93af7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1ec57f8-415a-4fc0-bf8b-e1cf3936c127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9828bb-beee-493b-882b-61ae63857615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa1c91d-af9f-4676-84ea-eb90b6b0c205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca0457d-972e-40e2-80b1-2067dc89c592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59a8ab23-0cb4-4dba-93c8-64dcb58624bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d048180b-a4ae-409d-bbd7-ebd2649e38d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e7fb2a-2a96-424d-aed1-485461d5f483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7741d49-8b86-4b48-99a0-03965d8124d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc5bfb03-b504-4de6-ab55-8f06ef2db1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e675e461-1edb-4e5a-bbc3-605d6324f810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c323a08b-b625-4303-b977-4e98fbae0eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67173a73-7cbb-4aa1-a3e8-b7f64929f965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c6db433-d94c-4dde-93ce-d18988408640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21faf9a8-d88b-4aff-8bb7-4f12cc6892fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be14fe4-1a88-4a83-8445-efdd5beb0756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2ce798f-7ab8-4cbe-9250-91345c1a40dd
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_4
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_4/test_labels.txt

📊 Raw data loaded:
   Train: X=(724, 24), y=(724,)
   Test:  X=(181, 24), y=(181,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 715 samples, 5 features
   Test:  172 samples, 5 features
✅ Client client_4 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2558, val=0.0882 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0956, val=0.0754 (↓), lr=0.001000
   • Epoch   3/100: train=0.0862, val=0.0762, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0862, val=0.0740 (↓), lr=0.001000
   • Epoch   5/100: train=0.0855, val=0.0742, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0849, val=0.0743, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 1 Summary - Client client_4
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0071
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0071
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2489, R²: -0.0080

============================================================
🔄 Round 4 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1017, val=0.0835 (↓), lr=0.000250
   • Epoch   2/100: train=0.0848, val=0.0857, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0845, val=0.0827 (↓), lr=0.000250
   • Epoch   4/100: train=0.0835, val=0.0829, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0834, val=0.0833, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0831, val=0.0832, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 4 Summary - Client client_4
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0071
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0247
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0087

============================================================
🔄 Round 8 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0956 (↓), lr=0.000063
   • Epoch   2/100: train=0.0801, val=0.0953, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0800, val=0.0951 (↓), lr=0.000063
   • Epoch   4/100: train=0.0799, val=0.0950, patience=1/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0798, val=0.0950, patience=2/15, lr=0.000031
   • Epoch  11/100: train=0.0796, val=0.0951, patience=8/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 8 Summary - Client client_4
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0118
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0092
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0902, RMSE: 0.3003, MAE: 0.2542, R²: -0.0835

📊 Round 8 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2482, R²: -0.0003

============================================================
🔄 Round 11 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0864 (↓), lr=0.000016
   • Epoch   2/100: train=0.0822, val=0.0864, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0821, val=0.0864, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0821, val=0.0864, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0820, val=0.0864, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0819, val=0.0865, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 11 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0073
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0004
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2505, R²: -0.0197

📊 Round 11 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2487, R²: -0.0090

📊 Round 11 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2494, R²: -0.0175

📊 Round 11 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: 0.0001

📊 Round 11 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2499, R²: -0.0035

============================================================
🔄 Round 19 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0841 (↓), lr=0.000004
   • Epoch   2/100: train=0.0799, val=0.0841, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0798, val=0.0840, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0797, val=0.0840, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0795, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 19 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0206
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0722
============================================================


============================================================
🔄 Round 21 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 21 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0622
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0413
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2497, R²: -0.0058

📊 Round 21 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2488, R²: -0.0003

============================================================
🔄 Round 24 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 24 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0423
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0450
============================================================


============================================================
🔄 Round 25 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 25 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0544
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0017
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2483, R²: 0.0067

============================================================
🔄 Round 26 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 26 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0458
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0456
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2485, R²: 0.0061

============================================================
🔄 Round 27 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 27 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0531
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0007
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2491, R²: 0.0030

📊 Round 27 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2492, R²: 0.0020

📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0008

📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0004

📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0001

============================================================
🔄 Round 35 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 35 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0399
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0298
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0002

📊 Round 35 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0003

📊 Round 35 Test Metrics:
   Loss: 0.0833, RMSE: 0.2885, MAE: 0.2495, R²: -0.0003

============================================================
🔄 Round 40 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 40 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0329
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0529
============================================================


============================================================
🔄 Round 41 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 41 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0405
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0094
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: -0.0002

============================================================
🔄 Round 43 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 43 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0289
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0762
============================================================


============================================================
🔄 Round 44 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 44 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0352
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0469
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: 0.0000

============================================================
🔄 Round 50 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 50 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0455
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0096
============================================================


============================================================
🔄 Round 52 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 52 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0429
   Val:   Loss=0.0817, RMSE=0.2857, R²=0.0177
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2495, R²: 0.0003

============================================================
🔄 Round 53 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 53 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0414
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0243
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0004

============================================================
🔄 Round 56 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 56 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0436
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0121
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0005

============================================================
🔄 Round 57 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 57 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0402
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0299
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0006

📊 Round 57 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0006

============================================================
🔄 Round 59 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 59 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0426
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0139
============================================================


============================================================
🔄 Round 60 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 60 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0387
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0385
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0007

============================================================
🔄 Round 62 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 62 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0378
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0397
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0006

📊 Round 62 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0005

============================================================
🔄 Round 65 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 65 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0437
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0121
============================================================


============================================================
🔄 Round 66 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 66 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0347
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0316
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: 0.0004

📊 Round 66 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0005

============================================================
🔄 Round 68 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 68 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0498
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0155
============================================================


============================================================
🔄 Round 69 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 69 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0380
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0364
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0008

============================================================
🔄 Round 71 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 71 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0428
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0174
============================================================


============================================================
🔄 Round 74 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 74 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0264
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0480
============================================================


============================================================
🔄 Round 75 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 75 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0386
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0354
============================================================


============================================================
🔄 Round 76 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 76 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0383
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0368
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

📊 Round 76 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

📊 Round 76 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0010

📊 Round 76 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0009

📊 Round 76 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0008

============================================================
🔄 Round 85 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 85 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0268
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0726
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

📊 Round 85 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0013

============================================================
🔄 Round 90 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 90 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0391
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0215
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0016

============================================================
🔄 Round 94 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 94 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0218
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0922
============================================================


============================================================
🔄 Round 95 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 95 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0420
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0194
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0019

============================================================
🔄 Round 97 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 97 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0376
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0247
============================================================


============================================================
🔄 Round 98 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 98 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0385
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0179
============================================================


============================================================
🔄 Round 101 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 101 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0369
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0335
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0019

============================================================
🔄 Round 102 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 102 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0355
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0427
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0019

============================================================
🔄 Round 103 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 103 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0382
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0194
============================================================


============================================================
🔄 Round 105 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 105 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0411
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0224
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0019

============================================================
🔄 Round 107 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 107 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0345
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0013
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0021

============================================================
🔄 Round 111 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 111 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0405
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0245
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0021

📊 Round 111 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0020

📊 Round 111 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0020

============================================================
🔄 Round 116 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 116 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0333
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0515
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0020

============================================================
🔄 Round 118 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 118 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0384
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0266
============================================================


============================================================
🔄 Round 119 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 119 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0402
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0223
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0018

============================================================
🔄 Round 122 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 122 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0365
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0281
============================================================


============================================================
🔄 Round 124 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 124 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0407
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0155
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0016

📊 Round 124 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0016

============================================================
🔄 Round 128 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 128 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0330
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0195
============================================================


============================================================
🔄 Round 129 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 129 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0390
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0186
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0017

📊 Round 129 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0017

📊 Round 129 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0015

📊 Round 129 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0015

============================================================
🔄 Round 136 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 136 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0313
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0500
============================================================


============================================================
🔄 Round 137 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 137 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0437
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0025
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2493, R²: 0.0014

📊 Round 137 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

============================================================
🔄 Round 142 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 142 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0389
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0159
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

============================================================
🔄 Round 144 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 144 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0356
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0277
============================================================


============================================================
🔄 Round 145 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 145 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0316
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0043
============================================================


============================================================
🔄 Round 146 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 146 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0386
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0161
============================================================


============================================================
🔄 Round 147 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 147 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0339
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0348
============================================================


============================================================
🔄 Round 148 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 148 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0368
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0121
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0013

📊 Round 148 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

============================================================
🔄 Round 152 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 152 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0359
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0255
============================================================


============================================================
🔄 Round 154 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 154 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0302
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0413
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

============================================================
🔄 Round 156 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 156 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0411
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0104
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

📊 Round 156 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0012

============================================================
🔄 Round 158 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 158 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0340
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0336
============================================================


============================================================
🔄 Round 162 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 162 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0304
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0183
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2494, R²: 0.0009

📊 Round 162 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: 0.0009

📊 Round 162 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2495, R²: 0.0009

============================================================
🔄 Round 167 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 167 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0297
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0334
============================================================


============================================================
🔄 Round 168 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 168 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0338
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0294
============================================================


============================================================
🔄 Round 169 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 169 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0335
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0221
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0011

============================================================
🔄 Round 170 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 170 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0412
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0002
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0011

📊 Round 170 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0013

📊 Round 170 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0013

============================================================
🔄 Round 174 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 174 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0326
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0359
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0014

============================================================
🔄 Round 175 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 175 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0325
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0412
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0014

📊 Round 175 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0015

============================================================
🔄 Round 178 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 178 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0280
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0523
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0015

============================================================
🔄 Round 179 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 179 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0241
   Val:   Loss=0.0716, RMSE=0.2677, R²=0.0187
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0016

============================================================
🔄 Round 181 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 181 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0349
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0315
============================================================


============================================================
🔄 Round 182 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 182 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0348
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0331
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2494, R²: 0.0017

============================================================
🔄 Round 183 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 183 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0310
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0180
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0018

============================================================
🔄 Round 184 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 184 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0424
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0026
============================================================


============================================================
🔄 Round 185 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 185 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0341
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0362
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0018

📊 Round 185 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0018

============================================================
🔄 Round 187 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 187 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0368
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0234
============================================================


============================================================
🔄 Round 189 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 189 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0311
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0470
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0019

📊 Round 189 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0020

📊 Round 189 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0020

============================================================
🔄 Round 192 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 192 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0350
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0288
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0021

📊 Round 192 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0021

============================================================
🔄 Round 196 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 196 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0369
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0250
============================================================


============================================================
🔄 Round 197 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 197 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0336
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0347
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2493, R²: 0.0022

============================================================
🔄 Round 198 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 198 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0399
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0035
============================================================


============================================================
🔄 Round 199 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 199 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0349
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0336
============================================================


============================================================
🔄 Round 200 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 200 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0283
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0457
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0021

============================================================
🔄 Round 202 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 202 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0351
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0305
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0021

📊 Round 202 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0020

============================================================
🔄 Round 207 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 207 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0445
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0193
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0019

============================================================
🔄 Round 210 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 210 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0328
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0370
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2493, R²: 0.0019

============================================================
🔄 Round 211 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 211 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0369
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0222
============================================================


❌ Client client_4 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
