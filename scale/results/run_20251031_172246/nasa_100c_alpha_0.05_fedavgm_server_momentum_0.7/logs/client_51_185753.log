[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e26ca7a5-752f-44e5-a5b3-762ad5640ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1547ce35-72ce-4542-be51-c0f6f02dcb28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f85aa4b5-8955-447b-a6c2-55fd8bf60ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02a85ce-da16-4fd7-83ac-ced0b84b6606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c357b6-3d7f-444b-9d5b-fb4c0e2ce637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0db21473-f5a4-4f54-ba5a-87bb3758957d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 896013b8-d6d1-4416-b4a7-47acf2f00b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3555e900-d130-4a3f-b05f-1752fd75a406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f9d458-c472-4054-ae43-952d74c0d218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c6c8a6-7c29-4a8c-ae14-d9033c9e3ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a2ce77-9662-4e9b-96d6-22bd1a093865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec11ef2c-2361-45d8-91cc-8ba98b3b4a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60853c6b-f3db-4b1d-8037-95fd8d915768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9c5f684-6afa-4410-8665-2dc53dd5c80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff286e5-d614-4235-8b9c-686ac3cf7381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3dba38f-afeb-41ba-ad64-ca787cf21d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b65bdd8-934b-4061-9b70-09044952dd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 756e5cb4-f6d6-445d-a8d6-b3f45bdbb85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb25eb4-69e5-4fc4-b371-4c05975ca828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448eb541-4530-4ad4-90c2-bf5819bcdc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19e42ae3-13b5-439c-befe-8c6c22fab0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f843907-f0b0-46e9-bae6-661fe2dbf51c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c31c5b3-a766-4f95-81e5-4daa73fa1817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9392bdb-0f46-4f81-81b9-259faa6bc108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c1159d-b492-484b-9665-cf4f6b881908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a8f9b67-aa64-4149-8fd8-e03dabfc095c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d66f5ae9-6fbe-4657-998d-07b9003895c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44c82b59-fb00-4f81-a1bc-01b5ec3665db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f872a40-529f-4814-a72c-0c90055e3284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9533292-5c6e-49b0-918b-1a0d627901a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e734170-2d00-4485-b67c-a1897c180ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b2be0d-5719-4242-855a-fb1b5888cd95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e251cc3b-8df6-47ae-b6e6-8a7c48e5e021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c7f3bae-e76c-4107-a94d-23bbdf188024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 764eb47e-35c1-421d-872f-da92ba60d058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e60c2a66-5ece-44f8-bc5a-a6016c936df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8235940-cd22-4fee-8e4e-97fccf35b1a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aa40ae6-5a66-4e8a-96f3-6d556c3cdd32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56dc0051-39c2-4ff4-906a-11deb7b78d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 978ea95c-ba08-4541-b62b-5d07d49c8c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b991c68d-1798-4654-8ccd-abd7c75ba9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c86396f-81ea-470c-9ea3-d314d21e3a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331dd169-e8c6-48ac-8f42-90de0d6f3914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03ba7ba9-aeee-4288-824d-51ab67294c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd62537-f161-4861-84d9-5deb7a9e785f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85e19eae-09bf-4c9e-a9fd-b5339245ead1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe878124-5967-4734-9a15-d30db90580ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f74f1b-2ddc-4661-9bc8-13117f93775e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e75e34f-0c74-4460-b4de-0f23e2c380de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3572c3ee-abea-4500-a6c0-c87ab0fbb4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691ccb7c-33fe-419f-add7-903ef0029f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79912299-107b-45e4-a354-7ff93488ba71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6371564-708e-4a65-8866-ae20954c0b96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a54848eb-2e4f-490c-9946-7c4086f7c570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80478351-a544-4300-a9b2-c1f544b6e360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016a4bfb-956d-45a8-a035-c5c341647b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4814df7d-1ade-4f94-9211-f7a2bbc18513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66bfa60-e675-49c9-997e-f341591027e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c351a845-10e7-4aed-8fab-e84b76e1fc70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e9109c5-d8e9-4b7d-b9f0-d33fa642ed40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d8ee6e-a68f-4fb2-8437-720967a7f0ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812e7805-0fdd-48f8-a36c-11b04cc69cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35887af4-261a-4e0e-adb6-650ac22fedb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a550eb82-8d25-4766-ba61-86fe7ac9b2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f494d8a8-224e-4673-bd81-3217a3e2d79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31f8579b-6eca-4348-aa7c-42d6dab3c2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aacbf55-7bcf-4da2-82a6-c657c3cfc3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4eda9d9-9333-4447-a58f-1a22575190ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21096d45-7238-4975-87d5-fc6ffa47b529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2e526b-42c1-43d8-ab2c-59cb68c3fa37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9afd4e-9ec6-4391-84d5-afd44dbb6251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04a7d661-9524-4b03-a8bc-2165a9cae265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba4318e-967e-450c-af54-8cf37d3e0d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3227b52a-cb4e-4ba9-af29-7188c8b633f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 696839b8-628f-48d9-9d11-4fde35a02d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3bcf936-854f-44b8-8041-d99697ca66b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd25e344-79aa-4448-92b4-cc4d7cebf199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e157bdf-8946-4c45-b800-c6d7d7a7a2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a509122-83d1-42e0-baeb-b38960e13c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214b1858-716e-4d73-87e3-4c6451467d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d9e824-6681-48e3-a5e9-5d0dbcaf4812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccd1a7c-06b1-407c-b153-db60164157bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11394eac-cc57-4889-a633-f7d417143e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 386575c6-03ba-4907-814b-4bb5e4810d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea8c1d8-c4a0-4320-bb43-eb144a3d63b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0540d56f-4ab6-462a-84c8-0c54245efe83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf2bf04-2a1e-44fb-93e6-11accd49c615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 193708fe-06fc-45c1-b2bd-157e701cab08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcaf0192-2bc6-48e1-91ea-eb0cf266889c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61a0e43c-990b-48c3-ae0b-9227d91c29b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 747b30a0-60dd-4510-9316-8f1e9c9e0954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a37a9b1-c764-4d72-a192-d8a525920307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f42c3b-e34e-4cf5-b7f1-71b2b229f029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2683991-ae91-413d-be65-79f9976502fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4314862-14bb-458b-9d21-53cd0e2428ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7898643-cdf6-47a6-9add-8af285909fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11275fda-e24b-45e2-9e7c-eb346b8f7f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f809591e-a8ec-4d82-ba50-c8e954f43c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a068ae72-e59a-4164-8c0e-e88b1fd9821a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c12a96cf-53e7-46f5-a376-a95e182361c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae536a04-be0b-4cb2-a1b0-5f212934c5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8292e130-9e43-4cee-b781-bdfc99ebc3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fceaf00c-76fb-443b-9c6b-f13f2840be5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 327aa3ff-6298-47a4-9d3a-b80d04d0e730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 173dd774-0ef6-4775-b201-e71cc8dca25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a716d462-428d-42b5-9e3c-f205140c11a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54065e8f-328e-4bc0-a045-1bc098b83409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d12421-f537-4701-8afc-d0f58cc5db7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b7c9a9-26f8-4c6f-a970-d8e9a53f0de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e784cbb9-65b5-4ab2-91cb-517d7b231076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc392b36-69e4-4cce-8cba-12d27bc44e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5182969-e836-4561-9f58-38d86666cbbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a807158-3143-4deb-b540-1042cf9e7802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a434ea-0a35-4cb6-b535-bee1eae6b7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 627c05bc-ca56-4d2b-9c55-c7cc112767e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f991d643-2995-452a-b820-931c45f77e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c35c9ca-1541-4821-8405-ac08a7164ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257de23f-204f-4f41-a2d3-b658ab4feb31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a038d50d-1c00-4f73-997b-ce18b97a1280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b3a875-cf45-40e9-81fc-ce960b3a580f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215fa581-5b46-42c5-8302-e808a094882c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d508cc2-684c-47c4-9561-975cae974ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929794c2-3e51-417a-8261-85a6dc6487e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f28945c9-4df4-40bd-888c-5c0569dae01d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c3ac9f8-7e4d-4a53-bec8-6d4fb491ca49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6104915-ca00-4a49-8129-514bb877ffa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 580332e7-9e6d-4aa0-81fe-18a11afc7f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b0520c-d06a-49e4-ab02-7a82f0a0baef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d197f134-f730-4a51-8f66-05c52c6457a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7655d83a-f651-4932-9dae-9ff559b84cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1cebfe5-12ed-406b-91b4-c88d934d564c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3207d736-473d-4626-a370-669d5065ffcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44353a69-f6a8-4d57-ba9b-3f5ad8ee4f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a832961-74e1-4e8a-a37e-f3378bdc57ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bbd2c3b-44e7-4313-a921-1dc76a847e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55efc79a-5133-4395-9cc6-33939ef05a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95390490-082c-414b-99ee-50778c61920c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90fe4c86-a8ac-4fe4-a945-e64bc7160752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51dff80-43a6-42f6-ae55-f6e98b788c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27071ce1-7bdb-41a2-ad32-bbf18c1414e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd3af79-0903-497c-9726-863d6ebcac87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b36a7e-0c7f-44c9-b3ec-03944047b615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb649c74-de9f-4895-9d7d-f061548deb3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dff17fa-d14e-42f8-ba8a-d26710c5c395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ddb5f50-e2af-4160-ac3a-72ac2a8f7392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8940ecdd-2de4-4ded-948d-480adcaa3cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64591f3c-bc04-40f5-9e3d-d8c95e43de47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5b1cba-f329-4ee2-abd4-156333a36a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd098ccc-44ed-4766-a0a0-85ba48933e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8931e58f-06cc-4301-b2e9-1b7588a07d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01100c7d-f58b-4b6d-9cb2-f93e196a2ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23aaa1e-5573-40d5-942b-749b75c72f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2672fbd5-2056-4b46-a3f0-387fd1262de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a252c34f-4bfb-409d-8223-698f3680d1ed
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_51
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/test_labels.txt

📊 Raw data loaded:
   Train: X=(505, 24), y=(505,)
   Test:  X=(127, 24), y=(127,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 496 samples, 5 features
   Test:  118 samples, 5 features
✅ Client client_51 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2396, R²: 0.0076

============================================================
🔄 Round 15 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0818 (↓), lr=0.001000
   • Epoch   2/100: train=0.0789, val=0.0832, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0777, val=0.0818, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0762, val=0.0817, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0749, val=0.0817, patience=4/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0658, val=0.0852, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 15 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0622
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0156
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2398, R²: 0.0013

============================================================
🔄 Round 16 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0745 (↓), lr=0.000500
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0808, val=0.0768, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0798, val=0.0765, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0789, val=0.0771, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0753, val=0.0774, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 16 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0365
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0031
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0739, RMSE: 0.2719, MAE: 0.2343, R²: 0.0392

============================================================
🔄 Round 24 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0740 (↓), lr=0.000125
   • Epoch   2/100: train=0.0823, val=0.0741, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0816, val=0.0742, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0810, val=0.0741, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0804, val=0.0738, patience=4/15, lr=0.000125
   • Epoch  11/100: train=0.0776, val=0.0733, patience=5/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0748, val=0.0740, patience=15/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 24 Summary - Client client_51
   Epochs: 21/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0756
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0694
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0754, RMSE: 0.2746, MAE: 0.2374, R²: 0.0206

============================================================
🔄 Round 27 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0667 (↓), lr=0.000063
   • Epoch   2/100: train=0.0867, val=0.0665, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0864, val=0.0663, patience=2/15, lr=0.000063
   ✓ Epoch   4/100: train=0.0862, val=0.0661 (↓), lr=0.000063
   • Epoch   5/100: train=0.0860, val=0.0660, patience=1/15, lr=0.000063
   • Epoch  11/100: train=0.0851, val=0.0660, patience=7/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 27 Summary - Client client_51
   Epochs: 19/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0476
   Val:   Loss=0.0661, RMSE=0.2571, R²=0.0531
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0756, RMSE: 0.2749, MAE: 0.2379, R²: 0.0181

============================================================
🔄 Round 28 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0777 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   • Epoch   2/100: train=0.0832, val=0.0775, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0831, val=0.0774, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0830, val=0.0773, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0830, val=0.0773, patience=4/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0827, val=0.0770, patience=4/15, lr=0.000008
   📉 Epoch 18: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0825, val=0.0768, patience=14/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 28 Summary - Client client_51
   Epochs: 22/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0431
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0472
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2382, R²: 0.0162

📊 Round 28 Test Metrics:
   Loss: 0.0758, RMSE: 0.2754, MAE: 0.2385, R²: 0.0149

============================================================
🔄 Round 30 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0801 (↓), lr=0.000004
   • Epoch   2/100: train=0.0830, val=0.0800, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0829, val=0.0800, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0829, val=0.0800, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0829, val=0.0800, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0828, val=0.0799, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 30 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0381
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0253
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2386, R²: 0.0139

📊 Round 30 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2388, R²: 0.0132

📊 Round 30 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2388, R²: 0.0129

📊 Round 30 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2389, R²: 0.0126

============================================================
🔄 Round 35 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 35 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0373
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0135
============================================================


============================================================
🔄 Round 39 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 39 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0360
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0269
============================================================


============================================================
🔄 Round 40 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 40 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0261
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0606
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2390, R²: 0.0119

📊 Round 40 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2390, R²: 0.0119

============================================================
🔄 Round 42 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 42 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0337
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0380
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

📊 Round 42 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

============================================================
🔄 Round 45 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 45 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0431
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0033
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

============================================================
🔄 Round 47 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 47 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0333
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0168
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

============================================================
🔄 Round 48 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 48 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0400
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0065
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

============================================================
🔄 Round 49 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 49 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0399
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0137
============================================================


============================================================
🔄 Round 50 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 50 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0362
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0185
============================================================


============================================================
🔄 Round 51 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 51 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0411
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0027
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

============================================================
🔄 Round 54 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 54 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0333
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0418
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

📊 Round 54 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

============================================================
🔄 Round 56 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 56 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0344
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0408
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

📊 Round 56 Test Metrics:
   Loss: 0.0761, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

📊 Round 56 Test Metrics:
   Loss: 0.0760, RMSE: 0.2758, MAE: 0.2391, R²: 0.0119

============================================================
🔄 Round 61 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 61 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0403
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0171
============================================================


============================================================
🔄 Round 63 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 63 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0273
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0259
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0121

============================================================
🔄 Round 67 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 67 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0283
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0597
============================================================


============================================================
🔄 Round 68 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 68 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0260
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0818
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0122

📊 Round 68 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0122

============================================================
🔄 Round 73 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 73 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0338
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0336
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0122

📊 Round 73 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0122

============================================================
🔄 Round 76 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 76 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0410
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0121
============================================================


============================================================
🔄 Round 78 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 78 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0283
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0570
============================================================


============================================================
🔄 Round 79 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 79 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0394
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0229
============================================================


============================================================
🔄 Round 80 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 80 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0399
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0205
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

📊 Round 80 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

📊 Round 80 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

============================================================
🔄 Round 85 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 85 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0341
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0395
============================================================


============================================================
🔄 Round 86 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 86 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0252
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0740
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

📊 Round 86 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

============================================================
🔄 Round 89 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 89 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0423
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0076
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

============================================================
🔄 Round 90 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 90 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0408
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0040
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 96 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 96 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0411
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0137
============================================================


============================================================
🔄 Round 97 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 97 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0404
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0162
============================================================


============================================================
🔄 Round 98 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 98 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0356
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0395
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 101 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 101 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0315
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0467
============================================================


============================================================
🔄 Round 102 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 102 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0381
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0285
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

📊 Round 102 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 105 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 105 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0311
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0507
============================================================


============================================================
🔄 Round 107 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 107 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0268
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0537
============================================================


============================================================
🔄 Round 108 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 108 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0448
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0022
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 111 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 111 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0262
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0682
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 112 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 112 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0380
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0246
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 114 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 114 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0354
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0306
============================================================


============================================================
🔄 Round 115 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 115 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0387
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0216
============================================================


============================================================
🔄 Round 116 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 116 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0370
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0337
============================================================


============================================================
🔄 Round 117 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 117 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0325
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0512
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

📊 Round 117 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

📊 Round 117 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

📊 Round 117 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

============================================================
🔄 Round 125 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 125 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0282
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0481
============================================================


============================================================
🔄 Round 126 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 126 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0310
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0531
============================================================


============================================================
🔄 Round 128 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 128 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0374
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0277
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

============================================================
🔄 Round 132 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 132 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0292
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0451
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

📊 Round 132 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

📊 Round 132 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

📊 Round 132 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

============================================================
🔄 Round 143 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 143 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0347
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0249
============================================================


============================================================
🔄 Round 145 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 145 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0452
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0094
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0123

📊 Round 145 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 150 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 150 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0249
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0707
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 151 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 151 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0287
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0632
============================================================


============================================================
🔄 Round 153 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 153 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0406
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0080
============================================================


============================================================
🔄 Round 154 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 154 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0335
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0142
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

📊 Round 154 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 158 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 158 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0322
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0492
============================================================


============================================================
🔄 Round 159 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 159 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0344
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0379
============================================================


============================================================
🔄 Round 160 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 160 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0402
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0147
============================================================


============================================================
🔄 Round 161 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 161 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0349
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0357
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 163 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 163 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0385
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0070
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 164 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 164 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0332
   Val:   Loss=0.0989, RMSE=0.3145, R²=0.0223
============================================================


============================================================
🔄 Round 165 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 165 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0276
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0598
============================================================


============================================================
🔄 Round 167 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 167 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0332
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0464
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

📊 Round 167 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

============================================================
🔄 Round 169 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 169 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0294
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0557
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2391, R²: 0.0124

📊 Round 169 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0124

============================================================
🔄 Round 173 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 173 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0314
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0557
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0124

============================================================
🔄 Round 178 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 178 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0430
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0149
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0124

============================================================
🔄 Round 180 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 180 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0324
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0134
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0124

📊 Round 180 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

📊 Round 180 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

============================================================
🔄 Round 185 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 185 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0382
   Val:   Loss=0.0962, RMSE=0.3102, R²=0.0216
============================================================


============================================================
🔄 Round 188 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 188 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0385
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0012
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

============================================================
🔄 Round 189 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 189 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0383
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0298
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

============================================================
🔄 Round 190 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 190 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0397
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0236
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

============================================================
🔄 Round 191 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 191 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0364
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0349
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

============================================================
🔄 Round 194 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 194 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0436
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0074
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

📊 Round 194 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

📊 Round 194 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

============================================================
🔄 Round 198 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 198 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0343
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0457
============================================================


============================================================
🔄 Round 199 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 199 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0349
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0423
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

============================================================
🔄 Round 201 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 201 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0436
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0027
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2392, R²: 0.0123

============================================================
🔄 Round 206 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 206 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0364
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0210
============================================================


============================================================
🔄 Round 207 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 207 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0451
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0026
============================================================


❌ Client client_51 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
