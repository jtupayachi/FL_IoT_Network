[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ddc71fd-0dd9-4f3d-911d-ff2a39a3d73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 175db74c-b1f0-41a9-93a2-b2e54a2ae763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d15347d-cd9e-4945-9a9f-c6c4e95f7f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b39237fd-3e68-48ba-b64e-85125c1335ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0188f7bc-3033-4d20-8dcc-ecc7f102e81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae71875d-40cf-4e61-8cfe-f78cd9eac07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c4526c-7cc4-463d-aead-f294e3da4c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9558731-9658-4f5d-a4ae-49a5d54890e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c6ad78-126f-4c31-b14f-1e7df8368a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30fe88f6-2a91-4a93-9448-d66229bf5702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0351d36-eef6-4a9b-af18-e93008a37536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1258f589-c489-4432-bce2-9597dacf70b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a41d467b-343a-44a5-86cb-d351cff0a7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c17c869-ca56-46af-8e05-9614cfdfba44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc844ee4-c6b1-4496-a82f-0f2734d76064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4530e3cc-2ad6-48e9-8ab5-39996953b7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b30c40e-dbca-4d32-8bab-34f010c62b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94aa1d4-67c9-4346-bfb1-06fa1772d0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec656f1d-06d1-43c8-94af-219052f5fe8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22860625-94db-4f68-9eeb-573e5a1cc5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37977849-8a4e-4fbf-974a-f31a48c34635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67c4185b-9aa7-437d-bc54-2fe81f29c612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 913ad704-003c-4050-be51-57a9b4a2d201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c13ad01e-1606-433b-9109-4085208f42cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b27a09d4-4ef2-4367-852d-a452f3efd9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac01dfd3-53e8-4013-9415-79164a955484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29ed6116-a647-4ada-9856-b738e783aadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61710f70-f837-46f4-b075-994b876955aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e2a3a08-89d6-4793-9697-2fa95c43fa18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 152bb349-cef5-447a-b071-af02bf1c2d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3639be4-be7f-4b4f-acf6-b573f5b6a03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06604949-13c4-4f79-808f-1b485809c06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eacb5d49-ab18-41f9-92af-17a6686c68d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de83271-b1f8-4bf5-b8ca-112badaf7b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd2f93e-2bb8-46c5-8811-152a061e079e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f2f5055-089d-4683-a1c0-6fef6274fb25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4683de58-0f3f-43dc-9f52-2498698a9099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb0757eb-30e7-41a7-a2f7-f180a781b859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0331956e-e2ce-4868-a30c-d946d871ebb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69666fb5-3aa9-4d86-8a97-804e4c3ee6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f08c15de-72bb-4643-930e-31a86c943e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8309f9e7-4889-459d-bcc9-da1018212bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a186aaef-5f42-4f4a-aa2d-47e8441610b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e0f115-d9af-4b4b-b7c5-5c4ffed38135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d807406d-e96e-45a4-8f5e-40a1edf10da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ebd0673-20ff-4509-a775-1f3e3d7a9eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c04bcb6-f9a1-4874-a7e4-dd6ce7ce9b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a41ed044-cc6c-447f-915e-b83e53f19a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d090d9bc-ec52-4ac5-a532-6ce5962a6f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 437ada50-d3b2-4046-89bc-d6ff7c394f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10c9fe2-893f-469e-a949-eb1c3ad7aa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43ef526-fec4-4cf3-a3ac-13a02103f014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e583cc9b-23a4-492a-b367-f1b85a69443c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed7f7cb-3388-437d-ac38-851aaa18aadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9a6ed21-5012-4d9d-8bab-edcc9137d9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be3955fb-4386-4253-8260-14a2d0988c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8acddc2b-5bd5-4717-92e1-7f0aecf71bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf33ca0b-f40f-4a0a-ac43-1726de51b7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a49fa881-b661-40f2-bc57-2642e0ca5095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5fd26d6-3d52-40f2-be2f-02202c0b951a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fcc0950-4132-4372-bb51-7424e331ced4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0cc4a60-124a-46d8-a62d-9a3ed8e7839d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a466498-9e30-4f12-b3f1-169694b8f54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38923635-16c7-4278-8859-8cdb94d79dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca37952-e0e8-4233-b91e-c32b093a71d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28919877-36cd-40eb-89ea-87456a8ca65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 365ea9b5-54ba-4fa2-9700-3be81d943c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d334d6f-a390-4863-97f7-ffaee771479f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc4ee54d-e5bd-4fa0-b0eb-533e0abe673d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85919834-5b63-432d-a8f6-37bf55ad7970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e05fd55f-dd14-43c1-a635-5b0aa10b1ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b565e8-480c-4696-8001-4f69dc64eece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db0d1769-8b04-4620-a04e-2964de2e41a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbcb177d-5842-49bb-ba0f-566919889b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 624f85d7-a7ba-423e-8ec1-85e172538fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3490672-f18f-4208-8e44-cafd90e5a50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d417e51-7f3f-4f92-a0b4-c5bf781c329a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2798641c-21ff-427a-9fb5-c06263608616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77d37b5e-1879-4e21-8597-db3961311ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd08d7ed-d2d2-4837-ab10-feaa46241c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f139a83-0f91-4010-9f1f-6930336a872e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f676d3b-ba0b-43b2-abcf-7065c4c18696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55cc91c-1be0-41ea-a577-fdb2728fe5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1787a8-c5a6-4829-9d14-16f5bf5b0e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5498c9-4b45-4bfa-a998-98fe4a983ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f963fa-8be0-49eb-8541-9971d3231551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f87671-54a3-457a-a976-ba190d69a0a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eaf451e-b3da-446e-8e51-89df4124d47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8fff572-2603-4ef5-80de-8cf8901569a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5ea853-f312-4198-b942-3ad1895c335e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c758b0-2ed6-4ae5-823a-2601363a386c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe46fc5-07f5-4465-8593-f3576c37a42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6bbe0bb-ed94-4d76-ace8-4a58aa73257c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b88592-b096-45a9-89fc-bcd0daa3d4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8731da8-3ff6-48cd-8777-aaeabe803003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b3b98e0-7e42-4051-97d5-fdbe79275f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78afe30c-ddca-4bd8-9396-c06ad43e5f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe4e68e-7525-48ee-888e-485842741a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52651463-2caf-4c0a-801d-9ef04cf5b196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7a0394-7517-464a-9554-ac77f141920e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d60623ab-b7a6-4903-a151-b315245fa986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d477a0-fec9-4fd8-ae22-6b6d187b18fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0870e7-5ec4-4103-8b2e-589d4b005e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 955dc06a-8e09-45ef-bfc8-cf1657395138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a59cf6-96a1-481f-9e6d-a7054c6da682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4ce732-c90e-4bdb-a0dc-52f85afd79b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c0bfbd-5bfa-47f4-a5e4-697cbe0a648e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 584de5c6-6c81-46ce-bbd4-592f1719ccc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f17aaeb-5a46-4066-9d7c-4841869ee5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59be7314-317d-45b1-b9dd-ab3e57fe4aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ddd1385-92f0-4596-bce6-4343f9a0444e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 381ec076-9dd3-4d5e-8065-43ccb2f5ed49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d345ab2b-c665-4123-9335-ca5cbf978ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0592badd-25a9-4575-a870-8ff3857f7b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ad794b-aaa8-4d17-a248-3e345de86515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 645b1c84-4443-4ff6-909f-426be5e91445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26c4f478-d11d-4167-b6ab-13bdfd60786a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215bfc85-8832-483b-ae1f-492a6610e897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ef5ea2-56cb-4e7e-9969-5c04a7eb4bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab75af8-e852-4825-b8b0-bccbb79f4fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4eb6d8a-881b-4b11-ad59-d9811d22a495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e62806ec-5aae-4e6e-87fb-4a70b8a9524f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f76fba-cb20-4c20-a133-9a0cec7f1504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb3e2493-b04f-4cf9-9d9c-9480091822f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f998f4-3b05-4b4f-86ea-a367c0f30f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cecfa805-d1f7-4504-98fe-8861037f13c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55eb63da-5990-44f0-9b07-5bb2ce09f88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61770823-ce1b-4b48-9a02-6571004fd492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b0f098-fe32-40d1-afe1-319e3d34b9fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72616b5-8cc7-4076-beee-029c42dd52c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 313ef590-1dfa-4da7-95a9-d4bffa07a03c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 146ddd0e-f0b5-4bde-b8c0-8bb6dd690a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb194dd-7dee-446f-bd40-1d7cea5faf56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e942150e-570c-432a-8662-1610cb259b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78d29d57-7ba2-44f5-8370-cdf85a17bd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4f8ebb-71cd-4b41-93ea-dc05153b5747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a115813d-f4ec-4c90-9de4-b9c09fa88280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0825719d-70ee-4596-8957-81900927d2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3261ed0-c392-4a83-8444-43a5c3153f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8193cd7-9a03-481d-b1be-90a910ab6fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 367d5130-7022-427f-bf7f-51635403ee56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7296ba9a-7c77-478b-93d3-4e1bdf6c700b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 268bf3cc-11c6-4f09-ab58-154feb3e7d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c553ae-14cc-41a2-b5ff-68173d0e211d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df94edfa-9a39-4ce1-a656-9fe4f76c238a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b12f003-7afb-44d2-b05e-3948b6b09cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc50dbdd-6655-4ed6-9af7-d46ea48f115b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361cfd13-b5a9-479d-b365-a56b4983920b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c12c719-a1a8-4b90-bb47-5432e2b3984c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 160c3354-b96d-4e29-96fb-0585f2cddeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09642455-96a9-4c89-adf8-a6e94f5f319d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98c6611-3ba6-4e0f-8bc0-67f7e23defc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f63a942-c75d-4483-a59a-09f6e997897e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb43fa1-6f30-4abd-8ba8-bc863286ffee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f9d41b-d6e2-4277-8cd5-86ad42c9bfa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edbd609c-aa5c-4162-822c-3243a4ccad24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4faa334c-4ea0-4d03-8431-24084c6788c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e680d38-6cde-45cf-b084-a0e24689ab6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac26994-b865-426a-b58f-7d2d357905a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f9aeb15-fc22-4b88-9ac1-13b82d94ae1b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_53
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/test_labels.txt

📊 Raw data loaded:
   Train: X=(1126, 24), y=(1126,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1126 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_53 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 11 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0781 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0864, val=0.0771 (↓), lr=0.001000
   • Epoch   3/100: train=0.0853, val=0.0772, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0847, val=0.0774, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0844, val=0.0774, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0812, val=0.0777, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 11 Summary - Client client_53
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0073
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0070
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2563, R²: -0.0342

📊 Round 11 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2597, R²: -0.0903

============================================================
🔄 Round 16 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0766 (↓), lr=0.000250
   • Epoch   2/100: train=0.0869, val=0.0765, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0861, val=0.0765, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0855, val=0.0764, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0851, val=0.0764, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0831, val=0.0768, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 16 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0267
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0061
============================================================


============================================================
🔄 Round 17 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0888 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.0850, val=0.0875 (↓), lr=0.000063
   • Epoch   3/100: train=0.0841, val=0.0873, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0839, val=0.0872, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0838, val=0.0872, patience=3/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0832, val=0.0869, patience=2/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0828, val=0.0867, patience=12/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 17 Summary - Client client_53
   Epochs: 24/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0043
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0268
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0915, RMSE: 0.3025, MAE: 0.2630, R²: -0.0956

📊 Round 17 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2631, R²: -0.0910

============================================================
🔄 Round 19 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0825 (↓), lr=0.000016
   📉 Epoch 2: LR reduced 0.000016 → 0.000008
   • Epoch   2/100: train=0.0893, val=0.0821, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0889, val=0.0820, patience=2/15, lr=0.000008
   ✓ Epoch   4/100: train=0.0888, val=0.0819 (↓), lr=0.000008
   • Epoch   5/100: train=0.0886, val=0.0817, patience=1/15, lr=0.000008
   📉 Epoch 10: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0877, val=0.0813, patience=2/15, lr=0.000004
   📉 Epoch 18: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0872, val=0.0810, patience=12/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 19 Summary - Client client_53
   Epochs: 24/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0391
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0232
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0918, RMSE: 0.3030, MAE: 0.2640, R²: -0.0991

📊 Round 19 Test Metrics:
   Loss: 0.0925, RMSE: 0.3041, MAE: 0.2643, R²: -0.1076

============================================================
🔄 Round 21 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0993 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0864, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0993)

============================================================
📊 Round 21 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0676
   Val:   Loss=0.0993, RMSE=0.3151, R²=-0.0736
============================================================


============================================================
🔄 Round 22 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 22 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0733
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0923
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0938, RMSE: 0.3062, MAE: 0.2644, R²: -0.1228

============================================================
🔄 Round 23 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 23 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.1011
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0160
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0937, RMSE: 0.3061, MAE: 0.2645, R²: -0.1220

📊 Round 23 Test Metrics:
   Loss: 0.0927, RMSE: 0.3045, MAE: 0.2640, R²: -0.1100

============================================================
🔄 Round 25 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0928, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0928, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0928, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 25 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0929, RMSE=0.3047, R²=-0.0666
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0927
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2635, R²: -0.1015

============================================================
🔄 Round 27 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 27 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0542
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0842
============================================================


============================================================
🔄 Round 28 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 28 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0467
   Val:   Loss=0.1006, RMSE=0.3172, R²=-0.0861
============================================================


============================================================
🔄 Round 35 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 35 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0364
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.1109
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2600, R²: -0.0592

📊 Round 35 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2599, R²: -0.0586

============================================================
🔄 Round 39 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 39 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0385
   Val:   Loss=0.0974, RMSE=0.3120, R²=-0.0827
============================================================


============================================================
🔄 Round 40 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 40 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0454
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0340
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2599, R²: -0.0588

============================================================
🔄 Round 42 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 42 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0365
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0750
============================================================


============================================================
🔄 Round 43 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 43 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0455
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0395
============================================================


============================================================
🔄 Round 44 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 44 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0438
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0950
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2599, R²: -0.0589

============================================================
🔄 Round 45 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 45 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0493
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0203
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2599, R²: -0.0590

============================================================
🔄 Round 46 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 46 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0405
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0513
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2600, R²: -0.0591

============================================================
🔄 Round 47 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 47 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0544
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0491
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2600, R²: -0.0593

============================================================
🔄 Round 48 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 48 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0508
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0114
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2600, R²: -0.0594

============================================================
🔄 Round 49 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 49 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0431
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0481
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2600, R²: -0.0592

📊 Round 49 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2600, R²: -0.0594

============================================================
🔄 Round 54 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 54 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0518
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0317
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2600, R²: -0.0596

📊 Round 54 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2600, R²: -0.0597

📊 Round 54 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2600, R²: -0.0599

============================================================
🔄 Round 59 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 59 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0350
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0775
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2600, R²: -0.0599

📊 Round 59 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2599, R²: -0.0584

============================================================
🔄 Round 65 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 65 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0335
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0716
============================================================


============================================================
🔄 Round 66 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 66 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0512
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0041
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2598, R²: -0.0576

📊 Round 66 Test Metrics:
   Loss: 0.0884, RMSE: 0.2972, MAE: 0.2599, R²: -0.0581

============================================================
🔄 Round 69 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 69 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0464
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0201
============================================================


============================================================
🔄 Round 70 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 70 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0406
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0472
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2599, R²: -0.0587

============================================================
🔄 Round 73 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 73 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0451
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0281
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0885, RMSE: 0.2974, MAE: 0.2600, R²: -0.0592

============================================================
🔄 Round 76 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.1044 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.1044, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.1044, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.1044, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.1043, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.1042, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1044)

============================================================
📊 Round 76 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0360
   Val:   Loss=0.1044, RMSE=0.3231, R²=-0.0719
============================================================


============================================================
🔄 Round 82 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 82 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0365
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0666
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0882, RMSE: 0.2970, MAE: 0.2597, R²: -0.0560

📊 Round 82 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2597, R²: -0.0558

============================================================
🔄 Round 89 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 89 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0325
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.1008
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2598, R²: -0.0575

============================================================
🔄 Round 92 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 92 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0513
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0020
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2599, R²: -0.0582

📊 Round 92 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2599, R²: -0.0584

📊 Round 92 Test Metrics:
   Loss: 0.0884, RMSE: 0.2973, MAE: 0.2599, R²: -0.0586

============================================================
🔄 Round 96 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 96 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0393
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0481
============================================================


============================================================
🔄 Round 97 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 97 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0522
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0007
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2599, R²: -0.0578

📊 Round 97 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2598, R²: -0.0575

============================================================
🔄 Round 101 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 101 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0506
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0172
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2598, R²: -0.0571

📊 Round 101 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2598, R²: -0.0573

📊 Round 101 Test Metrics:
   Loss: 0.0883, RMSE: 0.2972, MAE: 0.2598, R²: -0.0575

📊 Round 101 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2598, R²: -0.0572

============================================================
🔄 Round 112 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 112 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0417
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0352
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0882, RMSE: 0.2970, MAE: 0.2597, R²: -0.0562

============================================================
🔄 Round 118 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 118 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0403
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0392
============================================================


============================================================
🔄 Round 120 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 120 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0260
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.1084
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2596, R²: -0.0550

📊 Round 120 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2596, R²: -0.0546

============================================================
🔄 Round 122 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 122 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0321
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0786
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2595, R²: -0.0540

============================================================
🔄 Round 124 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 124 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0418
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0181
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2595, R²: -0.0538

📊 Round 124 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2595, R²: -0.0537

============================================================
🔄 Round 126 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 126 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0392
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0294
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2595, R²: -0.0536

============================================================
🔄 Round 131 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 131 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0422
   Val:   Loss=0.0847, RMSE=0.2909, R²=-0.0198
============================================================


============================================================
🔄 Round 132 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 132 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0469
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0058
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2594, R²: -0.0528

============================================================
🔄 Round 136 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 136 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0371
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0332
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2593, R²: -0.0522

📊 Round 136 Test Metrics:
   Loss: 0.0878, RMSE: 0.2964, MAE: 0.2593, R²: -0.0519

============================================================
🔄 Round 139 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 139 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0304
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0584
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2592, R²: -0.0515

============================================================
🔄 Round 143 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 143 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0291
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0607
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2592, R²: -0.0512

📊 Round 143 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2592, R²: -0.0513

============================================================
🔄 Round 145 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 145 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0429
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0103
============================================================


============================================================
🔄 Round 146 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 146 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0379
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0322
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2592, R²: -0.0516

============================================================
🔄 Round 148 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 148 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0395
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0179
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2592, R²: -0.0512

📊 Round 148 Test Metrics:
   Loss: 0.0878, RMSE: 0.2962, MAE: 0.2592, R²: -0.0509

============================================================
🔄 Round 150 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 150 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0305
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0511
============================================================


============================================================
🔄 Round 152 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 152 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0372
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0219
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0503

📊 Round 152 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0503

============================================================
🔄 Round 157 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 157 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0238
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0770
============================================================


============================================================
🔄 Round 158 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 158 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0307
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0502
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2590, R²: -0.0492

============================================================
🔄 Round 161 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 161 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0297
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0750
============================================================


============================================================
🔄 Round 163 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 163 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0302
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0519
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2589, R²: -0.0485

📊 Round 163 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2589, R²: -0.0484

============================================================
🔄 Round 168 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 168 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0362
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0331
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2589, R²: -0.0488

============================================================
🔄 Round 173 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 173 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0385
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0130
============================================================


============================================================
🔄 Round 174 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 174 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0340
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0312
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2590, R²: -0.0496

============================================================
🔄 Round 175 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 175 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0359
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0249
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2590, R²: -0.0496

📊 Round 175 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2591, R²: -0.0498

📊 Round 175 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2591, R²: -0.0499

============================================================
🔄 Round 179 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 179 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0347
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0285
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2591, R²: -0.0500

📊 Round 179 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0503

============================================================
🔄 Round 183 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 183 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0221
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0831
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0505

📊 Round 183 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0505

📊 Round 183 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0505

============================================================
🔄 Round 186 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 186 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0310
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0510
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0505

============================================================
🔄 Round 187 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.1049 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.1049, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.1049, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.1049, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.1048, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.1048, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1049)

============================================================
📊 Round 187 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0369
   Val:   Loss=0.1049, RMSE=0.3239, R²=-0.0296
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0506

📊 Round 187 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0505

============================================================
🔄 Round 190 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 190 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0280
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0624
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0506

📊 Round 190 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0507

============================================================
🔄 Round 193 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 193 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0441
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0011
============================================================


============================================================
🔄 Round 194 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 194 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0250
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0739
============================================================


============================================================
🔄 Round 195 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 195 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0445
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0035
============================================================


============================================================
🔄 Round 196 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 196 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0382
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0358
============================================================


============================================================
🔄 Round 197 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 197 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0260
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0795
============================================================


============================================================
🔄 Round 198 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 198 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0410
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0259
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2592, R²: -0.0514

📊 Round 198 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2592, R²: -0.0511

============================================================
🔄 Round 200 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 200 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0458
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0040
============================================================


============================================================
🔄 Round 201 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 201 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0322
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0415
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2591, R²: -0.0503

📊 Round 201 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2591, R²: -0.0500

============================================================
🔄 Round 204 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 204 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0289
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0569
============================================================


============================================================
🔄 Round 205 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 205 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0361
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.1037
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2591, R²: -0.0501

============================================================
🔄 Round 207 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 207 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0367
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0262
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2590, R²: -0.0495

============================================================
🔄 Round 208 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 208 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0285
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0564
============================================================


============================================================
🔄 Round 210 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 210 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0250
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0811
============================================================


❌ Client client_53 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
