[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4796ea8f-3463-4743-bea4-ecd7287a7ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a950daa4-3841-4596-9de2-144f9b978d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c126cc48-6a40-4a2e-820f-5b5dc2338b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14750cb6-ff01-413a-ba65-3658fd47aa89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5939f2b0-8cbb-42f6-9806-94ada1ae3a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f0caf20-cf66-46eb-b19d-f80769f49c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fda7a8dc-f610-4a1e-b2f2-f8452a053a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5c07ab-2617-4443-86fa-158a9d66c0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5abb5d7f-5efd-4dbd-b103-c176ee8769a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a4b332d-99c5-4a4f-9c5f-760ea21dbd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7926423-e5ca-4626-bb2c-1e0a07b2dc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f8d1cac-bdf4-48b1-9753-9341e2fe45cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f23dc2a-0c9f-4afe-bbb1-43e73a0ba421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37dddc2b-a3c6-42c9-98b8-86f900e078dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c29ca4-d846-4a2c-ab7d-6139b46c9709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81a0c10-87e5-49a6-aedc-d80cd3c39ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 341c8bd8-bdca-4c5c-8451-42059366e177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f46ca9c6-278d-403f-8d88-93d1a7013017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 596f2d25-302a-4e6f-bb1d-20c15d42c9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a34aa0-a845-4c82-a22c-bf5b2eb066ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ae5c03-4215-46f4-96e9-42d1e65f00e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d77e48-2c17-409c-8cbd-e64257265a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44cebe31-bf95-4324-a5e6-bdf1505fe68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d975ef0-8880-4613-8b79-ad6f95e804ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92d26397-3215-472b-bf02-04bb97afef65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b63a900-f005-4f01-a88e-685d8e60ee91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1243b0-ddc4-4b47-8c94-a5a661871d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf74dd1-5bed-4cf6-b7ae-0f946ce9e730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8f36ad-2b4f-4e71-b3ae-55612559ed86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec1a7fbf-72ca-4c7a-bf79-0abd402feca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ae5cf9-c70a-4e48-b180-9cab00179d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 186a9c56-5c47-4ef7-a980-be11ef49f968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5e5dda-19cd-4c72-9702-feebb1d7d11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7def1e8f-1793-4030-ab7f-dcc2dd374453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 278bf003-97e4-43f5-9ad7-368bd4db8430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22458fbb-8242-4983-b616-8a0d38eac50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f3ee59a-eab7-4538-a4b4-38f5d6278fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a82b812-1ed9-4061-a110-f0859a00d177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1471e39d-fb49-419d-96c7-d1e3bdcb95a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c823b3c-03a2-4882-8753-1e7072ad7618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff9990b7-42fb-4049-9c80-d5ae6e4bbb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26a5414-5389-428b-b043-17db56172caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda35aba-0865-45d7-8b1f-21cad3a0969e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f7518d-4321-49ba-a7c7-3f1be8637e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b6d0ac-e5b7-4f7e-929c-d3f866df9467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b3bfa79-fc68-40f8-af2c-b70e22a2c23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda812d3-c928-483f-81be-fb031edc3b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f8a3459-c38b-4357-a395-f1af042ade02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e83023a7-00e4-40fe-aa25-a1b6de7f873d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0f0e8c-2db5-48ca-88ac-46a80af40f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95fb8374-001e-45c2-b036-3d7dd7bb9a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa5b92a1-d43b-4122-b5c1-321e144edfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67030a3b-2ea1-4cee-93e1-200b4906f547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d6fc271-bff8-445c-91db-d0a8d53b2b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf0c4b0-c514-408f-a413-5ad5f62ab5df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a59ceb52-1d6b-4913-ad9b-971c040d24f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4faa41f-7f55-4d5d-90d7-c05d1f24440e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693010d4-cf26-4d37-91a5-5d079053f8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33c89d0-c2e6-45c0-b286-bcb78b4f5067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ef4977-dc82-4b48-b099-52cf6c97dc6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98eecd6-1f1f-47bf-9dcf-398a61062aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a728d310-c49f-4ea6-bc22-55914b1afcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a905dc56-8b94-4044-a954-e3427db7272c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5d6870-9575-45e2-816a-76628be0d9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3e476e0-e4c3-4a83-99eb-6a399d660b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ea0c34-9188-417b-a915-a775100238c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ddd7591-add9-43a5-a6fc-475909c711de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b20bbe6-0dbc-48af-a9c3-0d206f0473f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e9ed510-bcb9-4610-878b-0f211366119f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a493138d-e8c1-4c9d-8316-1190c995546a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0719d170-9ce8-4116-9d68-360199eca623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f31cfe-d730-4b85-b5ec-6965e9d09121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e58fe21-5632-43cf-8bcd-ddcd49b69ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4702072b-300b-41d0-b4d9-0332691e042b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd62af52-2e95-473c-8979-76944deccc1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4a5f518-02f3-4dbd-8714-693c6088393e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e1e036-f794-466d-9281-cb8f57fb8942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7239e678-cbe1-41bd-afe3-437e111b79f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec191d0-5228-497c-88cb-e2d742d87533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a88980-6500-491b-990e-cea668deab33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e67b26e-3427-40a8-99b2-a166e67e1a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33aa2fe1-3799-44ff-9e8b-93e7bf1d30c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcd26b8b-7c85-4480-909a-73b347c86183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3bd3af8-7bb1-4db1-be4e-37c4b1287a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a6061ee-4b4d-4a13-8b27-9fecf696041a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cff466c-e685-4db6-93f6-b9ba753b7566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7662b37-0035-44ac-b91e-f34064b2469d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8e7148-05d6-4241-ad1a-160872a87194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469882a4-8546-49e1-afa6-1299e6f9fedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1502f493-6ab6-4370-8785-1fb32338d301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce97091a-f354-4aaa-8a22-e3b22192e892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211287aa-0d8f-4290-a630-9782883513ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17da931-7bc9-47bb-973b-091af95c36c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a891cdf-19c1-465f-9f1a-0ded3f3837d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8278380-80ba-4202-a6a5-0e56af4268e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa7eb019-e491-4704-85d6-cc4a542b0cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07bd5f53-ef48-47d1-b36a-840bb52c012b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a1ca9c-c34f-4b24-abfb-04acc8450852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9432a2-973c-4d4c-bfcd-4df90d22c699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 632addde-5484-4d40-849e-c7d074343c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f2839a-fe52-4bc7-8a99-28f581c7d972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f61812eb-1c20-4727-8a43-a2b52d668745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09334795-b827-4d9b-bc73-29d0d38d8c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7226ed7-c9f2-4785-b47a-352b6b7aed3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c69c57-55b7-4f10-a638-49bfbf840e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc401a71-0787-46aa-a9d4-1ba37bbb552f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c641382-f558-46ce-914c-b375e0169d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2912b9a6-de7c-4aae-ba4a-c89a22cc13f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f09817e2-3e58-45f4-b3a0-0d434c98e504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d79edbe0-9ad1-43dd-ab7d-b636e3898423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081e9670-da68-4493-974b-54e77fcf19ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa85c45d-3948-4ea7-bc36-918eb9888f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de6935a1-a7b6-4624-874c-fedc0aa6bb94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 810334bc-8780-4552-b52d-a79b4419359c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6823601a-dbf0-4e61-83e8-59b0d79b56c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76d504d6-06f9-45a5-8507-f4cf1051d83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d78dcd8-6715-42f2-a397-805f6a796383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18545ac-6e20-4a0f-99aa-fd994c699d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c5926d-cdb5-4358-b63c-825fc73f64ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb137525-5b13-4e75-9318-8b6576909bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c5d8ec-9e85-4908-a558-2e2b454ad2c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56159a92-5617-4ca1-9484-5f756bf1d921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a849dd6d-9803-458d-9d65-6c6a34bdc610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d9f199-dc2c-4858-81e5-0a3924c3568d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57969b61-36b9-4a6d-9b07-c17a86d0c4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6653c659-aa7f-4bd1-b95d-8317b24d4f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 285a3827-d135-4341-82fe-61595e6c203b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f870b0a-cedd-4bf8-be5f-052ffef588f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f0680ee-502b-4ccc-aebf-e1a3d500006b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49775a9e-9eb1-4b3f-abdd-3c999d0be4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53704ab5-88c9-44e3-a358-eec84b1daac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5674a7f6-ec0f-4f30-9cb2-549c7a14a58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c60496c-2d9b-448e-a855-257154cfabb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f16258a1-3cf7-4085-84b4-e7962e31fe23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d78ca31-e6b2-420a-a665-f3f8d1d05ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fe551c-3b60-4f8e-8af5-bae8a445d5ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c78c7d2-3f73-4748-ab27-e587258ece2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c1c451-7a18-4fcc-bb77-e7f185ce81b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 268c0894-5a1a-4233-b8e0-6344899ccad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeccc574-2e57-4012-b365-f078ace99e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa86c53b-3be9-4454-b12c-b98e90f7b1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde02a5f-6d00-4306-8de6-32b7d22fac4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eac3e3f6-5262-4ed3-a04b-eea000bbe045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4846d86-3dab-47d8-aae0-8be9d7f798cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6d2f5d-b4eb-40d1-9be0-ddfe2da0b334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e1a0ba-26b9-4922-b0d0-09d67dac500c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7b1dabf-aa2a-4dcd-82a3-7e09d2ca2a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8767ce2e-fee9-4b46-bf2f-c282ee2256b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2f0ade-94b2-4c02-af77-8f104edfe5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc97addc-caf7-443f-a3e4-8ff4136c323b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8621c584-d853-4a7d-a1ea-def54026e00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 414c0d43-3182-4210-82ab-ad97c6999d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef57b3d-b87b-46e4-ba34-cb3e3ba0f2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11df4671-80ba-4b67-9242-6f37672a8242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 626d8559-cff4-450c-9fd0-70175d7112b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d48e0c7e-9021-4a91-8de9-f36e8aca0dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d16da1d-0222-4441-8c01-a6748272d6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1481b0d8-5074-4a17-a1ff-ecc0fb4353f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459e99ef-dc74-4ce4-8103-8292f048caed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eb0e7f0-0aa0-4d06-adf8-45c22911b6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe29ab18-155c-46cf-90d7-447cf6392cc1
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_54
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/test_labels.txt

📊 Raw data loaded:
   Train: X=(3010, 24), y=(3010,)
   Test:  X=(753, 24), y=(753,)

⚠️  Limiting training data: 3010 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  744 samples, 5 features
✅ Client client_54 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2614, R²: -0.0206

📊 Round 0 Test Metrics:
   Loss: 0.0895, RMSE: 0.2992, MAE: 0.2592, R²: -0.0039

============================================================
🔄 Round 18 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0793, val=0.0777 (↓), lr=0.001000
   • Epoch   3/100: train=0.0769, val=0.0786, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0756, val=0.0782, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0742, val=0.0788, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0671, val=0.0809, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 18 Summary - Client client_54
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0899
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0161
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2589, R²: 0.0022

============================================================
🔄 Round 19 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0700 (↓), lr=0.000250
   • Epoch   2/100: train=0.0829, val=0.0699, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0823, val=0.0699, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0817, val=0.0696, patience=3/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0813, val=0.0695 (↓), lr=0.000250
   ✓ Epoch  11/100: train=0.0790, val=0.0677 (↓), lr=0.000250
   • Epoch  21/100: train=0.0754, val=0.0664, patience=4/15, lr=0.000250
   📉 Epoch 28: LR reduced 0.000250 → 0.000125
   • Epoch  31/100: train=0.0720, val=0.0670, patience=14/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 19 Summary - Client client_54
   Epochs: 32/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.1098
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.0825
============================================================


============================================================
🔄 Round 20 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0821 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0810, val=0.0811 (↓), lr=0.000125
   • Epoch   3/100: train=0.0806, val=0.0807, patience=1/15, lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   ✓ Epoch   4/100: train=0.0803, val=0.0804 (↓), lr=0.000063
   • Epoch   5/100: train=0.0801, val=0.0803, patience=1/15, lr=0.000063
   • Epoch  11/100: train=0.0791, val=0.0794, patience=3/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031
   📉 Epoch 20: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0783, val=0.0790, patience=9/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 20 Summary - Client client_54
   Epochs: 27/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0622
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0207
============================================================


============================================================
🔄 Round 21 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0823, val=0.0759 (↓), lr=0.000008
   • Epoch   2/100: train=0.0822, val=0.0758, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0822, val=0.0757, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0821, val=0.0756, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0820, val=0.0755, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000004
   📉 Epoch 17: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0816, val=0.0749, patience=14/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 21 Summary - Client client_54
   Epochs: 22/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0318
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0229
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2572, R²: 0.0173

============================================================
🔄 Round 23 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0861 (↓), lr=0.000002
   • Epoch   2/100: train=0.0784, val=0.0861, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0784, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 23 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0435
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0174
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2574, R²: 0.0166

============================================================
🔄 Round 24 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 24 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0387
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0289
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2577, R²: 0.0144

============================================================
🔄 Round 25 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 25 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0421
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0034
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2579, R²: 0.0131

============================================================
🔄 Round 27 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 27 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0301
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0056
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2580, R²: 0.0126

📊 Round 27 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

📊 Round 27 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2581, R²: 0.0120

============================================================
🔄 Round 31 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 31 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0224
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0291
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2582, R²: 0.0118

============================================================
🔄 Round 33 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 33 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0178
   Val:   Loss=0.0660, RMSE=0.2570, R²=0.0331
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2582, R²: 0.0117

📊 Round 33 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2582, R²: 0.0117

📊 Round 33 Test Metrics:
   Loss: 0.0882, RMSE: 0.2969, MAE: 0.2582, R²: 0.0117

============================================================
🔄 Round 38 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 38 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0162
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0458
============================================================


============================================================
🔄 Round 42 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 42 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0235
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0095
============================================================


============================================================
🔄 Round 44 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 44 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0286
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0031
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2582, R²: 0.0119

============================================================
🔄 Round 46 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 46 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0268
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0052
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2582, R²: 0.0120

📊 Round 46 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2582, R²: 0.0120

============================================================
🔄 Round 53 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 53 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0250
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0163
============================================================


============================================================
🔄 Round 54 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 54 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0225
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0268
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0121

============================================================
🔄 Round 56 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 56 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0263
   Val:   Loss=0.0871, RMSE=0.2950, R²=0.0125
============================================================


============================================================
🔄 Round 57 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 57 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0243
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0168
============================================================


============================================================
🔄 Round 60 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 60 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0247
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0195
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0122

============================================================
🔄 Round 64 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 64 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0235
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0203
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0122

📊 Round 64 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0121

============================================================
🔄 Round 67 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 67 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0214
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0312
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0122

📊 Round 67 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0122

============================================================
🔄 Round 70 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 70 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0252
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0165
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 72 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 72 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0242
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0213
============================================================


============================================================
🔄 Round 73 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 73 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0225
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0218
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 75 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 75 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0277
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0103
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

📊 Round 75 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 77 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 77 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0263
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0090
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 78 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 78 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0247
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0151
============================================================


============================================================
🔄 Round 79 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 79 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0280
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0049
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 80 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 80 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0186
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0365
============================================================


============================================================
🔄 Round 81 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 81 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0152
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0405
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0122

📊 Round 81 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0121

============================================================
🔄 Round 84 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 84 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0252
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0098
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0121

📊 Round 84 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0121

📊 Round 84 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0122

📊 Round 84 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

📊 Round 84 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 89 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 89 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0242
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0175
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

📊 Round 89 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 93 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 93 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0259
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0107
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

📊 Round 93 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

📊 Round 93 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

============================================================
🔄 Round 98 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 98 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0272
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0095
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

============================================================
🔄 Round 100 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 100 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0206
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0200
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

============================================================
🔄 Round 102 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 102 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0234
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0182
============================================================


============================================================
🔄 Round 103 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 103 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0269
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0125
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

============================================================
🔄 Round 107 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 107 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0325
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0113
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

📊 Round 107 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

📊 Round 107 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

============================================================
🔄 Round 113 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 113 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0220
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0336
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

============================================================
🔄 Round 117 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 117 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0290
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0043
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

============================================================
🔄 Round 119 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 119 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0237
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0242
============================================================


============================================================
🔄 Round 120 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 120 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0251
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0159
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 121 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 121 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0229
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0217
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

📊 Round 121 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

📊 Round 121 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 129 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 129 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0203
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0356
============================================================


============================================================
🔄 Round 131 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 131 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0276
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0064
============================================================


============================================================
🔄 Round 133 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 133 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0217
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0301
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 140 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 140 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0273
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0035
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 141 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 141 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0264
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0099
============================================================


============================================================
🔄 Round 142 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 142 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0195
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0371
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

📊 Round 142 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 145 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 145 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0249
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0131
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 146 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 146 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0210
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0334
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

📊 Round 146 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 149 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 149 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0229
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0253
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

📊 Round 149 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 154 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 154 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0235
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0131
============================================================


============================================================
🔄 Round 156 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 156 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0227
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0149
============================================================


============================================================
🔄 Round 157 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 157 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0217
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0255
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

============================================================
🔄 Round 159 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 159 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0198
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0376
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

📊 Round 159 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0122

============================================================
🔄 Round 163 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 163 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0312
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0092
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2582, R²: 0.0122

📊 Round 163 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

📊 Round 163 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

📊 Round 163 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0122

📊 Round 163 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

📊 Round 163 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

📊 Round 163 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

📊 Round 163 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 177 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 177 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0273
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0018
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 178 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 178 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0271
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0035
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0123

============================================================
🔄 Round 180 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 180 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0215
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0330
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

============================================================
🔄 Round 182 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 182 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0275
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0020
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0124

============================================================
🔄 Round 183 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 183 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0214
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0174
============================================================


============================================================
🔄 Round 184 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 184 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0287
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0053
============================================================


============================================================
🔄 Round 186 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 186 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0297
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0030
============================================================


============================================================
🔄 Round 187 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 187 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0285
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0050
============================================================


============================================================
🔄 Round 188 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 188 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0253
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0174
============================================================


============================================================
🔄 Round 189 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 189 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0295
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0135
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

============================================================
🔄 Round 192 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 192 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0251
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0177
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

============================================================
🔄 Round 195 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 195 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0221
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0233
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0126

============================================================
🔄 Round 198 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 198 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0207
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0376
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0126

============================================================
🔄 Round 199 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 199 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0202
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0154
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0126

============================================================
🔄 Round 200 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 200 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0257
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0163
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

📊 Round 200 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

============================================================
🔄 Round 205 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 205 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0197
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0323
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

============================================================
🔄 Round 207 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 207 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0229
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0260
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

📊 Round 207 Test Metrics:
   Loss: 0.0881, RMSE: 0.2968, MAE: 0.2581, R²: 0.0125

❌ Client client_54 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
