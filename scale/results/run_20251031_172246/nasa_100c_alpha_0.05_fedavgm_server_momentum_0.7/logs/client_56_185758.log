[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1948a0-b19b-474c-9179-adecc0a1a317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba87a9c-c35e-4fa4-9cad-378d4a76ce3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ee2bfc9-5f03-4703-8f37-f0405623990a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240b5e97-e4d4-49f7-b243-6d9d30750db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f848ecd2-1feb-4292-b3aa-b4aac2833062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f03714f-4538-4eea-9602-a8541a00603f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02235ad0-8727-4762-a2fa-5cc4d8c0353f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a56454b-b9c9-4ec3-b55f-db17d888fd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f597506-5f84-4114-bd10-6bcc8d841e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 036c8e8e-2a81-4f55-8648-1d6b239ca252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65b35216-4080-4b8e-bc45-8d68f802a6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ececf7a0-35a3-48ad-abb2-b2a67262920f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be32548-9c17-4337-8423-374f8416966d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49d5dbba-b98a-4808-b3ec-6e5bde01831c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a9153cc-82b9-4a75-9696-5cd0ef195ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 279cf615-dde9-4907-9e4a-23d1356144bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ecbcdf-dfcc-4365-8baa-f4a97e42484f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41cc2c15-d6cb-4802-9df3-928fc9c7eb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9a5921-18ce-4740-a5dc-1d460e3a30b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da53661b-8024-4ac3-8f6b-f93439177731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77dc6f3d-b132-41f3-8440-ddc909cb2b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f980bfe-b751-40ff-964a-65cb79cb176d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5103b8a6-bba1-4b2f-b582-3a6c83fd5305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2032a7e-ae4f-4fc5-86f5-9cb5b4b0be8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40ab962b-bd59-4fde-b5ba-0e8009468eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e53158-976d-4361-b4a0-49fb84e16782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af1f81d9-b716-4da5-95e9-a12ee59743b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c8fb38-5050-4b2d-81bd-1418b28bd7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8c5ff3-7de1-4b7c-b8ed-1f7979160770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c63a809b-4908-4513-a539-1ae2f4ecae2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5ab908-80c3-4433-bde1-ffbca1884a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c2f175-b85e-40dc-b1f8-bafb5de8258f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93ce29fd-5d52-478c-9971-571c5d4314ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca62c3fd-98a1-4aac-a731-9be876c94737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ffb0388-d6f5-41bf-a9fa-0d771cadb8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0807e5f4-d49f-4c2b-8ba2-b5cc02b07222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c7231ea-25da-40f6-b032-9f58ecf19af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6b9ca1-100d-4471-813b-3269e65e7107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c96d46d-ba8b-4a23-8275-266db5fb56f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d92d9fc-6864-4c4b-87d4-db907365ceb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d44e00-f274-4eb8-88e3-77f128ecf21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a434a73-3c47-4918-948e-592d9411f254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c544813-434c-4bda-acea-3edd23777978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e97bed1e-781c-4f43-8734-c1bea0076790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41b2c054-e172-4c9b-8e4c-707552417c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b483be49-0cd6-4da0-a160-4d1a3121e76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040bd08c-d481-4c57-aae1-8be83cea80d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82cef022-9666-4380-94a9-5e18b973fe46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90147554-9899-49d3-af6e-d7794e38773f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3183d84-a1a3-44e3-9aa9-a9a47d8d87fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 190bf215-090e-4c6f-927a-52b04d8eee64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b2bb03e-3d86-47c4-992e-f89bab705bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d94814d-3b7b-4398-871d-5bb32aee4bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcdc2c06-6fca-4cf9-8f36-0a77bd2e279c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d67a196-d208-42e8-bf8d-b5beec667829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90177a5c-faaf-4b96-97f0-e89ef5b6c08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9962bb3f-ebe4-4536-a0b4-61bd916a66d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b93063-4920-4102-9d13-d3d8fd9bb310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd34063f-cf89-48ad-b254-051a93c14cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e22fe1be-7f0d-4def-b882-b2fa3c69f321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c9d2026-9149-44a8-a94a-55ba51b7c1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 426094a1-2c7e-4596-a79f-a874a6afeb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aeef159-1a96-4cda-b9e0-038e41f05c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 149fcd36-11df-4e45-b1ba-deaa24d88659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de7a37a7-07d9-4830-8630-6eed98a0d0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a2c269e-8890-478a-92e1-d4dac13e69c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f35e7bf-d138-44eb-9c4a-39abf46ae09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58938fb-6b2f-49e7-b973-e7c4cea42495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a24559-3b5a-4c99-bed6-6a34fc895818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ecda002-726b-47be-a938-c6f0d66c40d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a629dcaf-a1b5-48dd-b4c0-781f0d311f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9d619f-329b-4149-bd73-00807dd9051b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c8f5dcd-d536-4c6d-9667-07e038db5517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5630d9a-1261-48bb-86dd-90b529b67ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f547ea6-f14c-4b14-a8d6-bc275a2fb8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 273c04b0-7947-4c68-9419-fec283aa2ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9442e325-e1ec-4034-b564-fd7b029487ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959961af-16d6-4b43-9b13-9e31a3962571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ad5dcb-7491-488f-891f-f77d7bfbb930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba3f8e79-0ff9-4acb-ab09-41c6089697df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 892f0be3-f67d-4126-8083-f6e086aa6042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f67cc8-cf9f-4416-9feb-5734a043eff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08083e5a-63ca-49c2-a935-63991954bd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2669f1c-1573-4fe6-8643-f10cade1b932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53ebae03-1ec6-4eda-a625-86dfc669276c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d82264f9-4d54-4d3a-a7a7-eee465928a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76b46192-0c81-4d3f-9249-6488eb5d6686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e4ed6c-74e4-4ed9-8ceb-fbf0fbf0fc23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b33483a-59ed-461b-87e9-32c76fec0fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c2757d-1e11-46c1-a579-8e56e8ee2bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed6fb44f-1236-4cb9-b315-86e7e20921e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e6d23d4-c60f-4f2f-82bd-6cc1656369e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d4cadf1-998a-4e9d-b7f3-66da2ef8b519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e42f1e35-a6eb-4a00-ac5e-41e14be9e099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe18706f-71e7-47ed-b764-1e796b945ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53104827-6ac6-4050-bd3d-5e550f07c812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93075336-fbca-493f-b9e3-3dfe8c715aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 252a2d0a-ebbb-4056-a388-49fef67bc773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e69ded3-3b89-4bfb-a809-0429ace4aa7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 018f7773-4898-4b70-91fd-b4598ed78ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13ae3057-5938-45d4-a826-c324bac3edef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063bae66-5659-452d-8d52-a091d81218ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc0414e-69bd-4126-b02a-817ca5d02f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c5e380-9c4d-4f90-970d-19859ae6d528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1fe1c58-2d68-4fbe-bfff-9126f6036d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20a16037-0675-4799-8d6d-de48ca63592c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87a89305-8eaa-4c4c-8210-de72e3d7081a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e47aefc0-e9ef-4d41-8fd8-487eb1072f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4e71c3d-adcb-423e-8289-b1aba58691a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d4f200c-d69b-417a-867d-efd3b575f8c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c457ba8-d540-4342-8178-fb1dc4121ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc9cd08d-c3c0-45b9-9629-d95ec4c25825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f4f3b56-46ec-4373-9bf5-d7ee5d46ec82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5d2efd7-59c1-417a-be35-6cd980c1b4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56328562-4c42-49ec-bd0e-1cd8b499b457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 390d63a8-40a1-4410-9320-7ce1a0e47f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9396e08-5ce2-4665-b5f0-31487de5b95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d246712-02b0-4f34-abae-c864bd14fbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03f95ef8-49c6-43db-b411-18629d79c6f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31382a64-638b-4dde-989f-376dba3ca0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea057367-8689-4c2f-b704-f7d0ba27533f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9974c0a-4964-4f79-8b73-63bd71d74ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7a25eee-24f8-4b29-b43f-ea47698a510f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa22763-b5d7-4ab9-80e7-8a8ae72a0c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9bdf8d-397a-4624-8133-1aceaeb5d707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a210f9d8-0243-4aaa-913b-24f8da94866d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a265791-2b18-4f35-a4a3-d2f53db09bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be49896b-4d90-48e0-8af0-cd7c11c20878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cacdc9a4-2188-4f42-a6d3-6731c9b23f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f3f9ba-ae2a-4a70-bbad-af96355490e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbfce28a-a9ac-4f8b-918b-6ef635dd3383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e938993a-9bf0-4f75-ab00-27aa6b7de249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aea3c68-6213-488a-82ce-68cab77a5e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06df9c34-74ca-441b-b7fb-9d183e98e4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa7708d4-8304-4bab-97f7-9b47cc9fc40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f40837-127b-4af4-8f0a-79146b78359a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68cae98e-3fd9-4d22-a9b4-47a46c0d2893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fae296e-90d8-4e2c-aa7a-6c7bb55c2954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ebfad8e-d686-4cae-9490-3e37ef4f9de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5eb5b77-3027-4923-8b6c-1a2ae912ecb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e06a96c6-77c8-42a5-9763-96b3db240e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e81d221c-728b-4a15-bf8a-a542c19482a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da2fa4bf-079b-4f15-8c32-27d5e53102f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3431755-a7dc-4336-a0a7-44d1ab84bd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee0307fd-73e0-4505-9953-750fd89f6cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0ad3c6-5f65-4e1d-a383-0a7e65c0341e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b9174b-84e0-4270-8a02-befcfef483c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa8dc75-3999-4519-86a4-1f9952cd9f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b97880c7-602f-4a9b-a254-83dc4910b4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7355c89-44ad-435a-b9a8-2a0e228430e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b8b2060-1c80-45f3-ac8f-12b17776a4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e392d0-d952-4e08-a9eb-b2c2f6cc3784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b6bb54-7c31-4602-b1b1-536d05bcad91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e0ce2d-2724-4237-80e9-2966f3434718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85896e12-46ac-4030-8fd7-0daa65fd192a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee898a16-d768-4200-9366-00a5ec6918cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544bfefe-785f-411e-88c6-a9941ebf9bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10719a84-0f47-4d3a-90b8-cd6f31730de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f1f1877-7833-4946-852b-fe9906c1e447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c472814f-6b7a-46b6-a3ac-d4e6f5c326a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd84f9d0-42cd-467d-b6d3-76c0b2073e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ebe1a0-5ed3-4cb2-9691-e930eef6713b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb4ae6c-da4a-4856-b544-14a506d8382a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bec4701-bc5e-438e-8e7a-9ba71db53720
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_56
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/test_labels.txt

📊 Raw data loaded:
   Train: X=(1226, 24), y=(1226,)
   Test:  X=(307, 24), y=(307,)

⚠️  Limiting training data: 1226 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  298 samples, 5 features
✅ Client client_56 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 12 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0779 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0797, val=0.0756 (↓), lr=0.001000
   • Epoch   3/100: train=0.0784, val=0.0761, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0776, val=0.0758, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0764, val=0.0758, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0678, val=0.0787, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 12 Summary - Client client_56
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0428
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0087
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2443, R²: 0.0744

============================================================
🔄 Round 16 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0745 (↓), lr=0.000250
   • Epoch   2/100: train=0.0755, val=0.0741, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0750, val=0.0739 (↓), lr=0.000250
   • Epoch   4/100: train=0.0744, val=0.0737, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0739, val=0.0737, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0714, val=0.0732, patience=2/15, lr=0.000250
   • Epoch  21/100: train=0.0675, val=0.0731, patience=12/15, lr=0.000250
   📉 Epoch 22: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 16 Summary - Client client_56
   Epochs: 24/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0717, RMSE=0.2678, R²=0.1161
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0480
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2406, R²: 0.0927

============================================================
🔄 Round 18 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0790 (↓), lr=0.000125
   • Epoch   2/100: train=0.0748, val=0.0791, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0745, val=0.0789, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0742, val=0.0786, patience=3/15, lr=0.000125
   ✓ Epoch   5/100: train=0.0738, val=0.0784 (↓), lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0724, val=0.0780, patience=6/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0715, val=0.0776, patience=9/15, lr=0.000031
   📉 Epoch 22: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 18 Summary - Client client_56
   Epochs: 27/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.0959
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0618
============================================================


============================================================
🔄 Round 19 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0714 (↓), lr=0.000016
   • Epoch   2/100: train=0.0777, val=0.0713, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0776, val=0.0711, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0774, val=0.0710, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0773, val=0.0710, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0768, val=0.0707, patience=5/15, lr=0.000016
   • Epoch  21/100: train=0.0761, val=0.0704, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 19 Summary - Client client_56
   Epochs: 21/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0581
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0528
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2399, R²: 0.0923

============================================================
🔄 Round 25 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0723 (↓), lr=0.000016
   • Epoch   2/100: train=0.0760, val=0.0722, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0759, val=0.0721, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0757, val=0.0718 (↓), lr=0.000016
   • Epoch   5/100: train=0.0755, val=0.0715, patience=1/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0749, val=0.0706 (↓), lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0746, val=0.0703, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 25 Summary - Client client_56
   Epochs: 26/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0766
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0831
============================================================


============================================================
🔄 Round 27 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0713 (↓), lr=0.000004
   • Epoch   2/100: train=0.0769, val=0.0713, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0768, val=0.0712, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0768, val=0.0712, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0768, val=0.0712, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0768, val=0.0711, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 27 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0502
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0722
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2403, R²: 0.0880

============================================================
🔄 Round 29 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 29 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0490
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0725
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0780, RMSE: 0.2792, MAE: 0.2409, R²: 0.0866

============================================================
🔄 Round 30 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 30 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0573
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0109
============================================================


============================================================
🔄 Round 31 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 31 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0486
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0637
============================================================


============================================================
🔄 Round 32 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 32 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0480
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0617
============================================================


============================================================
🔄 Round 33 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 33 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0528
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0402
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2414, R²: 0.0851

📊 Round 33 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2415, R²: 0.0849

============================================================
🔄 Round 35 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 35 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.0554
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0279
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2416, R²: 0.0844

============================================================
🔄 Round 39 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 39 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0499
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0469
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2416, R²: 0.0842

============================================================
🔄 Round 41 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 41 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0414
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0825
============================================================


============================================================
🔄 Round 42 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0649, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 42 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0472
   Val:   Loss=0.0650, RMSE=0.2549, R²=0.0597
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2416, R²: 0.0842

============================================================
🔄 Round 44 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 44 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0456
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0644
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2416, R²: 0.0842

============================================================
🔄 Round 50 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 50 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0496
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0087
============================================================


============================================================
🔄 Round 51 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 51 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0528
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0344
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2417, R²: 0.0841

============================================================
🔄 Round 53 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 53 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0564
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0218
============================================================


============================================================
🔄 Round 55 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 55 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0415
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0818
============================================================


============================================================
🔄 Round 56 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 56 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0451
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0633
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2416, R²: 0.0842

============================================================
🔄 Round 59 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 59 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0484
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0261
============================================================


============================================================
🔄 Round 60 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 60 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0496
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0505
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2416, R²: 0.0842

============================================================
🔄 Round 61 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 61 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0545
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0306
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2416, R²: 0.0841

📊 Round 61 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2417, R²: 0.0839

============================================================
🔄 Round 63 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 63 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0467
   Val:   Loss=0.0666, RMSE=0.2580, R²=0.0234
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2417, R²: 0.0837

============================================================
🔄 Round 66 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 66 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0527
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0219
============================================================


============================================================
🔄 Round 68 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 68 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2741, R²=0.0559
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0250
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2418, R²: 0.0833

============================================================
🔄 Round 74 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 74 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0556
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0278
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2418, R²: 0.0831

============================================================
🔄 Round 78 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 78 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0528
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0308
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2418, R²: 0.0830

============================================================
🔄 Round 79 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 79 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0461
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0643
============================================================


============================================================
🔄 Round 80 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 80 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0453
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0626
============================================================


============================================================
🔄 Round 81 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 81 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0414
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0789
============================================================


============================================================
🔄 Round 84 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0638 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0638, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0638, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0638, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0638, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0638, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0638)

============================================================
📊 Round 84 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0529
   Val:   Loss=0.0638, RMSE=0.2527, R²=0.0299
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2420, R²: 0.0824

============================================================
🔄 Round 86 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 86 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0510
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0404
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2419, R²: 0.0824

============================================================
🔄 Round 89 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 89 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0451
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0383
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2419, R²: 0.0825

📊 Round 89 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2419, R²: 0.0825

📊 Round 89 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2419, R²: 0.0825

📊 Round 89 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2419, R²: 0.0825

============================================================
🔄 Round 98 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 98 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0539
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0307
============================================================


============================================================
🔄 Round 99 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 99 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0516
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0425
============================================================


============================================================
🔄 Round 101 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 101 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0509
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0442
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2420, R²: 0.0821

============================================================
🔄 Round 102 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 102 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0490
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0506
============================================================


============================================================
🔄 Round 105 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 105 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0466
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0566
============================================================


============================================================
🔄 Round 106 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 106 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0589
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0090
============================================================


============================================================
🔄 Round 107 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 107 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0486
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0536
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2420, R²: 0.0821

============================================================
🔄 Round 108 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 108 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0556
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0196
============================================================


============================================================
🔄 Round 111 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 111 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0521
   Val:   Loss=0.0673, RMSE=0.2595, R²=0.0376
============================================================


============================================================
🔄 Round 112 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 112 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0508
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0346
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2419, R²: 0.0821

============================================================
🔄 Round 113 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 113 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0453
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0638
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2420, R²: 0.0820

📊 Round 113 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2420, R²: 0.0819

============================================================
🔄 Round 115 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 115 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0514
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0421
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2420, R²: 0.0819

============================================================
🔄 Round 116 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 116 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0538
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0293
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2420, R²: 0.0819

============================================================
🔄 Round 120 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 120 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0480
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0530
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2420, R²: 0.0817

============================================================
🔄 Round 121 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 121 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0428
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0375
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2421, R²: 0.0816

📊 Round 121 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2421, R²: 0.0815

============================================================
🔄 Round 125 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 125 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0486
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0504
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2421, R²: 0.0814

📊 Round 125 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2421, R²: 0.0814

📊 Round 125 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2421, R²: 0.0814

============================================================
🔄 Round 132 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 132 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0532
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0297
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2421, R²: 0.0812

============================================================
🔄 Round 134 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 134 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0526
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0336
============================================================


============================================================
🔄 Round 135 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 135 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0565
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0170
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2422, R²: 0.0811

📊 Round 135 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2422, R²: 0.0809

============================================================
🔄 Round 139 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 139 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0524
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0343
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0807

============================================================
🔄 Round 140 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 140 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0524
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0335
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2423, R²: 0.0806

============================================================
🔄 Round 141 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0659, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 141 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0426
   Val:   Loss=0.0659, RMSE=0.2567, R²=0.0734
============================================================


============================================================
🔄 Round 142 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 142 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0480
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0497
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2423, R²: 0.0805

============================================================
🔄 Round 146 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 146 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0470
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0507
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2423, R²: 0.0805

============================================================
🔄 Round 147 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 147 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0519
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0223
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2423, R²: 0.0805

============================================================
🔄 Round 150 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 150 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0508
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0154
============================================================


============================================================
🔄 Round 152 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 152 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0535
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0262
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0800

📊 Round 152 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2424, R²: 0.0799

============================================================
🔄 Round 156 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 156 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0483
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0423
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2424, R²: 0.0798

============================================================
🔄 Round 158 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 158 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0402
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0833
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0797

============================================================
🔄 Round 159 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 159 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0456
   Val:   Loss=0.0689, RMSE=0.2626, R²=0.0588
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0796

============================================================
🔄 Round 161 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 161 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0500
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0324
============================================================


============================================================
🔄 Round 162 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 162 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0486
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0427
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0793

📊 Round 162 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0793

📊 Round 162 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0793

============================================================
🔄 Round 168 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 168 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0406
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0803
============================================================


============================================================
🔄 Round 171 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 171 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0506
   Val:   Loss=0.0720, RMSE=0.2682, R²=0.0378
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0794

============================================================
🔄 Round 172 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 172 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0464
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0560
============================================================


============================================================
🔄 Round 175 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 175 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0493
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0443
============================================================


============================================================
🔄 Round 176 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 176 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0536
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0251
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0795

============================================================
🔄 Round 179 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 179 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0527
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0225
============================================================


============================================================
🔄 Round 181 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 181 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0414
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0739
============================================================


============================================================
🔄 Round 182 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 182 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0480
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0503
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0796

📊 Round 182 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0796

============================================================
🔄 Round 185 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 185 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0481
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0492
============================================================


============================================================
🔄 Round 186 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 186 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0467
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0557
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0796

============================================================
🔄 Round 187 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 187 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0448
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0589
============================================================


============================================================
🔄 Round 188 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 188 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0456
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0441
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0795

📊 Round 188 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0796

============================================================
🔄 Round 192 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0650, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 192 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0490
   Val:   Loss=0.0650, RMSE=0.2549, R²=0.0435
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0796

============================================================
🔄 Round 193 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 193 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0514
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0391
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0797

📊 Round 193 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0797

📊 Round 193 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0797

============================================================
🔄 Round 196 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0628 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0628, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0628, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0628, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0628, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0628, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0628)

============================================================
📊 Round 196 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0383
   Val:   Loss=0.0628, RMSE=0.2506, R²=0.0963
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0797

============================================================
🔄 Round 197 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 197 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0569
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0156
============================================================


============================================================
🔄 Round 198 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 198 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0543
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0065
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2424, R²: 0.0796

============================================================
🔄 Round 200 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 200 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0500
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0431
============================================================


============================================================
🔄 Round 201 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 201 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0549
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0219
============================================================


============================================================
🔄 Round 202 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 202 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0522
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0337
============================================================


============================================================
🔄 Round 204 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 204 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0484
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0493
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0793

============================================================
🔄 Round 206 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 206 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0546
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0239
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2425, R²: 0.0793

📊 Round 206 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2425, R²: 0.0792

📊 Round 206 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2425, R²: 0.0791

============================================================
🔄 Round 210 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 210 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0415
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0639
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2425, R²: 0.0791

============================================================
🔄 Round 211 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 211 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0516
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0371
============================================================


❌ Client client_56 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
