[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fb38c06-7a96-4c27-b9f7-5eee64b769a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc20bf93-adb0-4751-8a69-d539f38d6da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db90acb-c92d-48ac-82ad-6cf5e3ff61ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcdf39d5-309e-4bfb-8160-1b61e3b34028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a6be636-8722-4e1f-a2a2-55d454a0002d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd0bb4c-f975-462b-ac9f-0e3ed71751dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c755349-ae03-45b1-b69e-ce0f8e2e4558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8cd2f3-9bf3-4deb-b571-d4d1f08e152b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70559f73-0b45-405f-be5a-4107c1d872cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e0beff-6217-427d-b859-c9d8c38f05e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae21624a-e89b-4656-9953-4534fbd85e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264df541-de10-490d-895d-eb4e3c7f243b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a5a8cf5-923c-4581-ae05-8731ec0bb2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d31d8f-3233-4281-abef-22d152630fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3c9d3c-2967-4b95-b359-a221dda147eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c76a3e2b-bb5d-4665-8429-7770d1424a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2425eebd-c9dc-4915-bcf2-8232210f1764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d11f14fc-12ca-4f58-b2dd-1d675abb20cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd27fa5e-4c75-49a4-9adf-c931ac726655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68f3948-46db-4092-aa04-22751e1efcdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90743192-b6d9-413b-a931-5eae779b24d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a329b01f-3ec4-4598-aa9b-b398a7189d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa28b335-3f5d-4545-8427-6e6a891b85ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86957052-a79a-448e-9c1f-559a2099ae56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 552b4b1d-a594-4ba3-a324-3664b24114ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68df1ac-0d77-4f1a-86af-f8c31989deb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12cbfa61-8cd3-46fe-bebd-8a104d0849ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88267497-74fa-4754-97c2-66f815f72d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fd4777d-c855-4017-8277-a51387084be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b185178-7fba-4bd0-89f0-642b2419d279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181cebde-e80d-4468-a860-5f593262f54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c71b20-3d1d-4368-a0de-1045505bc385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4fd31a-b6ec-463d-9a8a-087fd672fcd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49cd0b21-21be-4654-941e-e9aead7693a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb171c7d-348f-44a8-a3af-e2069dc28518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05eb40d9-065b-4722-8de7-0ff7cfe3210d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfdb3e0f-8b49-44f0-a885-43ebfdb50d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34045753-bbb8-47ec-822d-eace71920a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83f487b2-24ed-464f-8860-e355fe12bc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27f16d01-818d-4f8b-a905-ef5e6cdb662c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06ffd5ba-0c75-42e6-9f2c-efaa28ffb62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10dd0a78-4a9b-4f54-b294-0301c4914d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419680b9-2153-424f-ab8e-5c7397800b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82f7c23b-d2af-4e7e-bffb-5bb71fea0ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 736a89cb-c455-4cad-9a07-a4fe059cd540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08c472af-800b-41b7-94c1-15a33b42f0e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfcfb3a9-fb7f-4176-a555-c6edff4d7200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2bbc95e-941f-4ded-9239-9e7b71098a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25805cc-fc9e-4432-93ed-c5f140be6444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 958fc5df-e4b1-4f7e-b76f-1df65d6474eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fac2f1ea-64ee-4223-bddf-a2cb0ca0f989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43060031-5cd0-434a-886d-31d6cd15db5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e073f36-29c7-4bb9-95f3-ba36b591ee0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf75429d-36e3-4a6c-96f0-75b759257f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 228160d2-86c4-4eb2-a071-b6a2c577ca24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec220fad-4d58-4594-9da7-bc0609df42a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb2e4e8a-8991-4161-8beb-57a85b631ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f62b35-8d60-4ed2-b1ef-c7cfec61337c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafc4519-eb31-47e9-856b-4d035522b708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2f34938-7d2c-4987-b2ff-b88a8cda1be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e119f235-7eac-4e63-8e34-544df5df616b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d1a7183-2cb9-40e0-867c-38e500a7ba6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737306e3-ec39-48ef-a36f-df194fb86d7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff69012-3df7-4cd9-9858-e70f00c6baff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54049360-3fa8-4f36-9c87-3ccae28df1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2129a4d6-c93c-43bf-8628-3c545abb9c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3078e84e-9d07-49ff-ab61-fb54183ee539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed2abb5d-e0ee-4fe5-86c1-44727a8e57f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a084d553-a4f5-40b8-8643-87ca196d0781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9f4ba6-5ace-4171-ac9c-9fd9f2bc1d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccaa5f7e-2150-467c-b09d-fd999765f888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b8ef1ba-5b05-4c64-b10c-574409f10fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e084b6-819f-4c2c-b886-c316b4175590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e11f28-42b1-4426-b44a-e68d3e4eae27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9393c37-cddb-48d1-8389-fe51ef8fda43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b04c902-c53d-4eeb-8e88-8d556c284d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80108217-e6f0-42a9-8cc5-61a7e10c1e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3cfbfc7-7334-452e-868e-858ce8c88769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2521732d-378b-4465-ba5c-c6943e99fa70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c48f39-c16b-45fd-94e5-8da9efdc743f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42a91f32-9881-4fe8-afcf-4ada9c38f0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd9b64ab-5f22-4e84-8aa9-de8b48c6c276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a688d703-2450-4313-bc2a-777152e1ecef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7135455-c1c2-48db-99d6-3c751d85aa72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1ad5f8-ae9b-4d4e-9bd3-e9800042d837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea30d88-e38d-467d-a607-86d5f487cb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5231f773-8d1d-4883-ab1a-f14ab4e4f9dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5bfaca4-077d-4699-a7c5-4355b9e0cc00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eaaf4f6-e887-46ce-9fdf-620f9b63194d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb2ae9a6-b326-4f7e-870b-4be52604d369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364676b7-efb5-4a2a-ac07-d7d6a99a09da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37253bb5-4ac8-42c9-8db7-9556b633e5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0eef0e-0cd1-4bab-a639-db1de943c98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc95f93-f6c7-4e8b-b536-a43b2e19e140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f052b252-7bdd-472e-bf21-7cf184d0f0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904ba301-fc9d-4d1c-894b-f590285b6655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa230c8-789f-4c7f-a0b8-a8ead3714462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f2926d-6db5-445a-9405-d3b03b1301cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e1f59ac-b3de-40e4-bff7-0e39e00e47f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53509544-c4b0-43c8-b2f1-0e88bae433df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f78e35d-7482-4db9-a703-a461fe564a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91eec7bd-4867-4c1e-8616-a0ed9d41a2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23e27588-da4c-430f-af04-52b72fd16f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 633f6b2e-fafb-477c-8433-d790ac59908a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b51ef51d-b6c6-4f54-98dc-0f4f1b86f113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4973fbbb-9922-4632-a156-321624e81936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa69c8b3-5214-447e-a380-deb392f12551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1bd130-56fc-42d5-810f-bc4f537818f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090c183f-1186-4db8-8765-ec6ace1f50f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8521d636-7bb6-44cb-a28a-764fecb1a0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc99999a-bfb7-4c56-afcb-ebcde20d67e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585800cc-8d1c-41fd-8f98-b20a896405f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5498715e-6e2f-4d17-8502-5b3924695d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665e93d5-3093-4eb0-8d62-18be886b5f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c957621-c664-40ec-a348-233bc6bfae64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dddd0218-697a-4f84-a714-e3ee23faa28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf91dc54-7526-4052-bc7d-3e37d7679be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb026e6-050d-45ea-95c9-6216a9920ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 837d436e-9748-447a-9bb3-ecf9112d4343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc264d1-6170-4cb7-9f2b-50ab4d2c227b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 474aac35-2eb3-4419-8511-bc21c79b4394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57685af6-2ba1-4adb-b9bf-ce1f3b03f7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3252b8c6-c38d-4b80-ba7f-1f669179d214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc15071-6bb7-4926-a724-dc30cea9318c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb86f5b4-92e7-44f2-8ae2-8c8e9a47da9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b097b49-8325-4207-9024-dd8ed069987d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d19bbe5d-5a58-45d4-bd54-ed1af4fdfdf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4980f17c-0067-4ed7-b2b3-d36f90f7d7a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd7a2d2a-256d-49d2-bfb8-0c7ceb678be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bccbb0b-44da-4162-800e-6b5e09d12bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a2ff07b-775e-4393-a8a5-7a1d32e11cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55087544-584a-413b-acb5-8d1151108858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86873915-8ef6-4c11-b5e3-4d45cb7aae54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b20c7f88-9420-4f18-af1a-bf7adf1239f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5f5c62-6711-4da0-b487-727e746c9785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d6d91e-6f93-41f9-bbf7-2997a48ca842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2deb3cca-a327-47b2-bde7-91aa67ce72be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 274a20c8-437e-47fb-9099-479ed08d4189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3636e6d2-72c4-4062-8388-507d34881905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a200c3-1cbf-4ae7-938b-0795a26b4541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6dade6a-96a3-4855-8f7a-6668b2682e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0abf97fa-9689-4538-bca2-1c88c825579d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0b9cae-cdfb-48c9-8986-a1ecb48600aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c91742-1e26-4a3c-8520-55beb52473f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bade9521-f017-42a3-90c1-8f98667f6c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b528a7-c2d4-497c-bc20-d8e39c865fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c38fa379-d4a5-4dc5-9d22-4ad0ba199734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad6fc672-f625-4500-b971-c71604195ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708a52ba-0e7e-4812-808d-5337291ae2da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e30e79a-e20b-4e6b-982a-fd1682d8f77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac87a7d6-20f2-4816-b85f-380c86f537af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa1b64d-a51c-4c68-a545-49a304b9f9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dcfbc23-bc18-4bf0-bc46-b55202908776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aefbe56-675b-4ff6-aa61-9cb3591664ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c064bbc9-f408-4248-a8de-74e99e27ceba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 381e7683-b806-4180-be28-9e2d17e7bd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3664498d-79a0-4792-8f51-17a3e92d17da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0674be-7720-4e52-8827-076a044e56cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c7be33-b8e4-457d-8b54-91ee0af3046f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980146c4-f697-4d08-a4d7-108bbfdb19ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b052e075-6f67-4751-bbc3-07c9279b6ea9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_57
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/test_labels.txt

📊 Raw data loaded:
   Train: X=(1626, 24), y=(1626,)
   Test:  X=(407, 24), y=(407,)

⚠️  Limiting training data: 1626 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  398 samples, 5 features
✅ Client client_57 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 13 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0831 (↓), lr=0.001000
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0831, val=0.0848, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0823, val=0.0852, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0815, val=0.0858, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0763, val=0.0882, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 13 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0042
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0080
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2494, R²: -0.0177

📊 Round 13 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2500, R²: -0.0226

============================================================
🔄 Round 15 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0821 (↓), lr=0.000250
   • Epoch   2/100: train=0.0864, val=0.0816, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0855, val=0.0812 (↓), lr=0.000250
   • Epoch   4/100: train=0.0849, val=0.0812, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0845, val=0.0811, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0827, val=0.0811, patience=8/15, lr=0.000250
   📉 Epoch 13: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 15 Summary - Client client_57
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0142
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0041
============================================================


============================================================
🔄 Round 16 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0743 (↓), lr=0.000125
   • Epoch   2/100: train=0.0895, val=0.0739, patience=1/15, lr=0.000125
   ✓ Epoch   3/100: train=0.0886, val=0.0736 (↓), lr=0.000125
   • Epoch   4/100: train=0.0881, val=0.0733, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0877, val=0.0732, patience=2/15, lr=0.000125
   • Epoch  11/100: train=0.0860, val=0.0730, patience=4/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0841, val=0.0733, patience=14/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 16 Summary - Client client_57
   Epochs: 22/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0017
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0170
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2503, R²: -0.0222

============================================================
🔄 Round 18 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0845 (↓), lr=0.000063
   • Epoch   2/100: train=0.0871, val=0.0841, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0864, val=0.0838 (↓), lr=0.000063
   • Epoch   4/100: train=0.0860, val=0.0837, patience=1/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0857, val=0.0836, patience=2/15, lr=0.000031
   • Epoch  11/100: train=0.0850, val=0.0834, patience=8/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 18 Summary - Client client_57
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0223
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0293
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2513, R²: -0.0294

============================================================
🔄 Round 20 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0806 (↓), lr=0.000016
   • Epoch   2/100: train=0.0888, val=0.0806, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0886, val=0.0806, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0884, val=0.0806, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0883, val=0.0806, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0877, val=0.0806, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 20 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0532
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0315
============================================================


============================================================
🔄 Round 21 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0903 (↓), lr=0.000004
   • Epoch   2/100: train=0.0875, val=0.0903, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0874, val=0.0902, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0874, val=0.0902, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0873, val=0.0902, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0872, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 21 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0464
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0714
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0845, RMSE: 0.2907, MAE: 0.2511, R²: -0.0309

📊 Round 21 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2511, R²: -0.0258

============================================================
🔄 Round 27 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 27 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0374
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0646
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2510, R²: -0.0229

📊 Round 27 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0209

============================================================
🔄 Round 29 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 29 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0365
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0323
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2508, R²: -0.0193

============================================================
🔄 Round 30 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 30 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0219
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.1020
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2507, R²: -0.0181

============================================================
🔄 Round 31 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 31 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0332
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0276
============================================================


============================================================
🔄 Round 32 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 32 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0401
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0055
============================================================


============================================================
🔄 Round 33 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 33 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0358
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0131
============================================================


============================================================
🔄 Round 34 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 34 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0338
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0233
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2503, R²: -0.0135

📊 Round 34 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2503, R²: -0.0134

============================================================
🔄 Round 45 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 45 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0334
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0061
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2503, R²: -0.0134

============================================================
🔄 Round 46 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 46 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0273
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0313
============================================================


============================================================
🔄 Round 47 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 47 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0222
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0504
============================================================


============================================================
🔄 Round 48 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 48 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0203
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0643
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2503, R²: -0.0134

============================================================
🔄 Round 51 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 51 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0262
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0595
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2503, R²: -0.0132

============================================================
🔄 Round 53 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 53 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0281
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0300
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2503, R²: -0.0133

============================================================
🔄 Round 54 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 54 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0319
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0175
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2503, R²: -0.0133

============================================================
🔄 Round 58 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 58 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0281
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0376
============================================================


============================================================
🔄 Round 63 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 63 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0305
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0179
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2502, R²: -0.0125

============================================================
🔄 Round 64 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 64 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0258
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0349
============================================================


============================================================
🔄 Round 66 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 66 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0319
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0083
============================================================


============================================================
🔄 Round 69 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 69 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0287
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0220
============================================================


============================================================
🔄 Round 72 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 72 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0306
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0213
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2502, R²: -0.0123

============================================================
🔄 Round 73 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 73 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0331
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0041
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2502, R²: -0.0123

📊 Round 73 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2502, R²: -0.0124

📊 Round 73 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2501, R²: -0.0118

============================================================
🔄 Round 79 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 79 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0321
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0135
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2501, R²: -0.0117

📊 Round 79 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2501, R²: -0.0114

============================================================
🔄 Round 81 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 81 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0270
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0288
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2500, R²: -0.0110

============================================================
🔄 Round 86 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 86 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0192
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0525
============================================================


============================================================
🔄 Round 88 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 88 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0183
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0559
============================================================


============================================================
🔄 Round 89 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 89 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0162
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0707
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2500, R²: -0.0109

📊 Round 89 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2500, R²: -0.0110

============================================================
🔄 Round 94 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 94 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0211
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0482
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2500, R²: -0.0112

============================================================
🔄 Round 95 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 95 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0284
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0266
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2500, R²: -0.0111

============================================================
🔄 Round 97 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 97 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0312
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0073
============================================================


============================================================
🔄 Round 99 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 99 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0282
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0191
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2500, R²: -0.0108

============================================================
🔄 Round 100 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 100 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0225
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0462
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2500, R²: -0.0107

============================================================
🔄 Round 101 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 101 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0237
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0401
============================================================


============================================================
🔄 Round 103 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 103 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0247
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0327
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2499, R²: -0.0105

============================================================
🔄 Round 106 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 106 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0260
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0256
============================================================


============================================================
🔄 Round 108 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 108 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0292
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0148
============================================================


============================================================
🔄 Round 109 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 109 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0232
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0422
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2499, R²: -0.0106

============================================================
🔄 Round 110 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 110 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0346
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0067
============================================================


============================================================
🔄 Round 115 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 115 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0236
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0557
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2499, R²: -0.0101

============================================================
🔄 Round 118 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 118 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0265
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0539
============================================================


============================================================
🔄 Round 119 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 119 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0288
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0238
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2499, R²: -0.0099

============================================================
🔄 Round 120 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 120 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0204
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0428
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2498, R²: -0.0097

📊 Round 120 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2498, R²: -0.0095

📊 Round 120 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2498, R²: -0.0094

📊 Round 120 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2498, R²: -0.0094

============================================================
🔄 Round 125 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 125 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0235
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0305
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2498, R²: -0.0093

============================================================
🔄 Round 130 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 130 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0285
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0135
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2498, R²: -0.0093

============================================================
🔄 Round 131 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 131 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0271
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0316
============================================================


============================================================
🔄 Round 133 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 133 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0282
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0445
============================================================


============================================================
🔄 Round 134 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 134 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0215
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0326
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2497, R²: -0.0088

============================================================
🔄 Round 137 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 137 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0326
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0163
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2497, R²: -0.0085

============================================================
🔄 Round 139 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 139 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0148
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0554
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2497, R²: -0.0083

============================================================
🔄 Round 140 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 140 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0241
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0186
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2497, R²: -0.0082

📊 Round 140 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2497, R²: -0.0082

============================================================
🔄 Round 143 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 143 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0228
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0246
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2497, R²: -0.0081

📊 Round 143 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2497, R²: -0.0081

📊 Round 143 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2497, R²: -0.0081

============================================================
🔄 Round 147 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 147 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0199
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0366
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2497, R²: -0.0081

============================================================
🔄 Round 148 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 148 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0235
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0231
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2497, R²: -0.0080

============================================================
🔄 Round 149 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 149 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0215
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0279
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2496, R²: -0.0077

============================================================
🔄 Round 154 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 154 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0215
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0272
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2496, R²: -0.0076

============================================================
🔄 Round 155 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 155 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0218
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0284
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2496, R²: -0.0075

============================================================
🔄 Round 158 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 158 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0233
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0181
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0074

📊 Round 158 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0072

============================================================
🔄 Round 162 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 162 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0247
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0143
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2495, R²: -0.0070

============================================================
🔄 Round 168 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 168 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0225
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0233
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2495, R²: -0.0070

============================================================
🔄 Round 170 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 170 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0223
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0214
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0071

============================================================
🔄 Round 176 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 176 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0300
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0004
============================================================


============================================================
🔄 Round 178 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 178 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0198
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0314
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0072

============================================================
🔄 Round 179 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 179 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0214
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0449
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0072

📊 Round 179 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0072

============================================================
🔄 Round 182 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 182 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0203
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0316
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0073

============================================================
🔄 Round 183 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 183 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0235
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0238
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0073

📊 Round 183 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0073

============================================================
🔄 Round 185 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 185 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0199
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0475
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2496, R²: -0.0073

============================================================
🔄 Round 186 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 186 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0241
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0154
============================================================


============================================================
🔄 Round 187 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 187 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0312
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0096
============================================================


============================================================
🔄 Round 188 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 188 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0125
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0643
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2495, R²: -0.0073

============================================================
🔄 Round 189 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 189 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0232
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0245
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2495, R²: -0.0073

📊 Round 189 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2495, R²: -0.0073

============================================================
🔄 Round 192 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 192 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0221
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0242
============================================================


============================================================
🔄 Round 193 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 193 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0154
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0529
============================================================


============================================================
🔄 Round 194 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 194 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0259
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0151
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2495, R²: -0.0073

============================================================
🔄 Round 198 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 198 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0195
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0369
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2495, R²: -0.0074

📊 Round 198 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2495, R²: -0.0072

📊 Round 198 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2495, R²: -0.0071

============================================================
🔄 Round 202 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 202 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0290
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0019
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2495, R²: -0.0071

============================================================
🔄 Round 203 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 203 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0198
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0397
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2495, R²: -0.0071

📊 Round 203 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2495, R²: -0.0070

============================================================
🔄 Round 207 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 207 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0206
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0263
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2495, R²: -0.0069

============================================================
🔄 Round 209 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 209 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0287
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0046
============================================================


============================================================
🔄 Round 211 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 211 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0217
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0216
============================================================


❌ Client client_57 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
