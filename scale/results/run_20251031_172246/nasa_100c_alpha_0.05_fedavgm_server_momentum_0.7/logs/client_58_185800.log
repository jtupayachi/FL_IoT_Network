[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0f5f487-ed7d-4afc-89f4-38bfa0a41d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1bd589d-5702-4de2-ac76-d68caf8004d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 628ff5f2-5120-4cf8-8036-3fc7080466cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb01eae-0d93-4ae8-9a73-181d954fe210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695e1e6e-491b-44e4-8e91-fc2e2f5c8152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17f35fac-def2-4298-90ff-dcb5508351ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b830f1b-0790-41c6-a141-ae062513e4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28034c11-9e2d-442d-8450-8046314a9a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f15250-609c-41d5-a9e3-4fd002b8a474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 003bf13a-778b-4dcc-9bf1-326576293dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d66257-ea78-4e7d-b707-aafca383962d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8d25f3-659a-4055-af61-1397ad7c12c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d449469-960f-421a-b70d-b933deb8dfd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964af195-0fc8-4765-af20-c8678fa2a61d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97f6e18-5da7-4dea-bdb6-51e4f1002e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 502eeaf8-99ee-4ac4-95da-93cc2ddd61cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4916d8f2-fb17-4271-a6d0-f179a36ae214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375f1391-e327-4136-936e-efbc6a4960b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44620cb4-828c-43f7-b6de-cbd6260b567f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ec2611-81d0-4582-8c2d-5d22c89d471d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aaf717f-409c-4b91-9a03-b5801cad80a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab3c53b-a713-44d3-9602-2eff295235d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43afad5a-0cfa-4328-9526-d8b35f41c56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1480557c-32f8-4877-bdbd-071ede9f59c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cc05c70-e9c0-479c-aff8-56fcbfafbbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86920b7b-a2c4-4531-8c29-e093de53873b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4c54bc8-7bed-460e-b19d-bb4a0b4ae676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08dc2441-def8-48f6-8030-d1feb4ca0cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc78804-0b25-4a73-8ffb-0063a2ccf73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51c0273c-3b5f-405b-95c1-d0151f3dc592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ef610b-cac3-4bef-a4dd-7eae35d0ba6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055a99b1-67e1-49c9-a09f-b670d5a29010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206e87a0-5891-44dd-bf6b-45120cd2650a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a2469b-4e2d-4e01-910b-2edb282612da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4bd7470-d742-4acd-af01-78acfcde4995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6176907c-fb0d-4460-9da1-9fc737613cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73bb8c09-639c-4c86-905e-fb7fbc3ceba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb7795c1-ba62-4ec7-afbb-560d5db76277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9144e6a4-5e2d-404d-9425-7b42e4649795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6cb10a7-039e-41c6-a7e7-3403d2ded4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0408b889-a251-4824-97e0-81282237b857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cfdb593-47a5-4116-9885-05f6086b8310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7798ab07-4da1-4c8e-856e-5505ccb7669e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0721d8b9-f30d-4aba-b2c9-711ec8497375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c269657f-698b-4b34-bb87-d2d6de3019f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ba9394-1514-4b63-9fa5-dacbaf41e62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f620f71-eac0-49c0-9b52-4ba0b59061aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b48d2ef-3d2d-40d2-9414-3377a752c72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06111d08-67dc-4c08-a531-8993d06439a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6ee17ab-c2c0-4528-9019-1230ddfafab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c48ecfb-b6dc-4882-8505-6a2de4893581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf583250-2510-4e07-b012-b4b8b873d329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0d299f-4a3c-4fae-a55c-9c535f192f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed93031-ff0b-449c-b3c2-2f8d96ce32f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19445d68-ef21-4054-aca6-62045452c154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff20f4f5-bbf7-4b93-9084-f029af731418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5009ed6c-af07-4cbe-9dc1-48f62cac45eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b624ed79-4b57-4551-a113-dbe01bebe7b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef179478-0d0b-45e3-a92a-e7f13d35cb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f6ed09a-7a95-47d8-b274-0c607ab64169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e640cb-c3e0-49f2-a83e-9f8e43a030a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3920d6bb-f8de-4bec-b674-28867061917e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10ef8774-29cb-4140-b504-dcb4045597e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53603158-12c9-47dd-975c-b8bce39a3fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43a30e6e-dd9a-4b85-a9fb-1a78fb064b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506bddb7-8eff-4874-80a6-d8334c58771a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9d940fc-7e8b-49e0-843a-84f4b58b02dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dde8204d-4ba9-4fd1-8653-04ecb50e632f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145eb0e2-ab9f-4628-aa2e-1f2274f8945e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb79fe23-4766-43ea-a546-8aca81f1a1fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ce01749-7017-46b0-94a3-435ad1c621bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 347d429c-afd5-4c2b-9c2b-54b6286a6449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dfe274a-6311-4a56-a816-3e00f7a0de5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 387107fe-7f26-4812-b44e-732c611cbb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db06b9d5-0c56-4d40-8ab3-7128d2b74e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e3bac6-9182-49df-993c-5904bb1b99dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e984bcc4-c14f-4b19-abb4-ca16c3a07760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9409f1f-44c7-423e-9fa0-02dd62b0bb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f218b24b-d2ab-4df7-bd64-006b5edc21e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e4e0bf-0c82-4121-bf1d-b391c86fbdc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f61aff7-ef9f-4dcd-b809-2e8368788739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03775db-fbab-42c5-8a3d-8e847d9e0e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7690b75e-aeb3-4e61-b0f2-348a1d508af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195c6cf9-3df6-4b46-8a87-094174a38165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71abb586-b1e8-4ac4-8610-75c5bbe72910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1c2be8-ad5b-40e7-a9cd-38d2f396d73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60bdc66-ad66-48a6-b4a0-b7a24a9c3763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39a1f481-f4df-442f-8e05-daab5a1516ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea86b7d-6f06-42a5-9eae-3c731eb30849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9351cdd-c6f5-48b1-8395-e7ed129092a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a840e09-a221-4eba-99c4-8f50bd5be99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52321d9b-d996-47de-bff3-69cc3fadbdb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 989380a9-a266-4213-aa35-eb37ab717664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e72987e9-ff5a-4eb1-823a-fd8e206216c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a91200-b237-4baa-9ded-9c6e621c2999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbc2d1d7-e742-4c15-82c0-f7d35ef79237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ad61d3-35f7-4ce9-87dc-30ac37cb6359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ade5ea-08a7-4483-9355-81164d8f7165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0f2b33-93df-40ee-8460-f949c4e69773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 014006e6-43fb-4b93-9424-a4cfb29654c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ec0affb-cd5b-4489-a215-9f5aeafa8a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3645926b-0e3e-45dd-b9d5-ebedfe6da198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5bd2457-701d-46d1-9dba-41a8cb32d126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cf6f7c8-6b6e-48dc-a33a-0b379d923d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad8c7ab6-41a3-4ac1-8889-60f49d2a1a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb1b23f-d224-49fe-bd8c-35394b405a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d9daf27-fd4f-4923-8f50-50bbf3030851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe3532d-d69b-49fd-9986-d32e24f3117a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a70b79-edff-446a-b99c-b1a3b557dfeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3096f41-45dd-4b6a-ba0f-d15adee790f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4c8f85-5aa1-4645-81df-eec2bc4dec2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943e622a-bc99-498b-a434-7b7898a6b3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 513c28cb-fd1e-4f0f-8c8b-210fcb9c3606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18753b63-bb5f-4a0c-8d4c-5ec1c3540127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c110407c-5a09-4ec6-a8de-32abfd591555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60cbc83c-a0b1-4f70-a363-38cb3ee19013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e23e86dc-7b58-477b-8214-8178b0ccd3e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be7a0dc-d91c-4396-ba19-8bcaff840f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d469b55-38f0-49e6-819d-e3aaf3b2d6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a15692-ad85-4ddf-82f7-26c80198ee49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107d9e9d-d747-46d1-883c-b8fd4fd6bc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16ffe46-86f8-47a0-9595-879f997029d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f60a3e4-1e53-4fe4-bf01-797f56604435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a209ae0-8dd9-4d0d-9fbb-6dcd4af3e8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6324fe51-2925-437e-9699-6500a7ced36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f64da67-72d1-45f4-85da-f78fb7c55541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cc9ee0d-2e52-48c9-9a35-e4d702cddf29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78557fce-6063-45da-86aa-593f4663b4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0fa3be4-ebf5-4a63-bd4e-6d740e207bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5719117d-38b2-40f4-be20-b60d47778b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e4d495-d1a7-40e6-834d-6594cd577999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c94152c3-6a10-41f7-b88a-445af71c62d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63d8bca1-eae9-460f-82b7-d4909fc994de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35232b50-9dab-4a6e-8e8e-0d8bccb7b9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0579fc-6d13-472b-abbc-e73c45903a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf7472a5-2f2d-4e11-ab90-4ed61d5598a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e9ca236-666a-476a-8bf1-812836fdc835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f9f5b09-c5c5-43e1-b93b-2dd9806afbc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c3dd49-8d83-4ecc-b720-8aff9f5a9cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4154d1c-929e-4d6a-aa39-11e344a80ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac598371-32cb-470e-a47b-110f464ad0d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac81ab0-70dd-473f-bbec-4b544394b797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b962aa-ede5-4877-9403-f6ac882dcad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f2adeb-2f6f-4cbf-b780-90e4e0b3dd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 901c118f-525f-4d13-8c34-4ad03c4b6572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4161f00-b7ff-4604-b505-c3c2aff16e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e947e6d-9148-43b5-9de0-18d5dde86c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f0e4e9-2c19-411c-9519-712e8bdc585a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a5362c-0667-4ffe-9e28-fecfc9b0347f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c8bbd5-059d-4e5c-a0b9-1f05ca89a33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe72613-f55d-4a23-96ce-4f5512685686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ae6933-98da-4523-bd06-12a14035cfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e999bf09-9152-4ccd-ba19-42a6e9a34100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f9d6ef-7433-48c5-93b0-9681e09bfce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 428a9f69-b8f3-48c1-ba69-ea84b603f029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95eb96fb-1154-4112-9290-13e6ef0806b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647bb2f0-5f07-4575-8372-5b9c184d231a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7edb215-eee2-42f0-b817-1ac8df772f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25db606a-ac78-4e96-b2a8-e7b13882d951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe5ef4a-5c23-4dff-959c-3f03dde86ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6580b11-41da-4421-b450-4eb25b5aa0c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa852e1-8ca5-4654-939f-96f0c51a9756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd5b27e-c691-47be-a3c8-6061f29fbba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e482db71-1ff8-4f5d-a99e-e57d80f1eb04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b34c5a79-acbb-4ccb-b1bf-e6d9d13ba01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267d5889-47d1-44cf-998b-53b46bde473d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07591927-c2aa-42bf-9241-9be7b4e75eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69eff48d-27cb-4a2a-b7b1-b096295c939d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77fe440c-693b-4ac7-b319-79ceed463099
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_58
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/test_labels.txt

📊 Raw data loaded:
   Train: X=(864, 24), y=(864,)
   Test:  X=(217, 24), y=(217,)

⚠️  Limiting training data: 864 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  208 samples, 5 features
✅ Client client_58 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 13 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0800 (↓), lr=0.001000
   • Epoch   2/100: train=0.0817, val=0.0805, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0807, val=0.0802, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0801, val=0.0806, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0795, val=0.0806, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0754, val=0.0807, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 13 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0006
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0223
============================================================


============================================================
🔄 Round 15 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0912 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0798, val=0.0905 (↓), lr=0.000250
   • Epoch   3/100: train=0.0791, val=0.0903, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0787, val=0.0901, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0783, val=0.0899 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0770, val=0.0896, patience=6/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 15 Summary - Client client_58
   Epochs: 20/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0338
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0079
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2461, R²: 0.0415

📊 Round 15 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2421, R²: 0.0698

📊 Round 15 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2405, R²: 0.0817

============================================================
🔄 Round 22 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0826 (↓), lr=0.000063
   • Epoch   2/100: train=0.0795, val=0.0826, patience=1/15, lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   • Epoch   3/100: train=0.0791, val=0.0826, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0789, val=0.0825, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0787, val=0.0825, patience=4/15, lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0780, val=0.0825, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 22 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0230
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0254
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2409, R²: 0.0813

============================================================
🔄 Round 28 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0860 (↓), lr=0.000016
   • Epoch   2/100: train=0.0785, val=0.0859, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0783, val=0.0859, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0782, val=0.0859, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0782, val=0.0859, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0779, val=0.0858, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 28 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0277
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0334
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0779, RMSE: 0.2790, MAE: 0.2439, R²: 0.0630

============================================================
🔄 Round 30 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0769 (↓), lr=0.000004
   • Epoch   2/100: train=0.0811, val=0.0769, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0811, val=0.0770, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0810, val=0.0770, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0810, val=0.0770, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0807, val=0.0770, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 30 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0273
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0047
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2448, R²: 0.0566

============================================================
🔄 Round 33 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 33 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0291
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0080
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2450, R²: 0.0553

============================================================
🔄 Round 35 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 35 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0173
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0290
============================================================


============================================================
🔄 Round 36 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 36 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0277
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0355
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2451, R²: 0.0547

📊 Round 36 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2451, R²: 0.0545

============================================================
🔄 Round 38 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 38 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0162
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0416
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2451, R²: 0.0544

============================================================
🔄 Round 40 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 40 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0282
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0101
============================================================


============================================================
🔄 Round 41 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 41 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0231
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0125
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2452, R²: 0.0544

============================================================
🔄 Round 42 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 42 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0206
   Val:   Loss=0.0682, RMSE=0.2611, R²=0.0235
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2452, R²: 0.0545

============================================================
🔄 Round 43 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 43 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0202
   Val:   Loss=0.0882, RMSE=0.2971, R²=0.0174
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2452, R²: 0.0545

============================================================
🔄 Round 46 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 46 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0278
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0031
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2452, R²: 0.0545

============================================================
🔄 Round 49 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 49 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0211
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0101
============================================================


============================================================
🔄 Round 50 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 50 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0222
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0142
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2452, R²: 0.0545

============================================================
🔄 Round 55 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 55 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0148
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0437
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2452, R²: 0.0547

============================================================
🔄 Round 57 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 57 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0192
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0363
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2451, R²: 0.0549

============================================================
🔄 Round 61 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 61 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0254
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0065
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2452, R²: 0.0543

============================================================
🔄 Round 66 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 66 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0207
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0142
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2453, R²: 0.0541

============================================================
🔄 Round 70 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 70 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0216
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0206
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2453, R²: 0.0543

============================================================
🔄 Round 73 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 73 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0289
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0249
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2453, R²: 0.0545

📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2453, R²: 0.0544

📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2453, R²: 0.0543

📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2453, R²: 0.0541

📊 Round 73 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2453, R²: 0.0541

============================================================
🔄 Round 81 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 81 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0259
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0090
============================================================


============================================================
🔄 Round 82 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 82 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0227
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0046
============================================================


============================================================
🔄 Round 83 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 83 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0193
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0332
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2455, R²: 0.0531

============================================================
🔄 Round 84 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 84 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0135
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0459
============================================================


============================================================
🔄 Round 85 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 85 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0194
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0275
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2455, R²: 0.0529

============================================================
🔄 Round 86 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 86 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0240
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0038
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2455, R²: 0.0531

============================================================
🔄 Round 87 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 87 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0183
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0290
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2454, R²: 0.0532

============================================================
🔄 Round 89 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 89 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0158
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0427
============================================================


============================================================
🔄 Round 90 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 90 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0177
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0293
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0787, RMSE: 0.2804, MAE: 0.2454, R²: 0.0535

📊 Round 90 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2454, R²: 0.0536

============================================================
🔄 Round 92 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 92 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0251
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0069
============================================================


============================================================
🔄 Round 93 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 93 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0214
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0172
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2454, R²: 0.0538

============================================================
🔄 Round 94 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 94 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0246
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0004
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2454, R²: 0.0539

============================================================
🔄 Round 96 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 96 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0252
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0092
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2454, R²: 0.0537

============================================================
🔄 Round 97 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 97 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0196
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0304
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2454, R²: 0.0536

============================================================
🔄 Round 98 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 98 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0242
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0087
============================================================


============================================================
🔄 Round 99 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 99 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0157
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0406
============================================================


============================================================
🔄 Round 101 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 101 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0208
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0222
============================================================


============================================================
🔄 Round 102 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 102 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0203
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0287
============================================================


============================================================
🔄 Round 103 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 103 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0176
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0236
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2455, R²: 0.0533

============================================================
🔄 Round 105 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 105 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0130
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0503
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2455, R²: 0.0533

============================================================
🔄 Round 107 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 107 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0221
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0202
============================================================


============================================================
🔄 Round 108 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 108 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0207
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0266
============================================================


============================================================
🔄 Round 109 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 109 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0127
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0528
============================================================


============================================================
🔄 Round 110 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 110 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0248
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0057
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2454, R²: 0.0535

============================================================
🔄 Round 112 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 112 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0215
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0133
============================================================


============================================================
🔄 Round 113 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 113 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0278
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0045
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2455, R²: 0.0532

============================================================
🔄 Round 114 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 114 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0232
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0111
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2456, R²: 0.0526

📊 Round 114 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2456, R²: 0.0523

📊 Round 114 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2456, R²: 0.0521

📊 Round 114 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2456, R²: 0.0520

📊 Round 114 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2456, R²: 0.0519

============================================================
🔄 Round 126 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 126 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0274
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0060
============================================================


============================================================
🔄 Round 127 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 127 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0243
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0010
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2457, R²: 0.0518

============================================================
🔄 Round 128 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 128 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0211
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0142
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2457, R²: 0.0518

============================================================
🔄 Round 129 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 129 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0228
   Val:   Loss=0.0675, RMSE=0.2597, R²=0.0107
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2457, R²: 0.0518

============================================================
🔄 Round 130 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 130 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0189
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0277
============================================================


============================================================
🔄 Round 131 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 131 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0246
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0039
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2457, R²: 0.0518

============================================================
🔄 Round 133 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 133 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0143
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0438
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2457, R²: 0.0515

============================================================
🔄 Round 134 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 134 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0185
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0242
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2457, R²: 0.0513

============================================================
🔄 Round 136 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 136 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0207
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0174
============================================================


============================================================
🔄 Round 137 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 137 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0185
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0286
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2458, R²: 0.0510

============================================================
🔄 Round 140 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 140 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0225
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0073
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2458, R²: 0.0508

============================================================
🔄 Round 144 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 144 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0286
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0280
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2458, R²: 0.0508

📊 Round 144 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2458, R²: 0.0509

============================================================
🔄 Round 147 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 147 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0203
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0202
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0505

============================================================
🔄 Round 151 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 151 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0213
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0127
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0504

============================================================
🔄 Round 152 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 152 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0146
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0391
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0504

============================================================
🔄 Round 153 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 153 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0241
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0047
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0504

============================================================
🔄 Round 156 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 156 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0267
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0125
============================================================


============================================================
🔄 Round 158 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 158 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0212
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0079
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2459, R²: 0.0500

📊 Round 158 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2460, R²: 0.0499

============================================================
🔄 Round 164 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 164 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0183
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0094
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2460, R²: 0.0496

📊 Round 164 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2460, R²: 0.0496

📊 Round 164 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2460, R²: 0.0496

============================================================
🔄 Round 168 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 168 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0194
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0184
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2460, R²: 0.0497

============================================================
🔄 Round 170 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 170 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0157
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0096
============================================================


============================================================
🔄 Round 171 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 171 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0184
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0181
============================================================


============================================================
🔄 Round 172 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 172 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0254
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0104
============================================================


============================================================
🔄 Round 175 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 175 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0184
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0246
============================================================


============================================================
🔄 Round 179 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 179 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0250
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0001
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2460, R²: 0.0502

============================================================
🔄 Round 180 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 180 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0103
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0602
============================================================


============================================================
🔄 Round 181 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 181 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0195
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0205
============================================================


============================================================
🔄 Round 182 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 182 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0290
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0191
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0503

============================================================
🔄 Round 184 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 184 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0239
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0053
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0504

📊 Round 184 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0504

============================================================
🔄 Round 187 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 187 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0087
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0531
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0504

============================================================
🔄 Round 192 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 192 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0203
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0198
============================================================


============================================================
🔄 Round 193 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 193 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0208
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0177
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0505

============================================================
🔄 Round 194 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 194 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0197
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0219
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0505

============================================================
🔄 Round 196 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 196 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0182
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0163
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0505

============================================================
🔄 Round 197 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 197 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0179
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0295
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0506

📊 Round 197 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2459, R²: 0.0504

============================================================
🔄 Round 202 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 202 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0203
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0199
============================================================


============================================================
🔄 Round 205 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 205 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0190
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0159
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2460, R²: 0.0502

============================================================
🔄 Round 206 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 206 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0194
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0168
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2460, R²: 0.0500

============================================================
🔄 Round 207 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 207 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0258
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0073
============================================================


============================================================
🔄 Round 208 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 208 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0147
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0391
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2460, R²: 0.0500

📊 Round 208 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2460, R²: 0.0499

============================================================
🔄 Round 210 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 210 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0134
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0424
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2460, R²: 0.0499

❌ Client client_58 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
