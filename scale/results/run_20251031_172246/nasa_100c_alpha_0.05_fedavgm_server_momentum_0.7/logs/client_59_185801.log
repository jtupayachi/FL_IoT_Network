[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0c3ee3-1d4d-40ee-9702-fed98b7f8432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59b64419-3097-400e-affc-444b036f8e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2dbe6c-6690-48bd-b8f5-12c9988c81c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758679f9-e86c-4c5d-8904-df929c270879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef9281a6-0ec9-4c21-9ebc-7818bf616195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87874722-ac08-4165-92c9-decb4b16a075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfbc900-c96e-4982-bb86-1e4c85ede497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72eff439-cb47-44f3-aaf8-26bb54c4f49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55b8b831-cc6f-47b3-891a-67f6191980cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aeeda2d-80f4-4fcb-8416-c7915277f85c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42dc35d7-9485-4b19-9115-f56d5b51b6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0552df-cb7a-41dc-8812-8d385966021d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896bfdbe-2fc5-463f-a5eb-73828c2dfef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8242534-4bb8-40ed-a7b4-1572c3750311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc08f52-33cb-4dd6-a5bc-70d8cfbd4de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388af49a-4000-42ed-b290-b77577aa3b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f3aa643-16fd-46f6-8af0-98ea085d4942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad3b47d-d562-4311-8af0-5259f436df33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bf61c53-86af-42ac-b14a-ed0115c82382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7573cdad-f3ab-45c1-b879-67b86390f8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2878f4eb-83fc-4241-aba2-c0e28a37e19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fec0f42-a402-4ac1-8ed5-d293e11db127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b47f7c-8b9d-4850-9bdc-d0acf7a6ed4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78a97f0-2c7e-434d-b027-60a19c54152e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26ef1a1-6363-4177-bc88-1a77da8b0371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a54c5d5f-c962-4762-aa9d-83674fccb97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bbadd63-596c-45bd-87de-7a2240289392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72e59c2a-5291-404a-854b-0047ca8054b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe3575ca-9b84-4885-8996-cefa55f306b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473bcd5a-097a-4824-a744-8838fb1291b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b34ed493-3bbc-4ea7-a2fb-e08c54d77d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27cfea0-f659-499e-878a-462f7267c80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d7c246-0026-48ad-9ff0-561e73b58c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cea562a-e8b5-45ec-b474-ae82a67ef67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb95eca-d213-47dc-8c57-1e5e1351657a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4285c9-3d6b-46ec-98f3-98dd337d6ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ceee5e-4251-4416-a33c-dec060a58ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54706563-cc67-47f4-a069-e7f2780c88e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f5b7faa-2bfc-4cb5-825c-91afeafa249b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 828f91d2-0361-4644-ba64-4f30d1d83224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c824bf-5d0c-4c95-afbc-80d5a1764f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf40b894-58b5-4cb2-bb18-e329f7fbf942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 321c5faf-90ae-4480-ad52-6b972c4e54dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee48b618-cd46-45e5-82dc-9380cf85952e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d6abca-e9a5-42bf-8f3f-fcb769d8fde6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b32a11b-9d5a-409b-941e-5028fc297f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78bfa48e-05f0-46a5-a876-828cd2d56aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfcbf9ad-1d62-426a-840a-4cc7ad99e7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95b65f7a-b066-4431-a583-0ef55e112263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f30bfa-68dc-4e85-92f5-37738063130d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706385d0-4425-4a01-b7d5-a500a69dafc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e5b4c8-4057-41c4-9564-c35ffb6c48da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d13d018-8b7d-4a0e-a752-d56396662d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e107c7d-818c-4d84-80f5-162f7bc1941e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f033db26-9503-44b7-9f7a-b221261a9e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c45116-e038-4e62-bf20-f112fcace94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ded7df5b-78cf-4344-bbbe-6fc9eb07fd85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac637c8-1b97-48fe-a8ae-e306064fd6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfccf05-7167-4072-88d3-2351082b4f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96029b1-74a4-4574-99cc-64478d232596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 771ffed6-6be8-441e-afc5-c34fb59e1bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b42a300-7ba5-4ce5-9b8a-3d613578cb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d95ed2e-5be1-4ee3-8bee-0ee7b9b30773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53d30926-50b1-4737-97f7-75be2d20a5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21e98ddf-52cc-499d-94da-404c047942f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f622e8-6d73-43c1-b137-138edc806c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14aadbda-bdf4-4387-8bd1-b99e22b3fe0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0690301-41ff-4a7f-af06-753dc0439236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd9c037-6491-40f1-8028-88696b0cd574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd446a7b-f36d-4fc7-a0ab-f60d77706556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cfce288-1fd7-4086-bf55-7d2c6618c5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c71b04d7-bf58-4912-9c84-359144266ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b120615-9142-4cff-9d9b-6909f3524cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc183e4-c99e-44d4-8baf-e4dd4844f303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d1c831-3420-4d2e-a4a4-49a7cd51e0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 200d7ef1-52e1-46c6-9231-892a056b2b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc3ba15-8cbc-4fb6-a49f-152437209322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0d4b95-706a-4923-9066-99cc236adef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b44a49-6468-42b6-90b2-178bce6f6969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd9c469-f38d-423c-8ccf-64ad21dcea4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3776757e-9891-42e1-8c63-f84f8cf944db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99cf09d3-912a-46dd-91e5-80715206e2c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec9a356d-134e-447f-a753-d067d5d81366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dffc4306-bf74-448f-be11-6126ab9bba77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd545ac-b5ee-4583-aa81-b7e89c888a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff269e22-dc20-4312-a134-ea1acc27d4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0442c5-ea69-43d1-8445-d56b7a216f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a97bc9d9-ec94-4ed9-9ffc-716cab21c8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14238ac3-f70f-46b3-8f9e-fb0859948c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d58fccc-02d7-4bb3-9c59-984d89d05e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message debeef2f-c152-4bea-bc2a-a27686a58232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09e6995c-47f3-4364-a8af-78a552b8a73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49223025-5d42-4c48-9ead-1a45274ad410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a71fd79-f552-440f-89ab-0c8c3237760d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a1994af-2fa1-4d2c-86c9-b7397588c783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e700ba-95c0-47ab-ae07-4ff87074cf82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd30b3d-a13e-4d2e-a7f7-eeba6c5da264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788d0a31-da8e-46a1-8fa2-d5bf751f4930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf9b63e-2e21-47bc-9327-622eb37e7b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54217397-8761-4895-8a4d-90edc8b33bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b46206-a98d-4550-9ea8-ceb71bbcb073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 579bda27-26a7-459a-9a4a-bfb3fdc2635d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c7e9d68-9e02-4c39-a913-c12fe0669088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64875647-7f68-4751-811f-eb78f4be4402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc0b6ca9-3e3c-4de2-ac9c-a97879e01470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b5b8b2-d953-4c0a-b9d6-4bdf643afce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0e8287-d3e6-4e00-b41f-781d839f5835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff4a95f-06c1-4997-8feb-b5da3cedafdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56022493-89b4-463c-a769-f40d1a435558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a842a70-719c-4e4e-85ce-f51d42a9031b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7489e9d-05da-4af5-90fa-a5de3c693bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd16da9c-cf95-4b40-a02a-cff46561b020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec48cd97-82f1-4266-a1c5-e80f7c928183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 679f9022-f4f8-47ef-8c77-4b6fe50fe6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a526293e-ecb6-4c01-8dd1-2e1028625d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01e67360-2031-477c-a1df-cb67768b2acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36542715-b318-47b3-b0e8-3a62daec69bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 113cc948-0862-4289-9a5c-8a9f0ab58420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81896442-34bb-44ef-92f3-2fd8bf9568ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f015b8a3-774d-4406-80b2-f0a90068e349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe197a0d-dea3-478b-a5c9-b45b6f077190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da8d1486-43ce-4095-8d75-c4f9c640e409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14278ad9-f941-49cd-89a3-e5bd09a285de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd8df5a-ca24-41cd-8512-cc97920dd365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c368bc5e-5dc0-4ecc-b1c1-837d9546f1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8e676fe-9292-4336-b79b-10510a14c7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce659afc-9db1-4265-9844-d113dcfccbfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01dbeaa1-a443-4077-9c17-44f3cadb736e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7441607-98f5-4dcf-88be-69fff8014db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2af3c13-8c4c-4227-bf2b-cb9531572651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75863f26-e493-4f8a-8de0-cf49794c72f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c01c2d10-6164-4dc8-acdd-3776beba9a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0d5157-e3ca-4a6e-86e7-bd8a64dffa5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050cdb64-9a3b-4798-95d8-744169f6fd40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa919c3-2391-4cdf-be82-f76c2231fe4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f33ca8c7-f7bc-4ace-a273-cd5cd709e032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3becd0c-28d2-4621-b796-4be0fd3d4e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f19fc54-b2b9-495c-8ae6-4cff396d309d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f530eda-0c0d-4289-a03f-488f78a4d545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96ad8ec4-8166-4ae7-a162-2171666dcdba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3071d8ac-1919-475c-90c9-7abfac2620e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dd4c390-5e37-4efa-8a4f-206b86cdc4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630f2a01-0271-49aa-a4e9-ff0f7697a50f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_59
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/test_labels.txt

📊 Raw data loaded:
   Train: X=(1113, 24), y=(1113,)
   Test:  X=(279, 24), y=(279,)

⚠️  Limiting training data: 1113 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  270 samples, 5 features
✅ Client client_59 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2594, R²: -0.0780

📊 Round 0 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2599, R²: -0.0816

============================================================
🔄 Round 16 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0810 (↓), lr=0.001000
   • Epoch   2/100: train=0.0819, val=0.0806, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0809, val=0.0797 (↓), lr=0.001000
   • Epoch   4/100: train=0.0802, val=0.0794, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0796, val=0.0795, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0747, val=0.0804, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 16 Summary - Client client_59
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0276
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0808
============================================================


============================================================
🔄 Round 17 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0895 (↓), lr=0.000250
   • Epoch   2/100: train=0.0814, val=0.0890, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0808, val=0.0887 (↓), lr=0.000250
   • Epoch   4/100: train=0.0804, val=0.0887, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0801, val=0.0887, patience=2/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0791, val=0.0887, patience=8/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 17 Summary - Client client_59
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0173
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0230
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0919, RMSE: 0.3031, MAE: 0.2605, R²: -0.1012

============================================================
🔄 Round 20 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0763 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0865, val=0.0752 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0857, val=0.0744 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0851, val=0.0738 (↓), lr=0.000063
   • Epoch   5/100: train=0.0847, val=0.0735, patience=1/15, lr=0.000063
   • Epoch  11/100: train=0.0837, val=0.0729, patience=5/15, lr=0.000063
   • Epoch  21/100: train=0.0820, val=0.0725, patience=3/15, lr=0.000063
   📉 Epoch 28: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0807, val=0.0725, patience=13/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 20 Summary - Client client_59
   Epochs: 33/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0059
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0141
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2608, R²: -0.1017

============================================================
🔄 Round 23 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0909 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0851, val=0.0896 (↓), lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   ✓ Epoch   3/100: train=0.0842, val=0.0885 (↓), lr=0.000016
   • Epoch   4/100: train=0.0836, val=0.0881, patience=1/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0833, val=0.0877 (↓), lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0820, val=0.0861, patience=2/15, lr=0.000008
   📉 Epoch 19: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0812, val=0.0853, patience=3/15, lr=0.000004
   📉 Epoch 27: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0809, val=0.0851, patience=13/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 23 Summary - Client client_59
   Epochs: 33/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0087
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0403
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0915, RMSE: 0.3024, MAE: 0.2594, R²: -0.0963

============================================================
🔄 Round 24 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0973 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0843, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0969, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0837, val=0.0966, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 24 Summary - Client client_59
   Epochs: 30/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0708
   Val:   Loss=0.0968, RMSE=0.3112, R²=-0.0682
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2588, R²: -0.0866

============================================================
🔄 Round 25 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 25 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0616
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0806
============================================================


============================================================
🔄 Round 29 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 29 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0425
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0274
============================================================


============================================================
🔄 Round 31 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 31 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0192
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.1105
============================================================


============================================================
🔄 Round 33 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 33 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0301
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0405
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2557, R²: -0.0524

============================================================
🔄 Round 34 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 34 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0270
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0536
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0877, RMSE: 0.2962, MAE: 0.2556, R²: -0.0516

📊 Round 34 Test Metrics:
   Loss: 0.0877, RMSE: 0.2961, MAE: 0.2555, R²: -0.0505

============================================================
🔄 Round 37 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 37 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0233
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0559
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2554, R²: -0.0493

============================================================
🔄 Round 42 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 42 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0226
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0507
============================================================


============================================================
🔄 Round 43 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 43 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0297
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0217
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0875, RMSE: 0.2959, MAE: 0.2554, R²: -0.0490

============================================================
🔄 Round 45 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 45 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0294
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0510
============================================================


============================================================
🔄 Round 47 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 47 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0267
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0355
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2553, R²: -0.0483

📊 Round 47 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2553, R²: -0.0482

============================================================
🔄 Round 52 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 52 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0332
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0569
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2553, R²: -0.0481

📊 Round 52 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2552, R²: -0.0476

============================================================
🔄 Round 62 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 62 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0296
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0228
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2552, R²: -0.0472

📊 Round 62 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2552, R²: -0.0470

============================================================
🔄 Round 65 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 65 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0254
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0455
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2551, R²: -0.0466

============================================================
🔄 Round 69 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 69 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0333
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0208
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2551, R²: -0.0465

============================================================
🔄 Round 75 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 75 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0326
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0119
============================================================


============================================================
🔄 Round 76 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 76 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0232
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0486
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2551, R²: -0.0460

📊 Round 76 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2551, R²: -0.0458

📊 Round 76 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2551, R²: -0.0457

============================================================
🔄 Round 80 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 80 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0285
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0281
============================================================


============================================================
🔄 Round 81 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 81 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0252
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0337
============================================================


============================================================
🔄 Round 82 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 82 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0303
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0161
============================================================


============================================================
🔄 Round 85 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 85 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0246
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0429
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2550, R²: -0.0451

============================================================
🔄 Round 88 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 88 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0321
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0051
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2550, R²: -0.0450

============================================================
🔄 Round 90 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 90 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0299
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0117
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2550, R²: -0.0448

============================================================
🔄 Round 94 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 94 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0335
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0024
============================================================


============================================================
🔄 Round 96 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 96 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0267
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0285
============================================================


============================================================
🔄 Round 97 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 97 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0347
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0028
============================================================


============================================================
🔄 Round 98 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 98 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0252
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0332
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2549, R²: -0.0444

============================================================
🔄 Round 99 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 99 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0342
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0048
============================================================


============================================================
🔄 Round 101 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 101 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0307
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0079
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2549, R²: -0.0442

📊 Round 101 Test Metrics:
   Loss: 0.0871, RMSE: 0.2952, MAE: 0.2549, R²: -0.0441

============================================================
🔄 Round 105 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 105 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0320
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0007
============================================================


============================================================
🔄 Round 106 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 106 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0234
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0393
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2549, R²: -0.0438

============================================================
🔄 Round 110 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 110 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0310
   Val:   Loss=0.0694, RMSE=0.2634, R²=-0.0038
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2549, R²: -0.0438

============================================================
🔄 Round 112 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 112 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0263
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0247
============================================================


============================================================
🔄 Round 113 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 113 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0250
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0314
============================================================


============================================================
🔄 Round 117 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 117 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0345
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0095
============================================================


============================================================
🔄 Round 118 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 118 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0315
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0131
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2548, R²: -0.0436

============================================================
🔄 Round 119 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 119 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0226
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0370
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2548, R²: -0.0436

============================================================
🔄 Round 121 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 121 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0339
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0079
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2548, R²: -0.0436

============================================================
🔄 Round 123 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 123 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0252
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0221
============================================================


============================================================
🔄 Round 125 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 125 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0174
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0579
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2548, R²: -0.0433

============================================================
🔄 Round 126 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 126 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0278
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0102
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0871, RMSE: 0.2950, MAE: 0.2548, R²: -0.0433

============================================================
🔄 Round 130 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 130 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0195
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0481
============================================================


============================================================
🔄 Round 134 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 134 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0236
   Val:   Loss=0.0956, RMSE=0.3091, R²=-0.0246
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2547, R²: -0.0429

============================================================
🔄 Round 137 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 137 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0303
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0008
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2547, R²: -0.0427

============================================================
🔄 Round 140 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 140 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0196
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0395
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2547, R²: -0.0427

============================================================
🔄 Round 141 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 141 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0268
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0061
============================================================


============================================================
🔄 Round 142 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 142 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0181
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0446
============================================================


============================================================
🔄 Round 143 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 143 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0231
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0220
============================================================


============================================================
🔄 Round 145 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 145 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0205
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0402
============================================================


============================================================
🔄 Round 146 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 146 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0228
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0232
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0870, RMSE: 0.2949, MAE: 0.2546, R²: -0.0422

============================================================
🔄 Round 149 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 149 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0247
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0137
============================================================


============================================================
🔄 Round 150 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 150 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0264
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0087
============================================================


============================================================
🔄 Round 151 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 151 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0177
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0409
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0869, RMSE: 0.2949, MAE: 0.2546, R²: -0.0419

============================================================
🔄 Round 155 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 155 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0221
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0230
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2546, R²: -0.0418

📊 Round 155 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2546, R²: -0.0417

📊 Round 155 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2546, R²: -0.0417

📊 Round 155 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2546, R²: -0.0417

============================================================
🔄 Round 159 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 159 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0218
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0225
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2546, R²: -0.0416

============================================================
🔄 Round 160 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 160 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0197
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0300
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2546, R²: -0.0416

📊 Round 160 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2546, R²: -0.0416

============================================================
🔄 Round 165 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 165 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0243
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0131
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2546, R²: -0.0415

============================================================
🔄 Round 166 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 166 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0244
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0275
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2545, R²: -0.0414

📊 Round 166 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2545, R²: -0.0411

============================================================
🔄 Round 172 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 172 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0198
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0297
============================================================


============================================================
🔄 Round 173 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 173 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0238
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0122
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2545, R²: -0.0408

============================================================
🔄 Round 177 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 177 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0204
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0285
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2545, R²: -0.0407

📊 Round 177 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2545, R²: -0.0406

📊 Round 177 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2545, R²: -0.0406

============================================================
🔄 Round 182 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 182 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0214
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0284
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2545, R²: -0.0406

============================================================
🔄 Round 185 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 185 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0260
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0180
============================================================


============================================================
🔄 Round 188 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 188 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0220
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0264
============================================================


============================================================
🔄 Round 190 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 190 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0197
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0336
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2545, R²: -0.0402

============================================================
🔄 Round 191 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 191 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0239
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0159
============================================================


============================================================
🔄 Round 192 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 192 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0181
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0379
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0400

📊 Round 192 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0400

📊 Round 192 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0399

📊 Round 192 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0398

============================================================
🔄 Round 198 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 198 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0293
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0420
============================================================


============================================================
🔄 Round 199 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 199 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0215
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0281
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0399

============================================================
🔄 Round 203 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 203 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0267
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0028
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0399

📊 Round 203 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0399

============================================================
🔄 Round 206 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 206 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0130
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0623
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0399

📊 Round 206 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0398

============================================================
🔄 Round 208 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 208 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0236
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0151
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2544, R²: -0.0398

============================================================
🔄 Round 209 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 209 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0278
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0616
============================================================


❌ Client client_59 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_message:"Socket closed", grpc_status:14}"
>
