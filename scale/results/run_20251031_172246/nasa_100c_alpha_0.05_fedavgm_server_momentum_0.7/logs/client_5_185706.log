[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e24bd754-effc-49c9-82b3-4468baeca16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message becbc5cf-9ecb-4fea-8912-79a1680c16b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a0cd6d-311f-4883-9c4d-9def07cfea76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc5700e8-bc09-4808-ad74-66ab42483d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83d9aaaf-ff69-4a7a-b581-dae5a425e98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26011d47-cbb8-4988-8612-8f58dc085576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c12cb7-2e74-4466-bae8-e63701ecbcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3399910-94c6-4999-b150-6f49bbf36be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a3a257a-5e92-43ff-927e-92b092e01cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20483564-36e8-4433-a008-2bedb4d4d5f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85c885ac-0aaf-460c-b12a-8d1e83905eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a3ed00-226a-4531-8036-5286df67f954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7e2ef5d-79f3-4357-9535-86ad69566dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcda5a19-615c-473f-9292-0c1948c99450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d329b9-d88e-4a39-ad88-cd0d0b64d037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9adefae-9523-42ce-8dd9-9999ecd5ecd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 576f399f-92e2-406a-9d27-2e0b236b94c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3edd845c-c2f4-4686-8b73-c8b926c5ccb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f89fcf1-2bbe-4d3d-8632-43e82831dd35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fc5099c-1f07-4cf1-a636-2def98edf8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdb12e55-a70c-4a71-81e2-bf30b5812644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b22603-5d46-4ea5-b40f-d2fee4292047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc33d192-40b1-441e-af0c-203f7cdcd6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5634eb4d-a4f2-41d8-ac08-97c88572373d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3820d3-e80c-4cac-9774-1405065cfb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6e764d-545d-4b7c-8c52-2c8028dfbfe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648ce899-a8fc-4525-b26b-5e9f86efc098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c38992-c582-4efe-ad2a-d85bcba9c12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd39a90d-f8b1-4887-870d-72216c6a43f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2abf0c9f-0831-40c5-89a0-a0f0bce0ff63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046b3352-75dc-46ab-b6bc-fce80c2d2644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661aea27-9731-444d-9fe2-508bddf859de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1fdd9d-7f28-40b4-a3cb-3ee5827202ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2544471a-5bda-4bae-b6ca-d01cd1a05bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17063476-0615-4ee1-9d6c-05000c97bd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a7bcacb-1d31-4f10-8767-6661c550ac21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f47780b1-3cac-4a78-b72e-d4ee3116611e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6263e8b0-0a79-4ac7-85af-0d8205c5fb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce05e834-82bf-48c5-8343-b53705bd2230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fdd2368-6fc0-490f-b173-f9955a7649b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f45b8782-7a23-4cc8-b81d-856ccd836691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8a88114-1862-44d4-92cf-4aaa2753f256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee1606f4-e29a-4261-a897-295cf1d8b98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f249ae-2e87-4eea-a869-858d527378ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9794b60-49d8-4012-9d3d-2518cc87c184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71d3f70c-3d6e-4e87-89da-c55bd8c428cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b75e54f-17d9-4a41-a5a5-1a14573edf6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b073c636-1de8-40f8-8d3e-54d2f5225601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79cbf7d2-8b0a-4840-a1c5-c0f8b87c13a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce5b7d5-f5ba-4787-b5ad-0b3e4e37c7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92adfe0-2ad5-401c-a5ba-432932c09ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf43eeb-338f-4395-8601-b322f97ae22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 771b36c4-37ea-409e-80c7-c8b2fecf6056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f879271d-bd77-47d0-b392-b9c1fa20c703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07f5b606-9a81-4021-8d37-034a7408cbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46893640-f367-4665-ad97-a3e9fb1e08cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813faae5-3225-4c72-9766-60000ddf69cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6cf3da3-47b9-4479-b4ff-c544106333ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 749cee3f-8480-4c82-9e70-11d42a3d10e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 133da97e-0bee-424b-854b-cc21c2786803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e1e91a-b61b-460e-b666-986f70f9e819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64527f1f-ce14-4b9a-b73f-2c564555b90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1f5641-665a-494a-9f07-d9c035215c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca3e39d-7899-499c-9126-05dd45819b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abf0c051-5eff-4750-b544-2e3f8d3614d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee02e0f7-5673-4103-93b9-a759e3ec2e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35da552e-69c0-42ec-91eb-f1c21230dbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117a6360-c90e-49b4-8ddd-44cd6539f75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f7131e-5073-4eb6-a277-cb65b67b4c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e2bd371-b1c2-4ff4-b15c-15fbcc3e893c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52affe4d-9864-458c-a074-dbc10052cf05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c309331-221d-4d12-b7d7-bdd14eb7ddda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52f4b9eb-ee40-4681-b237-42e834e02e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 258ef6bc-ad5f-4e74-915a-83894e2e3ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6a91d5-f131-45a8-8ef8-4c0aab9e987f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0da61ca1-2a97-40ce-bf89-cfea6c2ce6f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b85985-ebde-46ba-80a0-d67c4f6b75f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd96cd2-5341-4063-86e5-cc25fa33e974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f224cd0-56e7-4e03-96b0-1da4de4e93cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70aa8948-fb15-4293-becc-cf9e8673ba68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68876688-8cdf-49f5-91a5-e65bcaa10200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2ee586-a76d-401f-8c78-9b25a78f5ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1627317d-6c9c-4100-a6a6-5fbcd927c734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acd3f046-1dcc-4b74-8331-97042b976f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5675980-dae2-4823-a2f6-c7d41a6f0145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70119da9-35d9-4271-befa-ecfb673d3820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06046f0-ea1c-4ff7-ae03-d8f43e0b7bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f640ee8-d6e8-48e9-aa4d-2a2934434b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e02aeb4c-b58b-402d-8e6a-fff8a9b686a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f62367-8779-46d3-9209-7597704566fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40fe74e0-68c3-4853-aeb8-40f518b1fa19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff9b1e74-f70d-457f-8be5-ca443f2f8ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be7e41e0-86ae-4adc-9b6a-5dabeece9b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8fb330d-9b8b-476d-bd7e-5958f5875396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a58385-234c-4e29-bcb4-d5dcc8dc9c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8fa75a9-b0d8-49f8-99b6-e14fec01afbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3085f917-57ae-4e74-b9cc-7ec488e07ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e990cb-5096-4144-a7d0-cc4cb3ae8dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e9b3bf-593f-4c38-8fde-13875a67a64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e19cf79-9e21-403d-8076-a68b449a9810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a892a720-3f66-4910-849f-bc58f0e5b44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb5cdef5-91f3-4787-bdb8-e327d0cc76b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3bd0715-270a-40ef-9941-a9188f3a5827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fecaa263-f905-4e16-a83a-d5b281beafc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 596cb650-a2ab-4a5a-9007-8c79e6bb9152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21c6ae43-20b9-4c44-b2dd-cd38c744b664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928cc7eb-d503-4cef-9b9c-5710f337cead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb8a66e-520e-4d32-a061-54bbb8abd5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbcca7e1-3676-4953-9276-44dc193fb488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb59f771-6908-42d0-8cd4-297eaf4ecb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 126c01dd-4b2d-462b-876b-32c9ffef16c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee2d857-8dbd-4c9a-8060-5cc00fb49b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44bc3c61-1d72-4831-9dc1-ba7687c39af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 270a025a-418a-4b5a-890c-faf30c51fe86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ffe388-b82e-4797-939b-d728c28b15a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee4ce56-d79b-4c75-844f-f2ac059dfab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e2a244-27de-4270-bfda-0d2a499bcb16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a17aa27d-4cf7-4041-b74c-2462879905f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9eae62e-54c5-494d-844c-4e1595b8d316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d6fa59-1933-44df-8460-a295a3bf07dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a4451b-bfa9-43a0-a888-28f679ab0e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22878153-23ac-4bae-804c-04c834c4de17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 123db32c-3d10-497f-9279-f9dd54fe5219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5fbbc28-1c46-4200-819e-684027ebf45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697fcefd-654b-4809-84a2-d6fd84fc18e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 639a8afb-e597-4926-a811-6e4fe49a2e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0fdaf07-a746-41b4-acb9-03ca928c606e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c52761-4d2e-48af-8df1-2c9ebc74adaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e337e3-5107-4bd0-8904-a1f0160e01a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b492d1e1-d9cd-4c6a-8acc-5da70d8a0c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde282ae-834a-4339-92a7-900f1e34231a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad52b5f-5104-44ed-a2c1-20ea851e80b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6be9eb6-6872-4e55-8b2b-1b190a28f6e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e40611e-91d2-4b09-a431-22f8bee6f1d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749f0a2b-5165-4006-b482-6bf39ab6ce75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5746b5f2-4e2b-4738-9594-a157ff5356e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db3c2a30-0071-4abc-aeec-0057f667e927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4407782-ef51-435a-9477-ef3c01a8f401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b44546ad-1992-4902-8989-71ef128a15d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d9ae3f9-3ff7-40c9-a375-072066498ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b048eeb-3f5d-40ba-bc2d-046535cd0917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0dc1df-a163-4a5e-81e8-392f5ec82b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca4e38d-240d-4a31-9ea5-f151d1331645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ab673e-ba40-4a3b-a0b8-d0004973b5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d946b2d-ee95-4ce2-9b8b-fd207f092d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a5d31cd-8587-495a-862c-df7d40ad071a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00db153e-5930-4399-ba28-63500998a7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f444bc-4246-45e4-8598-6f9183833fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60321748-0202-492a-8aae-2916dace8155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c6ec18-a7ee-4b80-976b-ec3a6159b8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a1f3c27-03c2-4993-968e-0fc48abbf099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de35e676-d2a9-40ba-90d3-738a51c22841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3542fd51-f007-424a-a0bf-1db43ca7bc9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9da32b-fe56-41ec-94d0-febba511cbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf77ad9d-ce3d-4515-9b0a-d03b336913a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2521815e-9ac9-490e-af9d-5c79119d767f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebda97cd-3347-4114-a5e6-a6db7a91b4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08633f5d-f362-4f64-92a0-e826774d283e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214866bf-421b-46e8-84ca-0d89e98b5c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4caf2d6b-ba88-458f-8e2c-d43f985e1ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e946cfd-2ce4-45e1-a28a-8b35f54e17be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63aa9d2b-03f3-42c9-ae71-ff35c2175866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117fa766-b9ee-4b16-8b9b-623681d24bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b003a4b0-77ff-495a-93f9-0183b4e6bbaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47593c35-024c-402d-b1f5-d8d727fb3c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5296d58-cdd5-4e53-89f0-cb23fe29842a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b215f46-2cdd-4844-a73f-e33a51649e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d15eba4-9f09-4f18-8473-7c125547942b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0482f6f-873d-4bfb-a98a-56e9a9433854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 012b4b3e-78bc-4b8f-a6a8-41e5d2996974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8612e29c-b349-48c2-b9c2-fb26a2082a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 189b66d7-4f24-4612-ad21-3f99d38e1232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c7b038-d2f1-4525-9471-8f3dd261daf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93d94200-9ecb-4567-a2e0-808389b7c3cb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_5
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/test_labels.txt

📊 Raw data loaded:
   Train: X=(660, 24), y=(660,)
   Test:  X=(166, 24), y=(166,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 651 samples, 5 features
   Test:  157 samples, 5 features
✅ Client client_5 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2441, R²: -0.0127

📊 Round 0 Test Metrics:
   Loss: 0.3653, RMSE: 0.6044, MAE: 0.5339, R²: -3.5632

📊 Round 0 Test Metrics:
   Loss: 0.0859, RMSE: 0.2932, MAE: 0.2434, R²: -0.0736

============================================================
🔄 Round 7 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0885 (↓), lr=0.001000
   • Epoch   2/100: train=0.0847, val=0.0883, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0838, val=0.0886, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0835, val=0.0889, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0829, val=0.0899, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0791, val=0.0965, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 7 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0046
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0209
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2509, R²: -0.0459

============================================================
🔄 Round 12 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0794 (↓), lr=0.000250
   • Epoch   2/100: train=0.0885, val=0.0800, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0879, val=0.0800, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0875, val=0.0802, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0873, val=0.0804, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0863, val=0.0810, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 12 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0273
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0254
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2570, R²: -0.0988

============================================================
🔄 Round 16 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0913 (↓), lr=0.000063
   • Epoch   2/100: train=0.0888, val=0.0908, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0880, val=0.0906 (↓), lr=0.000063
   • Epoch   4/100: train=0.0876, val=0.0905, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0872, val=0.0906, patience=2/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0862, val=0.0908, patience=8/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 16 Summary - Client client_5
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0325
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0901
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2521, R²: -0.0695

============================================================
🔄 Round 17 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0904 (↓), lr=0.000016
   • Epoch   2/100: train=0.0891, val=0.0903, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0889, val=0.0902, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0888, val=0.0901, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0886, val=0.0901, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0881, val=0.0899, patience=3/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0879, val=0.0898, patience=13/15, lr=0.000004
   📉 Epoch 22: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 17 Summary - Client client_5
   Epochs: 23/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0431
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0704
============================================================


============================================================
🔄 Round 18 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0910 (↓), lr=0.000002
   • Epoch   2/100: train=0.0890, val=0.0910, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0890, val=0.0910, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0890, val=0.0909, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0889, val=0.0909, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0888, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 18 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0564
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0534
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2457, R²: -0.0388

📊 Round 18 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2482, R²: -0.0491

📊 Round 18 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2485, R²: -0.0503

============================================================
🔄 Round 23 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 23 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0733
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0214
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2479, R²: -0.0446

📊 Round 23 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2463, R²: -0.0314

============================================================
🔄 Round 26 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 26 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0418
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0634
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2457, R²: -0.0275

============================================================
🔄 Round 27 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 27 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0489
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0203
============================================================


============================================================
🔄 Round 32 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 32 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0239
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0620
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2449, R²: -0.0208

============================================================
🔄 Round 33 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 33 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0384
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0072
============================================================


============================================================
🔄 Round 34 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 34 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0238
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0524
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2449, R²: -0.0203

============================================================
🔄 Round 35 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 35 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0304
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0288
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2449, R²: -0.0202

============================================================
🔄 Round 36 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 36 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0292
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0314
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2449, R²: -0.0201

============================================================
🔄 Round 37 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 37 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0259
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0499
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2449, R²: -0.0201

📊 Round 37 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2449, R²: -0.0201

📊 Round 37 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2450, R²: -0.0202

============================================================
🔄 Round 41 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 41 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0298
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0376
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2450, R²: -0.0203

============================================================
🔄 Round 45 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 45 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0342
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0074
============================================================


============================================================
🔄 Round 46 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 46 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0344
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0048
============================================================


============================================================
🔄 Round 48 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 48 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0324
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0253
============================================================


============================================================
🔄 Round 50 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 50 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0238
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0522
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2452, R²: -0.0208

============================================================
🔄 Round 56 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 56 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0434
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0532
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2452, R²: -0.0209

============================================================
🔄 Round 58 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 58 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0251
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0447
============================================================


============================================================
🔄 Round 60 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 60 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0377
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0005
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0211

📊 Round 60 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0210

============================================================
🔄 Round 62 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 62 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0277
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0341
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2452, R²: -0.0209

📊 Round 62 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2452, R²: -0.0208

============================================================
🔄 Round 65 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 65 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0289
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0279
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0207

============================================================
🔄 Round 66 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 66 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0310
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0329
============================================================


============================================================
🔄 Round 69 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 69 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0377
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0042
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0207

============================================================
🔄 Round 71 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 71 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0249
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0396
============================================================


============================================================
🔄 Round 72 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 72 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0334
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0036
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0209

============================================================
🔄 Round 73 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 73 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0284
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0349
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0210

============================================================
🔄 Round 74 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 74 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0252
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0603
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0211

📊 Round 74 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0211

============================================================
🔄 Round 79 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 79 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0260
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0389
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0209

============================================================
🔄 Round 80 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 80 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0192
   Val:   Loss=0.0969, RMSE=0.3114, R²=-0.0588
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0208

📊 Round 80 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0206

📊 Round 80 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0204

============================================================
🔄 Round 84 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 84 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0257
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0505
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0203

============================================================
🔄 Round 85 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 85 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0291
   Val:   Loss=0.0741, RMSE=0.2721, R²=-0.0394
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0203

============================================================
🔄 Round 87 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 87 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0265
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0499
============================================================


============================================================
🔄 Round 88 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 88 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0288
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0234
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0206

============================================================
🔄 Round 91 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 91 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0257
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0360
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0209

============================================================
🔄 Round 93 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 93 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0303
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0188
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2454, R²: -0.0210

============================================================
🔄 Round 94 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 94 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0212
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0587
============================================================


============================================================
🔄 Round 95 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 95 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0261
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0414
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2454, R²: -0.0211

📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2454, R²: -0.0209

============================================================
🔄 Round 101 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 101 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0262
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0494
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2454, R²: -0.0209

============================================================
🔄 Round 107 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 107 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0263
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0319
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2454, R²: -0.0210

📊 Round 107 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2454, R²: -0.0211

============================================================
🔄 Round 110 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 110 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0246
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0761
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2454, R²: -0.0210

📊 Round 110 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2454, R²: -0.0209

📊 Round 110 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0208

📊 Round 110 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0208

============================================================
🔄 Round 117 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0990, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 117 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0285
   Val:   Loss=0.0990, RMSE=0.3147, R²=-0.0289
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2453, R²: -0.0208

============================================================
🔄 Round 118 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 118 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0303
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0126
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0207

============================================================
🔄 Round 119 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 119 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0342
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0043
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0205

📊 Round 119 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0204

📊 Round 119 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0203

============================================================
🔄 Round 124 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 124 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0266
   Val:   Loss=0.0990, RMSE=0.3147, R²=-0.0326
============================================================


============================================================
🔄 Round 125 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 125 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0359
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0077
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0203

============================================================
🔄 Round 128 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 128 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0271
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0332
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0203

📊 Round 128 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0204

📊 Round 128 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0204

📊 Round 128 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0204

============================================================
🔄 Round 132 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 132 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0257
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0557
============================================================


============================================================
🔄 Round 133 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 133 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0248
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0528
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0203

============================================================
🔄 Round 134 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 134 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0252
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0342
============================================================


============================================================
🔄 Round 136 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 136 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0270
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0264
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0202

============================================================
🔄 Round 138 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 138 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0312
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0101
============================================================


============================================================
🔄 Round 140 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 140 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0282
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0341
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2452, R²: -0.0201

📊 Round 140 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0202

============================================================
🔄 Round 144 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 144 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0281
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0252
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0202

📊 Round 144 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0203

============================================================
🔄 Round 147 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 147 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0289
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0223
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0204

============================================================
🔄 Round 148 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 148 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0275
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0454
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0203

📊 Round 148 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0202

============================================================
🔄 Round 152 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 152 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0242
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0345
============================================================


============================================================
🔄 Round 153 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 153 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0201
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0712
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0203

============================================================
🔄 Round 156 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 156 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0310
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0098
============================================================


============================================================
🔄 Round 157 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 157 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0286
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0156
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0203

📊 Round 157 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0202

============================================================
🔄 Round 159 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 159 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0262
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0265
============================================================


============================================================
🔄 Round 160 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 160 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0232
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0434
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0202

============================================================
🔄 Round 161 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 161 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0255
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0300
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0202

📊 Round 161 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2453, R²: -0.0201

============================================================
🔄 Round 164 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 164 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0287
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0326
============================================================


============================================================
🔄 Round 165 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 165 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0311
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0450
============================================================


============================================================
🔄 Round 166 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 166 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0250
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0288
============================================================


============================================================
🔄 Round 170 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 170 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0301
   Val:   Loss=0.0985, RMSE=0.3139, R²=-0.0199
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2454, R²: -0.0204

📊 Round 170 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2454, R²: -0.0204

============================================================
🔄 Round 173 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 173 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0254
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0275
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2454, R²: -0.0206

📊 Round 173 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2454, R²: -0.0206

============================================================
🔄 Round 175 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 175 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0331
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0115
============================================================


============================================================
🔄 Round 176 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0997, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0997, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 176 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0250
   Val:   Loss=0.0997, RMSE=0.3157, R²=-0.0319
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: -0.0207

📊 Round 176 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: -0.0207

============================================================
🔄 Round 179 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 179 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0247
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0308
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: -0.0208

📊 Round 179 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: -0.0209

============================================================
🔄 Round 186 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 186 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0294
   Val:   Loss=0.0971, RMSE=0.3117, R²=-0.0162
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: -0.0210

📊 Round 186 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: -0.0210

============================================================
🔄 Round 189 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 189 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0194
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0521
============================================================


============================================================
🔄 Round 192 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 192 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0247
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0298
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: -0.0212

📊 Round 192 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: -0.0212

============================================================
🔄 Round 198 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 198 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=-0.0243
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0339
============================================================


============================================================
🔄 Round 199 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 199 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0309
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0062
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: -0.0212

============================================================
🔄 Round 201 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 201 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0309
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0222
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: -0.0211

📊 Round 201 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: -0.0211

📊 Round 201 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: -0.0211

📊 Round 201 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: -0.0210

📊 Round 201 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: -0.0210

============================================================
🔄 Round 209 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 209 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0178
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0578
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2455, R²: -0.0210

❌ Client client_5 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
