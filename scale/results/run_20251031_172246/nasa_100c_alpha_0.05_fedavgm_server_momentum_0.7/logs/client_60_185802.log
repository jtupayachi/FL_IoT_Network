[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e89e3c9-9afe-4220-94bd-028538a3170c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aba61a2-02b5-4a88-89ad-87dabba3d98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd1c238-46c5-4354-b22d-73a7581b3451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a77af596-4eff-4d40-9ed2-11303a16f0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57cc6d49-c752-43a6-b723-38d264c56e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b55e85d-1648-4673-ab1c-456dc85f3b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7797388-834c-488c-9679-234d663c2895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe66e10-be3d-4660-83ea-d068d91277dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2459e2f8-afa5-4884-bca7-e53d0a1d0e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a5bd689-5eee-4f4c-873c-7e93a7b48f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1494a70e-8b65-492d-b7a4-bbee70b4d71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6662b1f2-2f0b-4cc5-b468-8155cf1f0007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d55c8160-8b3e-48ec-bd67-33c5a36e8c57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b4a18b-970e-409b-8643-b022e8135ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 766a3008-4543-458c-ab8c-aa8f5c65eeea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3daea6b-0451-4f76-8ccc-43d73481fa37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a6ddf1e-9fb4-45b8-a0ae-ed015107e1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f094079-aae5-488e-b0f3-eb40cab8a2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb58fd91-89a0-4642-8552-e64e6cb16be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a9af40-4ab4-432c-a8bf-46764ef02475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e598d658-4706-4bb7-8510-0c872adfdc9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f366ff-d21a-4436-9385-9d347ba0ed79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98c2305f-8dfc-451a-9c83-553c6c35646f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 398c0d1a-442b-4344-8f17-860809df4aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72068b13-602b-427d-8b8c-ef0ad83efae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f2f7621-7087-4f4a-9099-c1688f405226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c1fe991-da0a-4d9f-9af8-fd26d46b2739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2605315-4db0-4646-8da9-ccdb65f66854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334d4198-b6a5-4c6e-9b35-fd92d455786a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06c5559d-bb2e-4267-b666-4ecd51dea141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c3e83a-290a-48a8-9100-d20358654422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9855ef3d-12d4-4f6f-9c4c-1aaf0109951e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 609ea5bc-0216-4e40-9908-75b39f4aa75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4675ed2e-0f31-4031-8cd0-78f860b4dd0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d17a0e6-e34f-4361-94fe-4520ebf3c229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cad3331a-1bb5-4905-bd84-aae20c927bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f7ff65-382d-47e6-8284-72a6e1bc4f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d6e6db-0bcd-431b-8318-8cd1c059a4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ef99d1-7333-4efa-8c89-207732f326e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a159b4e-fd37-4e90-a57e-41882e2c5b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f307b8ee-8c24-465b-a8d4-8198db3e8ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b00ad7-68ed-4ff1-8a7f-b35fb5099f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa149c51-b454-4c3a-a06a-7f74a1e6be48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0baa8e8b-dbb4-44a7-8e93-69764c8336d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d5eb58-75b1-4cd4-a343-1bf297854cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64729a5d-b4cf-4b0c-8711-e82834af2b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08702d81-8fc8-4aa0-a8c6-cdcf4d6046fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbcff709-7dcc-44ec-9486-b3634bf9bc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f83399d-2829-45ab-bcbe-b5d8e2329866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c8cfb2-40a5-44a0-a48d-7821b74c0e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5efff858-8c31-48ef-b829-87a90c2f80d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ddc096-dd2b-41f5-b7c3-970192e04f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 197f45eb-e611-4c56-85b4-394340069340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3695156-e84a-48c3-b8c9-1cc51f475d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d87209ff-eaeb-49b4-bf15-6f09a1f6acec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b81c4b-3a5b-4051-bdad-589b21123bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e400e93c-cf00-4db8-bc80-11facfd5a06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b364f12-0827-47bd-adee-d25d32922a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed1ecee-5dff-4f97-97bf-e82c047ea6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9818759-0b69-4989-8c22-28462a7203fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e80bc8-5a9e-4dfa-9080-10f3b2992382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5b6598-69fa-4225-9648-812d86ee2dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86cc1d76-124e-41b4-a1e9-c0c7e483b4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a0356b-1a18-46c5-ab61-fe368c927c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ce19df-ef92-4903-9aa0-2c1b19b52759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154f997a-ff22-4b49-a4f4-87f1f64fc539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4cbbedc-fc4c-4850-8dc2-5ce04efe5314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac114aa-ee3a-49a7-8c07-6c8bb5d66cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51717c7-8ef6-422f-9dd4-9000e2492462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14728aa6-e073-4ffc-8fcc-e501f3049027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 199a3e6a-07e9-4af1-a3b6-80d0792b6ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f075b566-a657-4213-a89b-b6b4f409ce17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f1d14d-a0fd-4c0e-8ce8-92ce382e652d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e26cad4-114a-451e-be09-3337fa36f527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8bad115-8463-4931-9ef0-873bf18965a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 957dc20a-225c-4c8f-9414-4f5c1348d3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8195989b-6c8a-4378-8df9-62eeaf049f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc18be97-6d4d-4c33-9456-7bea3b8ef36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4340dd2c-79c2-4d51-9cdc-dfca1b27cd6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 954103ba-b9b5-4f5c-9208-c653728175e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1db521-763f-47b1-b7b5-b04527a28f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc8b92a2-b566-495d-83af-c1856923a32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924a0412-1fea-4cd8-be54-e21973c61bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022651bc-60d7-43cd-b00a-23b6822fc508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37980db2-378c-4d6b-9220-9ba9d6840e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78362174-7896-4a0c-9878-1a648dad3a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14589c41-7e8a-4967-853e-3ef4d1021efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce093bc-acd3-449c-9b69-e1fbb7dacd83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c02d81-c9e5-44ea-b1aa-0cd7020583a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1261616-7b43-4e83-afd9-9dd2554b0c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe3ae9e-b2e0-466d-9cfd-4dfaac43b9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8735c2a6-2db5-48fc-bdea-06f71ed3e90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88fb33af-93b6-4bf4-b955-6fc9e55db30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666576a6-0cf2-4228-8673-b6fc18fcd23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb73e489-8da1-4bb9-8e8d-ec9601a67899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d15112b-a471-4522-93f5-c253502ec053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f06629c-3601-41af-9990-be0a15d29726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caeeb0ba-35b8-4dc0-b97c-bd2320689888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ea06225-21d3-4177-b5a6-0247c44278f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249d8173-a5f5-4bf1-aa28-6ba7ccc304b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23f599c-1498-4ac3-aed1-0dbc04510897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23f6c89-bed8-4b47-8be6-150833826dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad339c3-b8b1-4b76-bb29-7290df58b639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1037a773-744b-4411-bc50-378465aabde3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 912e128a-18c9-4a3e-8a33-64f6096d030a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cdbe1bf-fd50-482e-a25c-ecc6a4c21299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9dfc23d-11d6-4fad-9c4a-371299c45212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da58f5d6-6a50-441a-9ff7-8252457dc2b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f9f4b1c-a0f5-497a-b514-c1ca3d95293d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e2672f-db04-4e68-b052-5ec723e339c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6f8f0c3-6d7c-4fc1-90c1-52beff8b0105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06cce9a2-c6a8-4133-b597-d43cb5b7f235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b648bb-ea51-4a68-b9e2-23802dbc03c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c99bc3f4-943f-43e6-a48e-da706887cbd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de8e618-bb56-4aaa-b7db-90cf40b9f39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 678613c3-7d96-4c2a-8f59-383d63e7b4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a22cd8b8-512a-4b8a-9fb6-b159446ac3c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d92a43db-be2e-42a8-ba8d-325a79e7fc06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e187435e-a160-412c-9f6f-fe054739a4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7462a6ad-598f-43ff-8a37-f49c1b334e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c241238-f48b-47ba-b0a4-3271af3d45b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba849fcf-0e8f-4ced-bd5b-e8cbbb653499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b87c79d-1298-45c4-93c6-352193101cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e155303-8b3a-489c-9549-5c7c711b1cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea4ee14f-5b34-485b-b215-7017f7fee153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05f65ca2-7a96-48a9-ab7d-4ef106737b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3bf8f7f-6eb6-4c29-ae67-936488b1ff04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99bb1f39-98ad-43d6-9463-67788ce4e9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 861b840e-98b9-43ba-aece-f1c66a96b8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e4f704-cab5-4198-beb5-95189c5b8611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 619adfc9-f587-4f13-971e-67a804a678ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a35b7a58-49f6-40a1-b4a7-b7348238d607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb7aa219-f929-48a5-9281-11d6b10c2ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14180d3e-480d-4f4c-a16e-126694b4ae22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a61d4a54-556c-4ecd-bf97-13991e465e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f5c367-8fcd-45e3-8bc8-f6d99a58da68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea1f3d63-23fe-414a-afb9-8ca8dbb45ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c1c8730-fd18-46af-9aa7-f0b9edb56d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efb2b6a1-8e42-4e30-a24e-74f871c15263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ce4a14-84be-41f5-a476-4de50ba0c9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d6a474-0441-4d25-9627-d59ce16023bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc60214-b747-4fdb-a4a2-5e7a46272811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e762b3f6-5f15-44d8-9cb7-32cff3bc741e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6124c0f8-81d4-4410-b80f-c291b3e240d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6636951-c060-48ed-9cfb-17fa0c4eac7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b54405-59c1-4987-8770-94a1878b82ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f63684-ba10-4dfb-87c5-d81ec6fca78f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_60
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/test_labels.txt

📊 Raw data loaded:
   Train: X=(1436, 24), y=(1436,)
   Test:  X=(359, 24), y=(359,)

⚠️  Limiting training data: 1436 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  350 samples, 5 features
✅ Client client_60 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 16 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0752 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0701, val=0.0739 (↓), lr=0.001000
   • Epoch   3/100: train=0.0690, val=0.0743, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0671, val=0.0734 (↓), lr=0.001000
   • Epoch   5/100: train=0.0654, val=0.0740, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0561, val=0.0782, patience=7/15, lr=0.001000
   📉 Epoch 13: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 16 Summary - Client client_60
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0646, RMSE=0.2541, R²=0.2122
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.1216
============================================================


============================================================
🔄 Round 17 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0719 (↓), lr=0.000500
   • Epoch   2/100: train=0.0721, val=0.0716, patience=1/15, lr=0.000500
   ✓ Epoch   3/100: train=0.0708, val=0.0713 (↓), lr=0.000500
   • Epoch   4/100: train=0.0699, val=0.0710, patience=1/15, lr=0.000500
   • Epoch   5/100: train=0.0690, val=0.0708, patience=2/15, lr=0.000500
   • Epoch  11/100: train=0.0649, val=0.0696, patience=2/15, lr=0.000500
   • Epoch  21/100: train=0.0585, val=0.0692, patience=4/15, lr=0.000500
   📉 Epoch 25: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0529, val=0.0707, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 17 Summary - Client client_60
   Epochs: 32/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0597, RMSE=0.2443, R²=0.2780
   Val:   Loss=0.0694, RMSE=0.2633, R²=0.1467
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0724, RMSE: 0.2690, MAE: 0.2286, R²: 0.1252

============================================================
🔄 Round 21 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000250 → 0.000125
   ✓ Epoch   1/100: train=0.0722, val=0.0735 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0716, val=0.0729 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0712, val=0.0723 (↓), lr=0.000125
   ✓ Epoch   4/100: train=0.0708, val=0.0717 (↓), lr=0.000125
   • Epoch   5/100: train=0.0705, val=0.0713, patience=1/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   ✓ Epoch  11/100: train=0.0691, val=0.0700 (↓), lr=0.000063
   📉 Epoch 17: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0679, val=0.0693, patience=5/15, lr=0.000031
   ✓ Epoch  31/100: train=0.0673, val=0.0689 (↓), lr=0.000031
   • Epoch  41/100: train=0.0667, val=0.0687, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 21 Summary - Client client_60
   Epochs: 46/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0672, RMSE=0.2593, R²=0.1704
   Val:   Loss=0.0689, RMSE=0.2626, R²=0.2166
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0709, RMSE: 0.2663, MAE: 0.2235, R²: 0.1429

📊 Round 21 Test Metrics:
   Loss: 0.0709, RMSE: 0.2662, MAE: 0.2231, R²: 0.1434

📊 Round 21 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2235, R²: 0.1409

📊 Round 21 Test Metrics:
   Loss: 0.0715, RMSE: 0.2674, MAE: 0.2247, R²: 0.1357

============================================================
🔄 Round 27 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0734 (↓), lr=0.000031
   • Epoch   2/100: train=0.0731, val=0.0734, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0729, val=0.0734, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0726, val=0.0734, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0724, val=0.0734, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0715, val=0.0732, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 27 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.1160
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.1052
============================================================


============================================================
🔄 Round 29 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0775 (↓), lr=0.000008
   • Epoch   2/100: train=0.0723, val=0.0775, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0723, val=0.0775, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0722, val=0.0775, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0722, val=0.0775, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0720, val=0.0775, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 29 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0724, RMSE=0.2692, R²=0.1067
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0898
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0720, RMSE: 0.2684, MAE: 0.2261, R²: 0.1295

============================================================
🔄 Round 30 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0793 (↓), lr=0.000002
   • Epoch   2/100: train=0.0720, val=0.0793, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0720, val=0.0793, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0719, val=0.0793, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0719, val=0.0793, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0719, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 30 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0721, RMSE=0.2686, R²=0.1031
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.1193
============================================================


============================================================
🔄 Round 32 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 32 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2675, R²=0.1083
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0975
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1272

============================================================
🔄 Round 35 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 35 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.1061
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0848
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0723, RMSE: 0.2688, MAE: 0.2268, R²: 0.1267

============================================================
🔄 Round 39 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0714, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 39 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2674, R²=0.1115
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0778
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0723, RMSE: 0.2688, MAE: 0.2268, R²: 0.1266

============================================================
🔄 Round 42 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 42 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.1086
   Val:   Loss=0.0665, RMSE=0.2579, R²=0.0811
============================================================


============================================================
🔄 Round 43 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 43 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.0997
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.1192
============================================================


============================================================
🔄 Round 44 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 44 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.1114
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0723
============================================================


============================================================
🔄 Round 45 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 45 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.1052
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0958
============================================================


============================================================
🔄 Round 46 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 46 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1136
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0634
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0722, RMSE: 0.2688, MAE: 0.2267, R²: 0.1270

============================================================
🔄 Round 48 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 48 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.1064
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0910
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0722, RMSE: 0.2688, MAE: 0.2267, R²: 0.1271

============================================================
🔄 Round 49 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 49 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0875
   Val:   Loss=0.0697, RMSE=0.2639, R²=0.1636
============================================================


============================================================
🔄 Round 54 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0654 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0654, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0654, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0654, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0654, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0654)

============================================================
📊 Round 54 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.1008
   Val:   Loss=0.0654, RMSE=0.2558, R²=0.1178
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1274

============================================================
🔄 Round 55 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 55 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1146
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0537
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1275

📊 Round 55 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2266, R²: 0.1277

============================================================
🔄 Round 60 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 60 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.1059
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0957
============================================================


============================================================
🔄 Round 63 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 63 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.1088
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0758
============================================================


============================================================
🔄 Round 66 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 66 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1075
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0774
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1273

📊 Round 66 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1274

📊 Round 66 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1276

============================================================
🔄 Round 71 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 71 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.1042
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.1002
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1276

============================================================
🔄 Round 72 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 72 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.0891
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.1532
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2266, R²: 0.1277

📊 Round 72 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2266, R²: 0.1278

============================================================
🔄 Round 74 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 74 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.1090
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0792
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1279

📊 Round 74 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1278

📊 Round 74 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2266, R²: 0.1277

============================================================
🔄 Round 79 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 79 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.1129
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0569
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2266, R²: 0.1277

📊 Round 79 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1276

📊 Round 79 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1273

============================================================
🔄 Round 86 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 86 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0996
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.1060
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1274

📊 Round 86 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1279

============================================================
🔄 Round 95 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 95 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.1057
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0824
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1281

============================================================
🔄 Round 98 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 98 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2730, R²=0.1095
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0689
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1280

============================================================
🔄 Round 101 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 101 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.1030
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.1001
============================================================


============================================================
🔄 Round 102 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 102 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.1060
   Val:   Loss=0.0674, RMSE=0.2597, R²=0.0790
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1280

============================================================
🔄 Round 103 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 103 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.1066
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0870
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1280

============================================================
🔄 Round 104 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 104 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.0889
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.1465
============================================================


============================================================
🔄 Round 105 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 105 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.1065
   Val:   Loss=0.0697, RMSE=0.2639, R²=0.0727
============================================================


============================================================
🔄 Round 106 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 106 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.1005
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0945
============================================================


============================================================
🔄 Round 107 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 107 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0897
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.1535
============================================================


============================================================
🔄 Round 112 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 112 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1004
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.1084
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0721, RMSE: 0.2686, MAE: 0.2266, R²: 0.1282

============================================================
🔄 Round 113 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 113 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0932
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.1380
============================================================


============================================================
🔄 Round 114 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 114 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1043
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0929
============================================================


============================================================
🔄 Round 116 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 116 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1033
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0982
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1281

📊 Round 116 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2266, R²: 0.1280

📊 Round 116 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2267, R²: 0.1279

============================================================
🔄 Round 120 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 120 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1030
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0972
============================================================


============================================================
🔄 Round 123 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 123 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.1111
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0638
============================================================


============================================================
🔄 Round 124 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 124 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.0892
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.1223
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2267, R²: 0.1277

============================================================
🔄 Round 125 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 125 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1038
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0955
============================================================


============================================================
🔄 Round 126 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0709, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0709, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0708, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 126 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2662, R²=0.1057
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0864
============================================================


============================================================
🔄 Round 127 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 127 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.1025
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.1005
============================================================


============================================================
🔄 Round 128 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 128 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.1015
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.1042
============================================================


============================================================
🔄 Round 129 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 129 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0970
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0960
============================================================


============================================================
🔄 Round 134 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 134 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0996
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.1111
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2268, R²: 0.1277

============================================================
🔄 Round 136 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 136 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1072
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0818
============================================================


============================================================
🔄 Round 137 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 137 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.1075
   Val:   Loss=0.0712, RMSE=0.2667, R²=0.0731
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2268, R²: 0.1275

📊 Round 137 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1274

📊 Round 137 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1274

============================================================
🔄 Round 141 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 141 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2675, R²=0.1105
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0697
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1273

📊 Round 141 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1274

============================================================
🔄 Round 143 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 143 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.1039
   Val:   Loss=0.0679, RMSE=0.2605, R²=0.0903
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1274

============================================================
🔄 Round 147 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 147 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.1021
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0808
============================================================


============================================================
🔄 Round 152 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 152 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0972
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.1157
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1273

============================================================
🔄 Round 153 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 153 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.1007
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0999
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1273

============================================================
🔄 Round 155 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 155 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.1033
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0891
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1273

📊 Round 155 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1272

============================================================
🔄 Round 158 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 158 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0910
   Val:   Loss=0.0665, RMSE=0.2579, R²=0.1432
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0722, RMSE: 0.2688, MAE: 0.2270, R²: 0.1269

📊 Round 158 Test Metrics:
   Loss: 0.0723, RMSE: 0.2688, MAE: 0.2270, R²: 0.1269

📊 Round 158 Test Metrics:
   Loss: 0.0722, RMSE: 0.2688, MAE: 0.2270, R²: 0.1269

============================================================
🔄 Round 167 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 167 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1043
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0857
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0722, RMSE: 0.2688, MAE: 0.2270, R²: 0.1269

============================================================
🔄 Round 168 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 168 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.0975
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.1099
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0722, RMSE: 0.2688, MAE: 0.2270, R²: 0.1270

📊 Round 168 Test Metrics:
   Loss: 0.0722, RMSE: 0.2688, MAE: 0.2270, R²: 0.1270

📊 Round 168 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2270, R²: 0.1272

============================================================
🔄 Round 172 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 172 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0990
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.1073
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1273

============================================================
🔄 Round 174 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 174 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0968
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.1135
============================================================


============================================================
🔄 Round 175 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 175 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0983
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.1092
============================================================


============================================================
🔄 Round 177 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 177 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0908
   Val:   Loss=0.0666, RMSE=0.2580, R²=0.1429
============================================================


============================================================
🔄 Round 179 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 179 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2719, R²=0.1015
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0973
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1276

📊 Round 179 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2268, R²: 0.1277

📊 Round 179 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2268, R²: 0.1277

============================================================
🔄 Round 183 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 183 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0944
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.1208
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2268, R²: 0.1278

📊 Round 183 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2268, R²: 0.1279

📊 Round 183 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2268, R²: 0.1280

📊 Round 183 Test Metrics:
   Loss: 0.0721, RMSE: 0.2686, MAE: 0.2268, R²: 0.1281

📊 Round 183 Test Metrics:
   Loss: 0.0721, RMSE: 0.2686, MAE: 0.2267, R²: 0.1282

============================================================
🔄 Round 196 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 196 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.1059
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0627
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0721, RMSE: 0.2686, MAE: 0.2267, R²: 0.1283

============================================================
🔄 Round 197 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 197 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.0914
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.1336
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0721, RMSE: 0.2686, MAE: 0.2267, R²: 0.1283

============================================================
🔄 Round 198 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 198 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1056
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0669
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0721, RMSE: 0.2686, MAE: 0.2267, R²: 0.1284

============================================================
🔄 Round 200 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0616 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0616, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0616, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0616, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0616, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0616, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0616)

============================================================
📊 Round 200 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0948
   Val:   Loss=0.0616, RMSE=0.2483, R²=0.1290
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0721, RMSE: 0.2686, MAE: 0.2268, R²: 0.1282

============================================================
🔄 Round 201 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 201 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0974
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.1031
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2268, R²: 0.1281

📊 Round 201 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2268, R²: 0.1280

============================================================
🔄 Round 204 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 204 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0871
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1493
============================================================


============================================================
🔄 Round 205 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 205 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1099
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0640
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0721, RMSE: 0.2686, MAE: 0.2268, R²: 0.1281

============================================================
🔄 Round 207 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 207 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.1032
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0902
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0722, RMSE: 0.2686, MAE: 0.2269, R²: 0.1278

============================================================
🔄 Round 210 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0708, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0708, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0708, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0708, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0707, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0707, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 210 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1053
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0832
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0722, RMSE: 0.2687, MAE: 0.2269, R²: 0.1278

❌ Client client_60 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
