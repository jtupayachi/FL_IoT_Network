[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62eea8cd-ea86-4f5b-9f74-53ab5002b3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65a17ab1-f595-4614-a442-fb89535b22ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec00f54-e53e-48fb-b601-329f0f175837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37413b4e-cbea-4bc1-aadb-bcb821986e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd995d0a-3972-4a11-b709-6fa3ad8f0725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad530129-dc9f-4851-9fff-9d77945cc196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9063bd3c-918c-4dc1-88d8-d1699f4a4ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4cf366-a3b0-4e78-9820-614c4f61d6b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d13dee68-9575-4458-a3b9-0e3977d698d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00242812-84e4-43c7-94a2-a81e5048f718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8df69924-83a4-4937-8a87-d0cebe8d7c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 483bf761-e179-4e7f-aaef-542fbe785856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e5bdc4-d824-40c8-a10b-4c37d9a29157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee7d6dc9-9e47-4978-95b3-1a108108d4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6306ec62-7f0f-4741-bdab-742aa17e5379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fddae4a-9492-4d0c-a4dc-e950a7466b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3beea342-c66c-42a8-83d1-ae755a6de3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 173b8688-7ebf-45db-ba54-3f906dfbc784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1800cf2f-ae60-4df6-9deb-4abcdd91731c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d376a88-e00a-4aec-973f-eb281e3408dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40794a49-238c-4b37-9225-19ed77ca244e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91995539-e1b1-41a8-972a-5286e20181d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bbd52fc-d396-4f56-95be-2fa186b07cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf084e04-ba2e-4067-9a1e-189674aa61f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3753bf6d-7896-4f16-98e1-a51322500476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d41a1b-d773-4faf-bcfe-db3fdaabceff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da50e441-fc4a-487f-8407-7f1c31071a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c07a387c-4eee-408b-b900-714cf59a28c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a8d4423-cdda-444a-aadc-117801e4313f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5435b57d-05ac-48b5-818d-48a9f13662e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e523567-b93e-4465-ac54-5917cdb506d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7048c08a-f398-4aff-83d9-7cf400a9830f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ea7bc8a-0048-4ceb-b858-b2a295cd16da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1365d98-118d-4b4d-a4a7-ccf82db643a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1644cad-6c2a-48dc-8aec-595e6790429b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43024963-4c8a-4941-abaa-23b04591dbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c926d294-3421-4347-95c4-28a66a693d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e30e0ee-c0fa-4406-89c3-8f09a55c6697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8250fde8-8247-4952-87c3-52856ab774c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19e8fbbe-5623-4851-ac7d-460601d386fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b223156-7e5d-4c4c-ab39-3e98a251e1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b3e998-c00c-45d7-9ed0-4afafb650cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffad7fec-735d-467a-84e5-0f63da41be32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f681ebc1-299b-449b-8eeb-c92ac4658221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59db659c-76ae-4d8c-9cae-8442ed267170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8223cb1-70d2-415b-a3c9-06f62595b5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebbc77b7-b3cd-4c0e-a076-da763f49960c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d9fc10-20a5-4280-bd37-fcfb963b50a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a47737-889e-4205-abd4-87885b4a73f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ff896a-92fa-499d-b0eb-db5b9cea1ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2bb4fd2-e78f-4911-93bd-c5560a7ff023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0fc0ca0-cde5-45f0-a289-04710f0d20f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cdfad8e-128b-4d9c-8dac-67dc63a0109d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf3d37d-1ca1-4832-b8a8-c2fc71e1f90b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe482a1d-72f1-4733-a3cf-8e221dec0d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1284adc-d12c-4596-b06d-96a0c38c06d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f909679-52b2-4402-b088-462de437728a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ef523ff-0e85-498a-9c03-c35651105c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5669f7-d66c-4cc1-9f68-5e13882bbeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11131568-5a12-4785-a205-f08eb025532f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c472d0f7-eec6-4879-b76f-28ac3716f658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b275fe-5158-4f03-9bee-5e1c9bdc287a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961d1c83-fbfa-409b-8fcd-e7b89457dffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35b4786-4db4-4a70-a065-0ca7275c2229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 583ff885-ee2a-4a1c-98d7-315d0e73a0ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81643eb7-9d35-4082-aa6c-349b21aa8f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d878ac43-6df6-4ac0-a100-d274d9c3e26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 530fdd75-363c-4306-8358-d918dcecab40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf07de45-634f-41f4-87b9-2ce2127dabd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a605096d-4556-4cef-a744-81719e0fb7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ba18b1f-6eba-46ef-9100-abd2b4691c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b214993-b488-40af-999d-e53039575c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a65e57d-7491-4042-9203-cbacd96a8f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d9f82ba-0b22-40f0-9504-950d2de54647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa04ae31-fcf0-4678-b66a-88935038807b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c16015f-1a7c-423e-98a0-316c613386a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd56cbc-dd6f-4951-946b-cab51d09bcef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a4442a-f2c5-4db5-b978-e3269a534279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94f6e5d-88e4-4e39-9856-56a7562bd13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d679863-4970-488d-ba4d-ec8baab68d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08355a83-148e-49dc-a636-69b13f3a3b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f66217c-6ca1-488e-a8e7-eb86e1bcc7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08496b01-0482-46da-b59b-39a7c4890577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcbcb8f-2599-43cf-aee5-80b16ebd9334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6108d2f-64d5-4481-beb3-f0b7e75be7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb28aad6-9b2d-4130-bccd-9dbb2d7ef4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1fd69fe-da42-4720-9cd2-3f366f969aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1243e0e1-1392-48cf-9286-3e7e969c9e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a24f8bc9-c394-48bb-a5f0-49331b05369c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e5015b8-d3f2-4152-8050-cd96400f871d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7ad660-d072-4e94-b6c7-a8f67803d802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e1284c-ba5b-496c-b476-a39dd884ad49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8097c803-586e-4aec-b663-8f1233bd4d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31db0ae5-8171-47b3-9c8d-dd3533088ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444c88c2-62dd-409d-b2c9-26abc02806bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6de41b-99d9-4f3a-9864-837974635d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ac3451-49dd-45db-9867-b47124557321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c2db22-b6cd-4038-b213-ebe968f101cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de1bcb98-6ab2-4322-a107-9e473e674beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 938e2e24-7711-4f32-9faf-f2a57ed14fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbff49a8-a382-48b6-80ba-4febdd16be4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffc0076e-6af9-4837-bbfc-ee9154ceebcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cde5660-ca0d-4d7b-b1de-299b0ee7a701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c93bde-b4d6-4b7a-b6c5-74b8c5eecb65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a883308e-b6d0-431a-a818-8cdce6098f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7393b80-79c9-4963-9eab-1a360afc4188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a7fa73c-c9fb-46d3-a5d4-427806fc583f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be3dc07f-8541-4c3e-adfa-d004e52094f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f021b77-795b-4a8d-9fe0-6434620f24c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ae27d1-02a0-4a6e-88f4-24c9518ef228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9530b54d-9399-44cd-b950-ebfd5a1fb31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c569a46b-734d-4bc0-b688-f59122172c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26caec79-2a6d-41f3-8612-4a4592fd02e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e384781-3a19-455c-a087-7763329630b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e7e1703-9969-4d8d-a058-67d4e38b17ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9294ce28-337c-46ad-b767-3eeefcf28d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa716167-9b84-4e43-8fd5-136d1708f400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e19cefe4-3874-4971-82b7-647afe24721d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f65436-e3ce-4700-ab40-37da198ea44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca7bb71-cd16-45cd-a85a-5ea93a15712e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e157abba-e2ca-4d8d-886f-425d4cadc7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 338c6fde-141a-4918-80c5-c3247b817aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccce78fb-de6d-4775-9d86-ebcea9fcf9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b210bbb-5817-4730-8fdc-4e393cd1431a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e0a29d-98de-4198-ae65-a0b1dc1ffab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0220aa9-62b0-4e6b-9de1-9b0c631e85f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b6d049e-156c-4e24-857b-19be2ae10e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a518a75-9bc9-4012-9d87-f4f34eed7bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e73c93f-7ddb-444b-a744-6f27aea60fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d07e8c-0fa3-4ae1-b310-fc9f003f55cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d94c6a7-96f9-4f69-be57-eeec9d695d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63c29ca-562f-44c6-9f72-8596160f39c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c14dc1-1596-43c2-a576-3cdf70b6a45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bbc620-428e-4a0c-820a-9c24842de5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ff5360-0f71-4bf1-b602-0685e60ab726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d2fb4f3-7657-47b0-83a0-3519fcd2b108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a188a3-68cb-464d-9a4d-ee186b2f1629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b01f7e87-03cb-47d9-a797-5f906dfaafa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0acb247-718a-4f78-827f-7fa1f54a80fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd108b9b-e7dc-48c5-9fda-c3a2023c6fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6edbba7c-30b3-4537-b249-51eae26998ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e41af2-afba-4dc9-a3f8-32c5bbe45181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f65abf-c794-4edf-82b6-e97cd47360a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6710b84f-9b91-43e3-bc80-8b953ef42321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a198f95b-b0f4-4da3-92c1-b59bd378e181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80607c49-6816-4291-b941-7c024263bbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184eac3a-ef6c-4e98-b0ed-332bac942b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b4ed955-ef42-4271-ba61-7ec03c9b7390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb0e09ab-c5f7-4662-af1e-815427e45a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd2c0f4-ce48-455e-9507-81b9f412754e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4734cc-6cbc-4651-8e31-d6ddcf3f1922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec94fdb-5570-4a87-9b25-491f864228c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c006a265-b2fa-4ea3-99f0-16db78803f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10c5d1b-0af7-4b9e-b984-c7602b2dd786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c51329a-0b29-4b92-b5ca-a3b80c6759cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32df6bce-6b40-4d30-b7af-066094fd80b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca4adc4-b3c0-4ab2-92f6-3e18c4808a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb21e968-d406-4d96-88b5-012b734f6100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84432013-6302-46ad-bf5a-ead2c34c2fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ecca3e-34f5-4fb8-9cf0-64b655b615e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6bf130-488e-45f1-87d6-22bb38c9c0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aa4defc-542c-439a-bc07-4e818fda2308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb768db-0d81-4e98-8972-89755f9bbbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d90a73e-e1ab-4f1b-8e91-727445afeff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b9e7cc-e1c0-4ad9-b792-b72f6a970a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e986601a-e53a-4b37-b23b-efb61a43ef4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 291e0ad4-518b-4b06-b585-e9a45e2d4373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0917c54-a24a-4bfb-be1e-4dd8f75037e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43fdee2c-87d2-46c2-b98e-dcee183f8fa2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_61
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/test_labels.txt

📊 Raw data loaded:
   Train: X=(1000, 24), y=(1000,)
   Test:  X=(251, 24), y=(251,)

⚠️  Limiting training data: 1000 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  242 samples, 5 features
✅ Client client_61 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 13 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0881 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0869, val=0.0861 (↓), lr=0.001000
   • Epoch   3/100: train=0.0853, val=0.0862, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0848, val=0.0859, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0858, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0769, val=0.0827 (↓), lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0612, val=0.0961, patience=10/15, lr=0.000500
   📉 Epoch 25: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 13 Summary - Client client_61
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.1395
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0331
============================================================


============================================================
🔄 Round 14 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0894 (↓), lr=0.000250
   • Epoch   2/100: train=0.0865, val=0.0890, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0862, val=0.0890, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0858, val=0.0890, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0855, val=0.0890, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0844, val=0.0888, patience=5/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0836, val=0.0886, patience=15/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 14 Summary - Client client_61
   Epochs: 21/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0076
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0377
============================================================


============================================================
🔄 Round 18 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0810 (↓), lr=0.000063
   • Epoch   2/100: train=0.0885, val=0.0809, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0880, val=0.0808, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0876, val=0.0808, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0873, val=0.0808, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0862, val=0.0810, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 18 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0258
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0100
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: -0.0230

============================================================
🔄 Round 19 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0844, val=0.0995 (↓), lr=0.000016
   • Epoch   2/100: train=0.0840, val=0.0998, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0837, val=0.1000, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0836, val=0.1002, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0834, val=0.1005, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0828, val=0.1013, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 19 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0218
   Val:   Loss=0.0995, RMSE=0.3155, R²=-0.0314
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: -0.0290

============================================================
🔄 Round 20 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0884, val=0.0833 (↓), lr=0.000004
   • Epoch   2/100: train=0.0883, val=0.0833, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0883, val=0.0833, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0883, val=0.0832, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0882, val=0.0832, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0880, val=0.0831, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 20 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0203
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0166
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2449, R²: -0.0320

📊 Round 20 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2459, R²: -0.0364

============================================================
🔄 Round 23 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0883, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 23 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0070
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0580
============================================================


============================================================
🔄 Round 25 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 25 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0094
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0197
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2447, R²: -0.0269

============================================================
🔄 Round 27 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 27 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0086
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0119
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2436, R²: -0.0185

============================================================
🔄 Round 30 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 30 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0007
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0329
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: -0.0176

============================================================
🔄 Round 31 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 31 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0046
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0334
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2434, R²: -0.0170

============================================================
🔄 Round 33 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 33 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0084
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0057
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2434, R²: -0.0163

============================================================
🔄 Round 34 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 34 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0070
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0032
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2433, R²: -0.0159

============================================================
🔄 Round 36 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 36 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0042
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0148
============================================================


============================================================
🔄 Round 40 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 40 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0031
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0489
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2433, R²: -0.0153

📊 Round 40 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: -0.0152

📊 Round 40 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2433, R²: -0.0151

============================================================
🔄 Round 44 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 44 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0058
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0067
============================================================


============================================================
🔄 Round 46 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 46 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0047
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0104
============================================================


============================================================
🔄 Round 47 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 47 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0039
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0135
============================================================


============================================================
🔄 Round 48 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 48 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0079
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0006
============================================================


============================================================
🔄 Round 49 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 49 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0052
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0082
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2433, R²: -0.0146

📊 Round 49 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2433, R²: -0.0145

============================================================
🔄 Round 51 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 51 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0064
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0039
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2433, R²: -0.0145

============================================================
🔄 Round 52 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 52 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0094
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0118
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: -0.0144

============================================================
🔄 Round 55 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 55 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0030
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0649
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: -0.0143

============================================================
🔄 Round 56 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 56 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0139
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0273
============================================================


============================================================
🔄 Round 57 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 57 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0079
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0061
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: -0.0140

📊 Round 57 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: -0.0140

============================================================
🔄 Round 63 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 63 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0080
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0012
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2432, R²: -0.0139

📊 Round 63 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2431, R²: -0.0136

📊 Round 63 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2431, R²: -0.0135

📊 Round 63 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2431, R²: -0.0134

============================================================
🔄 Round 72 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 72 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0029
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0270
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2431, R²: -0.0133

============================================================
🔄 Round 76 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 76 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0088
   Val:   Loss=0.0928, RMSE=0.3047, R²=0.0071
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2431, R²: -0.0131

============================================================
🔄 Round 79 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 79 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0040
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0111
============================================================


============================================================
🔄 Round 80 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 80 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0068
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0025
============================================================


============================================================
🔄 Round 81 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 81 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0075
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0078
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2431, R²: -0.0130

📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2431, R²: -0.0130

📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2431, R²: -0.0130

============================================================
🔄 Round 85 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 85 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0073
   Val:   Loss=0.0897, RMSE=0.2994, R²=0.0008
============================================================


============================================================
🔄 Round 87 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 87 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0114
   Val:   Loss=0.0900, RMSE=0.2999, R²=0.0156
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2431, R²: -0.0128

📊 Round 87 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2430, R²: -0.0126

============================================================
🔄 Round 93 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 93 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0009
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0251
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2430, R²: -0.0123

📊 Round 93 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0122

📊 Round 93 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0122

============================================================
🔄 Round 98 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 98 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0012
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0186
============================================================


============================================================
🔄 Round 99 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 99 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0086
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0170
============================================================


============================================================
🔄 Round 100 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 100 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0031
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0141
============================================================


============================================================
🔄 Round 103 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 103 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0026
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0124
============================================================


============================================================
🔄 Round 104 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 104 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0082
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0041
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0121

📊 Round 104 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0120

📊 Round 104 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0120

📊 Round 104 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0120

============================================================
🔄 Round 109 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 109 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0009
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0272
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0120

📊 Round 109 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0120

============================================================
🔄 Round 113 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 113 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0003
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0290
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0120

============================================================
🔄 Round 117 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 117 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0004
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0361
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0120

============================================================
🔄 Round 118 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 118 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0007
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0646
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0121

📊 Round 118 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0122

============================================================
🔄 Round 120 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 120 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0034
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0094
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0122

============================================================
🔄 Round 121 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 121 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0059
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0010
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2430, R²: -0.0123

============================================================
🔄 Round 122 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 122 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0077
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0127
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0805, RMSE: 0.2836, MAE: 0.2430, R²: -0.0123

============================================================
🔄 Round 126 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 126 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0081
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0027
============================================================


============================================================
🔄 Round 128 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 128 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0026
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0151
============================================================


============================================================
🔄 Round 129 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 129 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0067
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0010
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0122

📊 Round 129 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0122

============================================================
🔄 Round 131 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 131 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0080
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0103
============================================================


============================================================
🔄 Round 132 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 132 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0027
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0149
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0121

📊 Round 132 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0121

============================================================
🔄 Round 135 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 135 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0032
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0149
============================================================


============================================================
🔄 Round 136 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 136 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0052
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0649
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0121

📊 Round 136 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2430, R²: -0.0121

============================================================
🔄 Round 139 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 139 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0066
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0014
============================================================


============================================================
🔄 Round 140 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 140 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0067
   Val:   Loss=0.0926, RMSE=0.3044, R²=0.0016
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2429, R²: -0.0120

📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2429, R²: -0.0119

📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2429, R²: -0.0119

📊 Round 140 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2429, R²: -0.0118

============================================================
🔄 Round 145 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 145 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0122
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0201
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2429, R²: -0.0118

📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2429, R²: -0.0117

📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2429, R²: -0.0117

📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0116

📊 Round 145 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0116

============================================================
🔄 Round 151 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 151 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0100
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0145
============================================================


============================================================
🔄 Round 152 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 152 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0029
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0140
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0116

============================================================
🔄 Round 153 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 153 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0090
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0020
============================================================


============================================================
🔄 Round 154 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 154 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0049
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0110
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0115

============================================================
🔄 Round 157 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 157 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0046
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0061
============================================================


============================================================
🔄 Round 158 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 158 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0072
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0170
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0114

============================================================
🔄 Round 159 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 159 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0040
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0104
============================================================


============================================================
🔄 Round 160 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 160 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0052
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0050
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0114

============================================================
🔄 Round 163 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 163 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0076
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0037
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0113

============================================================
🔄 Round 164 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 164 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0052
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0053
============================================================


============================================================
🔄 Round 165 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 165 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0060
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0104
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0113

============================================================
🔄 Round 168 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 168 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0102
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0235
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0112

📊 Round 168 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0111

============================================================
🔄 Round 172 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 172 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0016
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0192
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2429, R²: -0.0110

============================================================
🔄 Round 175 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 175 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0043
   Val:   Loss=0.0970, RMSE=0.3115, R²=-0.0064
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2429, R²: -0.0110

📊 Round 175 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2429, R²: -0.0110

============================================================
🔄 Round 178 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 178 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0051
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0030
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0109

============================================================
🔄 Round 181 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 181 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0076
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0018
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0109

============================================================
🔄 Round 185 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 185 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0052
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0010
============================================================


============================================================
🔄 Round 186 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 186 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0047
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0049
============================================================


============================================================
🔄 Round 187 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 187 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0063
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0022
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0108

============================================================
🔄 Round 188 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 188 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0056
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0130
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0107

📊 Round 188 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0107

============================================================
🔄 Round 190 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 190 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0072
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0081
============================================================


============================================================
🔄 Round 191 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 191 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0073
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0027
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0107

============================================================
🔄 Round 195 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 195 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0084
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0097
============================================================


============================================================
🔄 Round 196 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 196 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0058
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0047
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0106

============================================================
🔄 Round 197 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 197 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0075
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0125
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0105

📊 Round 197 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0106

📊 Round 197 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0106

============================================================
🔄 Round 202 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 202 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0037
   Val:   Loss=0.0743, RMSE=0.2727, R²=-0.0081
============================================================


============================================================
🔄 Round 204 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 204 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0072
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0078
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0105

📊 Round 204 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0105

============================================================
🔄 Round 208 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 208 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0049
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0109
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2429, R²: -0.0105

❌ Client client_61 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
