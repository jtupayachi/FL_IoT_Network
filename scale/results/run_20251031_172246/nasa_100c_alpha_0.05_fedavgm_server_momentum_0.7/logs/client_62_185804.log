[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f7c44e3-9d4c-4fb2-801d-7af120ee19f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f67326-b163-46bb-94b7-2420e9090a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aea7670-f7d6-4348-9bc0-a69afed01ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 973f8d80-ff91-4711-8a6f-22ca5357d039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23d2f709-108d-4e96-9e7a-dab5780c504f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4720b48f-0822-4090-a62d-3071e92c118c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bccfd5c0-fa74-4b25-b932-56388c697272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b8b79b-ac93-464d-8e27-d4bab4860a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51b8a084-b74a-4ef4-bd4a-56487f1e5977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e6c836-886f-429f-98fe-e5542df5f82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5af40862-de95-4ea7-aa9a-237832289828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c6269b-9182-4d38-acbe-b9e9be369313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac8a738-973d-4cd2-8c09-af9e630c6ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1529755-bf18-4977-b541-2cb72a4e04fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3beba656-8ee5-4f89-8acf-4d0a5c9c1ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b0cb61d-bec1-4635-8404-f180102c3a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a0c3c77-accc-4e08-b1cc-5f10910d2bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9133c05-58d8-45db-9a76-63d6fb16f794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23dedd2e-1e3a-4e1a-92d2-84c862c1ff60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 686f7bcc-1f0a-4bb5-801e-ea45dbe31d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20002b46-6147-49d7-a19d-8ff60c5adfe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a945025d-a29c-47b3-8ac2-6aae117f180e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f373b2-ba77-4972-81a5-d2ba92f9b24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498f38c8-15ac-4789-ba09-75d11328fa22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 574668f0-cc3f-4dfb-995c-c47c320cfaa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d98669-05d7-4609-a344-e07013045e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dce5d80-1492-45e8-927d-2b3149b87230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13cbe55e-f405-40bf-8f6e-5f2bf01620d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ef87e5-03c2-409a-9d94-51f1dc65e3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a214d6e0-7500-4567-a073-01c74c1de774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a786c929-92e7-4336-9303-c9392180b1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c96868-726e-4db2-8d00-e28a3e64e5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc43a49f-b0bc-4c57-865b-b122e14ff58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec87cf94-740c-48a3-8717-89000dc5ed36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8672f6dc-b98f-4604-a323-4e34ecaeff25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed3b1e0-cf57-436d-8678-42e3b96a1d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29feb240-1647-4aa8-86e7-e384d3f4d09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d4c9055-ede8-4b3c-958e-02891cd20b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6add503-b805-42e7-b1fe-d768b5a7ea2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dbb977e-2319-45c2-970e-d4377cd5a86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c1e025-7d49-4d86-8307-86e706c385b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8ffc18-7c27-43fb-93a2-e2331c587a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de52ed0-708f-4a1a-a516-e25eb611f5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e65783b-3014-43fe-8e5a-759a173de6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 524c6614-9ccf-4403-aec8-1f689ddc38fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2bd8f94-e3d6-4d1e-ac9c-d70ad9e46e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e116e7cc-5811-4d5b-8fb1-529d2cd6125f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef6c8a3-6d1e-4af7-bb47-7833d6aae2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c356ce26-e702-4f0f-909d-888e7afb2dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b4e276-928f-4da9-befb-f78141080391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 451c4151-3c81-48b5-ae38-5f80717105ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffea38e-1f98-4a81-b639-82e3ad8edb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce76afc4-92ad-466a-bae7-831d62b638d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c74412f6-c31b-455a-afe5-e254135431f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cec1af0-7126-4f37-b267-8ed11421a2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fb18d31-5721-4bae-897c-b359a346420e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 054cfdac-a2aa-4fcd-bd79-38cf758a8a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc3a114-87f7-4525-8721-7e7bb0d05be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f285eb-8c4d-4358-a985-5695f7c751f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9bd8dc5-d297-45d0-957b-72709cae7c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424078a1-0e62-41de-8a1c-7a275e1a0e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc9ae991-8d1e-4063-9445-d2f6e8484d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20851f71-3bdd-4c58-acab-9beb8fd24d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9b918d-c4ef-485a-9d3e-8372699968e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f149e47d-b20e-4371-89db-37b8a1d1f952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb767086-ba2b-43bf-989e-bdee6dc8b4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6abf530c-aac1-4219-857d-81353ea13d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68dd1d3-9899-430d-81dd-0c442a02091b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b8a045-da3e-401f-829b-607ca6a21de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b8717a-fb23-4aaf-909e-4136514f01b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d068ffa-43c9-4202-8266-8f3cabf0f4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b711743c-75e5-4102-a78a-bca64dfbf87b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cad71d3-1298-4eda-9f8f-442aa69b911a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d61f217-8141-450c-8a24-b32a41c4cfd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2316f4a-1473-4130-9812-71fc023f8ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def44e96-018b-40e1-b3af-3f2d24161697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da23d81c-313c-445c-aeca-164f12f0789d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80ab46a9-09cf-4c77-b6f4-58b141aa67c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab14d511-02f8-41d0-9bf1-f20f5e1aa30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62953538-3e37-4be0-b003-26ea53895559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b71216de-7f92-465e-bdc1-a490ab204dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c436425b-25c1-483e-a9d9-62a9fd7a7dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac46b280-d11c-4d5c-8dc5-f377830d5b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b130f07-8e13-4fab-93a4-b7522160dccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27288f6c-fa5a-46b5-82c0-1d7e15692de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66ffd49-8a7b-4e66-9cdf-f230d1748054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d17fd9-a926-44c9-bddd-cd60ca56aacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e10ac3-8b79-4b13-ab82-65a2586ffab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c27f42-35e1-4b22-9c01-deab37effe24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca7e7dd-c90b-4ced-8397-51cd23abb0e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cba91500-215d-4fc6-8109-5e99d874100f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57756ebd-b18b-4bf3-98e4-13fa84292c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f5e45f-0038-4ac0-af56-9b731dc03ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5e8dfe-ae3f-41a7-9566-852d1813971d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2560e1be-bd6c-4845-b66c-9a97ac108f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83463cd1-e435-436f-b5e5-1ed93d2d1286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9d63bf-1231-4bfa-ab1b-bce63d25ee8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 339177be-5eee-4e2e-9f92-34b734e921d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e0b8fdd-a946-4019-9ebf-df4ef13c4751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11e1e0d2-72aa-432c-a41c-ebfa458331ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab1b509-7898-4b21-9719-710c030f4f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdbb611e-1164-4df3-a46f-9fa541228a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6375408-6b3a-4d0a-aed1-4036993eba9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd688a2a-a41c-4059-a7e1-a22cf5176152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 268d37ab-56bb-4517-8d39-51633dc6fc43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ab6b69-2e06-4975-84d3-415688bcff16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b21a33-cd59-4dc5-9ec0-c1120f29627e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02164310-8535-4fa5-9144-4c49b20fe5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c286ed8a-c636-4648-973e-b6c9244affa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59eb3594-52e7-4712-85c6-5760e5ec486d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f34f8f8-2aa6-47c8-b48b-4537ed441dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c6d8eb-1730-4d92-ae93-db7277bcd72d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b95db1d-ae1c-44db-8763-8b62b02f84f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db039ead-00af-47cb-be84-126abf79ab8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56ec3c7a-43d5-4f7b-816e-16d6c69936a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb38b36c-19a2-4f47-a61b-3009e09ce9f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f52764c-2171-40b5-948b-f8e0ff963d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed4d63b7-e835-468f-846d-0dd4e4b1b622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9691d4d5-84c5-44b1-a3ef-813a600a1827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6fbd38-d606-419b-b373-a0837a61f309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 532028ee-994f-4a80-9cb7-6f62264b524a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c065e7-bf75-471c-a22d-f782a807e948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595706ed-e3ab-443d-aee4-7bf3f7c84292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24fa631a-37ab-4939-90a6-2218bb33392c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10853a49-c587-4de1-b1d1-a0e335236de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08ec4b0-f19a-456a-8186-710c9ef2f0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a07e5e82-3837-49da-b49a-b5be906bc7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3da7921-8c8e-4f68-9d28-05395ea2b546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a81507fa-c339-4ff8-a1a2-96dbfd9e6b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484db720-1d59-4b0b-a9f3-617ebcf19eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d224ea-b95d-44d6-9dbf-b77a4a314e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d47282-5035-4d6d-a37a-7ddc0acceaff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce9b0c71-32cc-4586-af43-929a7e1501b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae18b28-da6d-4811-a654-fd5a6c513fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61b1413-f86c-42d9-abb4-9a88c1872ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54b06d13-739c-46d1-90c5-db71f55b627f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7bb0c0-e7ca-4e05-8668-bc9fb8bd2f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b9047f4-e8f2-4711-bde5-1cd6e70e2caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05dd2a43-357f-4585-b67d-00f5f457a23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305f1389-5960-4ccf-b6d1-2172f6a5dc7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ad98ddd-e27d-464f-8035-afebba2fcd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795ce291-bc15-4e5c-9829-9f8f2185c6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba937e7-4742-4b2e-b4f3-ee610b0aa1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b81fbb-e5b7-493e-924a-06042518f7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faaecdc5-00c4-4c8a-b356-d9c55d879189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ac488bf-3aeb-4447-853d-b03a4ff3b6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd182aa0-72de-4fad-9004-5c1164bbee43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c337ca8f-dc5b-442a-906d-46368575b66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6aaa9ce-62c1-44ab-ba55-407df5a997e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c58efd0-f006-4772-8883-d83a067ad1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89fd168-1161-41c0-b049-4141a278ade0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9d1675-e82b-436f-a664-8a1b244bc7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14eeeb0-d534-4df0-9b25-d92826fa9bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a9b0c7-2e05-4807-97a8-5a213f687d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da65a5db-1e77-46f1-a629-eeff4432f58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a539e978-8cf3-477d-b8d2-b00d527164d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce1e47d-a6e3-4c62-bfcc-7b2359d4a4c7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_62
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/test_labels.txt

📊 Raw data loaded:
   Train: X=(1464, 24), y=(1464,)
   Test:  X=(367, 24), y=(367,)

⚠️  Limiting training data: 1464 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  358 samples, 5 features
✅ Client client_62 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 17 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0855 (↓), lr=0.001000
   • Epoch   2/100: train=0.0847, val=0.0865, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0835, val=0.0865, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0827, val=0.0867, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0818, val=0.0872, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0756, val=0.0914, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 17 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0094
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0466
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0936, RMSE: 0.3060, MAE: 0.2665, R²: -0.1302

📊 Round 17 Test Metrics:
   Loss: 0.0945, RMSE: 0.3074, MAE: 0.2671, R²: -0.1401

📊 Round 17 Test Metrics:
   Loss: 0.0987, RMSE: 0.3141, MAE: 0.2715, R²: -0.1906

============================================================
🔄 Round 22 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0936 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0847, val=0.0921 (↓), lr=0.000250
   • Epoch   3/100: train=0.0841, val=0.0919, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0836, val=0.0920, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0831, val=0.0920, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0817, val=0.0920, patience=9/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 22 Summary - Client client_62
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0216
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0245
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.1003, RMSE: 0.3167, MAE: 0.2734, R²: -0.2105

============================================================
🔄 Round 23 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0951, val=0.0877 (↓), lr=0.000063
   • Epoch   2/100: train=0.0898, val=0.0879, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0875, val=0.0871 (↓), lr=0.000063
   • Epoch   4/100: train=0.0866, val=0.0866, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0862, val=0.0863 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0855, val=0.0858 (↓), lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0850, val=0.0856, patience=10/15, lr=0.000016
   📉 Epoch 22: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 23 Summary - Client client_62
   Epochs: 26/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0149
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0643
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.1005, RMSE: 0.3170, MAE: 0.2735, R²: -0.2126

============================================================
🔄 Round 24 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0966, val=0.0916 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.0952, val=0.0909 (↓), lr=0.000008
   • Epoch   3/100: train=0.0940, val=0.0904, patience=1/15, lr=0.000008
   ✓ Epoch   4/100: train=0.0931, val=0.0901 (↓), lr=0.000008
   • Epoch   5/100: train=0.0924, val=0.0899, patience=1/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0908, val=0.0894, patience=3/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   ✓ Epoch  21/100: train=0.0899, val=0.0890 (↓), lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001
   • Epoch  31/100: train=0.0896, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 24 Summary - Client client_62
   Epochs: 36/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0752
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0571
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0991, RMSE: 0.3148, MAE: 0.2720, R²: -0.1959

📊 Round 24 Test Metrics:
   Loss: 0.0983, RMSE: 0.3135, MAE: 0.2713, R²: -0.1862

📊 Round 24 Test Metrics:
   Loss: 0.0949, RMSE: 0.3080, MAE: 0.2679, R²: -0.1449

📊 Round 24 Test Metrics:
   Loss: 0.0945, RMSE: 0.3074, MAE: 0.2674, R²: -0.1402

📊 Round 24 Test Metrics:
   Loss: 0.0939, RMSE: 0.3065, MAE: 0.2668, R²: -0.1335

============================================================
🔄 Round 33 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0853, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0905, val=0.0850, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 33 Summary - Client client_62
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0697
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0599
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0937, RMSE: 0.3061, MAE: 0.2665, R²: -0.1310

============================================================
🔄 Round 34 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0926, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0926, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0926, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0925, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0925, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0794, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0919, val=0.0789, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0916, val=0.0786, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 34 Summary - Client client_62
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3029, R²=-0.0660
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0911
============================================================


============================================================
🔄 Round 35 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0930, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0881, val=0.0927, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0878, val=0.0924, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0876, val=0.0921, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 35 Summary - Client client_62
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0483
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.1618
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0932, RMSE: 0.3054, MAE: 0.2660, R²: -0.1253

📊 Round 35 Test Metrics:
   Loss: 0.0932, RMSE: 0.3054, MAE: 0.2660, R²: -0.1253

============================================================
🔄 Round 42 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0949, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0874, val=0.0946, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 42 Summary - Client client_62
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0556
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0965
============================================================


============================================================
🔄 Round 43 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0924, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0880, val=0.0921, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 43 Summary - Client client_62
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0541
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.1013
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2660, R²: -0.1257

📊 Round 43 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2660, R²: -0.1259

📊 Round 43 Test Metrics:
   Loss: 0.0933, RMSE: 0.3055, MAE: 0.2660, R²: -0.1262

📊 Round 43 Test Metrics:
   Loss: 0.0933, RMSE: 0.3055, MAE: 0.2660, R²: -0.1264

============================================================
🔄 Round 49 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0925, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0924, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0924, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0923, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0786, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0919, val=0.0780, patience=1/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0916, val=0.0776 (↓), lr=0.000001
   • Epoch  41/100: train=0.0914, val=0.0772, patience=10/15, lr=0.000001
   • Epoch  51/100: train=0.0912, val=0.0768, patience=7/15, lr=0.000001
   • Epoch  61/100: train=0.0910, val=0.0765, patience=2/15, lr=0.000001
   • Epoch  71/100: train=0.0908, val=0.0762, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 49 Summary - Client client_62
   Epochs: 74/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=-0.0446
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0900
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0933, RMSE: 0.3055, MAE: 0.2660, R²: -0.1265

📊 Round 49 Test Metrics:
   Loss: 0.0933, RMSE: 0.3055, MAE: 0.2660, R²: -0.1264

📊 Round 49 Test Metrics:
   Loss: 0.0935, RMSE: 0.3057, MAE: 0.2662, R²: -0.1281

============================================================
🔄 Round 57 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0899, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0889, val=0.0896, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0885, val=0.0895, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 57 Summary - Client client_62
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0716
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0306
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0935, RMSE: 0.3058, MAE: 0.2662, R²: -0.1285

============================================================
🔄 Round 60 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 60 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=-0.0873
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0130
============================================================


============================================================
🔄 Round 61 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0956, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0880, val=0.0950, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0877, val=0.0946, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0875, val=0.0941, patience=1/15, lr=0.000001
   • Epoch  51/100: train=0.0873, val=0.0937, patience=11/15, lr=0.000001
   • Epoch  61/100: train=0.0872, val=0.0934, patience=8/15, lr=0.000001
   • Epoch  71/100: train=0.0870, val=0.0931, patience=3/15, lr=0.000001
   • Epoch  81/100: train=0.0869, val=0.0928, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 61 Summary - Client client_62
   Epochs: 83/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0431
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0779
============================================================


============================================================
🔄 Round 62 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0924, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0923, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 62 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0922, RMSE=0.3036, R²=-0.0838
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0276
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0933, RMSE: 0.3055, MAE: 0.2660, R²: -0.1266

============================================================
🔄 Round 65 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.1011 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.1010, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.1009, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.1009, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.1008, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0867, val=0.1005 (↓), lr=0.000001
   • Epoch  21/100: train=0.0864, val=0.1001, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0861, val=0.0997, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0859, val=0.0994, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0857, val=0.0991, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 65 Summary - Client client_62
   Epochs: 53/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0487
   Val:   Loss=0.0995, RMSE=0.3154, R²=-0.1071
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0932, RMSE: 0.3052, MAE: 0.2658, R²: -0.1242

============================================================
🔄 Round 66 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 66 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0731
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0743
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2657, R²: -0.1239

📊 Round 66 Test Metrics:
   Loss: 0.0932, RMSE: 0.3052, MAE: 0.2658, R²: -0.1243

============================================================
🔄 Round 70 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 70 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0668
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0784
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0932, RMSE: 0.3053, MAE: 0.2658, R²: -0.1251

📊 Round 70 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2659, R²: -0.1260

============================================================
🔄 Round 76 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0900, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0894, val=0.0897 (↓), lr=0.000001
   • Epoch  21/100: train=0.0891, val=0.0892, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0888, val=0.0889, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0886, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0884, val=0.0882, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 76 Summary - Client client_62
   Epochs: 52/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0469
   Val:   Loss=0.0887, RMSE=0.2977, R²=-0.1338
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0932, RMSE: 0.3054, MAE: 0.2658, R²: -0.1254

============================================================
🔄 Round 77 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0993, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0990, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0866, val=0.0985 (↓), lr=0.000001
   • Epoch  31/100: train=0.0864, val=0.0981, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0862, val=0.0978, patience=7/15, lr=0.000001
   • Epoch  51/100: train=0.0860, val=0.0974, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0858, val=0.0971, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 77 Summary - Client client_62
   Epochs: 64/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0411
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.1182
============================================================


============================================================
🔄 Round 79 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0836, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0903, val=0.0832, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0900, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0897, val=0.0826, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 79 Summary - Client client_62
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=-0.0524
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0798
============================================================


============================================================
🔄 Round 80 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.1003, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0998, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0867, val=0.0993, patience=2/15, lr=0.000001
   • Epoch  31/100: train=0.0865, val=0.0989, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0863, val=0.0984, patience=11/15, lr=0.000001
   • Epoch  51/100: train=0.0861, val=0.0981, patience=8/15, lr=0.000001
   • Epoch  61/100: train=0.0860, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  71/100: train=0.0859, val=0.0974, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 80 Summary - Client client_62
   Epochs: 72/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0504
   Val:   Loss=0.0979, RMSE=0.3128, R²=-0.0972
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2656, R²: -0.1229

============================================================
🔄 Round 81 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0851, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0902, val=0.0846 (↓), lr=0.000001
   • Epoch  31/100: train=0.0900, val=0.0842, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0898, val=0.0838, patience=7/15, lr=0.000001
   • Epoch  51/100: train=0.0896, val=0.0835, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0894, val=0.0832, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 81 Summary - Client client_62
   Epochs: 63/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0452
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0843
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0929, RMSE: 0.3048, MAE: 0.2655, R²: -0.1214

📊 Round 81 Test Metrics:
   Loss: 0.0928, RMSE: 0.3046, MAE: 0.2653, R²: -0.1196

📊 Round 81 Test Metrics:
   Loss: 0.0927, RMSE: 0.3045, MAE: 0.2652, R²: -0.1191

============================================================
🔄 Round 86 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0932, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0873, val=0.0928, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0870, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0868, val=0.0921, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 86 Summary - Client client_62
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0562
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0468
============================================================


============================================================
🔄 Round 87 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.1060 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.1060, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.1059, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.1059, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.1058, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.1056, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0844, val=0.1053, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1055)

============================================================
📊 Round 87 Summary - Client client_62
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0516
   Val:   Loss=0.1055, RMSE=0.3248, R²=-0.0909
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0929, RMSE: 0.3048, MAE: 0.2654, R²: -0.1209

📊 Round 87 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2656, R²: -0.1233

📊 Round 87 Test Metrics:
   Loss: 0.0931, RMSE: 0.3052, MAE: 0.2657, R²: -0.1240

============================================================
🔄 Round 93 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0898, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0886, val=0.0895, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0882, val=0.0893, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 93 Summary - Client client_62
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0664
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0344
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0932, RMSE: 0.3052, MAE: 0.2657, R²: -0.1243

============================================================
🔄 Round 95 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 95 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0851
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0344
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0932, RMSE: 0.3053, MAE: 0.2658, R²: -0.1251

📊 Round 95 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2656, R²: -0.1235

📊 Round 95 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2656, R²: -0.1233

============================================================
🔄 Round 99 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0906, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0879, val=0.0903, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0876, val=0.0900, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 99 Summary - Client client_62
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0481
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.1075
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2656, R²: -0.1231

============================================================
🔄 Round 100 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.1016 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.1015, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.1015, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.1014, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.1013, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0863, val=0.1011 (↓), lr=0.000001
   • Epoch  21/100: train=0.0860, val=0.1006, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0857, val=0.1003, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0855, val=0.0999, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0853, val=0.0996, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1000)

============================================================
📊 Round 100 Summary - Client client_62
   Epochs: 53/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0398
   Val:   Loss=0.1000, RMSE=0.3163, R²=-0.1115
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2655, R²: -0.1226

============================================================
🔄 Round 103 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0866, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0893, val=0.0862, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0891, val=0.0859, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 103 Summary - Client client_62
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0522
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0907
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0930, RMSE: 0.3049, MAE: 0.2655, R²: -0.1221

📊 Round 103 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2655, R²: -0.1225

============================================================
🔄 Round 107 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0926, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0877, val=0.0923, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 107 Summary - Client client_62
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0581
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0688
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0930, RMSE: 0.3050, MAE: 0.2655, R²: -0.1227

============================================================
🔄 Round 108 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0932, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0931, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0930, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0930, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0929, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0925, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 108 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0930, RMSE=0.3050, R²=-0.0768
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0276
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0931, RMSE: 0.3051, MAE: 0.2656, R²: -0.1233

============================================================
🔄 Round 110 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0962, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0870, val=0.0958, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0867, val=0.0955, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 110 Summary - Client client_62
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0431
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.1047
============================================================


============================================================
🔄 Round 111 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0949, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0870, val=0.0944, patience=1/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0868, val=0.0940 (↓), lr=0.000001
   • Epoch  41/100: train=0.0866, val=0.0936, patience=10/15, lr=0.000001
   • Epoch  51/100: train=0.0864, val=0.0932, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 111 Summary - Client client_62
   Epochs: 60/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0331
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.1516
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0929, RMSE: 0.3048, MAE: 0.2654, R²: -0.1209

============================================================
🔄 Round 117 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.1018 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.1017, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.1017, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.1016, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.1016, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.1013, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0854, val=0.1009, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0851, val=0.1006, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0849, val=0.1003, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1008)

============================================================
📊 Round 117 Summary - Client client_62
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0469
   Val:   Loss=0.1008, RMSE=0.3174, R²=-0.0758
============================================================


============================================================
🔄 Round 118 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0985, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0869, val=0.0982 (↓), lr=0.000001
   • Epoch  21/100: train=0.0866, val=0.0978, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0864, val=0.0974, patience=8/15, lr=0.000001
   • Epoch  41/100: train=0.0862, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0860, val=0.0967, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 118 Summary - Client client_62
   Epochs: 52/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0445
   Val:   Loss=0.0972, RMSE=0.3117, R²=-0.0725
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0928, RMSE: 0.3047, MAE: 0.2653, R²: -0.1201

============================================================
🔄 Round 119 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0939, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0870, val=0.0934, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0867, val=0.0930, patience=11/15, lr=0.000001
   • Epoch  41/100: train=0.0865, val=0.0926, patience=8/15, lr=0.000001
   • Epoch  51/100: train=0.0863, val=0.0923, patience=3/15, lr=0.000001
   • Epoch  61/100: train=0.0861, val=0.0920, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 119 Summary - Client client_62
   Epochs: 63/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0394
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0821
============================================================


============================================================
🔄 Round 121 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0785, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0909, val=0.0780 (↓), lr=0.000001
   • Epoch  31/100: train=0.0906, val=0.0776, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0904, val=0.0773, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 121 Summary - Client client_62
   Epochs: 50/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=-0.0393
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.1127
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0927, RMSE: 0.3044, MAE: 0.2651, R²: -0.1182

============================================================
🔄 Round 122 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0951, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0868, val=0.0947 (↓), lr=0.000001
   • Epoch  31/100: train=0.0865, val=0.0942, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0863, val=0.0939, patience=7/15, lr=0.000001
   • Epoch  51/100: train=0.0862, val=0.0936, patience=2/15, lr=0.000001
   • Epoch  61/100: train=0.0860, val=0.0933, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 122 Summary - Client client_62
   Epochs: 64/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0340
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.1077
============================================================


============================================================
🔄 Round 124 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0913, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0873, val=0.0910, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0870, val=0.0908, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 124 Summary - Client client_62
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0529
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0571
============================================================


============================================================
🔄 Round 125 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 125 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0735
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0302
============================================================


============================================================
🔄 Round 126 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0882, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0882, val=0.0878, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 126 Summary - Client client_62
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0466
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.1053
============================================================


============================================================
🔄 Round 128 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 128 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0614
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0536
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0925, RMSE: 0.3042, MAE: 0.2649, R²: -0.1167

============================================================
🔄 Round 131 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0903, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0874, val=0.0899, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 131 Summary - Client client_62
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0587
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0388
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0925, RMSE: 0.3041, MAE: 0.2649, R²: -0.1160

============================================================
🔄 Round 133 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0940, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0868, val=0.0937, patience=7/15, lr=0.000001
   • Epoch  31/100: train=0.0865, val=0.0933, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0863, val=0.0931, patience=12/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 133 Summary - Client client_62
   Epochs: 44/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0465
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0580
============================================================


============================================================
🔄 Round 134 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 134 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0537
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0844
============================================================


============================================================
🔄 Round 136 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 136 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0667
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0358
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0923, RMSE: 0.3038, MAE: 0.2646, R²: -0.1137

============================================================
🔄 Round 137 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 137 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0779
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0028
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0922, RMSE: 0.3036, MAE: 0.2645, R²: -0.1127

============================================================
🔄 Round 140 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 140 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0733
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0091
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0921, RMSE: 0.3035, MAE: 0.2644, R²: -0.1116

============================================================
🔄 Round 141 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 141 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0604
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0416
============================================================


============================================================
🔄 Round 142 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 142 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0563
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0553
============================================================


============================================================
🔄 Round 143 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 143 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0506
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0906
============================================================


============================================================
🔄 Round 144 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 144 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0570
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0559
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0921, RMSE: 0.3035, MAE: 0.2644, R²: -0.1116

============================================================
🔄 Round 145 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 145 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0493
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0833
============================================================


============================================================
🔄 Round 147 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0949, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0864, val=0.0945, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0863, val=0.0941, patience=7/15, lr=0.000001
   • Epoch  41/100: train=0.0861, val=0.0938, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0860, val=0.0934, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 147 Summary - Client client_62
   Epochs: 53/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0321
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.1340
============================================================


============================================================
🔄 Round 148 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 148 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0592
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0469
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0920, RMSE: 0.3034, MAE: 0.2643, R²: -0.1109

📊 Round 148 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2642, R²: -0.1102

============================================================
🔄 Round 153 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 153 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0677
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0106
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2642, R²: -0.1097

📊 Round 153 Test Metrics:
   Loss: 0.0919, RMSE: 0.3031, MAE: 0.2641, R²: -0.1090

📊 Round 153 Test Metrics:
   Loss: 0.0919, RMSE: 0.3031, MAE: 0.2641, R²: -0.1088

============================================================
🔄 Round 159 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 159 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=-0.0672
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0244
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0918, RMSE: 0.3030, MAE: 0.2640, R²: -0.1078

============================================================
🔄 Round 160 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0967, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0856, val=0.0963, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 160 Summary - Client client_62
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0431
   Val:   Loss=0.0965, RMSE=0.3107, R²=-0.0714
============================================================


============================================================
🔄 Round 161 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0975, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0853, val=0.0971, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 161 Summary - Client client_62
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0377
   Val:   Loss=0.0974, RMSE=0.3120, R²=-0.0952
============================================================


============================================================
🔄 Round 163 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 163 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0509
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0640
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0917, RMSE: 0.3028, MAE: 0.2638, R²: -0.1062

============================================================
🔄 Round 164 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 164 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0566
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0429
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0916, RMSE: 0.3027, MAE: 0.2638, R²: -0.1061

============================================================
🔄 Round 166 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 166 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3027, R²=-0.0705
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0226
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0917, RMSE: 0.3027, MAE: 0.2638, R²: -0.1062

============================================================
🔄 Round 167 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 167 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0695
   Val:   Loss=0.0978, RMSE=0.3128, R²=-0.0098
============================================================


============================================================
🔄 Round 168 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 168 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0608
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0188
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0917, RMSE: 0.3028, MAE: 0.2639, R²: -0.1068

============================================================
🔄 Round 171 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 171 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0611
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0259
============================================================


============================================================
🔄 Round 174 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 174 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0487
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0816
============================================================


============================================================
🔄 Round 175 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0895, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0874, val=0.0891, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 175 Summary - Client client_62
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0411
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0947
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0919, RMSE: 0.3031, MAE: 0.2640, R²: -0.1086

============================================================
🔄 Round 178 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 178 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0592
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0458
============================================================


============================================================
🔄 Round 179 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 179 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0724
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0127
============================================================


============================================================
🔄 Round 180 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 180 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0541
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0560
============================================================


============================================================
🔄 Round 182 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.1015 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.1015, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.1014, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.1014, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.1014, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.1012, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1015)

============================================================
📊 Round 182 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0354
   Val:   Loss=0.1015, RMSE=0.3186, R²=-0.1282
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2642, R²: -0.1100

📊 Round 182 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2642, R²: -0.1105

📊 Round 182 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2642, R²: -0.1104

📊 Round 182 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2642, R²: -0.1104

============================================================
🔄 Round 188 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0990, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0855, val=0.0987, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 188 Summary - Client client_62
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0483
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.0576
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2642, R²: -0.1105

============================================================
🔄 Round 190 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 190 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0604
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0351
============================================================


============================================================
🔄 Round 194 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0868, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0880, val=0.0865, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 194 Summary - Client client_62
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0431
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0826
============================================================


============================================================
🔄 Round 195 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 195 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0554
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0579
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0921, RMSE: 0.3035, MAE: 0.2644, R²: -0.1120

📊 Round 195 Test Metrics:
   Loss: 0.0922, RMSE: 0.3036, MAE: 0.2644, R²: -0.1123

============================================================
🔄 Round 198 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 198 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=-0.0650
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0205
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0921, RMSE: 0.3035, MAE: 0.2644, R²: -0.1120

============================================================
🔄 Round 200 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0910, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0875, val=0.0907, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 200 Summary - Client client_62
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0492
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0609
============================================================


============================================================
🔄 Round 201 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0896, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0874, val=0.0892, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 201 Summary - Client client_62
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0478
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0725
============================================================


============================================================
🔄 Round 202 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 202 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0607
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0448
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0919, RMSE: 0.3031, MAE: 0.2641, R²: -0.1088

📊 Round 202 Test Metrics:
   Loss: 0.0919, RMSE: 0.3031, MAE: 0.2640, R²: -0.1086

============================================================
🔄 Round 209 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 209 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0544
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0516
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0918, RMSE: 0.3030, MAE: 0.2640, R²: -0.1081

============================================================
🔄 Round 210 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 210 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0548
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0594
============================================================


❌ Client client_62 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
