[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 254004f3-3b2c-4ee4-b7fd-14d5fdc16bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e059050-67dd-4aeb-a1d5-112737037449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a6a9b1-8d28-4254-ad0a-98f8ded61987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a63ef30-df0f-4a1d-86df-b1564fda05d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8afb5d6d-2005-4926-aa5d-894158c86e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a0db64-ded0-480e-aa79-44d9bfbcd522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac76e4bd-aae6-45f2-94ba-1f5c25123720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed2c2087-a334-4b1f-bbf7-7d0a9fb798ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 047f02a7-0d1b-42b0-9da7-4bc2459442aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9d05beb-29c3-49fe-8741-bb01da95e621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2541e2b-9e67-4b50-894a-007c77f68c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab55ca4e-b8ea-46be-b35e-df74092f1377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faaac88c-7d3e-4912-bce0-34625c390516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7104c375-624f-4cdc-8458-623cbbe54716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 015a06e4-09b9-4edf-b5f3-6a4689290b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae7a32d-c854-40b8-8448-764102948e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e28cca-7081-4f13-99b2-10d310ab68cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 272780c6-dd7a-456d-af2c-7c59a4af11f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d49a8062-3073-4060-b0d9-c34d0ce40ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 407efcc5-7b19-425f-8152-d9814e58d674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c4738c9-7ad1-4655-8f86-52b72ff8c5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14a263a-cb97-4cea-b624-1a383a1499c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5482cc0a-1c3a-4d0e-ab41-0a75957c5636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 755bf22a-a63d-4929-b81a-fc29ba95c7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2176680c-0405-4705-bd61-30370ac39b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb3801e-0939-4340-af79-1bab36e9bad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f5df269-3985-4e86-95c1-ed585205d835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec8e58ea-d3da-48ef-9693-45c17e405372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38805be1-f647-430d-bb6d-43c40f4cb49f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc62f0e-bbde-4cb0-95f9-14665fd515be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7212180-eaca-4437-896a-88420a9bced0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce397093-6cdc-4d97-9927-2f6534788eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5920ec25-0566-4d91-b467-5127d6a563e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5682518-d83d-4ec9-92e8-ae61cd8bd41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c08009-8c9f-430e-ad4c-d21f6df87a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca699e7-3899-4b56-8bc0-9944417a8be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c058865-56b2-4bef-bc1b-f42571556f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06453e6d-4cd8-49b7-9685-ef08eb0d1c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 213cb9ea-38ed-4be4-a31d-94547272d4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8491767-2048-4a9d-a76c-5a04ced58f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb06c773-2571-4fd2-a336-32d8f9a85472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e494eae9-d430-4ea5-b9a2-f5d17ece00d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d29dda5-4e03-4389-9d86-e80bdcac07a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8562a8f-6f86-4d11-8a32-ffb9dad34873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f7334fb-9233-4be3-87b1-ff75f545bb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 740695bd-14ef-415d-86bf-3a2cd6095db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24800d6c-a7b8-45ca-8a98-a77d9806dff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4381deab-ede0-47a0-9958-938bdaa8a71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45902bbe-2625-454f-83e5-c92ba6c465a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28554c7c-8967-4e3f-8b8b-fa4e159d6603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafa3b96-f90b-4d62-829e-752d00689b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f67880d8-9a71-4198-bec8-cc901a85ee4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1962a4-2987-4437-aa66-327a6cb144fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f67775a-1607-45f7-89a2-dc5bc131c7a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bf57375-2712-41b2-a5c1-59e2f88b1f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6805bb22-f3ac-4015-8228-23c7575b107c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba98cfa6-c920-47f8-8ce5-8d1ffa9510c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3e1bb7f-df2f-4a2e-857f-e054dc7e51e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bc2acc-0146-4fdc-b879-c211c33267f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d530024-3c51-44c7-b1fb-2067a7f63209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c67dc1b9-bcd4-4f33-9a1b-4df585671626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cb9ca4d-6db3-47b4-b1a0-99698e2a95ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3797763-eca8-4230-9d46-a61e017fb5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590dd5db-e4cf-4f99-aff3-71fb5dcc5e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0ede98-731c-4cc9-bf62-98ac1b3a12cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3637f5bd-3ec3-430c-a3e5-f23078b6bb5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78fb2e8a-0316-4cbe-a6be-548ccb0a1966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c8aa016-14c4-4c8d-b467-38fc4fa1470d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e39897b-840a-4d41-a9fa-d7683dcb9bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc8e3030-6eea-4f28-a657-4e79bb3b0bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc03d204-f14f-47c5-a033-d253a8adda4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29db5f43-b337-44aa-a5ec-b184fe16388e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a6825d1-3dba-4f10-a2b1-edefc39ba9c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34010637-f6e9-4bfe-bf3a-53440afb0e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52a5352-0b1d-443a-a0c1-0aba94ebfc21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af8b3c6-bfc2-408e-b8c8-1f187189e5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc043765-c75f-4f67-a214-110232854812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5b876c-4aa9-4671-8e00-ac17da25dede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99741fa7-0e97-4f4f-a39c-562a884dd3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3b0e60-9f12-492c-94d0-51c16a446ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fcf3b5f-1103-4332-b47d-d5d478c823d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1164e20b-0dbe-4446-9859-41c0009cc599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9009f01-ecd0-4be7-b081-42de29b6f87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efddbb3e-c200-4d2a-9d4f-95474aefc36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7014aac-b0f1-4116-9706-1a95ab5e4e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38fba3ff-4c50-4e3d-8560-1ba6ad0fa3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1a289e3-e973-475d-bb41-d3f25b711de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de83007-9c5d-46d9-86a4-fd5f83c6777b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9548b06-7b2a-4751-88b1-e2bec47ad024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51de2ed9-a5f7-444a-8f7b-268d4d92f1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b7e1bef-9df8-4462-9232-8e425994f6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a42146b-86ff-46a1-960f-798acad15e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9cf7b04-9930-4318-8a9e-5e28f0f710eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b3b0b7-8fdd-4fff-bcb7-0669dfdf0652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9273489d-be0b-4cfe-8aea-33a43239b9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a6acf1b-60e4-492a-ae61-57c9c6cac92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9a6613a-22da-48b4-a62e-c098aff52828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac2abb8-dc09-44ac-97de-79b57dbe7916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2842053e-f6cc-4528-a609-51b850f8de52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b352f3e-d029-495f-8696-c717cbafa280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7dd50ec-ced5-4e22-9494-4c4121b3c217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8745c245-96a8-453b-b9a1-a00d2e63d165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2593653-7e7d-43c7-ad23-6538b4a55d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ca1e367-7c95-47c9-8609-30c65ae4b242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5449872-57b3-4462-aff3-cbcdeb8ba257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 076beb9e-88e3-4d3f-9a16-b635563d54b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bc047a5-13f0-43f6-9016-4411fd4e50dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f84fe01-878d-4443-9269-b7535c36b838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fded83e-b161-40df-8f51-22d54b397cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25af3638-c1d6-4fee-bc70-689007fedd18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a200c9e6-fa5a-4590-b988-9a4fbbedd61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 165c6b88-1ac5-4748-9a14-5ead8fc32da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e83e28-3284-48aa-8de0-855e102183c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0c980ad-3a5c-4aef-83bd-c55da079ce61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb2a0896-1b1e-487d-b610-096286d2ff19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4ff5386-fc45-4745-ac8e-377a4046a2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76817845-387f-4fc0-a000-5965f7c051d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9d74433-9dc6-46f5-a718-ad49d4ce94ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c8293c5-71bb-4577-9607-6fdbd888c953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc968afe-d598-4361-8ee3-5a7941d46013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fecefcf6-ac5f-4774-a3e5-18b97a33d9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a929414b-6d2a-4af6-a741-ed9dde9efc69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93871790-7a97-4505-b00a-8ba7f9f179d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d73f22-c807-4679-8f57-b06a7b3109d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ffa128-b426-4c2d-ba24-49d41a2bb1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e11729f-b770-4bbc-b568-b2423333acf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf864a11-de82-4220-a47e-5717d0a58192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7fc58e4-4348-4fa7-81c6-31ac835d59d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06303632-b7b0-415b-bb68-003e41383a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d234570-ad43-44af-bf1a-a0128fac50a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae12fde-7e8e-46e0-85b1-a50f807be38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5102eaad-c194-44e9-a706-8780af4fb6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed85ca09-427d-4e5c-b328-31e27d07bc84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8180de04-0d65-488e-9d19-0367c04cd646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4cd0b4a-ab65-43ec-8a9e-0adcbd2385fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef14e40-0ee8-4c33-be60-c1ae9e09038b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52269c88-dd45-4474-82b7-7a86e3b82df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 786ac5ab-0fe0-46a5-a574-012bb8bb1ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a061f4b-3148-4a34-88c7-4599107097cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a64d0e82-936b-499d-9598-b99576bb01fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59f1f368-6422-43b9-8c8d-41ff3eea0816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66cffe8b-2441-421a-869b-f4e197f3556d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6098585-4c69-4fcb-9051-c847c35543b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e386291b-31bf-4635-b28a-6c3740d1adec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b933ab4-91e8-409b-9537-a6f7a03430db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f20d96-7cc3-4d4b-9217-b056a4cf4857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ec709d7-606f-4f16-8f37-4f16e45d1376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c21268be-0aa9-411d-87b6-e4611afe8af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b6f2f9-7b25-4e62-892d-27516b408981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e45895-238a-40ae-8e8e-455da8491635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2d2cf3-6977-4ea5-bd20-a35de2e1ead3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f4d9ee9-5518-424d-a08e-b736cbf6118a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 701ab764-570f-4ced-ac37-463a05857c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b2a0771-4fd3-4944-929d-d9d719147066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3f654e0-f95a-4a38-a01f-b8bb61938b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ecd8cd6-eb05-40d7-8c03-e542e8a0ddd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca51f05d-90ea-43d6-9c78-27b101149bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8100f6a1-f56b-463e-834b-8780e1140f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4430648-35e8-4c8d-bbdf-45356f2b6ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf20c9c6-c342-493b-b091-317843ecf7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f61ff6-bc62-4ccd-a887-81dacdc0293f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874feccc-6168-470f-9155-2110b2e4f311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a37b12ff-d85d-4640-b423-f4d827248ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea193c7-ba8f-4081-82f9-a441bcb75da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa257376-b0b9-4155-b5af-1a80f410fffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f1d8948-26a0-4500-8bd7-99a9acbc4f23
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_63
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/test_labels.txt

📊 Raw data loaded:
   Train: X=(1341, 24), y=(1341,)
   Test:  X=(336, 24), y=(336,)

⚠️  Limiting training data: 1341 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  327 samples, 5 features
✅ Client client_63 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0737, RMSE: 0.2714, MAE: 0.2326, R²: 0.0255

============================================================
🔄 Round 15 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0779, val=0.0771 (↓), lr=0.001000
   • Epoch   3/100: train=0.0766, val=0.0769, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0753, val=0.0763 (↓), lr=0.001000
   • Epoch   5/100: train=0.0737, val=0.0764, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0644, val=0.0793, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 15 Summary - Client client_63
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0903
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0202
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0735, RMSE: 0.2711, MAE: 0.2319, R²: 0.0276

📊 Round 15 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2317, R²: 0.0291

============================================================
🔄 Round 25 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0756 (↓), lr=0.000250
   • Epoch   2/100: train=0.0788, val=0.0756, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0772, val=0.0761, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0763, val=0.0760, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0754, val=0.0758, patience=4/15, lr=0.000250
   • Epoch  11/100: train=0.0712, val=0.0740, patience=2/15, lr=0.000250
   📉 Epoch 20: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0663, val=0.0736, patience=8/15, lr=0.000125
   📉 Epoch 28: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 25 Summary - Client client_63
   Epochs: 28/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0693, RMSE=0.2633, R²=0.1511
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0224
============================================================


============================================================
🔄 Round 26 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0815 (↓), lr=0.000063
   • Epoch   2/100: train=0.0789, val=0.0811, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0786, val=0.0807 (↓), lr=0.000063
   • Epoch   4/100: train=0.0782, val=0.0804, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0779, val=0.0802 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0767, val=0.0791, patience=3/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0759, val=0.0784, patience=2/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0756, val=0.0782, patience=12/15, lr=0.000008
   📉 Epoch 32: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 26 Summary - Client client_63
   Epochs: 34/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0506
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0372
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2334, R²: 0.0203

📊 Round 26 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2337, R²: 0.0191

📊 Round 26 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2341, R²: 0.0166

============================================================
🔄 Round 31 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0810 (↓), lr=0.000004
   • Epoch   2/100: train=0.0792, val=0.0811, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0792, val=0.0811, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0792, val=0.0811, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0792, val=0.0811, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0791, val=0.0811, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 31 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0074
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0106
============================================================


============================================================
🔄 Round 32 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 32 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0147
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0347
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2343, R²: 0.0159

📊 Round 32 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2343, R²: 0.0157

============================================================
🔄 Round 34 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 34 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0107
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0071
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2343, R²: 0.0154

📊 Round 34 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2344, R²: 0.0150

============================================================
🔄 Round 39 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 39 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0047
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0118
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2344, R²: 0.0149

============================================================
🔄 Round 40 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 40 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0130
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0040
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2344, R²: 0.0148

============================================================
🔄 Round 42 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 42 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0092
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0061
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2345, R²: 0.0148

============================================================
🔄 Round 43 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 43 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0094
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0105
============================================================


============================================================
🔄 Round 44 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 44 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0096
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0077
============================================================


============================================================
🔄 Round 47 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 47 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0080
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0136
============================================================


============================================================
🔄 Round 48 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 48 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0119
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0200
============================================================


============================================================
🔄 Round 50 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 50 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0090
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0115
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2345, R²: 0.0145

============================================================
🔄 Round 52 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 52 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0143
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0129
============================================================


============================================================
🔄 Round 56 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 56 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0111
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0024
============================================================


============================================================
🔄 Round 57 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 57 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0150
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0156
============================================================


============================================================
🔄 Round 58 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 58 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0135
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0090
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2345, R²: 0.0145

📊 Round 58 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0145

============================================================
🔄 Round 60 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 60 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0055
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0056
============================================================


============================================================
🔄 Round 62 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 62 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0133
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0110
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0143

📊 Round 62 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0143

============================================================
🔄 Round 65 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 65 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0128
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0087
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0142

============================================================
🔄 Round 68 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 68 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0083
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0102
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0143

📊 Round 68 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0143

📊 Round 68 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0143

📊 Round 68 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0143

============================================================
🔄 Round 74 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 74 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0053
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0160
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0142

📊 Round 74 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0142

============================================================
🔄 Round 76 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 76 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0039
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0121
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0142

📊 Round 76 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0141

============================================================
🔄 Round 78 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 78 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0102
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0014
============================================================


============================================================
🔄 Round 81 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 81 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0055
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0166
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0141

============================================================
🔄 Round 83 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 83 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0060
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0130
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0140

============================================================
🔄 Round 84 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 84 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0018
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0261
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0140

📊 Round 84 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0141

============================================================
🔄 Round 87 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 87 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0103
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0006
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0142

============================================================
🔄 Round 89 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 89 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0129
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0170
============================================================


============================================================
🔄 Round 90 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 90 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0123
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0255
============================================================


============================================================
🔄 Round 91 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 91 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0116
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0149
============================================================


============================================================
🔄 Round 92 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 92 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0144
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0168
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0142

============================================================
🔄 Round 96 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 96 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0090
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0048
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0141

📊 Round 96 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0140

============================================================
🔄 Round 99 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 99 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0157
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0309
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0140

============================================================
🔄 Round 102 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 102 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0089
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0042
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0140

============================================================
🔄 Round 103 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 103 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0112
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0080
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0140

📊 Round 103 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0140

============================================================
🔄 Round 105 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 105 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0064
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0150
============================================================


============================================================
🔄 Round 106 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 106 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0069
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0121
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0140

📊 Round 106 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0140

📊 Round 106 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0141

============================================================
🔄 Round 109 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 109 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0138
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0138
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0141

📊 Round 109 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0142

============================================================
🔄 Round 112 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 112 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0089
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0004
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0142

============================================================
🔄 Round 113 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 113 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0126
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0120
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0142

============================================================
🔄 Round 114 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 114 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0133
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0213
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0142

============================================================
🔄 Round 119 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 119 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0019
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0164
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2346, R²: 0.0144

============================================================
🔄 Round 121 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 121 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0095
   Val:   Loss=0.0693, RMSE=0.2632, R²=-0.0129
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0145

============================================================
🔄 Round 123 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 123 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0068
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0198
============================================================


============================================================
🔄 Round 125 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 125 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0157
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0455
============================================================


============================================================
🔄 Round 126 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 126 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0058
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0124
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0145

📊 Round 126 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0145

============================================================
🔄 Round 129 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 129 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0063
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0104
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0145

============================================================
🔄 Round 131 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 131 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0089
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0032
============================================================


============================================================
🔄 Round 132 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 132 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0080
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0061
============================================================


============================================================
🔄 Round 133 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 133 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0125
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0147
============================================================


============================================================
🔄 Round 136 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 136 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.0180
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0145

📊 Round 136 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0145

📊 Round 136 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0145

📊 Round 136 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2346, R²: 0.0144

============================================================
🔄 Round 141 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 141 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0008
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0279
============================================================


============================================================
🔄 Round 142 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 142 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0136
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0223
============================================================


============================================================
🔄 Round 144 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 144 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0091
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0007
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0143

📊 Round 144 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0142

============================================================
🔄 Round 149 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 149 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0038
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0221
============================================================


============================================================
🔄 Round 150 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 150 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0065
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0095
============================================================


============================================================
🔄 Round 151 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 151 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0038
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0129
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0141

============================================================
🔄 Round 154 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 154 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0003
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0347
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0141

============================================================
🔄 Round 158 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 158 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0074
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0014
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0139

📊 Round 158 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0139

============================================================
🔄 Round 162 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 162 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0072
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0041
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0139

============================================================
🔄 Round 164 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 164 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0096
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0320
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0139

📊 Round 164 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0138

============================================================
🔄 Round 167 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 167 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0054
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0121
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0138

📊 Round 167 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0138

📊 Round 167 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0138

📊 Round 167 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0138

============================================================
🔄 Round 171 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 171 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0006
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0153
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0138

============================================================
🔄 Round 173 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 173 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0084
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0007
============================================================


============================================================
🔄 Round 174 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 174 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0038
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0137
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0139

============================================================
🔄 Round 177 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 177 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0101
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0093
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0139

============================================================
🔄 Round 180 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 180 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0151
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0511
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0139

============================================================
🔄 Round 185 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 185 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0049
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0132
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0139

============================================================
🔄 Round 186 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 186 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0036
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0186
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0139

============================================================
🔄 Round 187 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 187 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0031
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0283
============================================================


============================================================
🔄 Round 188 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 188 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0056
   Val:   Loss=0.0890, RMSE=0.2982, R²=0.0041
============================================================


============================================================
🔄 Round 189 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 189 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0140
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0418
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0140

📊 Round 189 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0140

============================================================
🔄 Round 192 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 192 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0093
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0045
============================================================


============================================================
🔄 Round 193 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 193 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0079
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0072
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0141

📊 Round 193 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0141

📊 Round 193 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0141

📊 Round 193 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0141

📊 Round 193 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0142

============================================================
🔄 Round 202 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 202 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0072
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0039
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0142

📊 Round 202 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0143

📊 Round 202 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2347, R²: 0.0142

📊 Round 202 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0142

============================================================
🔄 Round 210 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 210 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0093
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0154
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2348, R²: 0.0142

============================================================
🔄 Round 211 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 211 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0172
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0350
============================================================


❌ Client client_63 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
