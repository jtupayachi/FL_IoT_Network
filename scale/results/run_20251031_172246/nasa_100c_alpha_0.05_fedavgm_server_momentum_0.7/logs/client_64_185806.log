[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6107e1fa-dcb8-44dd-b541-1c59721b042b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c72a1b-0d28-4183-aa7b-3b6db87f395b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd504cbe-9fe2-4238-88ed-e4d41d5a4447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6600d6fb-0c85-44f3-9431-230acca4d854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df263c7c-2d26-4509-a9a1-ab16b4b0b55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9e54f46-d870-4325-8f9e-3071cc7c3784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8475bdd-c0a0-46e3-878a-df470e7cd19d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d247424-5090-4525-9b94-037da3d6a65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0c84da0-a785-44a2-a84c-545a66dfed94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23176a94-ca14-4994-914d-6e47c2407448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be7ee9d-433f-4c20-adfb-4b6db4bb50fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa47af1e-4d28-4017-8218-23e97856df53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c582d282-b1e5-46c2-b26b-320f77664cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14e7721-164c-4ca2-bf6d-1985d31a1ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df7a5dfd-7778-4f6b-9323-a59fb94f4783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d83697bc-906e-47d2-a58e-eefacfa1bae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c10290e-0317-45f9-add8-3ba05963f4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec178d4-827f-4d49-a8e4-ea708964d6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4fdffe6-150c-48f5-ac6a-d64efc362941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db14a4ca-56c6-4718-b566-f6b5c1fa0f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3713c31-3ae1-4334-b541-a0da229abb42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0419c502-7e79-4169-a77f-fb90af585158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b8787ae-b8ce-43ce-84d9-8f31d6ed25b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a138da3-7ac2-4db3-894e-52bb2096874b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fec035d0-9333-4f6c-b7f1-570b9f1dac93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 732be72f-e24a-431b-ac40-fc4398d3599d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7dcc089-5e1b-4899-9a3d-4b75eda17835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message befa7efd-a5c3-4f5a-8e0f-4195c60d751d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 727de35c-99d1-4d10-b74c-bde50740519f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f04ae4-d581-4019-a5fc-f8f462fef9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2faf7c8-e188-469e-9a5d-e4b57f588271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac753e45-9def-471f-bfa4-1b872046f134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66027a26-2f85-40e6-b594-42eb49eaa85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d3f7124-ea53-4d06-8464-ee31adf75480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2737f385-2849-49f0-b8e0-ecb65cc3d0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07c71e3-f75a-4259-8396-bdbaf86be056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b50c8a2-8bd0-4295-a162-564ce3393fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1b4f71-cce8-4001-b93e-a3056d37cafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c08251-f418-429a-a52d-95e0d2bfb089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e468ab4-6735-4529-a057-6de4aa99baf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd121ce4-cba9-4cb8-9d02-d5b0931c24b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e39b9120-b364-4b12-b9fb-5a51f11fa045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b525429e-4577-43b4-8d7a-14b3764959df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f0fc70-6df3-4909-8bd8-f77684fd8ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73d14a8-8188-4676-81f1-665ab74e2c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4526b6e8-4f01-42ed-8803-b9a8b9d401fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd13f6c-5fee-4e80-baf5-283a5ff3224e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ba738bb-8215-4fdb-9cd4-28db0cbe41f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac396472-9d7b-4f17-bd8a-97c04b3bd73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb55d5bc-0ad4-44f3-b57b-2db214327d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8f031c-a524-480d-89f7-d1d5f87387be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8524866d-ec16-47c4-a539-52ded372b9e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ed8a661-ea3f-4af8-a6ac-30120ed1a575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7262602b-c110-4f41-97fa-24d26e8f54a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2676ab49-ff04-4072-a774-506d739d681c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2726b3ae-1b03-437e-a764-118f690d11ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1605614c-474f-48b6-a3db-54726420a245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a6940b-3194-4b20-84ee-4ea96aa2b37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e19ee5-bbd9-4f80-9680-f9a9b28c2599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d2efa80-a85a-4cd3-b770-3d0722840210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce50bfe8-77dc-4d84-b380-f965ce1dc316
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b138a5-962a-42bc-9075-c38129ebd47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b83520-fa96-4e83-95d6-16b3ec4f39eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cb10682-b53e-4f60-b60e-0b4eb09a4680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ed30180-1eb9-4e05-bedb-5ec445005879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca143ce7-00cd-41ee-b7b0-0644f5307929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ce60d6-1c14-4df2-96d1-df8d1327c8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cfb6589-0579-4aec-9506-f662bc9b9632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97bffa32-5502-43c9-89b0-81ba5e683657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4968cd12-a372-44fd-b888-c8b29103d447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af172a0-8265-47c2-9fa0-854f97c00ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb6b215-dc4c-41b6-b99d-23258e88734d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3341875-c84f-40bf-8388-5cbd038258b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25e6dbf-c8e1-48a6-a0e5-e043e7dcb423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34f7c70-bd70-469e-9fad-785e3206b320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354b7a08-76ab-43d1-a214-c9e47302c3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6273e177-5c95-4c78-8312-615e55f29bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 062287f0-c047-4b4f-b2f3-03833d9b6e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb4f8c99-3965-4358-9885-9c809ee72837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f05be02-5053-4dff-a82d-211fa84cada9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6eca885f-dcdc-4882-818c-9ec3f7297c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ffdf33-788f-4a41-902c-45f00316c00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d61cf822-7f48-424a-804b-a3668b1bc809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87666c5d-8b77-4289-aac4-def16a6dd71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c56eafd-fb10-45e6-bbc3-4475671c644c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e35fcc08-ccb3-4f3e-8d3b-880f528541fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d84e71b-f346-4ced-b589-f615123fb8a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569ecae9-6878-4972-8d21-62aabb2d4ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5166044-ad5a-4384-abee-f75aa337beb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c6fdd3-5e46-4345-823f-84972e736295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80ee487f-c376-4edc-84f1-0d094dbc71c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e86869e-fc49-4111-8539-c82ee937dcd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5265a15e-9910-463e-a677-cc959380a3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e5be5f-bd7f-4ab8-accc-fa752226f339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49591d6-ab51-43ed-ba4d-26e58be239b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db5787dc-fbf6-4234-814c-c1e6d6e624ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476987e1-8ad5-42b7-be14-82880e2eebdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e966b1-ea5a-43c9-91d6-f33784187a52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a24735c6-463f-4f9b-a889-6853c8298504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 870a0927-aec7-44da-8c7f-fb9170aca439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06599789-dd70-4165-bff8-813c9af9f79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33565e4b-3e6f-4ec7-b134-f7a8e8f1aa73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6a89a6-6146-4d9c-953a-59059663b0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cee5c4c-c2b5-4a95-88c9-fc7249aa9327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a96fe346-d0a0-4bc6-b645-59e38e248496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4432b73f-05be-46c9-b219-e39c8ffd9916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7aa4d66-18f0-40e6-853a-23de73339597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5288da51-5110-4617-aab9-3c58f56616c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99670f9b-5fa8-4a74-933f-de4594d1dbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03bebbe3-6cd5-4f11-8fb4-fb7e23b6e582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b2a8d81-be09-49d3-8616-2161211722cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c84c6080-fb5d-40c9-9387-1e8483792946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 603e2a3e-c001-4134-922b-ec152d68969d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd868999-f784-46e6-a941-19071d93cb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7b453cc-9e64-4cc0-b8fa-77028de95fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a319257-dc2b-4ff2-9181-67745904c516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8820631-6cc0-4f09-a013-970ed6d74aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d79edb-10c6-4b59-9912-71fa97ace8f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 212ee28b-4d36-4f7a-9c66-60f11dddefdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b8e999-b7f3-48d1-aa04-611bccaec911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d71eaf70-6129-4758-a48a-010fb497d858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35f7c9b3-77c0-4dcb-8902-dd86a50557a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec2ff4c1-6e22-4b53-9bf4-30ac112d542a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce47b562-311c-4daf-acf6-d229b0e63385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c09e735d-b5a9-4ffa-b3d7-98dc0398e1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a2019d-4603-4ec8-98b7-d9f94e384b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b88f188-e895-4926-b296-fc0f05fb0d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f986cc-ad3a-428c-9e28-5d6f9c66bac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64e9a670-b62e-48c5-81b0-5911ea9d08a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaf35550-4681-4ac2-9cfa-9c0869def0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78458a86-1842-4ff7-af6b-854cc86f8252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c26fde5a-b0f4-4d96-8c8a-fbd9b570c97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e8714fa-1207-4219-9f15-541e31cf35f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b73f027-2a3c-46a8-95a6-ae111d1883e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 851bd707-3175-4f3c-9d9a-23dd6dfd8eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56cf7505-e066-44e7-8410-4e2c1c09102d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03869cff-28b0-4f45-82db-2b4de12bcc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15be5c3-9a0f-46e6-b0ff-c4209f28d11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19116312-e045-4de0-a653-94511f7a8c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27bcf000-146c-465b-a745-5fa6389527c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08190377-927a-4aaf-bc3b-5e51f424c21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eec8cfd-cf33-4e6f-bfc3-7676d30bd046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 157b9bbc-d70d-4fd2-8942-c77e44683b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e0c3cf5-c2a7-4674-9732-d1b3b97c5df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bff76f2-0652-46c0-94cf-a668f4776c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0622561-197b-4cfe-9d4d-03e6eb3d243e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d055dc0-c088-4507-ace4-6cd1cf888da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb8682c7-01a3-4f64-8194-3deac6c9b7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76686a09-d23b-4563-a07e-8c09b64cb2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853ef47f-6190-466f-969d-f6cd64110b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9f7cbff-322f-4a91-a7ec-9ceb833fdf87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dd07e4f-817e-458d-9ac8-209cd0c8eea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4335c35-f285-456e-a413-964f1cc4471c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83884306-e9c6-4c7c-9858-caf7c2cdd466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a41650d-f93c-4427-b035-6b1ce320b2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f6b3959-76aa-4dc9-a63a-817578447355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1685e10f-193a-4255-a2e1-c772c88f8108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef64c864-c0e7-462a-81fe-23d3e68a049b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0bc644-e84a-4b14-8b3a-acae97b3968a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ecb2c64-d390-4504-9941-4176c2d0a29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 455bc24d-c13a-4b89-94ec-4ab81ff2d259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d5d30e-60a7-42f8-b0ef-94beae37bd8d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_64
Server: localhost:8689
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/test_labels.txt

📊 Raw data loaded:
   Train: X=(1040, 24), y=(1040,)
   Test:  X=(261, 24), y=(261,)

⚠️  Limiting training data: 1040 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  252 samples, 5 features
✅ Client client_64 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2518, R²: 0.0122

============================================================
🔄 Round 15 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0694 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0752, val=0.0670 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0736, val=0.0654 (↓), lr=0.001000
   • Epoch   4/100: train=0.0723, val=0.0651, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0709, val=0.0644 (↓), lr=0.001000
   • Epoch  11/100: train=0.0644, val=0.0620, patience=2/15, lr=0.001000
   📉 Epoch 15: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0544, val=0.0697, patience=12/15, lr=0.000500
   📉 Epoch 23: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0620)

============================================================
📊 Round 15 Summary - Client client_64
   Epochs: 24/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0642, RMSE=0.2534, R²=0.2265
   Val:   Loss=0.0620, RMSE=0.2490, R²=0.1013
============================================================


============================================================
🔄 Round 16 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0789 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0736, val=0.0783 (↓), lr=0.000250
   • Epoch   3/100: train=0.0728, val=0.0779, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0721, val=0.0775 (↓), lr=0.000250
   • Epoch   5/100: train=0.0715, val=0.0772, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0696, val=0.0764, patience=5/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0682, val=0.0763, patience=9/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 16 Summary - Client client_64
   Epochs: 27/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0693, RMSE=0.2633, R²=0.1373
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0721
============================================================


============================================================
🔄 Round 17 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0749 (↓), lr=0.000031
   • Epoch   2/100: train=0.0745, val=0.0748, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0742, val=0.0747, patience=2/15, lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   • Epoch   4/100: train=0.0740, val=0.0746, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0738, val=0.0745, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0732, val=0.0742, patience=4/15, lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008
   📉 Epoch 20: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0728, val=0.0740, patience=14/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 17 Summary - Client client_64
   Epochs: 22/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.0839
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0941
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2484, R²: 0.0364

============================================================
🔄 Round 18 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0808 (↓), lr=0.000004
   • Epoch   2/100: train=0.0737, val=0.0808, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0736, val=0.0807, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0736, val=0.0807, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0735, val=0.0807, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0732, val=0.0805, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 18 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0869
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0018
============================================================


============================================================
🔄 Round 19 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 19 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0665
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0583
============================================================


============================================================
🔄 Round 20 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 20 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.0899
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0319
============================================================


============================================================
🔄 Round 21 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 21 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0942
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0693
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2452, R²: 0.0590

============================================================
🔄 Round 22 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 22 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2719, R²=0.1009
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0787
============================================================


============================================================
🔄 Round 24 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 24 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1087
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0902
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2450, R²: 0.0601

============================================================
🔄 Round 25 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 25 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1042
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.1027
============================================================


============================================================
🔄 Round 26 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0634 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0634, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0634, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0634, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0634, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0633, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0634)

============================================================
📊 Round 26 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.1011
   Val:   Loss=0.0634, RMSE=0.2518, R²=0.0949
============================================================


============================================================
🔄 Round 27 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 27 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.1032
   Val:   Loss=0.0686, RMSE=0.2620, R²=0.0769
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2459, R²: 0.0552

============================================================
🔄 Round 30 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 30 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0846
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.1284
============================================================


============================================================
🔄 Round 31 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0658, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0658, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 31 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0775
   Val:   Loss=0.0659, RMSE=0.2567, R²=0.1526
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2470, R²: 0.0493

📊 Round 31 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2471, R²: 0.0484

📊 Round 31 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2472, R²: 0.0480

============================================================
🔄 Round 36 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 36 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1056
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0249
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0476

📊 Round 36 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0476

============================================================
🔄 Round 41 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 41 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2695, R²=0.1031
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0267
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0477

============================================================
🔄 Round 42 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 42 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0995
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0303
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0477

📊 Round 42 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0478

============================================================
🔄 Round 45 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 45 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.0940
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0687
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0478

============================================================
🔄 Round 46 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 46 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.0769
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.1397
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0480

============================================================
🔄 Round 49 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 49 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.0982
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0597
============================================================


============================================================
🔄 Round 50 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 50 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0838
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.1177
============================================================


============================================================
🔄 Round 51 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0628 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0628, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0628, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0628, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0628, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0627, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0628)

============================================================
📊 Round 51 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0819
   Val:   Loss=0.0628, RMSE=0.2506, R²=0.1280
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2473, R²: 0.0480

📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2472, R²: 0.0481

📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2472, R²: 0.0483

📊 Round 51 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2472, R²: 0.0484

============================================================
🔄 Round 57 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 57 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0890
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0542
============================================================


============================================================
🔄 Round 58 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 58 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.0890
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0954
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2472, R²: 0.0487

📊 Round 58 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2472, R²: 0.0487

============================================================
🔄 Round 62 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 62 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.0929
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0831
============================================================


============================================================
🔄 Round 63 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 63 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.0941
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0743
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0480

📊 Round 63 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0479

============================================================
🔄 Round 66 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 66 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.1063
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0109
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0477

📊 Round 66 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0479

============================================================
🔄 Round 68 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 68 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2701, R²=0.0761
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.1319
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2473, R²: 0.0480

============================================================
🔄 Round 69 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 69 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.0867
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.1031
============================================================


============================================================
🔄 Round 70 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 70 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.0872
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0968
============================================================


============================================================
🔄 Round 71 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 71 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0928
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0721
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2472, R²: 0.0487

============================================================
🔄 Round 74 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0621 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0621, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0621, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0620, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0620, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0620, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0621)

============================================================
📊 Round 74 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0928
   Val:   Loss=0.0621, RMSE=0.2492, R²=0.0803
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2472, R²: 0.0488

📊 Round 74 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2472, R²: 0.0487

============================================================
🔄 Round 76 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 76 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0905
   Val:   Loss=0.0688, RMSE=0.2622, R²=0.0811
============================================================


============================================================
🔄 Round 81 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 81 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1001
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0541
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2473, R²: 0.0480

📊 Round 81 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: 0.0476

============================================================
🔄 Round 88 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 88 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0891
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0939
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2472, R²: 0.0486

============================================================
🔄 Round 90 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0699, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0699, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0699, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0699, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0698, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0698, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 90 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0698, RMSE=0.2642, R²=0.0954
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0732
============================================================


============================================================
🔄 Round 91 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 91 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.0886
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0881
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: 0.0492

============================================================
🔄 Round 94 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0645 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0645, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0645, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0645, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0645, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0645, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0645)

============================================================
📊 Round 94 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0991
   Val:   Loss=0.0645, RMSE=0.2540, R²=0.0437
============================================================


============================================================
🔄 Round 95 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0716, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0714, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 95 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2673, R²=0.0972
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0693
============================================================


============================================================
🔄 Round 98 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 98 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0841
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.1126
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: 0.0490

📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: 0.0489

📊 Round 98 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: 0.0488

============================================================
🔄 Round 103 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0713, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0713, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 103 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2668, R²=0.0898
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0829
============================================================


============================================================
🔄 Round 104 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 104 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0740
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.1591
============================================================


============================================================
🔄 Round 106 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0637 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0637, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0637, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0637, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0636, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0636, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0637)

============================================================
📊 Round 106 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0982
   Val:   Loss=0.0637, RMSE=0.2524, R²=0.0461
============================================================


============================================================
🔄 Round 108 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 108 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.0915
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0878
============================================================


============================================================
🔄 Round 109 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 109 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2677, R²=0.0920
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0867
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: 0.0493

📊 Round 109 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: 0.0494

============================================================
🔄 Round 112 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 112 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.0990
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0541
============================================================


============================================================
🔄 Round 113 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 113 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0848
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.1173
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2472, R²: 0.0492

============================================================
🔄 Round 114 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 114 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.0918
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0865
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: 0.0491

============================================================
🔄 Round 115 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 115 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.0948
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0714
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: 0.0490

📊 Round 115 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2472, R²: 0.0489

============================================================
🔄 Round 122 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 122 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0871
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0861
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2473, R²: 0.0486

============================================================
🔄 Round 123 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 123 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0719
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.1556
============================================================


============================================================
🔄 Round 124 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0643 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0643, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0643, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0643, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0643, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0642, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0643)

============================================================
📊 Round 124 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0894
   Val:   Loss=0.0643, RMSE=0.2535, R²=0.0881
============================================================


============================================================
🔄 Round 125 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 125 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0964
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0591
============================================================


============================================================
🔄 Round 127 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 127 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.0952
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0667
============================================================


============================================================
🔄 Round 130 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0631 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0630, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0630, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0630, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0630, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0630, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0631)

============================================================
📊 Round 130 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2760, R²=0.0955
   Val:   Loss=0.0631, RMSE=0.2511, R²=0.0498
============================================================


============================================================
🔄 Round 131 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 131 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.0950
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0617
============================================================


============================================================
🔄 Round 134 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 134 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.0858
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0876
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2474, R²: 0.0481

============================================================
🔄 Round 135 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 135 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0788
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.1307
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: 0.0480

📊 Round 135 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: 0.0479

📊 Round 135 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: 0.0477

============================================================
🔄 Round 139 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 139 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.0775
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.1255
============================================================


============================================================
🔄 Round 140 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 140 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0900
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0791
============================================================


============================================================
🔄 Round 141 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 141 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0958
   Val:   Loss=0.0679, RMSE=0.2607, R²=0.0546
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2475, R²: 0.0473

============================================================
🔄 Round 144 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 144 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.0843
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.1030
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2475, R²: 0.0474

============================================================
🔄 Round 146 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 146 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.0876
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0872
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2475, R²: 0.0475

============================================================
🔄 Round 147 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0713, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0713, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 147 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0713, RMSE=0.2671, R²=0.0898
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0816
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2475, R²: 0.0475

============================================================
🔄 Round 148 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0639 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0639, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0639, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0639, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0639, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0638, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0639)

============================================================
📊 Round 148 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0877
   Val:   Loss=0.0639, RMSE=0.2528, R²=0.0919
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2475, R²: 0.0473

============================================================
🔄 Round 149 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0650, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 149 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0766
   Val:   Loss=0.0650, RMSE=0.2550, R²=0.1397
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2475, R²: 0.0470

============================================================
🔄 Round 151 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 151 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0905
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0778
============================================================


============================================================
🔄 Round 153 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 153 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0890
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0845
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2475, R²: 0.0470

============================================================
🔄 Round 154 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 154 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.0885
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0833
============================================================


============================================================
🔄 Round 157 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0657 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0657, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0657, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0657, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0657, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0656, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0657)

============================================================
📊 Round 157 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0827
   Val:   Loss=0.0657, RMSE=0.2564, R²=0.1116
============================================================


============================================================
🔄 Round 158 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 158 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.0859
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0816
============================================================


============================================================
🔄 Round 162 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 162 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.0823
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.1067
============================================================


============================================================
🔄 Round 164 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 164 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2678, R²=0.0868
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0888
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2477, R²: 0.0461

============================================================
🔄 Round 165 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 165 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0798
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.1105
============================================================


============================================================
🔄 Round 166 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 166 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0864
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0876
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2477, R²: 0.0461

📊 Round 166 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2477, R²: 0.0462

📊 Round 166 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2477, R²: 0.0463

📊 Round 166 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2476, R²: 0.0465

============================================================
🔄 Round 173 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 173 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.0981
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0472
============================================================


============================================================
🔄 Round 174 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 174 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0824
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.1104
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2476, R²: 0.0469

============================================================
🔄 Round 177 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 177 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2686, R²=0.0840
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0983
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: 0.0470

============================================================
🔄 Round 178 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 178 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0847
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.1008
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2476, R²: 0.0471

============================================================
🔄 Round 179 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 179 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0719
   Val:   Loss=0.0689, RMSE=0.2626, R²=0.1451
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2475, R²: 0.0475

============================================================
🔄 Round 188 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0639 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0639, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0639, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0638, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0638, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0638, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0639)

============================================================
📊 Round 188 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0839
   Val:   Loss=0.0639, RMSE=0.2528, R²=0.0939
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2475, R²: 0.0475

============================================================
🔄 Round 189 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 189 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0802
   Val:   Loss=0.0673, RMSE=0.2595, R²=0.1218
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2475, R²: 0.0476

📊 Round 189 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2475, R²: 0.0478

============================================================
🔄 Round 192 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 192 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.0985
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0515
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: 0.0479

📊 Round 192 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2474, R²: 0.0481

📊 Round 192 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2474, R²: 0.0481

============================================================
🔄 Round 197 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 197 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0758
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.1399
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2474, R²: 0.0482

============================================================
🔄 Round 198 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 198 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.0962
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0558
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2474, R²: 0.0482

============================================================
🔄 Round 203 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 203 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.0921
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0728
============================================================


============================================================
🔄 Round 204 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 204 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.1004
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0381
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2475, R²: 0.0479

📊 Round 204 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2474, R²: 0.0479

============================================================
🔄 Round 208 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0714, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 208 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2677, R²=0.0891
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0873
============================================================


============================================================
🔄 Round 209 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 209 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.0867
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0899
============================================================


❌ Client client_64 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8689 {grpc_status:14, grpc_message:"Socket closed"}"
>
